Distributed Database Management Systems and the Data Grid

Heinz Stockinger
CERN, European Organization for Nuclear Research, Geneva, Switzerland
Institute for Computer Science and Business Informatics, University of Vienna, Austria
Heinz.Stockinger@cern.ch
tel +41 22 767 16 08

Abstract
Currently ,   Grid   research   as   well   as   distributed
database  research  deals  with  data  replication  but
both  tackle  the  problem  from  different  points  of
view.  The  aim  of  this  paper  is  to  outline  both
approaches  and  try  to  find  commonalities  between
the  two  worlds  in  order  to  have  a  most  efficient
Data   Grid   that   manages   data   stored   in   object-
o r ien ted   da tabases .   Ou r   ta rge t   ob jec t -o r ien ted
database  management  system  is  Objectivity/DB
which  is  currently  the  database  of  choice  in  some
existing High Energy Physics  (HEP) experiments as
well  as  in  next  generation  experiments  at  CERN.
The  characteristics  of  Data  Grids  are  described,
e sp e c i a l ly   w i th in   th e   H igh   En e rgy   Phy s i c s
community,  and  needs  for  Data  Grids  are  defined.
The  Globus  toolkit  is  the  Grid  middle-ware  on
which we base our discussions on Grid research.

1 Introduction
Gr id   compu t ing   in   genera l   comes   from   h igh-
performance  computing,  super  computing  and  later
cluster computing where  several processors or work
stations are connected via a high-speed  interconnect
in  order  to  compute  a  mutual  program.  Originally,
the  cluster  was  meant  to  span  a  local  area  network
but  then  it  was  also  extended  to  the  wide  area.  A
Gr id   i tse lf   is   supposed   to   connec t   compu t ing
resources over the wide area network.
The Grid  research  field  can  further  be  divided
into  two  large  sub-domains:  Computational  Grid
and  Data  Grid. Whereas  a  Computational  Grid  is  a
natural  extension  of  the  former  cluster  computer
where  large  computing  tasks  have  to  be  computed
at  distributed  computing  resources,  a  Data  Grid
deals with  the efficient management, placement and
replication of  large amounts of data. However, once
data are  in place, computational  tasks can be  run on
the Grid using  the provided data. The need  for Data
G r i d s   s t em s   f r om  
t h a t   s c i e n t i f i c
t h e   f a c t  
applications   like   data   analysis   in   High   Energy
Phy s i c s   (HEP ) ,   c l im a t e   mod e l l ing   o r   e a r th

observation  are  very  data  intensive  and  a  large
community   of   researchers   all   around   the   globe
wants to have fast access to the data.
In  the  remainder  of  this  paper  we  concentrate
on  the specific needs of High Energy Physics which
can  be  regarded  as  a  representative  example  for
o ther   da ta   in tens ive   research   commun i t ies .   In
particular,  we  focus  on  the  data  intensive  Large
Hadron  Collider  (LHC)  experiments  of  CERN,  the
European  Organization  for  Nuclear  Research  in
Geneva ,   Sw i tze r land .   A t   CERN ,   recen t ly   the
DataGrid  project  [1]  has  been  initiated  in  order  to
set  up  a  Data  Grid.  One  of  the  working  groups
explicitly  deals  with  data  management  in  a  Data
Grid  [2],  i.e.  in  the  DataGrid  project.  The  tasks  to
be   so lved   inc lude   da ta   access ,   m igra t ion   and
rep l ica t ion   a s   we l l   a s   que ry   e s t ima t ion   and
optimisation  in  a  secure  environment.  In  this  paper
we  deal with  the  replication  aspects  that  need  to  be
solved  in  the  DataGrid  project.  The  Globus  toolkit
[3]  is  the  middle-ware  which  we  will  use  for  the
Grid infrastructure.
Sc ien t if ic ,   da ta   in tens ive   app l ica t ions   use
large collections of  files  for storing data. As  regards
the   HEP   commun i ty ,   da ta   genera ted   by   large
detectors  have  to  be  stored  persistently  in  mass
storage  systems  like  disks  and  tapes  in  order  to  be
ava i lab le   fo r   phys ics   ana lys is .   In   some   HEP
experiments,  databases  are  used  to  store  Terabytes
and  even  Petabytes  of  persistent  data.  The  usage  of
databases  is  still  a  unique  feature  for  a  Data  Grid.
Le t   us   compare   th is   to   the   c l ima te   mode l l ing
c omm u n i t y :  
l a r g e
t h a t   r e s e a r c h   d om a i n  
i n  
collections  of  files  are  available  and  stored  in  so
called  “flat  files”  without  databases.  This  requires
additional  data  management  tasks  like  keeping  a
ca ta logue   o f   ava i lab le   f i les   whe reas   in   some
physics  experiments  in  the  HEP  community  the
database management system  (DBMS)  takes care of
this.

Currently,  some  new  experiments  in  HEP  use
ob jec t-or ien ted   da tabases   managemen t   sys tems
(ODBMS)  for  data  management.  This  is  true  for

1

BaBar  (an  experiment  at  the  Stanford  University
where  currently  about  150  TB  of  data  are  available
in  Objectivity/DB  [4]),  as  well  as  for  the  CERN
expe r imen ts ,   CMS   and   A t las .   Fo r   the   CERN
experiments  the  final  decision  about  the  DBMS
(object-oriented  or  relational,  which  vendor,  etc.)
has  not  been  made  yet,  but  the  current  software
deve lopmen t   processes   uses   an   ob jec t-or ien ted
a p p r o a c h   a n d   O b j e c t i v i t y   f o r   s t o r i n g   d a t a
persistently.  Consequently,  we  base  our  work  on
object-oriented  database  management  systems  and
in particular Objectivity/DB.
Recently,  Grid  research  as  well  as  distributed
da tabase   research   tack les   the   prob lem   of   da ta
replication  but  from  a  different  point  of  view.  The
aim  of  this  paper  is  to  outline  their  approaches  and
to  find  commonalities  in  order  to  have  a  most
efficient  Data  Grid  that  can  manage  Petabytes  of
data  stored  in  object-oriented  databases.  We  will
provide  a  first  basis  for  such  an  effort.  Since  Data
Grids  are  very  new  in  the  research  community,  we
see  a  clear  need  for  identifying  the  characteristics
and  requirements  of  Data  Grids  and  how  they  can
be  met  in  a  most  efficient  way.  Special  attention
w i l l   b e   g i v e n  
t o   d a t a   c o n s i s t e n c y   a n d
communication issues.
Optimising  data  replication  and  access  to  data
over   the  WAN  is  not  addressed  sufficiently  in
database  research.  In  a  DBMS  there  is  normally
only  one  method  of  accessing  data.  For  instance,  a
data  server  serves  pages  to  a  client.  For  the  Data
Grid,  such  a  single  access  method  may  not  be
op t im a l .   U s ing   an   ODMBS   a l so   h a s   som e
restrictions,  which  are  pointed  out  here  and  some
possible solutions are given.
We  elaborate  on  different  data  consistency
models  and  how  global  transactions  can  contribute
to  this.  Global  transactions  are  built  on  top  of
transactions  provided  by  a  database  management
system  at  a  local  site.  As  opposed  to  database
research,  a  separation  of  data  communication  is
required.  In  particular,  global  control  messages  are
exchanged  by  a  message  passing  library  whereas
the  actual  data  files  are  transported  via  high-speed
file  transfer  protocols.  A  single  communication
protocol  is  usually  used  in  a  commercial  ODBMS
for   exchang ing   sma l l   amoun ts   of   da ta   w i th in
d a t a b a s e  
t r a n s a c t i o n s .   T h i s   c omm u n i c a t i o n
mechan i sm   i s   op t im i sed   fo r   re la t ive ly   sma l l
t r an s a c t ion s   bu t   m ay   no t   b e   op t im i s ed   fo r
transferring  large  files  over  the  WAN  with  high
p e r f o rm a n c e   c o n t r o l  
i n f o rm a t i o n   e x c h a n g e d
between distributed sites. We will propose solutions
for  efficient,  asynchronous  replication  and  policies
with  different  levels  of  data  consistency  in  a  Data
Grid.

The  paper  is  organised  as  follows.  Section  2
will  give  an  introduction  to  related  work  in  the
database  as well  as  the Grid  community. The  issues
raised  there will be further analysed  in  later sections
of  the paper. Section 3 deals with  replica catalogues
and directory services  that are used  in Grid  research
and points out how  these  techniques can be mapped
to   the   da tabase   approach .   Sec t ion   4   d iscusses
Objectivity,  its  replication  option  and  some  general
ODBMS aspects. Since we assume  that  the usage of
Grid applications will not be  fully  transparent  to  the
end   use r ,   we   ded ica te   Sec t ion   5   to   poss ib le
implications.  Section  6  discusses  data  consistency
and  replication methods known  in database  research
and   p rac t ise .   Poss ib le   upda te   synch ron isa t ion
solutions  are  given  in  Section  7,  which  is  followed
by concluding remarks.

2 Related work on data replication
We  first  identify  some  selected  related  work  in  the
d a t a b a s e   c omm u n i t y   a s   w e l l  
i n  
t h e   G r i d
community.  From  this  we  derive  commonalities
and  discuss  briefly  what  the  contribution  for  an
efficient  Data  Grid  can  be.  The  common  aspects
will be dealt with throughout this paper.

2.1 Distributed DBMS research
Distributed  database  research  basically  addresses
the following issues.
•   Replica  synchronisation  is  based  on  relatively
small  transactions  where  a  transaction  consists
of   several   read   and/or   write   operations .   In
contrast,  in  HEP  a  typical  data  production  job
can  write  a  whole  file  and  thus  a  transaction
should be relatively “large”.
•   Synchronous   and   asynchronous   rep l ica t ion
(more  details  can  be  found  in  Section  6): Most
of  the  evaluation  techniques  are  based  on  the
amount of communication messages needed.
•   Cost  functions  for  network  or  server  loads  are
rare ly   in tegra ted   in to   the   rep l ica   se lec t ion
process of a DBMS.
•   Rather  low  amount  of  data  as  compared  to  the
Petabyte scale of HEP.
Data  access  over  the  WAN  and  optimisation  of
replicas  is  rarely  addressed  in  database  research.  In
a DBMS  there  is normally only one  internal method
of  accessing  data.  For  instance,  a  data  server  serves
pages  to  a  client.  In  detail,  a  client  sends  a  request
for data  to  the DBMS,  and  the DBMS  (in particular
the  data  server)  uses  the  implemented  method  for
serving   the   requested   data .   For   read   and   write
access  the  same method  is  used,  independent  of  the
amount  of  data  accessed.    For  the  Data  Grid,  a
single  access  method  is  not  optimal  depending  on

2

the  number  of  objects  to  be  accessed  from  a  file.
For  accessing  large  amounts  of  data  of  a  remote
file,   the  usage  of  a   file   transfer  mechanism  to
transfer  the entire file and access  the file  locally can
be  more  efficient  in  terms  of  response  time  than
remo te ly   access ing   (and   thus   s tream ing)   many
single objects of a file. More details will be given in
Section  5.  Based  on  cost  functions  it  can  be  even
more  efficient  to  send  the  application  program  to
the remote data [5].

2.2 Grid research
The   G lobu s   p ro jec t   p rov ide s   too l s   fo r   G r id
computing  like  job  scheduling,  resource  discovery,
security,  etc. Recently, Globus  is  also working  on  a
Data  Grid  effort  that  enables  fast  and  efficient  file
transfer,  a  replica  catalogue  for  managing  files  and
some more  replica management  functionality  based
on   files .   Replica   update   synchronisation   is   not
addressed.  In  the Grid  community  there  is  a general
tendency  to  deal  with  replication  at  the  file  level,
i .e .   a   s ing le   f i le   is   the   lowes t   granu lar i ty   of
replication. This has  the advantage  that  the structure
of   the   file   does   not   need   to   be   known   by   the
r ep l i c a t ion   m an ag e r   th a t   i s   r e spon s ib l e   fo r
replicating  files  from  one  site  to  another  sites  over
the  WAN.  This  is  also  a  valid  simplification  for
most  of  the  HEP  replication  use  cases  and,  thus,  is
also  the  main  focus  of  this  paper.  Related  work  in
the  HEP  community  can  be  found  in  the  two  Data
Grid  projects  PPDG  [6]  and  GriPhyN  [7].  There  is
still  the  possibility  to  deal  with  replication  at  the
object   level   which   requires   more   sophisticated
techn iques   than   f i le   leve l   rep l ica t ion .   Ob jec t
handling  is  addressed  in  [8].  However,  as  soon  as
data  items  in  a  replicated  file  are  changed,  these
changes  have  to  be  propagated  to  all  other  replicas.
Th i s   requ i re s   the   know ledge   abou t   the   da ta
structure   of   the   file .   Possible   solutions   to   this
problem are given in Section 6.

2.3  Commonalities  –  the  usage  of  a  replication
middle-ware
Resea rch   resu l ts   can   be   comb ined   f rom   bo th
communities  by  introducing  a  replication  middle-
ware  layer  that  manages  replication  of  files  (and
possibly  some  objects)  by  taking  into  account  that
each  site  in  a  Data  Grid  will  manage  data  locally
with  a  database  management  system.  Thus,  the
middle-ware  is  responsible  for  site  to  site  (or  inter-
site)  replication  and  synchronisation  whereas  the
local  DBMS  takes  care  of  transactions  on  local
data.

In  Grids  there  are  many  tools  for  monitoring
applications  and  network  parameters.  These  can  be
used  for  filling  the  gap.  Hence,  a  hybrid  solution

be tween   da taba se   and   G r id   re sea rch   can   be
identified.
One of the main questions to be answered is to
what  level  the  replication  middle-ware  will  be  able
to  replace a pure distributed DBMS approach where
also  inter-site  replication  issues  are  dealt  with.
Clearly,  with  a  replication  middle-ware  there  are
many  more  restrictions  for  update  synchronisation
and  transparent  access  to  data.  There  will  also  be  a
performance  penalty  for  replica  synchronisation.
However,  an  aim  of  the  replication  middle-ware  is
to  provide  several  relaxations  of  the  concept  of
transparent  data  access  and  data  consistency.  For
the  remainder of  the paper we  assume  to use  such  a
replication middle-ware for a Data Grid.

3   Rep l ica   ca ta logues   and   d irec tory
services
Access  to data  is most  important for data analysis  in
the   HEP   a s   we l l   a s   in   any   o the r   sc ien t i f ic
commun i ty .   Access   to   rep l ica ted   da ta   requ ires
specific  data  and  meta  data  structures  and  can  be
addressed   in   d ifferen t   ways .   A   DBMS   has   an
in t e rn a l   a c c e s s   m e thod   wh e r e a s   in   a   G r id
environment   these   data   structures   are   provided
explicitly   as   a   service   to   the   end   user .   In   this
sec t ion ,   emphas is   is   pu t   on   how   to   comb ine
techn iques   f rom   a   Da ta   G r id   and   a   da tabase
environment.
The  management  of  replicas  requires  certain
meta data structures  that store  information about  the
distribution   of   and   access   to   data .   Whereas   an
object  location  table  [9]  can  be  the  data  structure
for   manag ing   ob jec ts ,   for   f i les   we   can   use   a
directory service holding a replica catalogue.
There  are  many  ways  to  deal  with  replica
ca ta logues   and   many   d i f fe ren t   p ro toco ls   and
implementations  are  available.  We  want  to  limit
ourselves  here  to  the  approach  used  by  Globus.
Since  in  the  Globus  Data  Grid  effort  the  replica
catalogue  is  implemented  by  an  LDAP  directory
service, we dedicate  this section on analysing how a
directory  service  can  be  used  for  file  replication
where files are managed by a local DMBS.
In  principle,  a  DBMS  provides,  by  definition,
a   ca ta logue   of   f i les   tha t   are   ava i lab le .   As   for
Objectivity/DB  this  is  an  explicit  file  catalogue. An
LDAP  directory  service  basically  does  the  same  for
f la t   f i les   wh ich   may   or   no t   have   connec t ions
(associations  between  objects  in  two  or  more  files)
to  each  other.  Now  the  questions  arise  what  is  the
use  of  LDAP  when  data  are  stored  in  a  DBMS?  In
order  to  answer  this  question,  we  identify  the  key
p r o b l em s  
t h a t   n e e d  
t o   b e   a d d r e s s e d   i n   a

3

heterogeneous  Data  Grid  environment  with  many
sources  of  data:  managing  replicas  of  files  and
dealing with heterogeneous data stores.
•   Managing  replicas:  As  for  Objectivity,  a  file
catalogue exists. The granularity  for  replication
is  now  assumed  to  be  on  the  file  level.  When
multiple  copies  of  a  file  exist,  they  have  to  be
introduced  to  a  global  replica  catalogue  which
is   an   ex tended   vers ion   of   the   na t ive   f i le
catalogue  of  the  DBMS.  Furthermore,  a  name
space has  to be provided  that  takes  into account
m u l t i p l e  
r e p l i c a s .   B o t h  
f e a t u r e s   a r e
enhancements  to  a  DBMS  that  only  considers
single  sources  of  information.  Note  that  we
assume  here  that  the  underlying  DBMS  does
not  support  file  replication.  Using  the  LDAP
protocol  and  a  database  backend,  the  required
replica  catalogue  information  can  be  stored.
Ano the r   app roach   is   to   s imp ly   bu i ld   the
catalogue  and  the  access  methods  with  the
native  schema  of  the   DBMS  and  store  the
replica  information  in  a  particular  file  of  the
DBMS.
•   Heterogeneous  data  stores:  The  diversity  of
the   HEP   commun i ty   requ ires   an   approach
which  supports  heterogeneous  data  stores  since
d if feren t   k inds   of   da ta   may   be   s tored   in
different  formats  and  also  in  data  stores  of
d i f fe ren t   vendo rs .   Even   the   two   d i f fe ren t
da tabase   parad igms ,   re la t iona l   and   ob jec t-
oriented,  should  be  supported.  In  this  case,  a
standard protocol  for directory  information  like
LDAP  seems  to  be  a  good  choice  since  replica
loca t ion   informa t ion   can   be   accessed   in   a
uniform  way  without  the  knowledge  of  the
underlying data store.
Combining a DBMS with a directory  service means
to  expose  the  replica  catalogue  to  a  larger  user
community,  where  it  is  not  necessary  to  have  a
database  specific  front  end  to  access  the  directory
information .   However ,   the   LDAP   protocol   still
needs  to  have  a  database  backend  where  the  file
information  is  stored  and  concurrency  mechanisms
have  to  be  established.  The  database  backend  can
either  be  a  vendor  specific  and  LDAP  specialised
database,  or  any  database  of  choice  like  Oracle  or
Objectivity/DB.  The  usage  of  a  directory  service
allows  an  open  environment  and  hence  allows  the
integration  of  data  sources  of  different  kinds.  Note
that  the  problem  of  accessing  heterogeneous  data
se t s   i s   no t   add re s sed   he re   and   may   requ i re
m e d i a t o r s  
f o r   d a t a  
i n t e g r a t i o n .   H ow e v e r ,
introducing  LDAP  is  at  least  a  starting  point  for
extensibility.
Ano the r   po in t   impo r tan t   po in t   in   rep l ica
management  is  synchronisation  of  single  sites  and

keeping  replica  catalogues  up  to  date.  Using  the
LDAP  directory  service  also  implies  that  each  site,
that  stores  replica  catalogue  information,  runs  an
LDAP server  locally. LDAP commands can be used
for  synchronisation.  For  a  homogeneous  database
approach,  where  only  a  single  DBMS  is  used  to
store  the  entire  data  of  the Data Grid,  it may  not  be
n e c e s s a r y  
t o   h a v e   a n   LDA P   s e r v e r  
f o r
synchronisation  -  any  communication  mechanism
f o r   e x c h a n g i n g   s y n c h r o n i s a t i o n  
i n f o rm a t i o n
be tween   s i tes   in   the   Da ta   G r id   is   su f f ic ien t .
However,  since  each  data  site  using  a  directory
service  will  have  its  own  LDAP  server,  this  server
can  also  be  used  as  a  synchronisation  point  for
distributed  sites. Whenever  a  file  is  introduced  to  a
site,  this  information has  to be made public within a
global name space spanning all  the other sites  in  the
Data  Grid.  The  replica  synchronisation  protocol  to
use  depends  on  the  data  consistency  requirements
imposed by the application.
We   conc lude   tha t   the   usage   of   LDAP   in
combination  with  a  DBMS  seems  to  be  useful  in  a
heterogeneous  environment  and  for  synchronisation
of sites holding replica catalogue information.

4 Objectivity/DB
Since  Objectivity  is  the  main  ODBMS  system  we
are  referring  to  in  this  paper,  we  dedicate  this
section  to  explaining  more  details  of  this  product
and  problems  that  we  were  confronted  with  when
using  Objectivity  for  wide  area  data  replication.
Some  of  the  problems mentioned  are  specific  to  all
ob jec t -o r ien ted   da ta   s to re s   wh i le   o the r s   a re
Objectivity   specific .   However ,   the   usage   of   an
ODBMS   allows   us   some   simplifications   like   a
global namespace and a global schema information.
Ob jec t iv i ty /DB   i s   a   d i s t r ibu ted ,   ob jec t -
or ien ted   DBMS   wh ich   has   a   Da ta   Rep l ica t ion
Option  called  DRO.  This  option  is  optimised  for
synchronous  replication  over  a  local  area  network.
In  this  section,  we  briefly  describe  DRO  and  its
drawbacks,  and  state  complications  that  one  comes
across when persistent objects have to be replicated.

4.1 Objectivity’s data replication option
DRO  provides  a  synchronous  replication  model  on
the  file  level,  i.e. entire Objectivity databases which
are mapped  to physical  files  can be  replicated. Note
that in the following section we use the term replica
to  refer  to  a  ph y s i ca l   in s tan c e  (a   copy)   of   an
Objectivity file. There are basically  two ways  to use
DRO :   d a t a   c an   b e   w r i t t en   f i r s t ,   and   th en
synchronised  and  replicated  (populate  -  replicate).
Multiple  replicas  can  be  created  and  synchronised
and  the  data  can  be  written  into  all  the  replicas  at

4

the   same   t ime   (rep l icate   -   popu late).  Once  a
replica  is  synchronised  with  another  one,  all  the
da tabase   t ransac t ions   on   a   s ing le   rep l ica   a re
synchronised with other replicas.
Objectivity/DRO  performs  a  dynamic  quorum
calculation  when  an  application  accesses  a  replica.
The  quorum  which  is  required  to  read  or  write
replicas   can   be   changed ,   which   provides   some
flexibility  concerning  data  consistency.  The  usage
of  a  quorum method  is well  established  in  database
research and goes back to an early paper [10].
There   is   one   poss ib i l i ty   to   overcome   the
immediate  synchronisation.  A  replica  can  be  set  to
be  off-line.  However,  only  if  a  quorum  still  exists,
data  can  be  written  to  the  off-line  replica.  There  is
no   c l e an   w ay   in   DRO   to   p e r fo rm   a   r e a l
asynch ronous   o r   ba tch   rep l ica t ion   whe re   you
spec i fy   a   synch ron i sa t ion   po in t   in   t ime .   An
asynchronous  or  batch  replication  method  allows
replicas  to  be  out  of  sync  for  a  certain  amount  of
time.  Reconciliation  of  updates  is  only  done  at
certain  synchronisation  points,  e.g.  every  hour.  The
lack  of  such  an  explicit  asynchronous  replication
method  is  one  of  the  reasons  why  DRO  is  not
considered as a good option for WAN replication.
Like  many  commercial  databases,  Objectivity
does  not  provide  any  optimisation  for  accessing
replicas.  The  replica  catalogue  only  contains  the
number  of  copies  and  the  location  of  each  single
copy  of  a  file.  Once  an  object  of  a  replicated  file
has  to  be  accessed,  Objectivity  tries  to  get  the  first
copy  of  the  file  which  appears  in  the  catalogue.  It
does  not  examine  the  bandwidth  to  the  site  nor
takes   into   account   any   data   server   load .   Some
operations  such  as  database  creation  require  all
rep l icas   to   be   ava i lab le .   When   we   ta lk   abou t
Objectivity  in  any  other  section  or  subsection  of
this  paper  we  mostly  ignore  the  fact  that  DRO
exists  and  thus  see Objectivity  only  as  a  distributed
DMBS with  single  copies  of  a  file. However,  these
single copies of a file can exist at distributed sites in
the Data Grid  and  thus  remote  access  to Objectivity
data is possible.

4.2 Partial replication and associations
I n  
i n   m a n y   G r i d
t h i s   p a p e r ,   a s   w e l l   a s  
environments,  replication  is  regarded  to  be  done  on
the  file  rather  than  on  the  object  level  and  hence  a
file  is  regarded  to  be  the  smallest  granularity  of
replication.  In  Objectivity,  single  objects  are  stored
in  containers. Several  containers  are  stored  together
in  an  Objectivity  database  which  corresponds  to  a
file.  Each  object  can  have  associations  (also  called
links  or  pointers)  to  other  objects which may  reside
in  any  database  or  container.  Let  us  now  assume
that  two  objects  in  two  different  files  are  connected

via  one  association.  When  an  Objectivity  database
(a  file)  is  replicated,  this  association  gets  lost when
only  one  of  the  files  is  replicated. Note  that  there  is
still  the  possibility  of  remotely  accessing  objects.
Hence,  the  replication  decision  has  to  be  carefully
made  and  possible  associations  between  objects
have   to   be   con s ide red .   Th i s   may   re su l t   in
replicating  a  set  of  files  in  order  to  keep  all  the
associations  between  files.  Furthermore,  this  also
imposes  severe  restrictions  on  partial  replication
whe re   on ly   pa r t icu la r   ob jec t s   o f   a   f i le   a re
replicated.  Again,  when  a  certain  set  of  objects  is
selected which does not have associations  to objects
which  are  not  in  the  set,  the  replication  set  is
association  safe.  This  is  a  particular  restriction  of
object-oriented  data  stores  and  does  not  only  hold
for Objectivity.
Th i s   i s   a l so   an   impo r t   d i f f e r en c e   and
comp l ica t ion   compared   to   a   re la t iona l   DBMS .
Whereas  in  an  ODBMS  an  object  can  be  stored  in
any  file,  in  a  relational  database  data  items  are
stored  in  tables  that  have well  defined  references  to
other tables.

4.3 The Objectivity file catalogue
The  integration  of  files  into  the  native  Objectivity
file catalogue  is done with a  tool called ooattachdb
which  adds  a  logical  file  name  of  the  physical
loca t ion   in to   the   ca ta logue .   Fu r the rmo re ,   i t
gua ran tee s   tha t   l ink s   to   ex i s t ing   Ob jec t iv i ty
databases  are  correct.  The  schema  of  the  file  is  not
checked.  This  feature  is  used when  a  file  created  at
one  site  has  to  be  integrated  into  the  file  catalogue
of another site.
Since  the  native  catalogue  only  has  a  one-to-
one  mapping  from  one  logical  to  one  physical  file,
replicas  are  not  visible  to  the  local  site  (not  taking
into  account  DRO).  Furthermore,  it  is  possible  to
have  single  links  from  one  site  to  another  one.  For
instance,  site 1 has  a  file  called X  and  this  file  shall
be  shared  (not  replicated)  between  several  sites.
The  file  name  and  the  location  can  be  integrated
into  the  local  file  catalogue  and  a  remote  access  to
the file can be established. Note that this requires an
Ob j e c t iv i ty   Adv an c ed   Mu l t i - th r e ad ed   S e rv e r
(AMS)  running  or  the  usage  of  a  shared  file  system
like  AFS  that  connects  both  sites.  The  AMS  is
responsible   for   transferring   (streaming)   objects
f rom   one   mach ine   to   ano the r   one   and   thu s
establishes  a  remote  data  access  functionality.  We
want  to  address  the more  general  solution where  no
shared file system is available.
In  the  HEP  community  it  is  generally  agreed
and proven  that DRO  is not optimised  for  the use  in
a WAN. Hence,  all  our  discussions  here  neglect  the
DRO  of  Objectivity/DB  and  we  conclude  that  the

5

current  implementation  of  DRO  is  not  a  feasible
solution for the HEP community.

5 Implications for Grid applications
We  claim  that  the  usage  of  files  that  are  replicated
in  a  Data  Grid  will  have  implications  for  Grid
app l ica t ion s   tha t   a re   new   to   the   HEP   u se r
community.  We  want  to  address  explicitly  some
possibilities of how  a  replicated  file  instance  can be
accessed  and  give  some  implications  of  read  ahead
assumptions.

5.1 Accessing replicated files
A  standard  way  to  access  a  database  in  Objectivity
is  to  issue  an  “open”  command  on  the  physical  file.
Th is   concep t   is   un ique   for   the   ob jec t-or ien ted
database  concept  and  very  much  resembles  the
UNIX  way  of  accessing  files.  However,  if  a  single
object  is  accessed,  the  file  which  it  belongs  to  is
transparent  to  the  user.  Once  an  object  handle  or
reference  is  available,  the  object  ID  to  this  object
contains  information  about  the  file  to  which  it
belongs.  Since  the  native Objectivity  “open” works
on  the  Objectivity  catalogue  rather  than  on  the
global  replica  catalogue,  the  user  does  not  have
access  to  the  whole  name  space  in  the  Data  Grid.
The  “open”  has  to  be  adapted  to  do  the  lookup  and
the  data  access  via  the  directory  service.  Plug-ins
are  required  to  transfer  the  requested  data  to  the
user  application.  This  is  still  an  open  issue  and
needs further research concerning:
• 
caching files locally
•  
adding  the  file  to  the  local  catalogue  and
creating  a  replica:  this  may  only  be  useful
when data are accessed frequently
transferring  the  whole  file  versus  only  sub
sets of a file
Objectivity  provides    functionality  for  transparently
accessing  data  stored  on  tapes.  This  is  done  by
using an extension of  the AMS backend  that checks
if  a  file  is  locally  stored  on  disk  and  fetches  the  file
f rom   tape   i f   i t   i s   no t   found   on   d i sk .   Th i s
functionality  can  be  extended  to  go  to  a  global
replica  catalogue  and  fetch  files  from  remote  sites.
This  would  provide  a  transparent  way  of  accessing
replicas  of  files.  We  will  further  investigate  this
option.

•  

5.2 Read ahead
Reading  data   ahead  (pre-fetching)  before  using
them  is  a  commonly  used  optimisation  technique.
However,  this  imposes  another  problem,  which  we
want  to  illustrate  by  an  example.  Let  us  assume  a
file size of 2 GB and a program  that wants  to access
5  objects  in  the  file where  each  object  has  a  size  of

10  kB.  It  is  obvious  that  we  want  to  transfer  the
requested  objects  rather  than  the  whole  file,  and
having  unnecessary  information  transferred  over
the  network.  There  is  a  clear  need  for  a  mapping
instance  that  maps  requested  objects  to  files  in
order  to  determine  in  which  files  the  requested
objects  reside. Based on  the  type  (class definition  in
the  data  definition  language  of  the ODBMS)  of  the
objects  it  can  be  roughly  determined  how  much
da ta   needs   to   be   transferred   over   the   ne twork
(depending  on  how  much  dynamically  allocated
information  is  stored  in  the  object).  This  problem
cannot be solved when only  the “open” file operator
is   used .   On ly   a t   run t ime   the   app l ica t ion   can
determine which  data  are  needed  and  a  pre-fetching
of  requested  objects  can  tackle  this  problem.  We
can summarise  this as a query optimisation problem
where  access  to  the  data  shall  be  optimised  by
prov id ing   on ly   the   necessary   ob jec ts   tha t   are
required. Related work can be found [11,12].
Pre-fetching  can  also  be  addressed  at  the  file
level. We  assume  that  a  user  is  aware  that  files  are
distributed  to different sites  in  the Grid and  the  time
to access data very much depends on  the  location of
the  requested  file. We  further  assume  that  an  object
in a file can only be accessed when  the whole file  is
available  locally  at  the  client  site.  This  is  assumed
for  simplicity  and  we  neglect  the  fact  of  accessing
some  parts  of  a  file  remotely.  In  the  worst  case,  all
the  requested  files  are  available  remotely  and  need
to be  transferred  to  the  local site.  If  the size of a  file
is  large  and  also  the  amount  of  requested  files  is
high,  the  I/O  part  of  an  application  takes  a  long
time  before  the  actual  computation  on  the  data  can
be  done.  The  application  can  give  a  hint  to  the
system  to  tell  it how  long  it would need  to serve  the
required  files  and  when  the  computation  can  be
started.  Thus,  data  can  be  pre-fetched  before  the
app l i c a t ion   i s   u s ing   th e   d a t a .   In   th e   G r id
environment,  the  necessary  information  for  pre-
f e t ch ing   f i l e s   c an   b e   p rov id ed   by   d iv e r s e
monitoring tools and information services.
This   is   also   a   sociological   aspect   of   Grid
applications  in  the  sense  that  a  user  of  a  data-
intensive  application  requests  its  data  in  advance.
One  can  also  reserve  the  network  bandwidth  and
start the application at a certain point in the future.

6   Da ta   cons is tency   and   rep l ica t ion
methods
One  of  the  main  issues  in  data  replication  is  the
consistency  of  replicas.  Since  a  replica  is  not  just  a

6

simple  copy  of  an  original  but  still  has  a  logical
connection  to  the  original  copy, we  have  to  address
the  data  consistency  problem.  The  easiest  way  to
tackle  the  consistency  problem  is  in  the  field  of
read-only  data.  Since  no  updates  of  any  of  the
replicas  are  done,  the  data  is  always  consistent. We
can  state  that  the  consistency  can  reach  its  highest
degree.  Once  updates  are  possible  on  replicas,  the
degree   of   data   consistency   normally   has   to   be
decreased  (provided  we  have  read  and  write  access
to data)  in order  to have a reasonable good response
time  for  accessing  data  replicated  over  the  WAN.
Clearly,  consistency  also  depends  on  the  frequency
of updates  and  the  amount of data  items  covered by
the  update.  Thus,  we  can  state  that  the  degree  of
data  consistency  depends  on  the  update  frequency,
amount of data  items  covered by  the update  and  the
expected  response  time of  the  replicated system,  i.e.
the Data Grid.
Le t   us   now   iden t i fy   in   mo re   de ta i l   the
different  consistency  options  which  are  possible
and  which  are  reasonable  for  HEP  and  within  the
DataGrid project.
In  this  section  we  also  introduce  the  term
global  transaction  which  has  to  be  distinguished
from a local  transaction. A  local  transaction  is done
by  the  DBMS  at  the  local  site  whereas  a  global
transaction  is  an  inter-site  transaction  which  spans
t h u s   m u l t i p l e   d a t a b a s e
m u l t i p l e   s i t e s   a n d  
m a n a g em e n t  
s y s t em s .   F u r t h e rm o r e ,  
local
consistency  is  maintained  by  the  DBMS  whereas
the  global  consistency  spans  multiple  sites  in  the
Data Grid.

6.1 Synchronous replication
Th e   h igh e s t   d eg r e e   o f   con s i s t en cy   c an   b e
established  by  having  fully  synchronous  replicas.
This  means  that  each  local  database  transaction
needs  to  get  acknowledgements  from  other  replicas
(or  at  least  a  majority  of  replicas).  In  practice,  as
well  as  in  the  database  research  community,  this  is
gained  by  global  transactions  which  span  multiple
sites.  Objectivity/DRO  supports  such  a  replication
model.  Each  time  a  single  local  write  transaction
takes   p lace ,   the   2-phase-comm i t   pro toco l   and
normally also  the 2-phase-locking protocol are used
to  guarantee  serialisability  and  global  consistency.
Th i s   come s   a t   the   co s t   o f   re la t ive ly   wo r se
performance  for  global  writes  compared  to  local
writes  with  no  replication  at  all.  Consequently,  one
has  to  decide  carefully  if  the  application  requires
such a high degree of consistency.
We  derive  from  this  statement  as well  as  from
the   current   database   literature   that   the   type   of
replication  protocol  and  hence  the  data  consistency
model  has  to  be  well  adapted  to  the  application.

Data  in  the  DataGrid  project  will  have  different
types   and   no t   a l l   o f   them   requ i re   the   same
consistency  level.  In  this  paper,  we  try  to  point  out
br ief ly   where   d ifferen t   rep l ica t ion   po l ic ies   are
required.  Furthermore,  we  claim  that  a  replication
system of a Data Grid should not only offer a single
policy  but  several  ones  which  satisfy  the  needs  of
hav ing   d i f fe ren t   da ta   type s   and   deg ree s   o f
consistency.
For  a  middle-ware  replication  system  it  is
ra ther   d iff icu l t   to   prov ide   th is   h igh   degree   of
consistency  since  global,  synchronous  transactions
are  difficult  to  establish. Within  a  DBMS  a  global,
synchronous  transaction  can  be  an  extension  of  a
conven t iona l ,   loca l   transac t ion ,   i .e .   the   DBMS
specific   locking   mechanism   is   extended   to   the
replicas.  Since  a  distributed DBMS  like Objectivity
has   bu i l t- in   g loba l   transac t ions ,   no   add i t iona l
commun ica t ion   mechan ism   l ike   socke ts   o r   a
message  passing  library  is  required.  Hence,  the
performance  for  an  integrated  distributed  DBMS  is
superior  to  middle-ware  replication  systems  that
have to use external communication mechanisms.
Now  the  following  question  arises:  why  not
use  a  distributed  DBMS  like  Objectivity  to  handle
replication?  Several  points  are  already  covered  in
Sec t ion   4   bu t   the re   i s   ano the r   ma jo r   po in t .
Objectivity  does  not  provide  flexible  consistency
levels  different  kinds  of  data.  Hence,  we  aim  for  a
hybrid  solution  where  a  local  site  stores  data  in  a
DBMS  which  also  handles  consistency  locally  by
managing  all  database  transactions  locally.  A  Grid
middle-ware  is  required  to  provide  communication
and   co-ordination   between   the   local   sites .   The
degree  of  independence  of  a  single  site  needs  to  be
flexibly  managed.  A  form  of  global  transaction
system  is  necessary.  Let  us  illustrate  this  by  an
example.  Some  data  are  allowed  to  be  out  of  sync
(low  data  consistency)  whereas  other  types  of  data
always  need  to  be  synchronised  immediately  (high
consistency).  Thus,  global  transactions  have  to  be
flexible  and  do  not  necessarily  always  have  to
p rov id e   th e   h igh e s t   d eg r e e   o f   con s i s t en cy .
Fu r th e rmo r e ,   a   s i t e   m ay   ev en   w an t   to   b e
independent of others once data are available.

6.2 Asynchronous Replication
Based  on  the  relative  slow  performance  of  write
o p e r a t i o n s  
i n   a   s y n c h r o n o u s l y  
r e p l i c a t e d
environment,  the  database  research  community  is
searching  for  efficient  protocols  for  asynchronous
rep l ica t ion   a t   the   cos t   o f   lowe r   cons is tency .
Curren t ly ,   there   is   no   s tandard   for   rep l ica t ion
available, but a few commonly agreed solutions:
•   Primary-copy  approach:  This  is  also  known
as  “master-slave”  approach.  The  basic  idea  is

7

that  for  each  data  item  or  file  a  primary  copy
exists  and  all  the  other  replicas  are  secondary
copies  [13].  The  updates  can  only  be  done  by
the primary copy which  is  the owner of  the file.
If  a  write  request  is  sent  to  a  secondary  copy,
the  request  is  passed  on  to  the  primary  copy
which  does  the  updates  and  propagates  the
changes  to  all  secondary  copies.  This  policy  is
implemented  in  the  object  data  stores  Versant
[14 ]   and   Ob jec tS to re   [15 ] .   A l so   O rac le
provides   such   a   feature .   The   primary-copy
app roach   p rov ides   a   h igh   deg ree   o f   da ta
c o n s i s t e n c y   a n d   h a s  
im p r o v e d   w r i t e
performance  features  compared  to  synchronous
replication because  the  lock on  a  file has not  to
be  agreed  among  all  replicas  but  only  by  the
primary copy.
•   Epidemic   approach:   U se r   ope ra t ion s   a re
performed  on  any  single  replica  and  a  separate
activity   compares   version   information   (e .g .
t im e - s t am p s )   o f   d i f f e r e n t   r e p l i c a s   a n d
propagates  updates  to  older  replicas  in  a  lazy
manner  (as  opposed  by  an  eager,  synchronous
approach)  [16].  Thus,  update  operations  are
always  executed  locally  first  and  then  the  sites
c omm u n i c a t e  
t o   e x c h a n g e   u p - t o - d a t e
information.  The  degree  of  consistency  can  be
very   low   here   and   th is   so lu t ion   does   no t
exclude  dirty  reads  or  other  possible  database
anomalies.  Such  a  system  can  only  be  applied
for  non  time-critical  data  since  the  propagation
of  updates  can  also  result  in  conflicts  which
have to be solved manually.
•   Subscr ip t ion   and   re la t ive ly   independen t
s i t e s :   S im i la r   to   the   ep idem ic   app roach ,
another  policy  is  that  a  site  only wants  to  have
data  and  does  not  care  about  consistency  at  all.
When   any   o the r   s i te   does   upda tes   on   a
particular  file,  only  certain  sites  are  notified  of
the  updates.  This  follows  a  subscription  model
where  a  site  subscribes  explicitly  to  a  data
producing  site. A  site  that has not  subscribed  is
itself  responsible  to  get  the  latest  information
from  other  sites.  This  allows  a  site  to  do  local
changes  without  the  agreement  of  other  sites.
However,  such  a  site  has  to  be  aware  that  the
local  data  is  not  always  up-to-date.  A  valid
solution  to  this  problem  is  to  provide  an  export
buffer,  where  the  newest  information  of  a  site
is  stored,  and  an  import  buffer,  where  a  local
site  stores  all  the  information  that  needs  to  be
imported  from  a  remote  site.  For  instance,  a
local  site  has  finished writing  10  different  files
and  puts  the  file  names  into  the  export  buffer.
A  remote  site can  than be notified and  transfers
the  information  from  the  export  buffer  to  its

local  import  buffer  and  requests  the  files  if
n e c e s s a r y .   T h i s   a p p r o a c h   a l l ow s   m o r e
flexibility   concerning   data   consistency   and
independence  for  a  local  site. A  site  can  decide
i t s e l f   wh i ch   d a t a   to   impo r t   and   wh i ch
in fo rma t ion   to   f i l te r .   Fu r the rmo re ,   a   da ta
production  site  may  not  export  all  the  locally
available  information  and  can  filter  the  export
buffer  accordingly.  A  valid  implementation  of
this  approach  can  be  found  in  the  Grid  Data
Management Pilot (GDMP) [17].

6.3 Communication and Transactions
As  outlined  above,  there  is  a  clear  need  for  global
t r a n s a c t i o n s .   S u c h   a  
t r a n s a c t i o n   d o e s   n o t
necessarily  need  to  create  locks  at  each  site,  but  at
least  a  notification  system  is  required  to  automate
and  trigger  the  replication and data  transfer process.
In   general ,   there   is   a   clear   separation   between
exchanging  control  messages  which  organise  locks
and   upda te   no t i f ica t ions ,   and   the   ac tua l   da ta
transfer.  This  is  an  important  difference  to  current
d a t a b a s e   m a n a g em e n t   s y s t em s .   R e p l i c a t i o n
protocols  are  often  compared  by  the  amount  of
m e s s a g e s   s e n t  
i n   o r d e r  
t o   e v a l u a t e  
t h e i r
performance.  The  type  of  a  message  is  dependent
on  the  DBMS.  A  message  of  the  same  type  is  then
sen t   to   do   the   ac tua l   upda te   us ing   the   same
communication  protocol.  In Data Grids where most
of the data are read-only, we can divide the required
communication  into  the  following  two  parts.  This
concept is also realised in GDMP [17].
•  
control  messages:  These  are  all messages  that
are  used  to  synchronise  distributed  sites.  For
instance,  one  site  notifies  another  site  that  new
da ta   a re   ava i lab le ,   upda te   in fo rma t ion   is
p ropaga ted ,   e tc .   To   sum   up ,   rep l ica t ion
protocols are using these control messages.
•   data  transfer: This  includes  the  actual  transfer
of  data  and  meta  data  files  from  one  site  to
another one.
This separation  is similar  to  the FTP protocol where
we  also  have  this  clear  separation  between  the  two
tasks  [18].  The  main  point  for  this  separation  is  to
use  the  most  appropriate  protocol  for  a  specific
communication  need.  Simple  message  passing  is
app rop r ia te   fo r   exchang ing   con t ro l   me s sage s
whereas  a  fast  file  transfer  protocol  is  required  to
transfer  large  amounts  of  (large)  files.  In  a  Grid
environment  both  protocols  are  provided.  To  be
more  specific,  in  Globus  the  GlobusIO  library  can
be   used   fo r   con t ro l   messages   and   G r id -FTP
implementation  [19],  which  is  based  on  the  WU-
FTP  server  and  the  NC-FTP  client,  serves  as  the
data  transport mechanism. A  single  communication
protocol  used  in  an  ODBMS  like  Objectivity  may

8

not  be  optimal  for  transferring  large  files  over  the
wide area network.

6.4 Append Transactions
Based  on  the  HEP  requirements,  we  see  a  need  to
increase  the  traditional  DBMS  transaction  system
by a new transaction, called append transaction.
In  a  conventional  DBMS  there  exist  only  two
d ifferen t   k inds   of   transac t ions :   read   and   wr i te
transactions.  A  write  transaction  itself  can  either
write  new  data  (append)  or  update  existing  data.  In
terms  of  data  management,  these  two  operations
r equ i r e   d i f f e r en t   t a sk s .   Wh e r e a s   an   upd a t e
transaction  has  to  prevent  concurrent  users  from
reading  old  data  values,  an  append  transaction  only
has  to  make  sure  that  the  data  item  to  be  added
sa t is f ies   a   uniqueness  condition.   A   un iqueness
condition  is  a  condition  which  guarantees  that  a
data  item  appears  only  once  and  can  be  identified
uniquely.  In HEP  this  condition  can  be  satisfied  by
the   fo l low ing   fea tu re :   s i tes   o f ten   w r i te   da ta
independently  and  do  not  change  any  previously
written  data  items.  Since  different  sites  will  write
different  data  by  definition  (thus  we  can  derive  an
inherent  parallelism  in  the  data  production  phase),
this  uniqueness  condition will  hold.  This  is  true  for
HEP  specific  reconstruction  software  as  well  as
simulated data created via Monte Carlo processes.
Objectivity  provides  object  IDs  and  unique
database  IDs  for  single  files.  Hence,  it  has  to  be
guaranteed  that  newly  created  objects  do  not  have
the  same  OID  (the  same  is  true  for  database  IDs).
Since  an  append  transaction  does  not  have  to  lock
the whole  file  but  only  the  creation  of  new  objects,
it  can  allow multiple  readers  at  the  same  time while
an  append  transaction  creates  new  objects.  This
again  allows  for  having  different  consistency  and
response time levels.

6 .5   File   replication   with   Objectivity   using   a
replication middle-ware
Driven  by  real  world  replication  requirements  in
High  Energy  Physics,  we  want  to  give  a  possible
approach  for  replication  of  read-only  Objectivity
d a t a b a s e   f i l e s .   I n   p r i n c i p l e ,   r e p l i c a t i o n   o f
Objectivity  database  files  does  not  impose  a  big
problem  concerning  data  consistency.  Each  site  has
to  have  its  Objectivity  federation  that  takes  care  of
managing  files  and  the  Objectivity  file  catalogue.
The re   a re   seve ra l   way s   to   dea l   w i th   a   f i le
rep l ica t ion   o f   read -on ly   f i le s .   I t   ha s   to   be
gua ran teed   tha t   a   un ique   Ob jec t iv i ty   nam ing
scheme  is  applied  by  all  sites  in  the Data Grid. We
outline two possible approaches.
Each site can create a database file. In order  to
provide unique database names, a global  transaction

has  be  called  before  the  actual  file  creation.  The
transaction  checks  in  each  local  Objectivity  file
catalogue  if  the  file  already  exists.  If  not,  the  site
creates  the  database  locally  and  initiates  a  database
creation  at  the  remote  sites  as  well.  All  remote
replicas  of  a  specific  file  have  to  be  locked  since
only  one  site  can  write  into  a  file  at  a  time.  Once
the  local  site has  completed  the writing process,  the
lock  on  the  remote  replicas  is  released.  For  such  a
system we  require a  replica catalogue at each site  in
addition  to  the  local  federation  catalogue.  In  the
replica  catalogue  a  flag  is  needed  for  initiating  a
lock  on  a  file.  The  actual  file  locking  has  to  be
implemented with a call  to  the Objectivity database.
Fur thermore ,   each   transac t ion   on   a   f i le   in   the
Objectivity  file  catalogue  has  to  be  done  via  the
replication   catalogue .   Consequently ,   a   database
use r   is   no t   a l lowed   to   use   the   conven t iona l
Objectivity  “open”  to  create  a  new  file  but  has  to
contact  the  replica catalogue  in order  to write a new
database  file.  All  database  transactions  have  to  go
through  a  high  level  API  that  always  contacts  the
replica catalogue first.
An easier approach, which  is currently used  in
t h e   CMS   e x p e r im e n t ,   i s   t h e   a l l o c a t i o n   o f
Objectivity  database  IDs  to  different  remote  sites.
Th i s   gu a r an t e e s   on ly   a   un iqu e   d a t ab a s e - ID
allocation  but  not  a  unique  name  for  a  database.
Consequently,  in  order  to  have  a  fully  automatic
system,  a  unique  name  space  has  to  be  provided.
This  can  only  be  guaranteed  if  on  creation  of  a
database  file  the  name  is  communicated  to  other
sites and  then agreed on. However, another  solution
is  to  provide  a  naming  convention  like  adding  the
host  and  domain  name  of  each  local  site  to  the
database  name.  This  also  guarantees  unique  file
names.  The  populate-replicate  approach  also  does
not  require  the  locking  of  remote  replicas  which
allows  for  a  faster  local  write.  This  is  a  common
approach for asynchronous replication.

7 Possible Update Synchronisation  for a
Data Grid
In  the  previous  sections  we  have  mainly  addressed
replication  of  read-only  files. Although most  of  the
data  in  the  High  Energy  Physics  are  ready-only,
there  will  be  some  replicated  data  that  will  change
and   thus   need   upda te   synchron isa t ion .   In   th is
s e c t i o n   w e   p r o v i d e   s om e   p o s s i b l e   u p d a t e
s y n c h r o n i s a t i o n   s t r a t e g i e s   w h i c h   c a n   b e
implemented  using  a  replication  middle-ware  for
the Data Grid.
We  have  already  described  that  it  is  rather
difficult  for  a  middle-ware  system  to  do  replica

9

update  synchronisation  on  the  object  rather  than  on
the  file  level  since  a  middle  ware  system  cannot
access  DBMS  internals  like  pages  or  object  tables.
A   common   solution   in   database   research   is   to
communicate  only  the  changes  of  a  file  to  remote
sites. Since  an Objectivity  database  file  can  only  be
in te rp re ted   co r rec t ly   by   a   na t ive   Ob jec t iv i ty
process,  the  file  itself  appears  like  any  binary  file
and   a   conven t iona l   process   does   no t   see   any
s t ruc tu re   in   the   f i le .   We   ca l l   th is   the   binary
d i f f e r en c e   app roa ch .   As   second   possibility   to
update data stored  in an ODBMS, we use an object-
oriented  approach  which  requires  knowledge  about
the   schema   and   data   format   of   the   files   to   be
upda ted .   Bo th   approaches   are   ou t l ined   in   th is
section.

7.1 Binary Difference Approach
There  is  also  the  possibility  to  use  a  tool  called
XDe l ta   [20 ] ,   wh ich   p roduce s   the   d i f fe rence
between  any  two  binary  files.  This  difference  can
than  be  sent  to  the  remote  site.    This  site  can  then
update  the  file, which  is out of date, by merging  the
diff  file  with  the  original  data  file.  XDelta  is  a
library  interface  and  application  program  designed
to  compute  changes  between  files.  These  changes
(deltas)   are   similar   to   the   output   of   the   "diff"
program  in  that  they  may  be  used  to  store  and
transmit  only  the  changes  between  files.  However,
unlike diff,  the output of XDelta  is not  expressed  in
a  human-readable  format  -  XDelta  can  also  apply
these deltas to a copy of the original file(s).

7.2 Object-oriented approach
Another approach  is  to create objects  that are aware
of  replicas.  In  principle,  an  object  can  be  created  at
any  site  and  the  creation  method  of  this  object  has
to  take  care  of  or  delegate  the  distribution  of  this
object.  The  class  definition  has  to  be  designed  in  a
way  that  there  is  some  information  on  the  amount
and  the  site  of  replicas.  For  instance,  an  object
should be created at site 1 and replicated  to  the sites
X  and  Y.  A  typical  creation  method  can  look  like
follows:

object.create (site1, siteX,
siteY);

The   advantage   of   this   approach   is   that   all   the
necessary  information  is  available  to  create  the
object  at  any  site.  When  an  update  on  one  of  the
objects  is done,  the update  function has  to be  aware
of  all  the  replicas  and  the  sites  that  need  to  be
upda ted .   Th is   can   be   compared   to   the   s tored
p rocedu re   app roach   wh ich   i s   known   in   the
relational  database  world.  In  principle,  the  model

presented  here  has  similar  ideas.  A  local  site  may
update  immediately and can  store  the updates  into a
log  file.  Based  on  the  consistency  requirement  of
remote  sites,  the  log  information  is  sent  to  the
remote  sites  which  apply  the  same  update  function
as the original local site.
The  update  synchronisation  problem  is  then
passed   to   a   Rep l ica torOb jec t   tha t   is   aware   of
r e p l i c a s   a n d  
t h e  
r e p l i c a t i o n   p o l i c y .   T h e
Rep l ica torOb jec t   in   turn   can   prov ide   d ifferen t
cons is tency   leve ls   l ike   upda t ing   remo te   s i tes
immed ia te ly ,   each   hour ,   day ,   e tc .   When   large
amounts  of  data  are  used,  there may  be most  likely
a  scalability  problem  of  managing  all  the  logging
in fo rm a t ion .   How ev e r ,   s in c e   e a ch   ob j e c t   i s
identified  by  a  single  OID,  only  the  parameters  of
an  update method  together with  the OID  have  to  be
stored.

object.update_parameter_x (200);
// OID = 38-23-222-442

The  log  file  stores  the  triple  (x/38-23-222-442/200)
where  the  first  argument  is  the  parameter  of  the
object,  the  second  the  OID  and  the  third  the  new
value of the parameter.
The  modus  operandi  for  communicating  the
changes  is  like  the  following.  A  local  site  gains  an
exclusive,  global  lock  on  the  file  and  updates  the
required  objects.  In  parallel  the  log  file  is  written.
The  file  itself  is  transferred  to  remote  sites  with  an
efficient  file  transfer  protocol  whereas  the  remote
sites are notified via control messages.
Since  such  a  replication  policy  is  rather  cost
intensive  in  terms  of  exchanging  communication
messages  sending  data,  it  should  only  be  applied  to
a   relatively   small   amount   of   data .   In   the   HEP
environment,  there  exist  many  meta  data  sources
like  replica  catalogues,  indices  etc.  which  require  a
h igh   cons is tency   o f   da ta .   Fo r   such   da ta   th is
approach is useful.

8 Conclusion
The  data  management  efforts  of  the  two  research
communities  distributed  databases  and  Grid  deals
with  the  problem  of  data  replication where  the Grid
community  specifically  deals with  large  amounts  of
data  in wide area networks.  In  the HEP community,
da ta   are   of ten   s tored   in   da tabase   managemen t
systems,  and  it  is  appropriate  to  try  to  understand
the  research  issues of both communities: distributed
da taba se s   and   G r id ;   ana ly se   d i f fe rence s   and
commonalities, and combine common  ideas  to  form
an  efficient  Data  Grid. We  have  presented  research
issues  and  possible  solutions.  Thus,  we  provide  a

10

first  basis  for  the  effort  of  combining  both  research
communities.

Acknowledgement
We  want  to  thank  colleagues  from  the  following
groups   for   fruitful   discussions:   DataGrid   work
package  “Data  Management”  (including  CERN,
Caltech,  LBL  and  INFN),  CMS  Computing  group
(CERN,  Princeton  and  Caltech),  Globus  project  in
Argonne  and  ISI,  BaBar  experiment  at  SLAC  and
colleagues  taking  part  in  the  Data  Grid  discussions
in the Grid Forum 5 in Boston.

P r o j e c t :

References
[1]  T h e   E u r o p e a n   D a t a G r i d  
http://www.cern.ch/grid/
[2]  Wo lfgang   Hoschek ,   Jav ier   Jaen-Mar t inez ,
A s a d   S am a r ,   H e i n z   S t o c k i n g e r ,   K u r t
Stockinger, Data Management  in  International
D a t a   G r i d   P r o j e c t ,   1 s t   1 E E E ,   ACM
International  Workshop  on  Grid  Computing
(Grid'2000),   Banga lore ,   Ind ia ,   17-20   Dec .
2000.
[3]  The Globus Project, http://www.globus.org
[4]  Objectivity Inc., http://www.objectivity.com
[5]  He inz   S tock inger ,   Kur t   S tock inger ,   Er ich
Schikuta,  Ian  Willers.  Towards  a  Cost  Model
for  Distributed  and  Replicated  Data  Stores,
9 th   Euromicro   Workshop   on   Parallel   and
D is tr ibu ted   Process ing   PDP   2001 ,    IEEE
Compu te r   Soc ie ty   P re s s ,   Man tova ,   I ta ly ,
February 7-9, 2001.
[6]  P a r t i c l e   P h y s i c s   D a t a   G r i d  
http://www.ppdg.net
[7]  GriPhyN, http://www.griphyn.org
[8]  Koen.   Ho l tman ,   Pe te r   van   de r   S tok ,   Ian
Willers.  Towards  Mass  Storage  Systems  with
Object  Granularity.  Proceedings  of  the  IEEE
Mass   S torage   Sys tems   and   Techno log ies,
Maryland, USA, March 27-30, 2000
[9]  Koen  Holtman,  Heinz  Stockinger,  Building  a
Large   Location   Table   to   Find   Replicas   of
Physics  Objects,  Proc.  of  Computing  in  High

( P PDG ) ,

Energy  Physics  (CHEP  2000),  Padova,  Febr.
2000.
[10]  D.K.  Gifford.  Weighted  Voting  for  replicated
d a t a .     ACM-SIGOPS   Symp .   on   Opera t ing
Systems  Principles,  Pacific  Grove,  December
1979.
[11]  Kurt  Stockinger,  Dirk  Duellmann,  Wolfgang
Hoschek ,   E r ich   Sch iku ta .   Imp rov ing   the
Performance  of High Energy Physics Analysis
through  Bitmap  Indices.  11th  International
Conference  on  Database  and  Expert  Systems
A p p l i c a t i o n s ,   London   -   Greenw ich ,   UK ,
Springer-Verlag, Sept. 2000.
[12]  L .   M .   Bernardo,  A.  Shoshani,  A.  Sim,  H.
Nordberg.  Access  Coordination  of  Tertiary
S t o r a g e  
f o r   H i g h   E n e r g y   P h y s i c s
App l ica t ion s .   IEEE   Sympos ium   on   Mass
Storage  Systems,  College  Park,  MD,  USA,
March 2000.
[13]  Yuri  Breitbart,  Henry  Korth.  Replication  and
Consistency:  Being  Lazy  Helps  Sometimes,
Proc.  16  ACM  Sigact/Sigmod  Symposium  on
the  Principles  of  Database  Systems,    Tucson,
AZ 1997.
[14]  Versant, Inc. http://www.versant.com/
[15]  ObjectStore http://www.exceloncorp.com
/products/objectstore.html
[16 ]   D ivyakan t   Agrawa l ,   Am r   E l   Abbad i ,   R .
Steinke:  Epidemic  Algorithms  in  Replicated
Databases  (Extended  Abstract).  PODS  1997,
1997.
[17]  Asad  Samar,  Heinz  Stockinger.    Grid  Data
Management  Pilot  (GDMP):  A  Tool  for Wide
A rea   Rep l ica t ion ,   IA STED   I n t e r n a t i o n a l
Conference  on  Applied  Informatics  (AI  2001),
Innsbruck, Austria, 2001.
[18]  J.  Postel,  J.  Reynolds, RFC  959:  File  Transfer
Protocol (FTP), October 1985.
[19]  Globus  Project,  Universal  Data  Transfer  for
the Grid, White Paper, 2000.
[20]  J o s h u a  
P .   M a c D o n a l d ,   X D e l t a ,
http://www.XCF.Berkeley.EDU/~jmacd/xdelt
a.html

11

Contact Sheet

Heinz Stockinger
CERN
CMS Experiment, Computing Group
Bat. 40-3B-15
CH-1211 Geneva 23
Switzerland

Heinz.Stockinger@cern.ch
tel +41 22 767 16 08
fax +41 22 767 89 40

12

A Performance Analysis Framework for Database Management Systems 
 
 
José Antonio Fernandes de Macêdo  
e-mail: jmacedo@inf.puc-rio.br 
 
Philippe Picouet 
É cole Nationale Supérieure des Télécommunications de Bretagne (ENST-Bretagne) 
e-mail: Philippe.Picouet@enst-bretagne.fr 

PUC-RioInf.MCC40/04 November, 2004 

 

Abstract:  Performance  evaluation  of DBMS  is  a major  issue  since  it  is  generally  difficult  to 
model  experimental  and  performance  analysis  results.  In  this  paper,  we  propose  an 
application  framework  that  provides  a  model,  a  methodology  and  a  common  platform  to 
implement database evaluation analysis tools. Inspired on a conceptual UML model  [14],  this 
application  framework  provides  a  much  more  detailed  model  that  allows  capturing  the 
complex  structure  of  DBMS  modern  software.  We  use  a  recent  work  [1]  about  the 
implementation of a new data page layout to illustrate the instantiation of our framework. 
 
Keywords:  database  management  system,  performance  evaluation,  performance  analysis, 
application framework. 
 
 
Resumo: A avalia ç ã o de performance de SGBDs é uma importante questã o a ser tratada dada 
à   dificuldade  de  modelar  o  que  deve  ser  medido  e  analisar  os  resultados  obtidos.  Propomos 
neste  artigo  um  framework  de  aplicaç ã o  o  qual  fornece  um modelo,  uma metodologia  e  uma 
plataforma  comum  para  a  construç ã o  de  ferramentas  análise  de  performance  de  banco  de 
dados.  Inspirada em um modelo conceitual descrito  em UML  [14], este  framework provê um 
modelo que permite capturar a estrutura complexa de um SGBD. Usamos um recente trabalho 
[1] sobre implementa ç ã o de formatos de página de dados para ilustrar a instanciaç ã o do nosso 
framework. 
 
 
Palavras-chave: sistema de gerencia de banco de dados, avaliaç ã o de performance, análise de 
performance, framework de aplica ç ã o. 
 
 
 
 

 

   

 
 

SUMÁ RIO 

1. INTRODUCTION 

2. PERFORMANCE ANALYSIS OF DBMS 

3. A GENERIC FRAMEWORK FOR PERFORMANCE EVALUATION 

3.1. PERFORMANCE METRICS 

3.2. EVALUATING PERFORMANCE MODEL 

3.3. ADAPTING THE FRAMEWORK TO DBMS 

4. CACHE PERFORMANCE ANALYSIS – DEWITT MODEL 

4.1. STEP 1  –

 EXTENDING THE FRAMEWORK HOTSPOTS 

4.2. STEP 2  –

 DEFINING THE DBMS ALGORITHMS 

4.3. STEP 3 - CREATING SCENARIOS 

4.4. STEP 4  –

 DEFINING METRICS MODELS 

5. CONCLUSIONS 

1 

2 

4 

7 

8 

10 

13 

13 

15 

15 

17 

19 

ii 

 

1. Introduction 

Quantitative  performance  evaluation  is  a  major  concern  of  computer  science  research  and  systems, 

especially  for  complex  architectural  software  such  as  DBMS  [13,  7].  Since  new  algorithm  and 

platform  evolve  regularly,  it  is  necessary  to  compare  them  to  older  technologies  in  evaluating  the 

such  difficulties,  we  can  find  both  the  evolution  of  the  environment  and  the  complexity  of  the 

software  architectures:  the  evolution  of  the  environment  covers,  for  example,  the  hardware  progress, 

which  makes  it  almost  impossible  to  regenerate  a  previous  experimental  context;  the  complexity  of 

software architecture denotes the difficulty to identify the impact of software service implementations 

with complex interactions in a performance evaluation.  

Although  classic  performance  evaluation  models  are  well  known,  there  is  neither  a  unique 

methodology  nor  a  tool  that  supports  the  performance  analysis  tasks.  The  result  is  twofold:  on  one 

hand,  the  research  papers  proposing  some  specific  improvement  techniques  [9,  6,  15]  describe  some 

performance  analysis  comparisons  which  are  difficult  both  to  produce  and  reproduce;  on  the  other 

hand,  commercial  DBMS  have  many  difficulties  to  provide  software  adapted  to  specific  platforms 

[12].   

In this paper, we focus on these difficulties and propose a framework to support design, execution and 

reuse  of  performance  evaluation models.  Like  [16],  we  believe  that  such  performance  analysis  study 

should  be  conducted  from  the  very  beginning  of  a  certain  product  development  and  we  believe  that 

such framework could help to reach this step.  

In  Section  2,  we  analyze  the  difficulties  involved  in  the  production  of  a  quantitative  performance 

study  over  complex  software  architecture  and  especially  over  DBMS.  We  describe  the  main 

architecture  of  our  generic  framework  and  explain  how  to  specialize  it  for  DBMS  in  Section  3.  In 

Section  4,  we  describe  the  methodology  associated  with  our  framework  by  applying  it  to  a  recent 

study [1] proposing a new data page layout. We finally conclude in Section 5. 

 

 1  

 

 
 

2. Performance Analysis of DBMS  

Recent  publications  in DBMS  performance  analysis  [1,  2,  3,  5,  6,  9,  11,  13,  15] have  shown  that  the 

formalization  of  a  performance  model  is  essential  to  guarantee  a  good  interpretation  of  the  results. 

Although  the  performance  model  plays  a  major  role  in  database  research,  there  is  not  any  generic 

performance  model  to  evaluate  DBMS  behavior.  In  general,  when  it  is  necessary  to  elaborate  a 

performance model of any system we must answer the following questions:  

What  software component1  to measure? The  software  component  that must be measured  can  be of 

different granularity:  the entire system  (i.e. DBMS), a component  implementation, a data  structure or 

a  specific algorithm. For example,  in [13], transaction processing and database benchmark permitting 

measurement and comparison between different commercial DBMS performance are proposed, while 

in  [15]  we  propose  techniques  for  buffer  accesses  to  memory-resident  tree-structure  indexes,  where 

the efficiency of the different B+-trees is measured in order to avoid trash cashing. 

What  experimental platform  to  choose?  In  order  to execute  the  performance analysis we have  two 

possibilities in choosing the experimental platform: simulation artifact or real system.  The simulation 

artifact  simplifies  the  execution  of  the performance because  it  reduces  the  number of components we 

must  deal  with  regarding  the  real  system.  However,  it  is  hard  to  ensure  that  the  simulation  model  is 

credible,  if  the  simulation  is  accepted  as  being  accurate  and  useful.  On  the  other  hand,  the  use  of  a 

real  system  is  the most  reliable  and preferred way  to  validate  the performance  analysis but  it  is more 

complex  to build, analyze and reuse. Generally, publications utilize  their own DBMS  to execute  their 

experiments  because  it  gives  them  more  control  during  the  test  [11,  1,  5].  In  absence  of  DBMS,  a 

simulating environment is used in some publications [6]. 

What  measures  to  collect?  Although  some  publications  in  the  past  defended  that  it  is  sufficient  to 

use  simple  measurements  such  as  elapsed  time,  CPU  time  and  I/O  activity  [18]  to  measure 

performance,  in  actuality  we  see  that  the  influence  of  new  platform  features  in  the  DBMS 

                                                 
1 A software component is a software technology for encapsulating software functionality [17] 

2 

 
 

performance  is  crucial  [5,6,2].  Consequently,  we  must  take  into  account  the  operating  system, 

processor and device variables to model the DBMS behavior. 

How  to  interpret  data  results?  As  the  performance  analysis  expands  outside  the  DBMS,  it  needs 

help  on  how  to  effectively  use  data  results  to  enhance  the  identification  of  performance  bottlenecks. 

Most  importantly,  the  performance  analyst  must  be  trained  on  how  to  interpret  performance  data  so 

that  the  limitations  of  the  measurement  process  can  be  clearly  understood.  Thus,  cost  models  are 

required  to  characterize  the  performance metrics. Generally,  the  performance metrics  use  probability 

[6], queuing networks [19] or equation systems [5] models. 

In  addition  to  the  challenges  described  above,  the DBMS  also  has  some  particularities  that make  the 

performance modeling more complex: 

The  DBMS  is  situated  between  application  requests  and  platform  services  (operating  system, 

network, devices, etc)  that  force  the DBMS  to deal with  the complexity of this environment. Besides, 

the heterogeneity/complexity of  the applications  and platforms makes  the  description of performance 

properties via small sets of metrics difficult; 

The  multi-layering  and  variety  of  DBMS  software  architectures  and  the  diversity  of  software 

components  and  algorithms  found  in  a  DBMS  makes  it  hard  to  construct  simple  and  portable 

benchmarks.  Also,  it  is  difficult  to  identify  and  measure  the  performance  of  a  specific  component 

inside a complex software architecture; 

The  flexibility  of  DBMS  configuration  makes  it  difficult  to  provide  a  concise  representation  of 

system  resources.  The  large  set  of  system  parameters  makes  the  system  modeling  and  analysis 

difficult. 

As  previously mentioned,  although  there  is  a  lot  of work  that makes  use  of  quantitative  performance 

analysis  in  the  DBMS  area,  we  identified  a  lack  of  methodology  and  common  platform  to  build  a 

performance  analysis  model.  This  fact  forces  the  construction  of  a  performance  model  from  scratch 

each time. In summary, we need a methodology to guide the construction of a performance model and 

a system  that permits its  implementation and execution. Thus,  the Object Management Group (OMG) 

3 

 
 

has  defined  a UML  profile  [14]  that  enables  the  design  of  performance models.  This model  is  based 

on  the  identification  of workload,  resources  and  scenarios.  However,  this model  does  not  present  all 

service implementations needed to instantiate an application for several reasons: 

First,  in  complex  environments  such  as  DBMSs  we  need  to  analyze  facts  through  different  logical 

views independently of  the software physical implementation. Thus, we suggest the conversion of the 

UML  resource  concept  into  service  and  service  implementation  concepts.  The  service  represents  a 

logical view of the implementation artifacts named service implementation; 

Second,  in multi-layered  architectures we  need  hierarchical mechanisms  to  represent  the  relationship 

complexity. The new model must allow the description of software layers and their complexity;  

third,  it  is  necessary  to  measure  the  system  service  implementations  quantitatively  using  a  metrics 

model;  It  is  necessary  to  have  in  the model  classes  that  allow  the  definition  of  complex  formulas  to 

represent the wide range of cost models available; 

Fourth,  we  need  a  performance  model  to  implement,  execute  and  reuse.  In  this  manner,  the  model 

must  provide  mechanisms  that  permit  the  execution  and  evaluation  of  performance  models,  such  as 

measurers and execution engines. 

We  claim  that  an  application  framework  can  fit  all  these  requirements  [8]. Based  on  the OMG UML 

Profile  model  [20],  we  transform  this  model  into  an  application  framework  able  to  support  the 

creation of performance analysis  tools geared  towards  the DBMS analysis. We  identify  the  following 

five  elements 

fundamental 

to  performance  models:  scenario,  workload,  service,  service 

implementation  and  metrics.  Figure  1  illustrates  the  framework  overview:  a  scenario  drives  a 

workload  execution;  a  workload  represents  a  unit  of  job  with  applied  load  intensity  that  runs  over  a 

service;  a  service  is  the  logical  view  of  software  physical  implementation;  all  these  layers  can  use 

some kind of metrics to model their behavior. 

3. A Generic Framework for Performance Evaluation 

In  this  Section,  we  describe  the  framework  sketched  in  the  previous  section.  Based  on  the  five 

previously  identified elements (scenario, workload, service,  service  implementation and metrics), our 

4 

 
 

framework  UML  packages  (Figure  2)  recall  that,  besides  the  metrics  package,  the  scenario  package 

drives  all  the  other  packages,  but  relates  to  them  through  different  dependencies.  Two  kinds  of 

dependencies are stressed to differentiate the design and the execution of the performance framework: 

from a conceptual  point  of view, performance models  are  represented  as    layered  hierarchies  relating 

application  scenarios  (at  the  top)  to  software  implementation  (at  the  bottom)  through  specified 

workloads and service specification; 

From  an  execution  point  of  view,  all  these  layers  can  use  some metrics  to model  their  behavior. The 

scenario is restricted to a set of workloads, services and service implementations that will be executed 

in order to measure the system in a defined condition. 

We  will  now  detail  each  package  showing  internal  classes  as  Scenario,  Workload,  Service  and 

ServiceImplementation  (Figure  3).  These  classes  are  hierarchically modeled  using  the  design  pattern 

Interpreter/Composite  [10]  that  enables  the  implementation  of  hierarchical  structures  with  the 

expressive  power  of  a  regular  grammar.  Elementary  classes  are  the  leaf  classes  of  these  hierarchies, 

which  are  built  thanks  to  group  classes:  the  relationship  between  a  group  class  and  its  superclasses, 

for  example  GroupScenario  class  and  Scenario  class,  allow  defining  an  ordered  sequence  of 

elementary action.  

5 

 
 

 

 

PF_Scena ri o

<< GO F  In ter pre te r> >
Scena ri o

{ orde r ed }
Ta rge t
1 . .n1 . .n
Source
11

G roupScena ri o

E l e m en ta r yS ce na ri o

0 ..n0 ..n

Scena ri oExecu ti on

0 . .n
0 . .n

tri gge r
PF_Workl o ad
1 . .n
1 . .n

<<<<GOF  In te rp re te r>>>>
Wo rkl oad

1 ..n1 ..n
Ta r ge t
{o rde red }

11
Sou rce

Figure 1 - Framework Overview  

GroupWo rkl oad

E l em en ta ryWo rkl oad

1 ..n1 ..n

PF_Met rics

PF_Scenario

Se rvi ceRe l a t i on

Hierarchy

Ex ecuti on

Exc l u si v e

PF_Work load

Re l a t i onSem ant i cs

PF_Servic e

Non -Excl usi ve

execu te
PF_Se rvi ce

11

1 ..n1 ..n

<<<<GOF  In te rpre te r>>
>> Se rvi ce

11

Sou rce

Ta rge t
{orde red }

GroupSe rv ice

E l em en ta rySe rvi ce

1 . .n1 . .n

i mpl emen ted  by
PF_Se rvi ce Im p l em en tat i on
11
<<<<GOF  In t er prete r>>
>> Se rvi ce Im p l em enta ti on

PF_Servi ceIm pl ement ation

Figure 2 - Framework 
Packages 

S IRel a ti on

1 . .n1 . .n
Ta rge t
{o rde red }

11
Sou rce

G rou pS I

El em en ta ryS I

0. .n0. .n

 

Figure 3 - Framework Packages 
Relationships 

 

An  elementary  scenario  is  composed  of  a  set  of Workload,  Service  and  Service  Implementation  class 

instances  that  delineate  the  specific  context  that  must  be  evaluated.  The  Workload  class  aims  at 

defining  a  set  of  operations  to  be  executed  over  the  system.  Single  operations  are  denoted  by  the 

ElementaryWorkload class, and intuitively connect to corresponding services. The ElementaryService 

class  is  dedicated  to modeling  a  specific  service  carried  out by  the  system. Services  allow  defining  a 

logical  view  of  service  implementations  independently  of  the  physical  implementation  and 

organization aspects. With this approach, it is possible to model system functionality in a great variety 

of  ways.  Also,  the  service  represents  the  dynamic  portion  of  the  system  while  the  service 

6 

 
 

implementation definitions focus  on  its  static  structural portion. A  service  implementation  can define 

concrete  system  components  such  as  processors  and  devices  (i.e.,  cache,  memory,  disk,  etc)  or 

abstract  ones  such  as  database  modules  (i.e.  buffer  manager,  transaction  processor,  etc).  The 

ElementaryService  class  is  associated  with  a  software  component  that  implements  it,  represented  by 

the ServiceImplementation class.  

Concerning  the  Service  and  ServiceImplementation  classes,  both  have  associative  classes  that 

represent the semantics (exclusive or non-exclusive) of this relationship. For example, a query service 

can  be  related  with  two  types  of  optimization  that  are  exclusive  (conceptual  point  of  view).  Thus, 

during  the  execution  of  a  scenario  (ScenarioExecution  class),  only  one  type  of  optimization  will  be 

executed. 

3.1. Performance Metrics 

The  framework  provides  some  classes  to  assign  formulas  to  each  element  model  (workload,  service 

and service implementation) as we can see  in Figure 4 (there  is not any formula for  the scenario since 

they only compile results from other elements).  

In order to allow the definition of regular expressions, we have defined the Formula class that follows 

the  Interpreter  design  pattern  [10]  (Figure  4).The  Formula  class  may  contain  an  expression  or  a 

variable  that  delineates  the  quantification  of  an  element.  This  class  permits  us  to  define  group 

expressions  (Expression  class)  and  elementary  variables  (Variable  class). A  group  expression  can  be 

a  unary,  n-ary  and  boolean  expression.  These  classes  are  also  framework  hotspots  that  can  be 

extended  to  new  types  of  expressions  depending  on  the  type  of  systems  (see  below).  For  example,  a 

workload  instance  may  define  an  execution  timeout  variable  that  is  equivalent  to  two  seconds;  the 

query  service may measure  the  query  execution  stall  time  that  is  the  sum of  the  processor,  cache  and 

memory  stall  time.  Figure  4  illustrates  the  relationships  between  Workload,  Service  and 

ServiceImplementation  classes  with  Formula  class.  We  can  observe  that  the  Workload  class  must 

declare  one  or more  formulas  and  the  ServiceImplementation  class may  have  no  formula  associated. 

Note  that  the  Service  class  has  two  links  to  the  Formula  class  that  symbolize  the  variables  that  are 

7 

 
 

received  as  input  and  the  variables  that  are  sent  as  output,  permitting  the  definition  of  the  service 

interface  and  the  transformation  expressions.  For  example,  the  query  service  receives  the  number  of 

queries  to  be  executed  and  calculates  the  amount  of  execution  time  and  number  of  table  tuples 

returned.  

In  addition,  the  variables  can  make  use  of  predefined  units  and  types  symbolized  by  Unit  and 

ValueType classes. Thus, it is possible to declare new attributes to the workloads, services and service 

implementations elements. 

<<<<GOF In te rp re te r>...
Wo rkl oad

<<<<GOF In te rp re te r>>
>>  Ser vic e

<<<< GOF  In te rp r et er>>
>>  Ser vic eI mp le m en ta tio n

0 ..n0 ..n

Inpu t

1 ..n1 ..n

0. .n0. .n

<<GOF In te rp re te r>>
Fo rm u l a

Ou tp ut
0 ..n0 ..n

1 ..n1 ..n

Va ri ab l e

Exp res si on

KB

Se c

T ransSec

c on ve rts

0 ..n0 ..n

Un i t

0 ..n
0 ..n

Un i tConve rso r

Conve rso r

+va l ue

Va l ueType

0 ..n
0 ..n

Una ryExp re ssi on

Na ryExp re ss io n

Boo l eanE xp re ssi on

T ypeConve rso r

Ti me

Da te

Re al

Log

SQRT

Sum

M a x

ExpOR

ExpAND

Figure 4 - Cost Expression 

 

3.2. Evaluating Performance Model 

Finally,  the  ability  of  the  framework  to  validate  the  performance model  is  obtained  by  executing  the 

scenarios, collecting  the  results and making  scenario  comparisons. The  framework proposes partially 

implemented methods that must be used to compute the model evaluation.  

Schematically,  the  evaluate  method  of  PerformanceContext  class  starts  the  evaluation.  It  calls  the 

evaluate  methods  from  scenario  objects  that  are  propagated  to  the  evaluate  method  of  Workload, 

Service  and ServiceImplementation  classes. An  evaluate method of a  specific  service  implementation 

can  contain  custom  code  to  call  external  software  such  as  DBMS  or  an  OS  program  because  some 

8 

 
 

evaluations  may  need  to  use  real  systems  to  collect  measures  into  their  formulas.  Likewise,  the 

evaluate method can contain simulation code to generate data  to be used by cost formulas. After each 

evaluate  method  execution,  it  is  necessary  to  treat  data  and  compute  the  cost  formulas.  The  data 

manipulation and formula computation are made by the collectCost method presented in the Scenario, 

Workload, Service and ServiceImplementation classes. During execution,  the  result of each method  is 

propagated to the caller method until it reaches the PerformanceContext class where it is shown. Each 

evaluation method may  include  custom  codification  to make  coherent  interpretation  of  variables  and 

formulas.  

Scenario  comparison  is  an  important  features  provided  by  our  framework.  A  scenario might  be  seen 

as an execution plan that can be measured in several points. The ElementaryScenario class (Figure 5), 

which  represents  a  specific  service,  can  associate  diverse  measurers  that  will  collect  corresponding 

measures  during  the  evaluation  execution.  Each  measurer  attaches  some  start  and  stop measurement 

points  associated  with  a  service  (or  service  implementation).  Also,  a  measurer  is  defined  as  an 

expression that must be evaluated. For example, we can have a measurer that collects the elapsed time 

from the start of query execution until the first page stored in the memory. 

The  Comparison  class  associates  a  source  scenario  that  must  be  evaluated  and  compared  to  diverse 

target  scenarios.  The  possible  types  of  comparisons  are  represented  by:  Straight,  Contrast  and 

Analogy  classes.    The  straight  comparison  denotes  that  we  want  to  emphasize  both  similarities  and 

differences  while  the  contrast  comparison  emphasizes  mostly  differences  and  the  analogy  mostly 

similarities. 

9 

 
 

0..n0..n

<<GOF Interpreter>>
Formula
(from  PF_M e trics)

evaluate()

11

0..n0..n

Output

0..n0..n

Input

<<<<GOF Interpreter>>
>>  Service
(f rom  PF_Se rv ice )

evaluate()
addComponent()
execute()
collec tCos t()
compare()

s tart

end

1..n1..n

Measurer
name

s tart()
s top()
calculate()

0..n
0..n

s tart

end

<<<<GOF Interpreter>>
>>  ServiceImplementat ion
(f rom  PF_Se rvi ceIm p l em e nta t io n )

evaluate()
addService()
execute()
collec tCos t()
compare()

1..n
1..n
ElementaryS cenario
(from  PF_S cena ri o )

1..n1..n

1..n1..n target

Comparison

11 source

compare()

St raight

Contras t

Analogy

compare()

compare()

compare()

3.3. Adapting the framework to DBMS 

Figure 5 - Scenario Comparison 

 

In  this  section,  we  propose  some  specialization  of  the  former  framework  to  Database  performance 

evaluation.  More  accurately,  we  will  describe  some  specialization  of  the  previously  described 

Workload,  Service  and  ServiceImplementation  classes.  These  specializations will  be  used  in  the  next 

section to describe the implementation of a performance evaluation.  

Adapting the ElementaryWorkload Class 

In  a DBMS  context,  the ElementaryWorkload  class may  be  specialized  in DBMSWorkload  class  that 

represents a typical workload of the DBMS as illustrated in Figure 7. A DBMS workload is composed 

of  a 

transaction 

(TransactionType  class) 

that  uses  a  data  set 

(DataSet  class).  The 

ElementaryWorkload, TransactionType and DataSet classes are examples of framework hot spots that 

may  be  extended  according  to  the  application  needs.  Figure  7  illustrates  some  possible  extensions  of 

theses classes such as the TPCDataSet class that characterizes the TPC Benchmarks data sets [13] and 

the ZipfDistribution class that may be used to generate a data set using zipf distribution [20].  

Adapting the ElementaryService class 

As  we  have  observed  before,  services  allow  defining  a  logical  view  of  the  service  implementations 

independently  of  the  physical  and  organizational  aspects.  There  are  many  works  concerning 

10 

 
 

performance  analysis  of  services  either  at  large  granularity  (like  query  processing,  buffer  usage 

[1,2,3,5,6,11,15])  or  at  low  granularity  services  (as  algorithms  [9]).  Thus,  we  have  extended  the 

ElementaryService  class  with  the  DBMSService  class  (Figure  6)  including  some  typical  DBMS 

services. This class can be extended with another kind of services. 

E l em en ta rySe rvi ce

DBM SS ervi ce

E l em en ta ryWo rkl o ad

DBMSWo rkl o ad

Da taSe t

T ra nsa cti onT ype

Qu e ryMa nage r

Bu f fe rM anag e r

S to rageM an age r

T PCDa taSe t

Da taSkew Ge ne ra tor

Bu l kT ra ns Qu eryT ran s

Figure 6 - Service Hierarchy 

 

 

 

Norm a l Di stri bu ti o n

Un i formDi stri b u ti on

Zi p fDi stri b u ti on

Figure 7 - Workload Hierarchy 

 

Adapting the ElementarySI class 

In  our  framework,  we  have  divided  the  ElementarySI  class  as  platform  components,  DBMS 

components  and  algorithms  (see  Figure  8),  that  respectively  correspond  to  the  PlatformComponent, 

DBMSComponent  and  Algorithm  classes.  The  PlatformComponent  class  represents  the  external 

components  from  the  DBMS  in  contrast  to  the  DBMSComponent  class  that  describes  the  internal 

DBMS  components.  We  have  specialized  in  the  SOComponent  class  representing  the  memory 

hierarchy. The DBMSComponent class specialization will depend on the DBMS components we want 

to investigate in the performance evaluation.  

The  Algorithm  class  has  been  specialized  for  DBMS  algorithms  purposes.  An  algorithm  is 

represented  by  the  DBMSAlgorithm  class  that  is  composed  of  algorithm  components.  We  have 

defined  the  algorithm  component  as  a  sequence  of  operations  (read,  write,  etc),  data  structures  (list, 

B-tree,  etc)  and  reference  patterns.  The  reference  pattern  clarifies  how  a  set  of  algorithm  operations 

manipulates  a  specific  structure  because  it  influences  the  algorithm  performance.  Also,  we  have 

expressed  the  data  distribution  and  data  volume  through  the  DataSkew  and  DataVolume  attributes 

11 

 
 

because  the  algorithm  performs  changes  according  to  these  two  factors,  for  example  some  of  the 

currently most useful algorithms (e.g., sample sort, block radix) are dependent on the data distribution 

[4]. 

The  PlatformComponent-Algorithm  division  aims  at  describing  the  service  implementations 

according  to  different  grades  of  granularities.  Besides,  the  division  of  the  algorithm  in  sub-parts 

permits  us  to  compare  the  structure  of  several  algorithms  at  different  levels  of  granularity.  The 

granularity  level  that must be used on  the framework depends on the performance analysis’  goals: for 

example,  if  we  analyze  the  impact  of  a  new  buffer  replacement  algorithm,  we  have  to  define  the 

algorithm  service  implementations  and  compare  different  implementations.  However,  if  we  want  to 

identify  some  service  performances  or  possible  bottlenecks,  we  only  need  to  describe  services.  An 

important  aspect  of  our  framework  is  that  we  can  progressively  refine  it  using  different  levels  of 

granularity to obtain more details of DBMS behavior. 

E l em en ta rySI

P l a t form Com po ne n t

DBMSCom po ne n t

A l go ri thm

SO Co m po ne nt

DBMSA l go ri t hm

i s  comp os ed  by

DBMSA l go ri thmCompo ne n t

P rocessor

S to rag e

Re fere ncePa t tern

Da taSt ruc ture

1 ..n1 ..n

1 ..n
1 ..n

1 ..n1 ..n

1 ..n1 ..n
A l g ori thmOpe ra t i on

CPU

Memory

Cache

Prima ry

Secon da ry

Te rti ary

Ca ch eL 1

T LB

Ca che L2

Di sk

Figure 8 - Service implementations 

 

 

12 

 
 

4. Cache Performance Analysis – DeWitt Model 

To  describe  the  use  of  our  framework,  we  will  apply  it  to  [1],  a  performance  analysis  over  cache 

operation, and show how to instantiate our framework to implement this evaluation.  

In  [1],  the  authors  study  the  impact  of  a  new  type  of  data  page  layout  (PAX,  which  fits  better  the 

memory  cache)  on  query  execution  time.  The  proposal  is  validated  by  a  comparison  of  three  data 

page  layouts  (PAX,  NSM  [22]  and  DSM  [21]). Measurements  have  been  done  on  a  specific  storage 

manager and demand the implementation of the three page layouts.  

The  experiments  aimed  at  validating  data manipulation  algorithms  such  as  insert,  update,  delete  and 

two  query  operators:  scan  and  join.  Experiments  were  conducted  on  a  specific  platform  with 

identified  characteristics.  The  workload  consisted  of  one  relation  (TPC-H  fashion)  and  variations  of 

the  range  selection  query.  The  methodology  to  collect  the  experimental  measures  was  made  by 

reading two counters provided by one processor tool. 

We show in  that Section  that our application framework can help build the performance model. Also, 

we  aim  at  demonstrating  the  advantage  of  following  an  implicit  methodology  derived  from  the 

framework  instantiation  process.  Consequently,  the  designer  has  to  follow  a  four  step  process  to 

instantiate the framework: 

1.  Extend the framework hot spots; 

2.  Describe the DBMS algorithms; 

3.  Create scenarios; 

4.  Define the cost formulas. 

Below we  describe  each  step  showing how  to derive  the  framework  into  a  concrete  architecture. Due 

to  space  limitations, we  do  not  provide  exhaustive  details  and  restrict  the  presentation  to  the  specific 

scenario of range selection queries on a memory-resident relation. 

4.1. Step 1 – Extending the framework hotspots 

In  this  first  step,  we  must  re-examine  and  concretize  the  hotspots  defined  in  the  framework,  which 

are: workloads, services and service implementations. Generally, a hotspot is made of abstract classes 

13 

 
 

that  must  be  specialized  in  concrete  classes  [8].  However,  there  are  some  hotspots  that  are  made  of 

concrete classes, so that we can specialize these classes or use them as they are.   

The implementation used in DeWitt ’ s work is made specifically using an appropriate storage manager 

(SHORE).  Thus,  there  is  no  need  to  define  other  DBMS  services  (This  peculiarity  shows  another 

advantage  of  the  framework:  the  possibility  of  modeling  only  the  important  services  we  want  to 

evaluate).  This  approach  is  fundamental  in  order  to  generate  a  performance model  that  is  not  biased 

from specific proper implementations. Consequently, we define: 

the  storage  management  service  as  shown  in  Figure  9(a)  and  extend  it  to  represent  specifically  the 

SHORE storage service 

a  class named SHOREStorageComponent  that  symbolizes  the  service  implementation  responsible  for 

receiving a query and execute it in the SHORE storage manager (Figure 9(b)). 

the workload (PAXWorkload class, Figure 9(c)) that will trigger this service is composed of a range of 

select queries executing (RangeSelectQuery class) over a table created specially for the test, which we 

call PAX_Table.  

 

Elem en tarySe rvice

DBMSSe rvi ce

StorageManagem ent

SHOREStorageSe rvice

 

(a) 

ElementarySI

DMSCom ponent

SHOREStorageCom ponent

 

 (b) 

T ransact i onT ype

RangeSe l ectQue ry

Da taSe t

PAX_T ab l e

 

DBMSWorkl oad

PAXWo rkl oad

(c) 
Figure 9 – PAX DBMS Work, Service and Service Implementation 
 

14 

 
 

We must also declare the platform components that are necessary for the performance context such as 

cache,  CPU  and  memory.  For  example,  the  type  of  machine  (Dell  6400  PII  Xeon/MT),  the  cache 

features and the main memory capacity could be modeled by a class specialization shown in Figure 8. 

4.2. Step 2 – Defining the DBMS algorithms 

This  step  is  only  mandatory  if  you  investigate  a  specific  pre-determined  algorithm.  In  such  case, we 

have  to  specify each algorithm detailing all  internal  service  implementations  such  as  operations,  data 

structures and reference pattern. 

Concerning  DeWitt ’ s  work,  the  relevant  DBMS  algorithm  concerns  the  storage  manager  service 

related  to  the  task of  reading  and writing  data pages. Then, we  extend  the DBMSAlgorithm  class and 

define the AlgorithmDataStorage subclass (Figure 10). For each type of data page layout (PAX, NSM 

and DSM) we create a new specialized class and define its data structures and its operations (read and 

write).  

4.3. Step 3 - Creating Scenarios  

The  definition  of  scenarios  can  be  made  at  design  time  or  execution  time,  respectively  by  the 

performance  designer  during  the  instantiation  of  framework,  or  the  user  of  the  performance  tool 

during  the  execution  of  the  evaluation  performance.  These  approaches  depend  on  the  type  of 

performance  tool  we  want  to  build.  For  example,  the  definition  of  the  scenario  during  the  execution 

needs the construction of a complex user interface that must manipulate diverse hierarchies. 

 

 

DBMSA l go ri thm

A l go ri thm Da taS to rag e

PAXA l g

NSMA l g

DSM A l g

 
Figure 10 - PAX Algorithms 

15 

 
 

 

 

 

 

// Method of PAXScenario class 

void configure ( ) { 

PAXWorkload pw = new PAXWorkload(PAX_Table , RangeSelectTable); 

SHOREStorageService sss = new SHOREStorageService(); 

sss.addComponent(new SHOREStorageComponent()); 

NSMAlg nsm = new NSMAlg(); 

DSMALg dsm = new DSMAlg(); 

PAXAlg pax = new PAXAlg(); 

sss.addComponent(new GroupSI(nsm,dsm,pax, new exclusive( )); 

 

} 

Figure 11 - Configure PAX Scenario 

For  each  scenario  that  we  want  to  evaluate,  we  have  to  describe  a  concrete  class  that  extends  the 

Scenario abstract class. Each extended class will implement the configuration of the specific scenario 

describing  workload,  service  implementation  and  service  configuration  (Figure  11  -  Configure  PAX 

Scenario). Then, we implement the configure method of each scenario. This implementation describes 

a  particular  configuration  through  the  instantiation  of Workload,  Service  and  ServiceImplementation 

classes already defined in the first step.  

In  our  example, we want  to  create  the DWScenario  class, which makes  a  comparison  between PAX, 

DSM  and  NSM.  In  this  case,  Service  is  limited  to  the  storage  service  and  modeled  as  a  subclass  of 

DBMSService  class  (called  SHOREStorageService).  The  corresponding  service  implementation  is 

modeled  as  the  SHOREStorageManager  class  (Figure  9  –   PAX  DBMS  Work,  Service  and  Service 

Implementation(b))  that  is  a  subclass  of  the  StorageManager  class  (an  elementary  service 

implementation). The workload is modeled by the SHOREWorkload class. 

Then  it  is  necessary  to  associate  each workload with  the  service  that  it  triggers and,  for each  service, 

the  corresponding  service  implementation.  The  code  fragment  bellow  (Figure  11  -  Configure  PAX 

Scenario) illustrates the implementation of the configure method of the DWScenario class. 

16 

 
 

4.4. Step 4 – Defining metrics models 

The  metrics  model  is  essential  for  the  framework  instantiation  because  it  defines  the  cost  formulas 

associated with  workload,  service  and  service  implementation  elements.  These  formulas  are  used  by 

the  system  to  evaluate  the  performance,  permitting  the  comparison  between  different  executions  of 

scenarios.  As  presented  in  Figure  4,  formulas  are  regular  expressions  and  we  can  extend  the 

Expression  class  to  represent  a  wide  variety  of  functions  that  are  needed  to  create  the  performance 

model.  In  DeWitt ’ s  work,  the  formulas  presented  are  simple  sum  expressions  that  calculate  the 

execute  query  time.  The  formula  used  is:  Tq  =  Tc  +  Tm  +  Tb  +  Tr  –   Tovl,  where  Tq  is  the  time  to 

execute a query.  

As 

 

shown 

in 

Figure 12, the variables  that will be used by composing the cost formulas are created as extensions of 

the Variable class. Their values are collected from the processor execution via a proprietary program. 

We  show  below  how  to  implement  the  external  program  call.  Moreover,  we  capture  program 

variables  to  fill  up  the  cost  formulas.  Figure  13  shows  how  to  implement  the  formula  in  the 

configuring method of the Scenario class. We can see  that  the CacheMiss and StallTime variables are 

used by Mult and Sum classes to create the expression objects. 

Variable
(f rom  Perf ormance Model)
name

CacheSize

CacheMiss

Cache No n
Block

MemoLat enc y

CacheAs s
oc it iv ity

CacheWrite
Polic y

CacheMis sOutStading

StallTme

 

 

Figure 12  –  Variable Especialization 

17 

 

 
 

void configure ( ) { 

   … 

   Expression TL1D = new Mult (CacheMiss, 4); 

   Expression TL1I = StallTime; 

   … 

   Expression TM = new Sum(TL1D,TL1I,…); 

   … 

   Expression TQ = new Sum(TC,TM,TB,…);    

} 

Figure 13 - Formula Codification 
 
An  interesting  characteristic  of  DeWitt ’ s  work  is  that  the  measurement  of  system  behaviors  is made 

outside  of  DBMS  by  an  appropriate  program,  even  though  the  implementations  were  made  into  the 

DBMS. This  approach  is  consistently  justified  since  the  objective  is  to  study  the  cache  performance, 

which  is  managed  by  the  computer  processor.  In  such  case,  the  best  cache  information  is  naturally 

collected directly from the processor via a specific program. This is achieved in our framework by the 

implementation of  the  evaluate method.  In  the  case of DeWitt,  it  is done  by  programming  the  access 

to  the  external  resources  in  the  evaluate  method  of  SHOREStorageManager  (Figure  9)  and  CPU 

classes  (Figure  8). Figure  14  is  shows  the  evaluate method  of  the  SHOREStorageManager  class  that 

connects  with  SHORE  and  executes  a  query.  Figure  15  shows  the  call  to  the  external  program  to 

collect the processor measurements and the variable assignment.  

 

// SHORE Storage Manager class 

// CPU class 

void  evaluate ( … ) { 

void  evaluate ( … ) { 

    … 

    … 

   connect( login, pass); 

   Execute_Program ( ); 

   Execute_Query (tx); 

   data = CollectData( ); 

   Disconnect( ); 

Scenario.setVariable(data); 

   …  

} 

    …  

} 

18 

 
 

Figure 14 - Executing Transaction on 
SHORE 

Figure 15 - Executing Processor 
Program 

5. Conclusions 

In  this  article,  we  proposed  generic  application  framework  architecture  to  achieve  a  quantitative 

performance evaluation on DBMS.  

This  framework  is  based  on  five  basic  abstractions  of  performance  analysis:  scenarios,  workload, 

service, service  implementation and metrics. The relationships between  these  abstractions  fit well  the 

representation  of  a  complex  multi-layered  architecture.  Some  extensions  of  the  model  for  DBMS 

have also been proposed.  

Thus,  our  framework  is  associated  with  a  methodology  that  guides  the  designer  of  a  performance 

evaluation  study  to  achieve  his/her  goals  and  to  produce  a  concrete  evaluation  platform.  We  have 

demonstrated  this  final characteristic on a  recent data  page  layout  study  [1]. We  have  shown  that  our 

framework also permits making comparison evaluations between alternative service implementations.   

We  believe  that  such  a  framework  should  provide  some  interesting  benefits  to  achieving  the 

following goals:  

• 

• 

capturing performance requirements within the design of performance context; 

executing  external  applications  in  order  to  collect  measures  and  integrate  the  performance 

analysis with disconnected service implementations; 

•  Specifying metric models for the workloads, services and service implementations. 

Further  studies have  to be  done. As we  have  noted  in  Section  2,  our work  is  partly  inspired  on UML 

profiles  and  a  deeper  study  on  how  that  model  and  our  framework  could  complement  each  other 

would be interesting. Moreover, since the UML profile is dedicated to modeling any kind of software, 

it would  be  interesting  to evaluate how generic our framework  is and  to  study  if  it can  be  specialized 

for other complex software domains. 

 

19 

 
 

References 
 
1.  Ailamaki, A.; DeWitt, D.; Hill, M; Skounakis, M.; Weaving Relations for Cache 
Performance; The {VLDB} Journal, p.169-180; 2001. 
 
 
 
2.  Ailamaki, A.; DeWitt, D.; Hill, M.; Wood, D.;DBMS on modern processors: Where does 
time go ?; International Conference on Very Large Databases (VLDB); 1999. 
3.  Boral, B.; DeWitt; D.; A Methodology for Database System Performance Evaluation; 
Technical Report; University of Wiscosin; 1983 
4.  G. Blelloch et al. A Comparison of Sorting Algorithms for the Connection Machine CM-2. 
Symposium on Parallel Algorithms and Architectures, Hilton Head, SC. 3-16, July 1991. 
5.  Boncz, P.; Manegold, S.; Kersten, M.; Database Architecture Optimized for new Bottleneck: 
Memory Access; International Conference on Very Large Databases (VLDB); 1999. 
6.  Cha, S.; Sangyong, H; Kim, K.; Kwon, K.; Cache-Conscious Concurrency Control of Main-
Memory Indexes on Shared-Memory Multiprocessor Systems; International Conference on 
Very Large Databases (VLDB); 2001. 
7.  Site visited in april 27th 2004: http://www.embarcadero.com/resources/tech_papers/ 
WhatPerformanceDoINeed_6_6.pdf 
8.  M. Fayad, D. Schmidt, R. Johnson. Building Application Frameworks: OO Foundations of 
Framework Design. John Wiley and Sons, 1999. 
9.  Christos Faloutsos, Raymond T. Ng, Timos K. Sellis: Flexible and Adaptable Buffer 
Management Techniques for Database Management Systems. IEEE Transactions on 
Computers 44(4): 546-560 (1995). 
10.  Gamma, E. ; Helm,  R.; Johnson, R.; Vlissades J.; Design Patterns: Elements of Reusable 
Software Architecture. Addison-Wesley, 1995.  
11.  Manegold, S.; Boncz, P.; Kersten, M.; What happens during a Join ? Dissecting CPU and 
Memory Optimization Effects; International Conference on Very Large Databases (VLDB); 
2000. 
12.  Site visited in april 26th 2004: http://otn.oracle.com/products/rdb/pdf/rdb_7105_on_ev56.pdf 
13.  Site visited in april 27th 2004: http://www.tpc.org/ 
14.  Object Management Group: UML Profile for Schedulability, Performance and Time. OMG 
Document ad/2001-06-14,http://www.omg.org; 2004. 
15.  Zhou, J.; Ross, K; Buffering Access to memory-resident index structures; International 
Conference on Very Large Databases (VLDB); 2003. 
16.  Dikaiakos, M.; Samaras, G.; A performance Analysis Framework for Mobile-Agent Systems; 
Workshop on Infrastructure for Scalable Multi-Agents Systems  (ICAA); 2000. 
17.  Site visited in may 17th 2004:http://encyclopedia.thefreedictionary.com/Software+component 
18.  Boral, H.; DeWitt, D.; A Methodology for Database System Performance Evaluation; 
Proceedings of the 1984 SIGMOD Conference, June, 1984. 
19.  Petriu, D.;  Shen, H.;Applying the UML Performance Profile: Graph Grammar based 
derivation of LQN models from UML specifications; in Computer Performance Evaluation - 
Modelling Techniques and Tools, (Tony Fields, Peter Harrison, Jeremy Bradley, Uli Harder, 
Eds.) Lecture Notes in Computer Science 2324, pp.159-177, Springer Verlag, 2002. 
20.  Site visited in may 17th 2004:http://linkage.rockefeller.edu/wli/zipf/ 

20 

 
 

21.  Copeland, G.; Khoshafian, S.; A decomposition storage model; in Proceedings of ACM 
SIGMOD Conference, pages 268-279, 1985. 
22. Ramakrishnan, R.; Gehrke, J.; Database Management Systems; McGraw-Hill; 2 edition, 
2000. 

21 

International Journal of Database Management Systems ( IJDMS ) , Vol.2, No.2, May 2010

A DBMS FOR MOB ILE TRAN SACT ION S U S ING
B I -STATE -TERM INAT ION

Sebastian Obermeier1 and Stefan Böttcher2

1 ABB Corporate Research, Industrial Software Systems, Segelhofstr. 1K, Baden, Switzerland
sebastian.obermeier@ch.abb.com
2 University of Paderborn, Fürstenallee 11, 33102 Paderborn, Germany
stb@uni-paderborn.de

ABSTRACT
Whenever distributed transaction processing in MANETs or other unreliable networks has to guarantee
atomicity and isolation, a major challenge is how long-term blocking of resources can be avoided in case
the mobile device looses connection to other participants of the transaction. We present a new technique
for treating blocked data of transaction participants that wait for a coordinator’s commit decision. Our
technique, Bi-State-Termination (BST), gives participants that have moved during transaction execution the
possibility to continue transaction processing before they know the coordinator’s decision on transaction
commit. The key idea of our technique is to consider both possible outcomes (commit and abort) of unknown
transaction decisions. Within this paper, we describe a fast implementation of the fundamental relational
database operations for a DBMS supporting the BST transaction synchronization protocol that avoids long-
term transaction blocking.

KEYWORDS
Mobile Database Transaction Processing, Transaction Blocking, Bi-State-Termination

1 .
INTRODUCT ION
With growing interest in mobile ad-hoc networks and increasing capabilities regarding processing power
and connectivity, an interesting and important challenge is to combine database technology with mobile
devices. However, a transfer of traditional research results to mobile devices is hindered by problems like
message loss, unpredictable disconnections of mobile devices, and network partitioning. When applying
database technology that was designed for traditional ﬁxed-wired networks in such mobile environments,
the problem of long or even inﬁnitely long blocking times for commonly accessed resources arises. For
instance, a message that releases blocked resources may never reach its destination and leads to blocking of
resources longer than intended.
It would
Traditional transaction processing is unsuitable for such a scenario for the following reason.
prevent participants that have moved during the atomic commit protocol execution and therefore have not
received the transaction’s commit decision from using parts of their own data in concurrent transactions.
In mobile networks, there is no guarantee that these moved participants will ever receive the transaction’s
decision. Therefore, traditional transaction processing would cause resources to be unusable for an inﬁnitely
long period of time.

1.1. Problem Description
Atomic commit protocols (ACPs) like 2-Phase-Commit (2PC, [9]), 3-Phase-Commit (3PC, [22]), and con-
sensus based protocols (Paxos Consensus, [10]) are used to guarantee an atomic execution of distributed

10.5121/ijdms.2010.2209

141

International Journal of Database Management Systems ( IJDMS ) , Vol.2, No.2, May 2010

transactions in ﬁxed wired networks. However, when transaction support is required for mobile ad-hoc
environments, problems like network partitioning, node disconnection, and node movement may lead to the
case where databases do not receive the atomic commit protocol decision and block. According to [18], we
can distinguish two kinds of blocking:

Deﬁnition 1 Atomic commit protocol blocking occurs, if during an execution of an atomic commit protocol
for a transaction T , an arbitrary sequence of failures leads to a situation where the atomic commit protocol
instance cannot terminate with a unique commit or abort decision d.

Several proposals, e.g. [10, 20], tackle the problem of atomic commit protocol blocking by using multiple
coordinators. Therefore, we do not focus on the problem of protocol blocking.

Deﬁnition 2 Transaction Blocking: A transaction T is blocked, after a database proposed to execute T (e.g.
by sending a voteCommit message) and waits for the ﬁnal commit decision, but is not allowed to abort or
to commit T unilaterally on its own.

Transaction blocking summarizes the unilateral impossibility to abort or commit a transaction, but does
not mean that a transaction U waits to obtain locks from a concurrent transaction, since in this case U can
be aborted by the database itself. Even time-out based approaches (e.g. “my commit vote is valid until
3:23:34”) cannot solve the problem of transaction blocking, since this would fulﬁll the requirements of the
coordinated attack scenario [9], in which a commit decision is not possible under the assumption of message
loss.
The problem of inﬁnite transaction blocking for a transaction T occurs, if a database has sent a voteCommit
message on T , but will never receive the ﬁnal commit decision, e.g. due to disconnection, movement, or
network partitioning. Whenever the database can still communicate, e.g. with the user, the blocked data of
T will prevent concurrent and conﬂicting transactions U from being processed.

1.2. Contributions
The main contributions of this paper are:
• It describes BST, a transaction termination mechanism for mobile transactions in unreliable environ-
ments that solves the inﬁnite transaction blocking problem, i.e. each database maintains control of
its resources during the whole transaction execution.
• It outlines how and proves that BST in combination with 2-Phase-Locking [8] guarantees serializ-
ability and atomicity.
• We give experimental results that demonstrate the feasibility of Bi-State-Termination in environ-
ments where the commit decision may get lost.
Beyond our previous contributions [18, 19], this paper further
• outlines how recovery from database main memory failures can be done with BST, and how BST
can be used as a log book,
• describes three BST implementations, one being a complete in-memory solution, one being a disk-
base solution, and one focusing on processing speed,
• outlines implementation details of the fastest variant regarding read and write operations,
• describes an evaluation comparing the presented BST implementations regarding transaction pro-
cessing time in case of blocked transactions.

2 . TRAN SACT ION MODEL
BST is a protocol that can be applied to databases that participate in an atomic commit protocol independent
of whether or not the other databases that also participate in the same global transaction use the same BST
protocol.
During the execution of a transaction, a database enters the following phases: the read-phase, the commit
decision phase, and, in case of successful commit, the write-phase. While executing the read-phase, each
transaction invokes necessary sub-transactions and carries out write operations on its private transaction
storage only. During the commit decision phase, the participating databases use an atomic commit protocol
to decide on the transaction’s commit decision. During the atomic commit protocol, participants vote for

142

International Journal of Database Management Systems ( IJDMS ) , Vol.2, No.2, May 2010

voteRequest

doCommit

result /
locks acquired

read
phase
abor t possible

voteCommit

write
phase
time

BST possible

Figure 1. 2PC Transaction Execution

“commit” or “abort”. A database that voted for “commit” is not allowed to abort or commit the transaction
on its own until it has received the coordinator’s commit decision. A participant that voted for “abort” can
immediately abort the transaction, which means, the database must restore a state that is equal to a situation
in which the transaction has never been executed, i.e. all changes caused by the aborted transaction must be
rolled back.
If the transaction’s outcome commit decision, which can be either commit or abort, is commit, the database
executes the sub-transaction’s write phase. During this phase, the private transaction storage is transferred
to the durable database storage, such that the changes done throughout the read-phase become visible to
other transactions after completion of the write-phase. If the outcome is abort, all involved databases abort
their corresponding sub-transactions.
Deﬁnition 3 Two operations Oi and Oj conﬂict ⇐⇒ ∃ tuple t ∃ attribute a : (Oi accesses t.a
∧ Oj accesses t.a ∧ ((Oi writes t.a) ∨ (Oj writes t.a)))

Deﬁnition 4 A transaction Tj depends on Ti if and only if on a database D at least one operation Oi of Ti
conﬂicts with an operation Oj of Tj , and Oi precedes Oj .

Deﬁnition 5 The serialization graph of a set of transactions contains the transactions as nodes and a di-
rected edge Ti → Tj for each pair (Ti , Tj ) of transactions for which Tj depends on Ti .

Deﬁnition 6 Serializability requires the serialization graph of all committed transactions to be acyclic.

Deﬁnition 7 Assume a database in state S0 executes a transaction Ti . Then, we call ResultTi (S0 ) the
result value that the databases returns after ﬁnishing the read phase of Ti .

Above the time line, Figure 1 shows the standard application of 2PC for a distributed transaction Ti when a
locking mechanism like 2-Phase-Locking [8] is used for transaction synchronization. Below the time line,
Figure 1 illustrates the possible database reactions in case the database does not receive expected messages
after a timeout. As long as the database has not voted for commit, it can still abort Ti and release the locks.
Different from traditional 2PC, Bi-State-Termination (BST) allows a database to terminate a transaction
even after the commit vote has been sent and before a doCommit or doAbor t command has been received.
The transaction execution shown in Figure 1 involves two messages showing that the so-called lock point
was reached: Both the voteRequest message and the doCommit message indicate that all databases have
obtained all necessary locks. However, for the purpose of ensuring serializability, it is only necessary to
reach this lock point once, as atomic commit protocol optimizations like “unsolicited vote optimization”
[23] show.
As the transaction sequence is ﬁxed after the voteRequest message has been received by each database,
serializability is guaranteed. In other words, serializability does not require to hold any lock longer than
until the database receives the voteRequest command. However, for ensuring strictness, i.e. to guarantee
recoverability and to avoid cascading aborts, each database must hold all locks until the doCommit message
is received and the write phase has been ﬁnished. Unfortunately, if the doCommit message is lost or cannot
reach a database, the database must hold the locks and cannot abort the transaction on its own, which
however, is possible before the vote for commit message has been sent.
In the remainder of this section, we develop a solution that not only unblocks and processes concurrent and
depending transactions if the commit decision cannot be received by a database for a longer period of time.
Our solution, which is called Bi-State-Termination (BST) of a transaction Ti , also guarantees atomicity.

143

International Journal of Database Management Systems ( IJDMS ) , Vol.2, No.2, May 2010

The main idea of BST is that if the coordinator’s decision for a transaction Ti is delayed, a concurrent
transaction Tc depending on Ti can be processed by transferring the required locks from Ti to Tc , and then
by executing Tc on two database states: one state having Ti committed, the other state having Ti aborted.
However, it is the database’s choice whether or not and after which timeout it applies BST.
We want to achieve that all transactions belonging to a distributed global transaction are executed in an
atomic fashion, and that each concurrent execution of different distributed global transactions is serializable,
i.e. the execution produces the same output and has the same effect on the databases as some serial execution
of the same distributed global transactions.

Deﬁnition 8 Assume that a database is in a state S0 that has been created by some previous transactions
before the write phase of Ti is executed. Assuming no concurrent transaction has changed the database state
while Ti is executed, we call the database state that is caused by the write phase of Ti the state STi . Let
Ti consist of the sequence of operations Oi1 , Oi2 , . . . , Oin . When this sequence of operations is applied to
the database, we call the changes that have been made by the operations the delta of the transaction Ti . We
write ∆Ti (S0 ) if the sequence of operations Oi1 , . . . , Oin is applied on the database state S0 . When Ti has
been committed, the result of applying ∆Ti to the database state S0 becomes visible for other transactions,
thus we get the new database state STi , for which we write STi = S0 ⊕ ∆Ti (S0 ).

Note, that when a transaction Ti , which, for example, increments integer values, is executed on two different
database states S0 and S1 , the transaction execution can lead to different deltas ∆Ti (S0 ) and ∆Ti (S1 ).
However, when Ti does not include branches or loops, the sequence of operations remains the same for all
executions.

Lemma 9 Assume a database is in state S0 , a transaction Ti is executed, and a concurrent transaction Tj is
started, but Ti does not depend on Tj and vice versa. Therefore, the changes of transaction Tj do not affect
the execution of the transaction Ti . The equations

∆Tj (S0 ) = ∆Tj (STi ) and ∆Ti (S0 ) = ∆Ti (STj )

hold, which means that the modiﬁcations of a transaction Tj are independent of any previous modiﬁcation
of a non-dependent transaction Ti and vice versa.

Proof Assume the database state before the execution of Ti and Tj is S0 .

Tj does not depend on Ti and
Ti does not depend on Tj
⇐⇒ ∀ tuple t ∀ attribute a (¬Oi accesses t.a
∨¬Oj accesses t.a ∨ (Oi reads t.a ∧ Oj reads t.a))
(follows from Def. 3 and 4)
=⇒ S0 ⊕ ∆Ti (S0 ) ⊕ ∆Tj (STi )
= Ojn (. . . Oj2 (Oj1 (Oin (. . . Oi1 (S0 )))))
= Oin (. . . Oi2 (Oi1 (Ojn (. . . Oj1 (S0 )))))
=⇒ (cid:0)∆Tj (S0 ) = ∆Tj (STi )(cid:1) ∧ (∆Ti (S0 ) = ∆T (STj ))
(since operations do not conﬂict)
= S0 ⊕ ∆Tj (S0 ) ⊕ ∆Ti (STj )
Therefore, whenever a set BT of transactions is blocked, the result of a transaction T may only be inﬂu-
enced by those transactions DBT ⊆ BT on which T is dependent.

3 . SOLUT ION
In the following, we focus on the question:

What can a database D executing a transaction Ti that is blocked do, when a concurrent
transaction Tc requests access to data tuples accessed by Ti in a conﬂicting way.

One proposed solution to answer this question can be found in standard literature for databases, and is quite
simple: Let Tc wait until Ti has released its locks and is completed. However, during the waiting, the

144

International Journal of Database Management Systems ( IJDMS ) , Vol.2, No.2, May 2010

S0
WWWWWWWWWWWWWWWWWWWW
gggggggggggggggggggg
Ti aborts
Ti commits
S0 ⊕ ∆Ti (S0 )
S0
OOOOOOOOOOO
OOOOOOOOOOO
ooooooooooo
ooooooooooo
Tc commits
Tc aborts
Tc commits
Tc aborts
S0 ⊕ ∆Tc (S0 )
S0 ⊕ ∆Ti (S0 ) S0 ⊕ ∆Ti (S0 ) ⊕ ∆Tc (STi )
S0
Figure 2. Possible database states if Tc depends on Ti , and Ti blocks

Level 0

Level 1

Level 2

number of transactions that wait concurrently may increase if the blocking continues. Furthermore, if Tc is
a distributed transaction too, this may cause further transactions to wait on other databases, too. Another
possibility is to abort the concurrent transaction Tc . Although correct, this behavior is not satisfying.
Our solution called Bi-State-Termination is based on the following observation: Whenever transaction
blocking occurs, the database does not know whether a transaction Ti waiting for the commit decision will
be aborted or committed. However, only if the transaction is committed, the database state changes. Let S0
denote the database state before Ti was executed. Although the database does not know the commit deci-
sion for Ti , it knows for sure that either S0 or S0 ⊕ ∆Ti (S0 ) is the correct database state, depending on the
commitment of Ti . Figure 2 shows these two possible states in the tree. With this knowledge, the database
can try to execute a concurrent transaction Tc that depends on Ti on both states S0 and S0 ⊕ ∆Ti (S0 ).
Whenever the two executions of Tc on S0 and on S0 ⊕ ∆Ti (S0 ) return the same results to the Initiator,
i.e. ResultTc (S0 ) = ResultTc (STi ), Tc can be committed regardless of Ti , even though Tc depends on
Ti . Otherwise, it is the application’s choice whether it handles two possible transaction results. However,
since Tc depends on Ti , we might have ∆Tc (S0 ) (cid:54)= ∆Tc (STi ). Therefore, the database must store both
deltas ∆Tc (S0 ) and ∆Tc (STi ), and if Tc commits before Ti is committed or aborted, the database knows
that either the state S0 ⊕ ∆Tc (S0 ) is valid, or the state S0 ⊕ ∆Ti (S0 ) ⊕ ∆Tc (STi ) is valid.
Figure 2 shows the execution tree different of a different situation, i.e. with both Ti and Tc being blocked.
The leaves represent the database states that may be valid depending on the decisions for the blocked
transactions Ti and Tc .

3.1. Bi-State-Termination
Let Σ = {S0 , . . . , Sk } be the set of all legal possible database states for a database D . A traditional
transaction Ti is a function Ti : Σ (cid:55)→ Σ, Sa → Sb , which means the resulting state Sb of Ti depends only
on the state Sa on which Ti is executed.
A Bi-State-Terminated transaction Ti is a function BST : 2Σ (cid:55)→ 2Σ ,
(cid:123)(cid:122)
(cid:125)
(cid:124)
(cid:123)(cid:122)
(cid:125)
(cid:123)(cid:122)
(cid:125)
(cid:124)
(cid:124)
→ {Si , . . . , Sj }
∪ {Ti (Si ), . . . , Ti (Sj )}
{Si , . . . , Sj }
Initial States
Ti commits
Ti aborts
that maps a set ΣInitial ⊆ Σ of Initial States to a super set ΣInitial ∪ {Ti (Sx )|Sx ∈ ΣInitial } of new states,
where Ti (Sx ) is the state that is reached when Ti is applied to Sx .
This concept of Bi-State-Termination leads to the following commit decision rules for the transaction exe-
cution of a transaction Ti on a database DB :
DB checks Ti ’s dependencies on concurrent blocking transactions. The following situations may occur: Ti
is independent of all currently blocked transactions. Then, Ti can be executed immediately.
Otherwise, Ti depends on a set {T1 . . . Tn} of blocked transactions. As Ti depends on each of the trans-
actions {T1 . . . Tn}, each of them has reached its lock point before Ti . Thus, for any concurrent execution
of {T1 . . . Tn}, there is an equivalent serial execution ESE of {T1 . . . Tn}. As ESE only has to reﬂect the
order in which transactions leave the lock point, ESE can always be constructed, as described below. Thus,
serializability is guaranteed for {T1 . . . Tn}. Then, DB can Bi-State-Terminate the transactions {T1 . . . Tn},
i.e. DB can execute the transaction Ti on all possible combinations of abort and commit decisions of the
transactions {T1 . . . Tn} in ESE .
The serializable sequence ESE of the transactions {T1 . . . Tn}, on which Ti is executed, must obey the
following conditions. For each pair (Tj , Tk ) of the transactions for which a dependency Tj → Tk exists, Tj
left its lock point before Tk left its lock point. However, in order to execute the transaction Tk that depends

145

International Journal of Database Management Systems ( IJDMS ) , Vol.2, No.2, May 2010

on the blocked transaction Tj , the transaction Tj must have been Bi-State-Terminated. In this case, Tj has
completed all of its operations before Tk has started. Thus, Tj is executed before Tk within ESE .
Note that if there is no dependency Tj → Tk , and no dependency Tk → Tj , the execution sequence of
the blocked transactions (Tj , Tk ) does not matter since the transactions are independent of each other, cf.
Lemma 9.
This means, the transaction Ti must at most be executed on all combinations of commit and abort decisions
for the blocked transactions T1 . . . Tn , but only on one sequence (permutation) of the transactions T1 . . . Tn .
If Ti is executed on multiple database states, this might yield to different results. Let S1 . . . S2n be the states
that can be reached by any combination of commit/abort decisions on the n transactions {T1 . . . Tn} that
are Bi-State-Terminated. If ResultTi (S0 ) = . . . = ResultTi (S2n ) holds, transaction Ti can be committed
since it has a unique result. Otherwise, the application that initiated Ti can choose whether
• it aborts Ti completely,
• it commits Ti and deals with multiple possible results,
• it aborts or commits Ti only for some commit/abort combinations of Bi-State-Terminated trans-
actions, called execution branches. For example, the application may specify that Ti should only
commit when Tk aborts, and that Ti should abort otherwise,
• it waits.
When Ti or a single execution branch of Ti commits, the database merges the corresponding delta of Ti
with the possible branch state.

Example 10 Assume Tc depends on Ti , but, different from Figure 2, Tc shall only commit when Ti
commits and otherwise abort. As illustrated in Figure 3, a commit of Tc would only involve the left-
most and rightmost branches of Figure 2. Therefore, ∆Ti (S0 ) in Level 1 of Figure 2 is replaced with
(∆Ti (S0 ) ⊕ ∆Tc (STi )) in Level 1 of Figure 3 since, in this case, a commit of Ti automatically means a
commit of Tc . Note that in this example, the commit decision for Tc is made before the decision of Ti ,
but the execution sequence is the other way round, namely Ti < Tc . Furthermore, the tree of Figure 3 is
ﬂattened one level compared to Figure 2 since only Ti is yet blocked.

S0
RRRRRRRRRRRRR
lllllllllllll
Ti commits
Ti aborts
S0 ⊕ ∆Ti (S0 ) ⊕ ∆Tc (STi ) Level 1
S0
Figure 3. Tc should commit only if Ti commits

Level 0

3.2. Complexity
lt can be seen that the complexity of the Bi-State-Termination of Ti depends on the number of blocked
transactions b, and that BST has a complexity of O(2b ) database states. However, our implemented solution
uses a compact data structure and optimizes read and write operations in such a way that each transaction
operation must only be executed once, regardless of the number of blocked transactions. Although, in the
worst case, the number of tuples may grow exponentially, standard database query optimization techniques
can be fully applied. Furthermore, a transaction still can wait instead of being executed on too many states.

3.3. Correctness
Theorem 11 Bi-State-Termination in combination with 2-Phase-Locking guarantees serializability.

Proof As our solution uses Two-Phase Locking (2PL) and 2PL is proven to guarantee serializability accord-
ing to [5], we show that Bi-State-Termination does not change the order of pairs of conﬂicting operations of
transactions given by 2PL and therefore guarantees serializability, too: Our transaction execution involves
one point, namely the lock point, where each transaction that belongs to a global transaction must hold
all locks. This means that the request to vote on a transaction T ’s commit status can only be sent by the
coordinator after all databases acquired the necessary transaction locks for their sub-transactions T1 . . . Tn

146

International Journal of Database Management Systems ( IJDMS ) , Vol.2, No.2, May 2010

of T , which each database indicates by sending the sub-transaction’s result. The sequence of transactions
is ﬁxed at that time when each transaction enters its lock point and is not changed by BST. Although Bi-
State-Termination may release locks after this lock point, the release of locks does not change the order of
comitted transactions for the following reason. A transaction Tc that gets locks from a Bi-State-Terminated
transaction Ti is either executed after Ti has been committed (Ti < Tc ) or Ti is aborted.

Note that although the commit command for Tc may be issued before the commit command of Ti , the order
of applying the transactions on the database is still Ti < Tc .

4 . BST REWR ITE RULE S
Our BST rewrite rule system modiﬁes each database relation in such a way that it gets an extra column
“Conditions” that describes for each database tuple the condition under which it is regarded as being true.
Furthermore, the database contains a single table “Rules’’ storing rules that relate these conditions to each
other.
Whenever currently active transactions insert, delete or update tuples in a relation R, whether or not a tuple
t will ﬁnally belong to R depends on the commit or abort decision of these transactions. We use a condition
in order to express which of the active transactions must commit and which must abort, such that a tuple t
ﬁnally belongs to a relation R. In our implementation, each relation R is augmented by an extra column
“Conditions” that, for each tuple t, stores the condition under which it ﬁnally belongs to R.
This can be implemented by the following rewrite rule that modiﬁes the create table command for database
relations:
create table R ( <column deﬁnitions> )
⇒ create table R’( <column deﬁnitions, string conditions>)

4.1. Status Without Active Transactions
When all transactions are completed either by commit or by abort, the column “Conditions” contains the
truth value “true” for each tuple in each relation of the database. The truth value “true” represents the fact
that the tuple belongs to the relation without any further condition about the commit status of an active
transaction.

4.2. Write Operations on the BST Model

4.2.1.
Insertion
Whenever a tuple t = (value1 , . . . , valueN ) is inserted into a relation R by a transaction with transaction
identiﬁer Ti , we implement this by inserting t(cid:48) = (value1 , . . . , valueN , Ti ) into the relation R(cid:48) , i.e.
the
database system implementation applies a rewrite rule:
inser t into R values (value1 ,. . .,valueN )
⇒ inser t into R’ values (value1 ,. . .,valueN , Ti ).
The idea behind the value Ti stored in the condition column of R(cid:48) is to show that the tuple t belongs to the
database relation R if and only if transaction Ti will be committed.

4.2.2. Deletion
Whenever a tuple t = (value1 , . . . , valueN ) is deleted from a relation R by a transaction with transaction
identiﬁer Ti , we look up the tuple t(cid:48) = (value1 , . . . , valueN , C ) ∈ R(cid:48) representing the tuple t ∈ R, where
C is the condition under which t belongs to the database relation R.
We implement the deletion of t from R by the transaction Ti by replacing the condition C found in t(cid:48) with a
condition C2 and by adding a logical rule to the table Rules stating that C2 is true if and only if C is true and
Ti is aborted. For this purpose, the database system applies the following rewrite rule, where A1 , . . . , AN
denote the values (value1 , . . . , valueN ) for the attributes of R:

delete t from R where t.A1=value1 , . . .,t.AN =valueN
⇒ update t’ in R’ where t.A1=value1 , . . .,t.AN =valueN set condition=C2 ;
inser t into rules values ( C2 , C1 and not Ti )

147

International Journal of Database Management Systems ( IJDMS ) , Vol.2, No.2, May 2010

The idea behind this rewriting is the following. (not Ti ) represents the condition that transaction Ti will
be aborted. The inserted rule states that C2 is true if C1 is true and Ti will be aborted. After the update
operation, we have a tuple t(cid:48) = (value1 , . . . , valueN , C2 ) in R(cid:48) which represents the fact that t belongs to
R if and only if C2 is true, i.e. if C is true and Ti is aborted.

4.2.3. Update
An update of a single tuple is simply executed as a delete operation followed by an insert operation.

4.2.4. Set-Oriented Write Operations
When a transaction inserts, updates, or deletes multiple tuples within a single operation, this can be imple-
mented by a collection of individual insert, update, or delete operations.

4.2.5. Completion of a Transaction
When transaction Ti is completed with commit, the condition Ti is replaced with true in each rule in the
Rules table and in each value found in the column “Conditions” of a relation R(cid:48) . However, when Ti is
completed with abort, Ti is replaced with false in each rule found in the Rules table, and each tuple of R(cid:48)
containing the value Ti in the column “Conditions” is deleted.
Furthermore, rules that contain the truth value true or false are simpliﬁed. Whenever this results in a rule
(C , true) or in a rule (C , false), then C itself is replaced with the value “true” or “false” respectively. Other
rules that contain C are simpliﬁed as well. Furthermore, all tuples t(cid:48) in which C occurs are treated as
follows. If the rule is (C , true), the value C is replaced with true in each tuple t(cid:48) in which C occurs in
the column “Conditions”. However, if the rule is (C , false), each tuple t(cid:48) in which C occurs in the column
“Conditions” is deleted. Finally, rules (C , true) or (C , false) are deleted from the relation Rules.

Example
Consider a database with a relation R that only consists of the attribute “Name” and initially stores only
a single data record with the value “Mitch”. On R, the database executes the sequence T1 < T2 < T3 of
transactions:
T1 : insert "Miller"
T2 : delete "Mitch"
T3 : change "M" to "R" in each name
Line Name Condition
Mitch
1
Mitch
2
3
Miller C1
Mitch C2
4
Miller C1
5
Mitch C3
6
7
Miller C4
Ritch
8
C5
9
Riller C6

Comment
(cid:40)
Initial
(cid:40)
Content after BST
of T1
 Content after BST
Content after BST
of T1 , T2
of T1 , T2 , T3
Table 1. Content after Bi-State-Terminating T1 , T2 , and T3
Line 1 of Table 1 represents the initial database state S0 of R(cid:48) , lines 2-3 show the content of R(cid:48) after BST of
T1 , lines 4-5 represent the table content after BST of T1 and T2 , while lines 6-9 show the table after BST of
T1 , T2 , and T3 . The conditions Ci in the column “Condition” of Table 1 are linked to the “Rules” column
of Table 2. Table 2 deﬁnes for each condition Ci by a boolean formula composed of other conditions and/or
elementary conditions Tj , Tk , where Tj in the column “Deﬁnition” of Table 2 represents that transaction Tj
will commit and Tk represents that Tk will abort. When Ci is valid, the row (<t>, Ci ) of Table 1 represents
that the tuple <t> is in R. The condition C4 , for example, is fulﬁlled when T1 commits and T3 aborts. In
this case, line 7 of Table 1 becomes valid.

148

International Journal of Database Management Systems ( IJDMS ) , Vol.2, No.2, May 2010

Condition Deﬁnition
–
–
T1
C1
C1
T1
T2
C2
T2T3
C3
C4
T1T3
C5
T2T3
C6
T1T3

Comment
Initial
(cid:40)
Content after BST of T1
 Content after BST
Content after BST
of T1 , T2
of T1 , T2 , T3
Table 2. Rules Table after Bi-State-Terminating T1 , T2 , and T3

4.3. Read Operations on the BST Model
Whenever a read operation on R is implemented by a read operation on R(cid:48) , the conditions are kept as part
of the result. The relational algebra operations are implemented as follows.

4.3.1. Selection
Each selection with selection condition SC that a query applies to a relation R, will be applied to R(cid:48) , i.e.
the database system applies the following rewrite rule to each selection:
SC(R) ⇒ SC(R’)

4.3.2. Duplicate Elimination
Duplicate elimination is an operation that is used to implement projection and union. When duplicates
occur, their conditions are combined with the logical OR operator. That is, given the relation R(cid:48) contains
two tuples t(cid:48)
1 = (value1 , . . . , valueN , C1 ) and t(cid:48)
2 = (value1 , . . . , valueN , C2 ) these two tuples are deleted
and a single tuple t(cid:48) = (value1 , . . . , valueN , CC 12 ) is inserted into R, and a rule (CC 12 , C1 or C2 ) is inserted
into the Rules table.

4.3.3. Set Union
Set union of two relations R1 and R2 is implemented by applying duplicate elimination to the set union of
R(cid:48)
1 and R(cid:48)
2 . The database system applies the following rewrite rule:
R1 ∪ R2 ⇒ removeDuplicates(R1 ’ ∪ R2 ’)

4.3.4. Projection
Projection of a relation R1 on its attributes A1 , . . . , AN is implemented by applying duplicate elimination
to the result of applying the projection to R(cid:48)
1 including the column “Conditions”. The database system
applies the following rewrite rule:
P(A1 , . . .,An ) (R1 ) ⇒ removeDuplicates(P(A1 , . . .,An , conditions) (R(cid:48)
1 ))

4.3.5. Cartesian Product
Whenever the cartesian product R1 × R2 of two relations R1 and R2 must be computed, this is implemented
1 = (value1 , . . . , valueN , C1 ) of R(cid:48)
2 ) of tuples t(cid:48)
1 , t(cid:48)
2 as follows. For each pair (t(cid:48)
1 and R(cid:48)
using R(cid:48)
1 and
2 , a tuple t(cid:48)
1 = (value21 , . . . , value2N , C2 ) of R(cid:48)
t(cid:48)
12 = (value1 , . . . , valueN , value21 , . . . , value2N , CC 12 )
is constructed and stored in (R1 × R2 )(cid:48) . The database system applies the following rewrite rule:
R1× R2 ⇒ (R1 × R2 )’
where (R1× R2 )’ can be derived by computing the set
{ (t1 ,t2 ,CC 12 ) | (t1 ,C1 ) ∈ R1 ’ and (t2 ,C2 ) ∈ R2 ’ }
and by adding a rule ( CC 12 , C1 and C2 ) for each pair of C1 and C2 to the Rules table.

149

International Journal of Database Management Systems ( IJDMS ) , Vol.2, No.2, May 2010

4.3.6. Set Difference
Whenever the set difference R1 − R2 of two relations R1 and R2 must be computed, this is implemented
2 as follows. The set difference contains all tuples t(cid:48)
1 = (value1 , . . . , valueN , C1 ) of R(cid:48)
using R(cid:48)
1 and R(cid:48)
1
for which no tuple t(cid:48)
2 = (value21 , . . . , value2N , C2 ) of R(cid:48)
2 exists, and furthermore, it contains a tuple
t(cid:48)
12 = (value1 , . . . , valueN , CC 12 ) for each tuple t(cid:48)
1 = (value1 , . . . , valueN , C1 ) of R(cid:48)
1 for which a tuple
2 = (value21 ,. . . , value2N , C2 ), C2 (cid:54)= C1 , of R(cid:48)
t(cid:48)
2 exists. The condition CC 12 is true if and only if (C1 and
not C2 ) is true. The database system applies the following rewrite rule:
R1 - R2 ⇒ R1 ’ - R2 ’
where ( R1 ’ - R2 ’ ) can be derived by computing the union of the following sets S1 and S2 :
S1 = { (t1 ,C1 ) | exists (t1 ,C1 ) ∈ R1 ’ and not exists C2 such that (t1 ,C2 )∈ R2 ’ }
S2 = { (t1 ,CC 34 ) | exists (t1 ,C3 )∈ R1 ’ and exists (t1 , C4 )∈ R2 ’ such that C3 (cid:54)= C4 }
and by adding a rule (CC 34 , C3 and not C4 ) for each pair of C3 and C4 used in S2 to the Rules
table.

4.3.7. Other Algebra Operations
Other operations of the relational algebra like join, intersection, etc. can be constructed by combining
the implementation of the basic operations. Of course, query optimization of operations like join etc. is
possible.

5 . DATABA SE CON STRA INT S
We classify two kinds of constraints: integrity constraints and consistency constraints. Following [3], in-
tegrity constraints are deﬁned as data tuple characteristics that are independent of other data tuples. Thus,
integrity constraints can be checked row-by-row. Consistency constraints, as deﬁned in [8], specify rela-
tionship characteristics of two or more data tuples. Thus, consistency constraints can be formulated as read
queries that return boolean values. We assume that before a constraint check is performed, the database is
in a valid state, i.e. it’s integrity and consistency constraints are fulﬁlled. Thus, a transaction converts the
database from one valid state to another valid state, and we only have to check whether the changes of a
transaction violate the deﬁned constraints.

5.1.
Integrity Constraints
One characteristics of BST is that the data accessed by write operations is already present in the database
before the transaction is committed, and that the data accessed by pending delete operations is still present.
Furthermore, each commit/abort combination of Bi-State-Terminated transactions is possible. Thus, in-
tegrity constraints can be checked for each database row without obeying the conditions relation. When-
ever a data item violates an integrity constraint, the transaction must be aborted, otherwise the database can
vote for commit.

5.2. Consistency Constraints
Consistency constraints formulated as boolean queries are checked as follows. The query is evaluated and
eventually returns different result values including conditions representing validity, for example RQ =((true),
Ck ), whereas Ck can be composed of different condition formulas. Whenever a consistency constraint may
be violated, i.e. we get a result value ((false), Ck ), we furthermore check whether the composed condition
formula Ck is a contradiction. If Ck is not a contradiction, the consistency constraint may be violated and
the database votes for abort. If the database gets ((true), Ck ) and ((false), Cl ) values and all Cl are a con-
tradiction, the database votes for abort since the consistency constraint is fulﬁlled and cannot be violated.

Referential Integrity Constraints
For referential integrity, we join the primary and foreign key, eliminate duplicates, and derive the corre-
sponding condition formulas for each joined data item. Then, we check for each joined tuple whether the
formulated referential integrity constraint may be violated.

Example 12 Assume the relation Order contains IDs of tuples of the relation Customer. A referential
integrity constraint C assures that each order contains an ID of a customer listed in relation Customer, i.e.

150

International Journal of Database Management Systems ( IJDMS ) , Vol.2, No.2, May 2010

ID Attributes
1
α1
2
α2

(1)
(2)

Conditions

Table 3. R” is derived from the table R by adding the column “Conditions”

∀o ∈ Order ∃c ∈ Customer: o.CID = c.CID. Assume, a referential integrity constraint RC results in the
constraint value Rt =((true), C1 ∧ C6 ⇒ (C 3 ∧ C 2) ∨ C6 ) for a certain data item, which indicates that
the referential integrity is fulﬁlled when the formula Rt is true. Since Rt is a tautology, the constraint is
fulﬁlled regardless of which Bi-State-Terminated transactions commit or abort.

Whenever a database constraint may be violated by a transaction, the transaction cannot vote for commit
and thus is aborted.

6 . FA ILURE RECOVERY
The use of the Rules table allows implementing failure recovery in the following different way. A log
book for log-based failure recovery is not necessarily required for undoing or redoing a transaction for the
following reason. Whether or not a transaction is committed or aborted or currently running can be checked
by investigating the Rules table. An atomic write of the commit record to a log book can be replaced by an
atomic write operation on the Rules table which adds a rule (‘Ti ‘, true) if transaction Ti commits or (‘Ti ‘,
false) if transaction Ti aborts, before the entries ‘Ti ‘ are replaced with true or false respectively elsewhere.
After all simpliﬁcation steps have been applied to the Rules table and to the augmented relations Ri ’ and
after the distributed commit decision has been acknowledged by all transaction partners, the rule entry (‘Ti ‘,
true) or (‘Ti ‘, false) is not needed anymore and can be deleted from the Rules table. This approach is as
safe against power supply failures as log book-based approaches, because whether or not a transaction ‘Ti ‘
is completed can be seen by looking for an entry (‘Ti ‘, . . . ) in the Rules table, and all the derivation steps
on the Rules table and in the database relations R(cid:48)
i can be reconstructed from a given entry (‘Ti ‘, true) or
(‘Ti ‘, false) in the Rules table.

7 .
IM PLEMENTAT ION
We have implemented BST in three versions and have compared their performance using a stress test. The
ﬁrst implementation, called BST-Disk, uses the Rules table and rewrite rules as stated in Section 4, and
stores the Rules table as a separate database table on disk.
A modiﬁcation of this concept, the BST-RAM implementation, stores the Rules table completely within
main memory. This makes the Rules table management faster but also susceptible to failures like power
failure.
The third implementation, called Fast-BST, does not use a separate Rules table anymore. Instead, Fast-BST
adds an additional column “Condition” of type string to each table, which stores the conditions under which
the corresponding data row becomes valid. Thus, conditions need not be derived from the Rules table; each
tuple contains its conditions within the “Condition” column. Thus, Fast-BST makes Rules table lookups
to derive the conditions under which a tuple becomes valid superﬂuous, and Fast-BST speeds up write
operations that operate on many tuples for the following reason: The database does not need to generate
and associate unique IDs to replaced conditions, it can update the “Condition” column in one pass by
concatenating its value with the transaction ID. Furthermore, Fast-BST is not susceptible to power failures
as BST-RAM as it does not hold the Rules table in its main memory.
In the following, we describe the Fast-BST implementation that is used in the evaluation.

7.1. Fast-BST – Write Operations
Fast-BST implements the concept of BST as follows. Fast-BST stores the before image and the after image
of tuples that have been modiﬁed by BST transactions. For this purpose, the Fast-BST adds the column
“Conditions” to each table R that it uses to construct the relation R”, cf. Table 3.
The step of Algorithm 1 is executed for each insert statement INSERT INTO R <data> of a transaction
Ti . Two equal insert statements are executed twice and are not mixed.

151

International Journal of Database Management Systems ( IJDMS ) , Vol.2, No.2, May 2010

Algorithm 1 Implementing Inserts
1. Insert the tuple (<data>,Ti ) into the corresponding table R”, and add Ti to the column
“Conditions” of the newly inserted tuples.

For each delete statement DELETE ...
rithm 2 is required.

Algorithm 2 Implementing Deletes

WHERE <X> of a transaction Ti , the rewriting shown by Algo-

1. Add the substring Ti to each entry in the column “Conditions” of each row where <X>
evaluates to true. Simplify the Conditions, if Ti wants to delete a tuple that Ti has just
inserted before.

Algorithm 3 describes the update operation for the update statement UPDATE ...

WHERE <X>.

Algorithm 3 Implementing Updates
1. Copy the tuples for which <X> evaluates to true into new data tuples, and concatenate Ti to
the existing entries of the “Conditions” attribute of the new tuples. Update the newly copied
tuples according to the update statement.

2. Add Ti to each entry in the column “Conditions” of each row where <X> evaluates to true
and that was not copied and updated in Step 1.

Example 13 Assume that we execute the following sequence of three transactions T1 , T2 , and T3 , each
containing one update statement, on Table 3.
T1:
UPDATE Table1 SET Attributes=α3 WHERE ID=1
T2:
UPDATE Table1 SET Attributes=α4 WHERE ID=2
T3:
UPDATE Table1 SET Attributes=α2
WHERE (Attributes=α3 ∨ Attributes=α4)
Table 4 shows the result when all of the distributed transactions T1 . . . T3 block and Bi-State-Terminate.
Fast-BST marks all tuples changed by transaction T1 as before image (line (1)), copies them to line (3), and
executes the update (on line (3)). Note that Table 4 shows the result when all transactions T1 , T2 , and T3
block, therefore it already contains the entry for T3 in line (3). The same algorithm is applied for T2 . When
T3 is executed and both transactions T1 and T2 block, T3 depends on T1 and T2 . However, FAST-BST
does not explicitly check for this dependency. In our example, T3 only modiﬁes data when either T1 or T2
commit. This dependency is maintained automatically by Step 1 of Algorithm 3 since the <condition>
of the update statement of T3 is only true in lines (3) and (4). Then, these two rows are copied to the rows
in line (5) and line (6), and T3 is added to the “Conditions” column of each of these rows.

7.2. Fast-BST – Read-Operations
Read operations are modiﬁed in the following way: Each value of the returned result additionally contains
the corresponding value of the “Conditions” column. Thus, each read operation must be processed by the
database only once, regardless of the number of depending blocked transactions. However, the result R is
not directly returned to the application, Fast-BST ﬁrst checks whether the result R contains any entries in
the “Conditions” column. If this is the case, it is the application’s choice whether it handles these multiple
uncertain results, or whether the application delays the read operation until the transactions listed in the
“Conditions” column of R have been committed or aborted. If the application can handle multiple results,
we can reduce the amount of transferred data by returning an object that represents the different possible
valid database states directly within the application by means of the “Conditions” column.

152

International Journal of Database Management Systems ( IJDMS ) , Vol.2, No.2, May 2010

ID Attributes
1
α1
2
α2
1
α3
2
α4
1
α2
2
α2

Conditions
T1
T2
T1 , T3
T2 , T3
T1 , T3
T2 , T3

(1)
(2)
(3)
(4)
(5)
(6)

Table 4. Content of Table 1 after Bi-State-Terminating T1 , T2 , and T3

7.3. Commit and Abort
The following rules apply when a blocked transaction Ti commits or aborts:
Ti commits: Delete all rows that contain Ti in the column ”Conditions”. Delete the string Ti from all
entries within the “Conditions” column of the table.
Ti aborts: Is treated as Ti commits.

Example 14 Assume T3 commits. In this case, lines (3) and (4) are deleted from Table 4. Furthermore, the
string T3 must be deleted in Lines (5) and (6) from the attribute values for the column “Conditions”, since
a commit of T1 or T2 automatically implies that the changes of T3 become valid.
Note that the data set increases only temporarily and collapses to the original size when the commit decision
for the Bi-State-Terminated transactions is known. For example, when the database receives the commit
decisions for T1 and T3 , the database knows the exact unique value for the data tuple with ID 1, which
corresponds to Line (5) in case T3 and T1 commit, to Line (3) in case T1 commits and T3 aborts, and to
Line (1) in case T1 aborts.

8 . EX PER IMENTAL EVALUAT ION
We choose the TPC-C benchmark [14] for generating the test data and transactions. The following questions
motivate our experimental evaluation: Which BST implementation is faster? How many transactions can be
Bi-State-Terminated until the execution time or the database size for following transactions is unacceptably
high? How does BST affect the overall transaction throughput and transaction execution time, when a
certain percentage of transactions block?

8.1. BST Stress Test
Having a data hotspot, the used BST implementation may have great inﬂuence on the transactions execution
times since in this case a lot of transactions depend on each other. As this results in a growth of database
states, we have compared the three BST implementations and determined how many blocked transactions
per tuple each BST implementation can handle in a stress test. For this stress test, we have generated
a database table consisting of a single data tuple. We have sequentially executed a number of database
transactions on this table that do not ﬁnish, i.e.
the transactions do not get a commit decision and thus
block. Each of these blocked transactions has incremented or decremented the same data that is initially
present. In order to be able to process further transactions, we have used our three BST implementations
to terminate each blocked transaction. For this reason, each blocked transaction has doubled the number of
possible database states, and thus the number of possible values for the initial tuple grows exponentially for
the number of blocked transactions. We have measured the time for processing the (n + 1)th transaction
when n transactions are blocked and terminated by BST for each BST implementation.
The y -axis of Figure 4 indicates the required time to process a single update transaction when the number
of transactions indicated on the x-axis is terminated by BST. As all of these blocked transactions depend
on each other, and all of them are coded to modify the initial tuple, the resulting growth in time and space
is exponential. However, as the test indicates, the processing of a transaction when 10 blocked transactions
have been terminated by BST does not take a large overhead for the Fast-BST implementation.
Both implementations that use a separate “Rules” table, i.e. BST-Disk and BST-RAM, are signiﬁcantly
slower than the Fast-BST implementation. The reason is that when transactions update a lot of data tuples,

153

International Journal of Database Management Systems ( IJDMS ) , Vol.2, No.2, May 2010

Figure 4. BST Stress Test – Performance

the corresponding condition must be derived from the Rules table for each updated data tuple, and a new
condition ID must be generated and assigned separately to each data tuple. In comparison, Fast-BST only
adds the transaction’s ID to the “Conditions” column of all updated tuples, which can be done much faster.
On the y -axis, Figure 5 shows the number of tuples that are generated by BST for a single update operation,
while the number of transactions indicated on the x-axis has been terminated by BST. Note that our BST
implementations do not differ in the number of resulting tuples. Although the database’s size grows expo-
nentially each time a blocked transaction is terminated by BST, it is the database’s decision to use BST for
a transaction Ti or to wait until the decision for transactions on which Ti depends is known.
As we have seen, using the Fast-BST implementation allows the database to terminate more blocked trans-
actions without a signiﬁcant loss of performance. For this reason, we use the Fast-BST implementation in
the following TPC-C benchmark test.

8.2. BST TPC-C Test
The TPC-C benchmark [14], an online transaction processing benchmark test, simulates an online-shop-
like environment in which users execute order transactions against a database. The transactions addition-
ally include recording payments, checking the status of orders, and monitoring the level of stock at the
warehouses.
We used a TPC-C “scaling factor” of 2, which results in 139 MB of data and a total amount of 294 trans-
actions, 41,8% of them containing update operations. Characteristic for our implementation of the TPC-C
benchmark is that the involved update transactions operate on a set of data tuples whose cardinality is low
(i.e. 2 tuples), so we can expect a lot of depending write transactions. In order to simulate transaction block-
ing, a separate coordinator instance coordinates each transaction and delays the commit command based
on different parameters in order to simulate blocked distributed transactions. For example, to simulate a
transaction blocking of 1% of all transactions, we delayed the commit command of each 100th transaction.
Figure 6 shows the sum of all successfully committed transactions on the y -axis. On the x-axis, the overall
time is shown. The different curves indicate whether BST was enabled, and they vary in the percentage of
blocked transactions. Note that due to our simulated hotspot, a huge amount of transactions depend on each
other. We can see that BST-enabled transaction processing is able to commit a lot more transactions than
BST disabled transaction processing.

154

02468101214161820123456789101112Time (s)No. of blocking transactionsTime for processing a single transaction when x depending transactions blockBST-DiskBST-RAMFast-BSTInternational Journal of Database Management Systems ( IJDMS ) , Vol.2, No.2, May 2010

Figure 5. BST Stress Test – Space

Note that the additional space used by BST is rather low, i.e., in our TPC-C experiments, BST requires only
about 2% more space.

8.3. Evaluation Summary
We have run a stress test to compare three implementations for BST. While the BST-Disk and BST-RAM
implementation use a separate Rules table in order to manage the dependencies of the before- and after-
images of the transactions, the Fast-BST implementation directly annotates the rule under which each data
tuple becomes valid to the data row. The Fast-BST implementation is able to cope with 10 blocked trans-
actions that all write on the same tuple without causing a loss of performance, while the BST-Disk and
BST-RAM implementations can only handle 5 to 7 blocked transactions accessing the same tuple within
reasonable time.
When setting up a transaction scenario, two extreme scenarios are possible that inﬂuence the outcome of
BST: In the ﬁrst scenario, each transaction operates on different tuples that are not accessed by any other
transaction. In the second scenario, each transaction operates on the same tuples. As transaction blocking
in the ﬁrst scenario does not have any inﬂuence on other transactions, enabling BST does not commit more
transactions than disabling BST. In the second scenario, a blocked transaction would immediately prevent
all following transactions from being processed. In this scenario, BST would allow the commitment of
almost all transactions, while disabling BST would result in a total blocking situation.
Due to these two possible extreme scenarios, we used the TPC-C benchmark that simulates a typical ware-
house environment to get an impression of how BST enhances transaction processing in a real-world sce-
nario. We have preferred the Fast-BST implementation, which is able to enhance the amount of committed
transactions in our TPC-C benchmark by 40 to 70%, depending on the number of blocked transactions.
Finally, note that if no more space is available or the required processing time grows, the database can decide
for each individual transaction whether to use BST or to wait for the commit decision as in 2PC. In other
words, our solution does not force the database to accept long execution times, and BST-enabled transaction
processing never blocks more transactions than traditional transaction processing. Our approach can be
regarded as a generalization of traditional 2PC in the sense that for each individual transaction executed on
a local database, BST is possible but not required.

155

050010001500200025003000350040004500123456789101112No. of TuplesNo. of blocking transactionsNumber of tuples accessed by a single transaction updating one tuple of R when x depending transactions blockBi-State-TerminationInternational Journal of Database Management Systems ( IJDMS ) , Vol.2, No.2, May 2010

Figure 6. BST evaluation on the TPC-C benchmark

9 . RELATED WORK
Concurrency control like multiversion concurrency control [4, 24], timestamp-based concurrency control
[17], or optimistic concurrency control [12, 16] omit the use of locks. However, these approaches do not
solve the inﬁnite transaction blocking problem on concurrent transactions since each database that has sent
the voteCommit message proposes that it will commit the transaction regardless of the used concurrency
control mechanism. Therefore, without Bi-State-Termination, the database cannot process a transaction U
that is depending on a transaction T , while T waits for the ﬁnal commit decision, even if the database uses
locking-free concurrency control. This motivates the use of BST, which is a termination mechanism that
supports the actually used concurrency control mechanism.
Other approaches rely on compensation of transactions. [15], for instance, proposes a timeout-based proto-
col especially for mobile networks, which requires a compensation of transactions. However, inconsisten-
cies may occur when some databases do not immediately receive the compensation decision or when the
coordination process fails.
In order to enhance the availability of the coordination process, some proposals rely on multiple coordina-
tors. [10], for instance, proposes a consensus-based commit protocol that involves multiple coordinators.
However, the problem of transaction blocking in the sense of Deﬁnition 2, which occurs when the executing
database disconnects from the network after sending the voteCommit message, has, to the authors’ knowl-
edge, not been studied yet. Even 1PC [1, 2], which does not require a vote message but acknowledges each

156

010203040506070809010000,511,522,533,544,555,566,577,588,5Time (Minutes)% of committedTransactionsBST enabled, 1% blockingBST enabled, 5% blockingBST enabled, 10% blockingBST disabled, 1% blockingBST disabled, 5% blockingBST disabled, 10% blocking138,71 MB Data; 294 Transactions (41,8% Update, 58,2% Select)                                                 International Journal of Database Management Systems ( IJDMS ) , Vol.2, No.2, May 2010

operation, encounters the problem of transaction blocking since each acknowledged operation that accesses
a data tuple must block this data tuple until the transaction is successfully completed.
Our solution relates to three ideas that are used in different contexts: Escrow locks [11], speculative locking
[21], and multiversion databases [6, 7, 13].
Escrow locks are a reﬁnement of ﬁeld calls, which are used in environments where data hotspots are fre-
quently accessed. The escrow lock calculates an interval [i, k ] for an attribute a by means of the currently
processed updates. The interval indicates the actual upper and lower boundary that the attribute a may take.
When a further transaction relies on a precondition for a, the database checks whether the precondition
evaluates to true for each value of a that is contained in the interval [i, k ]. In contrast to the escrow locking
technique, Bi-State-Termination, is a transaction termination mechanism. BST neither relies on numerical
values, nor assumes that an attribute value must lie in a given interval. BST always knows the exact values
that an attribute can actually have and even allows an application to decide that a transaction Ti may only
be committed in a certain constellation of commit and abort decisions of transactions on which Ti depends.
Another related locking mechanism is Speculative Locking (SL) [21]. SL was proposed to speed up trans-
action processing by spawning multiple parallel executions of a transaction that waits for the acquisition
of required locks. SL has in common with Bi-Sate-Termination that SL also allows a transaction Tc to
access the after-image of a transaction Ti while Ti is waiting for its commit decision. However, unlike
Bi-State-Termination, SL does not allow committing Tc before the ﬁnal commit decision for Ti has been
received. This means, SL cannot successfully terminate Tc while the commit vote for Ti is missing. For
this reason, SL cannot be used to solve the inﬁnite transaction blocking problem that may occur in mobile
networks. Furthermore, our Fast-BST implementation can execute read-operations in one pass even if they
return multiple result values due to transactions that wait for the commit decision.
Multiversion database systems [6, 7, 13] are used to support different expressions of a data object. They
are used for CAD modelling and versioning systems. However, compared to BST, multiversion database
systems allow multiple versions to be concurrently valid, while BST allows only one valid version, but
lacks the knowledge which of the multiple versions is valid due to the atomic commit protocol. Whenever
BST requires multiple transaction executions that all return the same result, BST is even transparent to the
application. Furthermore, multiversion database systems are mostly central embedded databases that are
not designed to deal with distributed transactions. Instead, the user explicitly speciﬁes on which version he
wants to work.
Complementing this contribution, [19] describes how arbitrary database constraints beyond functional de-
pendencies and referential integrity constraints, can be checked on the BST implementation. Further-
more, [19] suggests a different treatment for row-based integrity constraints and general consistency con-
straints.

10 . SUMMARY AND CONCLU S ION
Transaction blocking occurs very frequently, i.e. a sub-transaction has voted for commit, but has not re-
ceived the commit decision, yet. We argue that the risk of inﬁnite transaction blocking, which can occur if
the database moves or disconnects, is not appropriately solved by other approaches to distributed transac-
tion processing. We have explained the concept of Bi-State-Termination that is useful to terminate blocked
transactions without violating atomicity, even without knowing the explicit coordinator decision on commit
or abort. We have described three different implementations and have experimentally evaluated them.
Our experimental results have shown that Bi-State-Termination enhances the number of committed trans-
actions and that BST is able to deal with a large number of depending blocked transactions without expe-
riencing signiﬁcant performance loss. This justiﬁes using BST in mobile ad-hoc networks that are exposed
to the risk of transaction blocking.
To summarize, we consider Bi-State-Termination as a useful option that is usable for mobile networks in
order to terminate a transaction instead of just waiting for the commit decision for a long time.

157

International Journal of Database Management Systems ( IJDMS ) , Vol.2, No.2, May 2010

RE FERENCE S
[1] M. Abdallah, R. Guerraoui, and P. Pucheral. One-phase commit: Does it make sense? In ICPADS ’98: Proceed-
ings of the 1998 International Conference on Parallel and Distributed Systems, page 182, Washington, DC, USA,
1998. IEEE Computer Society.
[2] Y. J. Al-Houmaily and P. K. Chrysanthis. 1-2pc: the one-two phase atomic commit protocol. In Proceedings of
the 2004 ACM Symposium on Applied Computing (SAC), Nicosia, Cyprus, March 14-17, pages 684–691, 2004.
[3] R. Bayer, H. Heller, and A. Reiser. Parallelism and recovery in database systems. ACM Trans. Database Syst.,
5(2):139–156, 1980.
[4] P. A. Bernstein and N. Goodman. Multiversion concurrency control - theory and algorithms. ACM Trans.
Database Syst., 8(4):465–483, 1983.
[5] P. A. Bernstein, V. Hadzilacos, and N. Goodman. Concurrency Control and Recovery in Database Systems.
Addison-Wesley, 1987.
[6] W. Cellary and G. Jomier. Consistency of versions in object-oriented databases. In D. McLeod, R. Sacks-Davis,
and H.-J. Schek, editors, 16th International Conference on Very Large Data Bases, August 13-16, 1990, Brisbane,
Queensland, Australia, Proceedings, pages 432–441. Morgan Kaufmann, 1990.
[7] I.-M. A. Chen, V. M. Markowitz, S. Letovsky, P. Li, and K. H. Fasman. Version management for scientiﬁc
In P. M. G. Apers, M. Bouzeghoub, and G. Gardarin, editors, Advances in Database Technology
databases.
- EDBT’96, 5th International Conference on Extending Database Technology, Avignon, France, March 25-29,
1996, Proceedings, volume 1057 of Lecture Notes in Computer Science, pages 289–303. Springer, 1996.
[8] K. P. Eswaran, J. N. Gray, R. A. Lorie, and I. L. Traiger. The notions of consistency and predicate locks in a
database system. Commun. ACM, 19(11):624–633, 1976.
[9] J. Gray. Notes on data base operating systems. In M. J. Flynn, J. Gray, A. K. Jones, et al., editors, Advanced
Course: Operating Systems, volume 60 of Lecture Notes in Computer Science, pages 393–481. Springer, 1978.
[10] J. Gray and L. Lamport. Consensus on transaction commit. ACM Transactions on Database Systems (TODS),
31(1):133–160, 2006.
[11] J. Gray and A. Reuter. Transaction Processing: Concepts and Techniques. Morgan Kaufmann, 1993.
[12] T. Haerder. Observations on optimistic concurrency control schemes. Inf. Syst., 9(2):111–120, 1984.
[13] R. H. Katz. Toward a uniﬁed framework for version modeling in engineering databases. ACM Comput. Surv.,
22(4):375–409, 1990.
[14] W. Kohler, A. Shah, and F. Raab. Overview of TPC Benchmark C: The Order-Entry Benchmark. Technical report,
http://www.tpc.org, Transaction Processing Performance Council, 1991.
[15] V. Kumar, N. Prabhu, M. H. Dunham, and A. Y. Seydim. Tcot - a timeout-based mobile transaction commitment
protocol. IEEE Transactions on Computers, 51(10):1212–1218, 2002.
[16] H. T. Kung and J. T. Robinson. On optimistic methods for concurrency control. ACM Trans. Database Syst.,
6(2):213–226, 1981.
[17] P.-J. Leu and B. K. Bhargava. Multidimensional timestamp protocols for concurrency control. In Proceedings of
the Second International Conference on Data Engineering, pages 482–489, Washington, DC, USA, 1986. IEEE
Computer Society.
In Proceedings of the 11th
[18] S. Obermeier and S. Böttcher. Avoiding inﬁnite blocking of mobile transactions.
International Database Engineering & Applications Symposium (IDEAS), Banff, Canada, 2007.
[19] S. Obermeier and S. Böttcher. Constraint checking for non-blocking transaction processing in mobile ad-hoc net-
works. In Proceedings of the 12th International Conference on Enterprise Information Systems (ICEIS), Funchal,
Madeira - Portugal, 2010.
[20] P. K. Reddy and M. Kitsuregawa. Reducing the blocking in two-phase commit with backup sites. Inf. Process.
Lett., 86(1):39–47, 2003.
[21] P. K. Reddy and M. Kitsuregawa. Speculative locking protocols to improve performance for distributed database
systems. IEEE Transactions on Knowledge and Data Engineering, 16(2):154–169, 2004.
[22] D. Skeen. Nonblocking commit protocols. In Y. E. Lien, editor, Proceedings of the 1981 ACM SIGMOD Inter-
national Conference on Management of Data, Ann Arbor, Michigan, pages 133–142. ACM Press, 1981.
In
[23] M. R. Stonebraker. Concurrency control and consistency of multiple copies of data in distributed ingres.
Distributed systems, Vol. II: distributed data base systems, pages 193–199, Norwood, MA, USA, 1986. Artech
House, Inc.
[24] G. Weikum and G. Vossen. Transactional information systems: theory, algorithms, and the practice of concur-
rency control and recovery. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 2001.

158

International Journal of Database Management Systems ( IJDMS ) , Vol.2, No.2, May 2010

Authors
Sebastian Obermeier works as a Scientist at ABB Cor-
porate Research. He holds a PhD and Diploma in Com-
puter Science from the University of Paderborn, Ger-
many. His research areas include the use of database
transaction technology within mobile ad-hoc networks
and security for critical infrastructures.

Stefan Böttcher is a Professor of Computer Science at
the University of Paderborn. His research areas cover
query optimization and compression in XML databases,
transactions in mobile ad-hoc networks, security and pri-
vacy. Before he joined the University of Paderborn, he
worked for several years at the German research labs of
IBM and Daimler Benz.

159

(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)

(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)

(cid:1)
(cid:1)

(cid:1)
(cid:1)

(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:4)(cid:1)(cid:11)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:16)(cid:17)(cid:7)(cid:1)(cid:18)(cid:13)(cid:5)(cid:7)(cid:1)(cid:18)(cid:11)(cid:11)(cid:1)(cid:12)(cid:4)(cid:19)(cid:16)(cid:7)(cid:1)(cid:20)(cid:1)(cid:21)(cid:1)(cid:22)(cid:23)(cid:23)(cid:24)(cid:1)
(cid:2)(cid:3)(cid:3)(cid:4)(cid:5)(cid:19)(cid:7)(cid:1)(cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:1)(cid:8)(cid:16)(cid:10)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:6)(cid:19)(cid:7)(cid:1)(cid:28)(cid:15)(cid:29)(cid:1)(cid:30)(cid:13)(cid:14)(cid:6)(cid:1)(cid:20)(cid:19)(cid:15)(cid:1)(cid:31)(cid:4)(cid:19)(cid:16)(cid:7)(cid:1)(cid:21)(cid:1)(cid:22)(cid:23)(cid:23)(cid:24)(cid:1)
(cid:1)

(cid:1)(cid:1)(cid:2)(cid:2)(cid:3)(cid:3)(cid:4)(cid:4)(cid:5)(cid:5) (cid:6)(cid:6)(cid:2)(cid:2)(cid:7)(cid:7) (cid:8)(cid:8)(cid:9)(cid:9)(cid:4)(cid:4) (cid:10)(cid:10)(cid:4)(cid:4)(cid:11)(cid:11)(cid:12)(cid:12)(cid:13)(cid:13)(cid:14)(cid:14) (cid:8)(cid:8)(cid:15)(cid:15)(cid:11)(cid:11)(cid:16)(cid:16)(cid:4)(cid:4)(cid:12)(cid:12) (cid:10)(cid:10) (cid:8)(cid:8) (cid:6)(cid:6)(cid:2)(cid:2) (cid:8)(cid:8) (cid:8)(cid:8)
(cid:17)(cid:17)(cid:16)(cid:16)(cid:4)(cid:4)(cid:2)(cid:2) (cid:8)(cid:8)(cid:18)(cid:18)(cid:13)(cid:13)(cid:13)(cid:13)(cid:4)(cid:4) (cid:10)(cid:10) (cid:10)(cid:10) (cid:8)(cid:8)(cid:19)(cid:19)(cid:11)(cid:11) (cid:20)(cid:20)(cid:11)(cid:11)(cid:21)(cid:21)(cid:11)(cid:11) (cid:10)(cid:10)(cid:4)(cid:4) (cid:10)(cid:10) (cid:8)(cid:8) (cid:8)(cid:8)

(cid:18)(cid:18) (cid:22)(cid:22)(cid:4)(cid:4)(cid:5)(cid:5)(cid:11)(cid:11)(cid:2)(cid:2)(cid:3)(cid:3)(cid:12)(cid:12)(cid:11)(cid:11) (cid:23)(cid:23)(cid:24)(cid:24)(cid:25)(cid:25) (cid:6)(cid:6) (cid:22)(cid:22) (cid:6)(cid:6)(cid:11)(cid:11) (cid:8)(cid:8)(cid:26)(cid:26)(cid:27)(cid:27)(cid:12)(cid:12) (cid:20)(cid:20) (cid:6)(cid:6) (cid:28)(cid:28) (cid:8)(cid:8)
(cid:29)(cid:30)(cid:6)(cid:21)(cid:6)(cid:10)(cid:13)(cid:31)(cid:10) (cid:8)!(cid:2)(cid:6)"(cid:4)(cid:12)(cid:10)(cid:6)(cid:20)#$(cid:8)(cid:30)(cid:6)(cid:25)(cid:6)(cid:28)(cid:27)(cid:11)(cid:12)(cid:11)$(cid:8)(cid:9)(cid:27)(cid:25)(cid:11)(cid:2)(cid:6)(cid:11)(cid:8)
(cid:4)(cid:12)(cid:13)(cid:9)(cid:15)(cid:10)(cid:19)  (cid:15)(cid:10)!(cid:10)(cid:19)(cid:16)(cid:27)(cid:19)(cid:7)(cid:9)(cid:13)(cid:1)

(cid:18)%&(cid:30)(cid:9)(cid:18)’(cid:30)(cid:7)(cid:1) (cid:30)(cid:29)(cid:10)(cid:19)(cid:1) (cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:1) (cid:19)"(cid:3)(cid:15)(cid:29)(cid:6)(cid:19)(cid:10)#(cid:6)(cid:19)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:4)(cid:16)(cid:15)(cid:10)(cid:13)(cid:3)(cid:19)(cid:1) (cid:26)(cid:6)(cid:9)(cid:12)(cid:13)(cid:9)(cid:14)(cid:6)$(cid:1) (cid:10)(cid:3)(cid:1) (cid:13)(cid:9)$(cid:6)(cid:9)(cid:1)
(cid:15)(cid:13)(cid:1)(cid:15)(cid:9)(cid:4)(cid:3)(cid:19)(cid:12)(cid:13)(cid:9)(cid:14)(cid:1)(cid:4)(cid:1)(cid:16)(cid:5)(cid:4)(cid:19)(cid:19)(cid:10)(cid:16)(cid:1)(cid:19)(cid:16)(cid:10)(cid:6)(cid:3)(cid:15)(cid:10)(cid:12)(cid:10)(cid:16)(cid:1)(cid:9)(cid:6)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:1)%(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)(cid:1)(cid:21)(cid:1)&(cid:2)(cid:3)(cid:3)(cid:4)(cid:5)(cid:19)(cid:7)(cid:1)(cid:1)(cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:1)
(cid:8)(cid:16)(cid:10)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1) (cid:8)(cid:6)(cid:9)(cid:10)(cid:6)(cid:19)’(cid:1) (cid:21)(cid:1) (cid:4)((cid:4)(cid:10)(cid:5)(cid:4)!(cid:5)(cid:6)(cid:1) (cid:13)(cid:3)(cid:5)"(cid:1) (cid:10)(cid:3)(cid:1) (cid:26)(cid:9)(cid:10)(cid:3)(cid:15)(cid:6)$(cid:1) (cid:12)(cid:13)(cid:9)(cid:14)(cid:1) (cid:27)(cid:3)(cid:15)(cid:10)(cid:5)(cid:1) (cid:22)(cid:23)(cid:23))*(cid:1) (cid:10)(cid:3)(cid:15)(cid:13)(cid:1) (cid:4)(cid:1)
(cid:14)(cid:13)$(cid:6)(cid:9)(cid:3)(cid:1) (cid:6)+%(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)(cid:1) ,(cid:10)(cid:15)(cid:29)(cid:1) (cid:12)(cid:9)(cid:6)(cid:6)(cid:1) (cid:4)(cid:16)(cid:16)(cid:6)(cid:19)(cid:19)(cid:1) (cid:15)(cid:13)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:12)(cid:27)(cid:5)(cid:5)(cid:1) (cid:15)(cid:6)-(cid:15)(cid:1) (cid:13)(cid:12)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)(cid:19)(cid:7)(cid:1) (cid:31)(cid:13)(cid:9)(cid:1)
(cid:4)(cid:16)(cid:29)(cid:10)(cid:6)((cid:10)(cid:3).(cid:1)(cid:15)(cid:29)(cid:10)(cid:19)(cid:1).(cid:13)(cid:4)(cid:5)*(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:9)(cid:6)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:1)(cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:19)(cid:1)(cid:29)(cid:4)((cid:6)(cid:1)!(cid:6)(cid:6)(cid:3)(cid:1) (cid:10)(cid:3)(cid:16)(cid:5)(cid:27)$(cid:6)$(cid:1) (cid:10)(cid:3)(cid:1)((cid:4)(cid:9)(cid:10)(cid:13)(cid:27)(cid:19)(cid:1)
(cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)(cid:1) $(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)(cid:19)*(cid:1) (cid:26)(cid:13)(cid:9)(cid:15)(cid:4)(cid:5)(cid:19)(cid:1) (cid:4)(cid:3)$(cid:1) (cid:5)(cid:10)!(cid:9)(cid:4)(cid:9)"(cid:1) (cid:16)(cid:4)(cid:15)(cid:4)(cid:5)(cid:13).(cid:19)(cid:1) ,(cid:29)(cid:10)(cid:16)(cid:29)(cid:1) (cid:13)(cid:12)(cid:12)(cid:6)(cid:9)(cid:6)$(cid:1) (cid:4)(cid:1) (cid:29)(cid:10).(cid:29)(cid:1)
((cid:10)(cid:19)(cid:10)!(cid:10)(cid:5)(cid:10)(cid:15)"(cid:1)(cid:15)(cid:13)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)%(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)(cid:7)(cid:1)(cid:1)
((cid:24))* (cid:17)(cid:9)(cid:19)&/(cid:1) 0(cid:26)(cid:6)(cid:3)+(cid:2)(cid:16)(cid:16)(cid:6)(cid:19)(cid:19)(cid:1) (cid:11)(cid:3)(cid:10)(cid:15)(cid:10)(cid:4)(cid:15)(cid:10)((cid:6)*(cid:1) (cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)(cid:1) $(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)*(cid:1) (cid:19)(cid:15)(cid:4)(cid:3)$(cid:4)(cid:9)$(cid:19)*(cid:1)
(cid:14)(cid:6)(cid:15)(cid:4)+$(cid:4)(cid:15)(cid:4)(cid:1)(cid:29)(cid:4)(cid:9)((cid:6)(cid:19)(cid:15)(cid:10)(cid:3).(cid:1)

(cid:1)
(cid:1)
(cid:1)(cid:2)(cid:20)(cid:12)(cid:27)(cid:3)(cid:31)(cid:13)(cid:20)(cid:6)(cid:27)(cid:2)(cid:8)
(cid:1)
(cid:8)(cid:15)(cid:4)(cid:9)(cid:15)(cid:10)(cid:3).(cid:1) (cid:12)(cid:9)(cid:13)(cid:14)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:9)(cid:6)1(cid:27)(cid:10)(cid:9)(cid:6)(cid:14)(cid:6)(cid:3)(cid:15)(cid:19)(cid:1) (cid:13)(cid:12)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) 2(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:4)(cid:5)(cid:1) (cid:25)(cid:6)(cid:3)(cid:15)(cid:6)(cid:9)(cid:1) (cid:12)(cid:13)(cid:9)(cid:1) (cid:8)(cid:16)(cid:10)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1) 3(cid:13)(cid:5)(cid:10)(cid:16)"(cid:1)
(cid:4)(cid:3)$(cid:1) (cid:8)(cid:16)(cid:10)(cid:6)(cid:3)(cid:15)(cid:13)(cid:14)(cid:6)(cid:15)(cid:9)(cid:10)(cid:16)(cid:19)(cid:1) 4(cid:25)52(cid:2)30(cid:8)(cid:8)(cid:1) +(cid:1) 6(cid:13)(cid:14)(cid:4)(cid:3)(cid:10)(cid:4)(cid:3)(cid:1) (cid:4)(cid:16)(cid:9)(cid:13)(cid:3)"(cid:14)(cid:1) (cid:12)(cid:13)(cid:9)(cid:1) &(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)
(cid:9)(cid:10)(cid:11)(cid:12)(cid:13)(cid:3)(cid:10)(cid:7)(cid:8) (cid:14)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:8) (cid:15)(cid:13)(cid:7)(cid:12)(cid:4)(cid:12)(cid:16)(cid:10)(cid:8) (cid:17)(cid:4)(cid:12)(cid:12)(cid:3)(cid:11)(cid:2)(cid:12)(cid:8) (cid:18)(cid:12)(cid:8) (cid:19)(cid:16)(cid:12)(cid:2)(cid:3)(cid:4)(cid:13)(cid:20)(cid:2)(cid:4)(cid:5)(cid:12)(cid:2)’7(cid:1) ,(cid:10)(cid:15)(cid:29)(cid:1) (cid:9)(cid:6)(cid:19)(cid:26)(cid:6)(cid:16)(cid:15)(cid:1) (cid:15)(cid:13)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1)
(cid:14)(cid:6)(cid:15)(cid:29)(cid:13)$(cid:13)(cid:5)(cid:13)."(cid:1) (cid:13)(cid:12)(cid:1) (cid:4)(cid:19)(cid:19)(cid:6)(cid:19)(cid:19)(cid:10)(cid:3).(cid:1) (cid:19)(cid:16)(cid:10)(cid:6)(cid:3)(cid:15)(cid:10)(cid:12)(cid:10)(cid:16)(cid:1) (cid:9)(cid:6)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:1) %(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)(cid:19)*(cid:1) (cid:19)(cid:13)(cid:14)(cid:6)(cid:1) (cid:13)(cid:12)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:16)(cid:9)(cid:10)(cid:15)(cid:6)(cid:9)(cid:10)(cid:4)(cid:1)
(cid:15)(cid:29)(cid:4)(cid:15)(cid:1) (cid:29)(cid:4)((cid:6)(cid:1) (cid:15)(cid:13)(cid:1) !(cid:6)(cid:1) (cid:16)(cid:13)(cid:3)(cid:19)(cid:10)$(cid:6)(cid:9)(cid:6)$(cid:1) !"(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) 5$(cid:10)(cid:15)(cid:13)(cid:9)(cid:10)(cid:4)(cid:5)(cid:1) 8(cid:13)(cid:4)(cid:9)$(cid:1) (cid:13)(cid:12)(cid:1) (cid:4)(cid:1) (cid:19)(cid:16)(cid:10)(cid:6)(cid:3)(cid:15)(cid:10)(cid:12)(cid:10)(cid:16)(cid:1) (cid:9)(cid:6)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:1)
%(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)(cid:1)(cid:4)(cid:9)(cid:6)/(cid:1)
(cid:1)(cid:3) (cid:30)(cid:29)(cid:6)(cid:1)(cid:10)(cid:3)(cid:16)(cid:5)(cid:27)(cid:19)(cid:10)(cid:13)(cid:3)(cid:1)(cid:13)(cid:12)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)%(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)(cid:1)(cid:10)(cid:3)(cid:1)(cid:10)(cid:3)(cid:15)(cid:6)(cid:9)(cid:3)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:4)(cid:5)(cid:1)(cid:16)(cid:4)(cid:15)(cid:4)(cid:5)(cid:13).(cid:19)9(cid:1)
(cid:1)(cid:3) (cid:30)(cid:29)(cid:6)(cid:1) (cid:10)(cid:3)(cid:16)(cid:5)(cid:27)(cid:19)(cid:10)(cid:13)(cid:3)(cid:1) (cid:13)(cid:12)(cid:1) (cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)(cid:19)(cid:1) (cid:10)(cid:3)(cid:1) (cid:10)(cid:3)(cid:15)(cid:6)(cid:9)(cid:3)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:4)(cid:5)(cid:1) (cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)(cid:19)(cid:1) (cid:4)(cid:3)$(cid:1)
(cid:4)!(cid:19)(cid:15)(cid:9)(cid:4)(cid:16)(cid:15)(cid:19)(cid:1)$(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)(cid:19)(cid:7)(cid:1)
(cid:30)(cid:29)(cid:6)(cid:1) (cid:4)(cid:16)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) (cid:10)(cid:3)(cid:10)(cid:15)(cid:10)(cid:4)(cid:15)(cid:6)$(cid:1) (cid:4)(cid:15)(cid:1) (cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:19)(cid:1) (cid:4)(cid:3)$(cid:1) (cid:2)(cid:26)(cid:26)(cid:5)(cid:10)(cid:6)$(cid:1) (cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:1) (cid:8)(cid:16)(cid:10)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1)
(cid:31)(cid:4)(cid:16)(cid:27)(cid:5)(cid:15)"(cid:1) ,(cid:10)(cid:15)(cid:29)(cid:10)(cid:3)(cid:1) &(cid:30)(cid:10)!(cid:10)(cid:19)(cid:16)(cid:27)(cid:19)’(cid:1) :(cid:3)(cid:10)((cid:6)(cid:9)(cid:19)(cid:10)(cid:15)"(cid:1) (cid:13)(cid:12)(cid:1) (cid:30)(cid:10)(cid:14)(cid:10);(cid:13)(cid:4)(cid:9)(cid:4)(cid:1) (cid:12)(cid:13)(cid:16)(cid:27)(cid:19)(cid:6)$(cid:1) (cid:13)(cid:3)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1)
(cid:10)$(cid:6)(cid:3)(cid:15)(cid:10)(cid:12)(cid:10)(cid:16)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) (cid:13)(cid:12)(cid:1) (cid:10)(cid:14)(cid:26)(cid:13)(cid:9)(cid:15)(cid:4)(cid:3)(cid:15)(cid:1) (cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)(cid:19)(cid:1) (cid:4)(cid:3)$(cid:1) (cid:4)!(cid:19)(cid:15)(cid:9)(cid:4)(cid:16)(cid:15)(cid:1) (cid:10)(cid:3)(cid:15)(cid:6)(cid:9)(cid:3)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:4)(cid:5)(cid:1) $(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)(cid:19)(cid:1) (cid:12)(cid:13)(cid:9)(cid:1)
(cid:15)(cid:29)(cid:6)(cid:1) (cid:12)(cid:10)(cid:6)(cid:5)$(cid:1) (cid:13)(cid:12)(cid:1) (cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:1) (cid:8)(cid:16)(cid:10)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1) (cid:4)(cid:3)$(cid:1) (cid:10)(cid:15)(cid:19)(cid:1) (cid:4)(cid:26)(cid:26)(cid:5)(cid:10)(cid:16)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:19)(cid:7)(cid:1) (cid:2)(cid:12)(cid:15)(cid:6)(cid:9)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:10)$(cid:6)(cid:3)(cid:15)(cid:10)(cid:12)(cid:10)(cid:16)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1)
(cid:4)(cid:3)$(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:10)(cid:3)(cid:19)(cid:26)(cid:6)(cid:16)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) (cid:13)(cid:12)(cid:1) (cid:4)((cid:4)(cid:10)(cid:5)(cid:4)!(cid:5)(cid:6)(cid:1) $(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)(cid:19)*(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) 5$(cid:10)(cid:15)(cid:13)(cid:9)(cid:10)(cid:4)(cid:5)(cid:1) 8(cid:13)(cid:4)(cid:9)$(cid:1) (cid:13)(cid:12)(cid:1) &(cid:2)(cid:3)(cid:3)(cid:4)(cid:5)(cid:19)(cid:7)(cid:1)
(cid:1)(cid:2)(cid:1)(cid:3)

(cid:1)

(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)

(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:4)(cid:1)(cid:11)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:16)(cid:17)(cid:7)(cid:1)(cid:18)(cid:13)(cid:5)(cid:7)(cid:1)(cid:18)(cid:11)(cid:11)(cid:1)(cid:12)(cid:4)(cid:19)(cid:16)(cid:7)(cid:1)(cid:20)(cid:1)(cid:21)(cid:1)(cid:22)(cid:23)(cid:23)(cid:24)(cid:1)
(cid:2)(cid:3)(cid:3)(cid:4)(cid:5)(cid:19)(cid:7)(cid:1)(cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:1)(cid:8)(cid:16)(cid:10)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:6)(cid:19)(cid:7)(cid:1)(cid:28)(cid:15)(cid:29)(cid:1)(cid:30)(cid:13)(cid:14)(cid:6)(cid:1)(cid:20)(cid:19)(cid:15)(cid:1)(cid:31)(cid:4)(cid:19)(cid:16)(cid:7)(cid:1)(cid:21)(cid:1)(cid:22)(cid:23)(cid:23)(cid:24)(cid:1)
(cid:1)

(cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:1)(cid:8)(cid:16)(cid:10)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:6)(cid:19)’(cid:1)$(cid:6)(cid:16)(cid:10)$(cid:6)$(cid:1)(cid:15)(cid:29)(cid:4)(cid:15)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)%(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)(cid:1),(cid:10)(cid:5)(cid:5)(cid:1)!(cid:6)(cid:1)(cid:10)(cid:3)(cid:16)(cid:5)(cid:27)$(cid:6)$(cid:1)(cid:10)(cid:3)(cid:1)0(cid:26)(cid:6)(cid:3)+
(cid:2)(cid:16)(cid:16)(cid:6)(cid:19)(cid:19)(cid:1)$(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)(cid:19)(cid:7)(cid:1)(cid:1)
(cid:8)(cid:13)(cid:14)(cid:6)(cid:1) (cid:13)(cid:12)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:4)$((cid:4)(cid:3)(cid:15)(cid:4).(cid:6)(cid:19)(cid:1) (cid:4)(cid:9)(cid:10)(cid:19)(cid:10)(cid:3).(cid:1) (cid:12)(cid:9)(cid:13)(cid:14)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:27)(cid:19)(cid:6)(cid:1) (cid:13)(cid:12)(cid:1) 0(cid:26)(cid:6)(cid:3)+(cid:2)(cid:16)(cid:16)(cid:6)(cid:19)(cid:19)(cid:1)
$(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)(cid:19)(cid:1)(cid:4)(cid:9)(cid:6)/(cid:1)
(cid:1)(cid:3) (cid:2)(cid:1)(cid:29)(cid:10).(cid:29)(cid:1)((cid:10)(cid:19)(cid:10)!(cid:10)(cid:5)(cid:10)(cid:15)"(cid:1)(cid:13)(cid:12)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)%(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)9(cid:1)
(cid:1)(cid:3) (cid:2)!(cid:19)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1)(cid:13)(cid:12)(cid:1)(cid:1)(cid:10)(cid:3)(cid:16)(cid:5)(cid:27)(cid:19)(cid:10)(cid:13)(cid:3)(cid:1)(cid:16)(cid:13)(cid:19)(cid:15)(cid:19)9(cid:1)
(cid:1)(cid:3) (cid:2)!(cid:19)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1)(cid:13)(cid:12)(cid:1)(cid:1)(cid:19)(cid:27)!(cid:19)(cid:16)(cid:9)(cid:10)(cid:26)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1)(cid:12)(cid:6)(cid:6)(cid:19)9(cid:1)
(cid:1)(cid:3) 6(cid:6)(cid:4)$(cid:6)(cid:9)(cid:19)(cid:1) $(cid:13)(cid:1) (cid:3)(cid:13)(cid:15)(cid:1) (cid:3)(cid:6)(cid:6)$(cid:1)(cid:15)(cid:13)(cid:1)(cid:9)(cid:6).(cid:10)(cid:19)(cid:15)(cid:6)(cid:9)(cid:1) (cid:10)(cid:3)(cid:1) (cid:13)(cid:9)$(cid:6)(cid:9)(cid:1)(cid:15)(cid:13)(cid:1)((cid:10)(cid:6),(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:19)(cid:1)
(cid:13)(cid:9)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:4)!(cid:19)(cid:15)(cid:9)(cid:4)(cid:16)(cid:15)(cid:19)9(cid:1)
(cid:11)(cid:3)(cid:16)(cid:9)(cid:6)(cid:4)(cid:19)(cid:6)$(cid:1)(cid:26)(cid:13)(cid:19)(cid:19)(cid:10)!(cid:10)(cid:5)(cid:10)(cid:15)"(cid:1)(cid:15)(cid:13)(cid:1)(cid:19)(cid:29)(cid:4)(cid:9)(cid:6)(cid:1)<(cid:3)(cid:13),(cid:5)(cid:6)$.(cid:6)9(cid:1)
(cid:11)(cid:3)(cid:16)(cid:9)(cid:6)(cid:4)(cid:19)(cid:6)$(cid:1) (cid:26)(cid:13)(cid:19)(cid:19)(cid:10)!(cid:10)(cid:5)(cid:10)(cid:15)"(cid:1) (cid:13)(cid:12)(cid:1) (cid:16)(cid:10)(cid:15)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) (cid:13)(cid:12)(cid:1) (cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:19)*(cid:1) !"(cid:1) (cid:13)(cid:15)(cid:29)(cid:6)(cid:9)(cid:1)
(cid:9)(cid:6)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:6)(cid:9)(cid:19)(cid:7)(cid:1)

(cid:1)(cid:3)

(cid:1)(cid:3)

(cid:1)
(cid:1)
+(cid:8)(cid:17)(cid:16)(cid:4)(cid:2)(cid:8)(cid:18)(cid:13)(cid:13)(cid:4)(cid:10)(cid:10)(cid:8)(cid:1)(cid:2)(cid:6)(cid:20)(cid:6)(cid:11)(cid:20)(cid:6)"(cid:4),(cid:8)(cid:17)(cid:16)(cid:4)(cid:2)(cid:8)(cid:18)(cid:12)(cid:13)(cid:14)(cid:6)"(cid:4)(cid:8)(cid:1)(cid:2)(cid:6)(cid:20)(cid:6)(cid:11)(cid:20)(cid:6)"(cid:4)(cid:8)
(cid:1)
(cid:30)(cid:29)(cid:6)(cid:1) 8(cid:27)$(cid:4)(cid:26)(cid:6)(cid:19)(cid:15)(cid:1) 0(cid:26)(cid:6)(cid:3)(cid:1) (cid:2)(cid:16)(cid:16)(cid:6)(cid:19)(cid:19)(cid:1) (cid:11)(cid:3)(cid:10)(cid:15)(cid:10)(cid:4)(cid:15)(cid:10)((cid:6)(cid:1) ,(cid:4)(cid:19)(cid:1) $(cid:6)((cid:6)(cid:5)(cid:13)(cid:26)(cid:6)$(cid:1) (cid:10)(cid:3)(cid:1) (cid:22)(cid:23)(cid:23)(cid:20)(cid:1) !"(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) 0(cid:26)(cid:6)(cid:3)(cid:1)
(cid:8)(cid:13)(cid:16)(cid:10)(cid:6)(cid:15)"(cid:1) (cid:11)(cid:3)(cid:19)(cid:15)(cid:10)(cid:15)(cid:27)(cid:15)(cid:6)(cid:1) (cid:10)(cid:3)(cid:1)8(cid:27)$(cid:4)(cid:26)(cid:6)(cid:19)(cid:15)*(cid:1),(cid:10)(cid:15)(cid:29)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:14)(cid:4)(cid:10)(cid:3)(cid:1).(cid:13)(cid:4)(cid:5)(cid:1)(cid:13)(cid:12)(cid:1)(cid:14)(cid:4)<(cid:10)(cid:3).(cid:1)(cid:9)(cid:6)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:1)(cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:19)(cid:1)
(cid:12)(cid:9)(cid:13)(cid:14)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:19)(cid:16)(cid:10)(cid:6)(cid:3)(cid:15)(cid:10)(cid:12)(cid:10)(cid:16)(cid:1),(cid:13)(cid:9)(cid:5)$(cid:1)(cid:12)(cid:9)(cid:6)(cid:6)(cid:5)"(cid:1)(cid:4)((cid:4)(cid:10)(cid:5)(cid:4)!(cid:5)(cid:6)(cid:1)((cid:10)(cid:4)(cid:1)(cid:11)(cid:3)(cid:15)(cid:6)(cid:9)(cid:3)(cid:6)(cid:15)(cid:7)(cid:1)
8(cid:9)(cid:10)(cid:6)(cid:12)(cid:5)"*(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) 0(cid:26)(cid:6)(cid:3)(cid:1) (cid:2)(cid:16)(cid:16)(cid:6)(cid:19)(cid:19)(cid:1) (cid:11)(cid:3)(cid:10)(cid:15)(cid:10)(cid:4)(cid:15)(cid:10)((cid:6)(cid:1) (cid:10)(cid:3)(cid:15)(cid:6)(cid:3)$(cid:19)(cid:1) (cid:15)(cid:13)(cid:1) $(cid:10)(cid:19)(cid:15)(cid:9)(cid:10)!(cid:27)(cid:15)(cid:6)*(cid:1) ,(cid:10)(cid:15)(cid:29)(cid:13)(cid:27)(cid:15)(cid:1) (cid:4)(cid:3)"(cid:1)
(cid:16)(cid:29)(cid:4)(cid:9).(cid:6)(cid:19)*(cid:1) (cid:26)(cid:6)(cid:6)(cid:9)+(cid:9)(cid:6)((cid:10)(cid:6),(cid:6)$(cid:1) (cid:19)(cid:16)(cid:29)(cid:13)(cid:5)(cid:4)(cid:9)(cid:5)"(cid:1) %(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)(cid:19)*(cid:1) ,(cid:10)(cid:15)(cid:29)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) $(cid:10)(cid:19)(cid:19)(cid:6)(cid:14)(cid:10)(cid:3)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) (cid:13)(cid:12)(cid:1)
<(cid:3)(cid:13),(cid:5)(cid:6)$.(cid:6)(cid:1)(cid:4)(cid:19)(cid:1) (cid:13)(cid:3)(cid:5)"(cid:1)(cid:26)(cid:27)(cid:9)(cid:26)(cid:13)(cid:19)(cid:6)(cid:7)(cid:1)(cid:2)(cid:5)(cid:19)(cid:13)*(cid:1)(cid:15)(cid:29)(cid:10)(cid:19)(cid:1) (cid:10)(cid:3)(cid:10)(cid:15)(cid:10)(cid:4)(cid:15)(cid:10)((cid:6)(cid:1) (cid:13)(cid:12)(cid:12)(cid:6)(cid:9)(cid:19)(cid:1)(cid:4)(cid:1).(cid:9)(cid:6)(cid:4)(cid:15)(cid:1)(cid:4)$((cid:4)(cid:3)(cid:15)(cid:4).(cid:6)(cid:1)(cid:15)(cid:13)(cid:1)
(cid:9)(cid:6)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:6)(cid:9)(cid:19)*(cid:1) (cid:13)(cid:12)(cid:12)(cid:6)(cid:9)(cid:10)(cid:3).(cid:1) (cid:15)(cid:29)(cid:6)(cid:14)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:26)(cid:13)(cid:19)(cid:19)(cid:10)!(cid:10)(cid:5)(cid:10)(cid:15)"(cid:1) (cid:15)(cid:13)(cid:1) (cid:26)(cid:27)!(cid:5)(cid:10)(cid:19)(cid:29)(cid:1) (cid:15)(cid:29)(cid:6)(cid:10)(cid:9)(cid:1) ,(cid:13)(cid:9)<(cid:19)(cid:1) ,(cid:10)(cid:15)(cid:29)(cid:13)(cid:27)(cid:15)(cid:1)
(cid:16)(cid:13)(cid:19)(cid:15)(cid:19)*(cid:1) (cid:15)(cid:29)(cid:9)(cid:13)(cid:27).(cid:29)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:13)(cid:3)+(cid:5)(cid:10)(cid:3)(cid:6)(cid:1) (cid:26)(cid:27)!(cid:5)(cid:10)(cid:19)(cid:29)(cid:10)(cid:3).(cid:1) (cid:13)(cid:12)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:19)(cid:7)(cid:1) (cid:30)(cid:29)(cid:4)(cid:15)(cid:1) ,(cid:4)(cid:19)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:10)(cid:14)(cid:26)(cid:27)(cid:5)(cid:19)(cid:6)(cid:1)
(cid:15)(cid:29)(cid:4)(cid:15)(cid:1) (cid:15)(cid:9)(cid:4)(cid:3)(cid:19)(cid:12)(cid:13)(cid:9)(cid:14)(cid:6)$(cid:1) (cid:14)(cid:4)(cid:3)"(cid:1) (cid:19)(cid:16)(cid:10)(cid:6)(cid:3)(cid:15)(cid:10)(cid:12)(cid:10)(cid:16)(cid:1) %(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)(cid:19)(cid:1) (cid:10)(cid:3)(cid:15)(cid:13)(cid:1) (cid:14)(cid:13)$(cid:6)(cid:9)(cid:3)*(cid:1) ((cid:10)(cid:19)(cid:10)!(cid:5)(cid:6)*(cid:1) (cid:6)(cid:4)(cid:19)(cid:10)(cid:5)"(cid:1)
(cid:9)(cid:6)(cid:4)$(cid:4)!(cid:5)(cid:6)(cid:1) (cid:4)(cid:3)$(cid:1) (cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:4)!(cid:5)(cid:6)(cid:1) (cid:6)+%(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)(cid:19)(cid:7)(cid:1) (cid:30)(cid:29)(cid:6)(cid:1) (cid:16)(cid:13)(cid:3)(cid:16)(cid:6)(cid:26)(cid:15)(cid:1) ,(cid:4)(cid:19)(cid:1) (cid:9)(cid:4)(cid:26)(cid:10)$(cid:5)"(cid:1) (cid:4)$(cid:13)(cid:26)(cid:15)(cid:6)$(cid:1) !"(cid:1)
(cid:9)(cid:6)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:6)(cid:9)(cid:19)*(cid:1) (cid:15)(cid:6)(cid:4)(cid:16)(cid:29)(cid:6)(cid:9)(cid:19)(cid:1) (cid:4)(cid:3)$(cid:1) (cid:14)(cid:4)(cid:3)"(cid:1) (cid:13)(cid:15)(cid:29)(cid:6)(cid:9)(cid:1) (cid:16)(cid:4)(cid:15)(cid:6).(cid:13)(cid:9)(cid:10)(cid:6)(cid:19)*(cid:1) (cid:4)(cid:26)(cid:26)(cid:6)(cid:4)(cid:9)(cid:10)(cid:3).(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) ,(cid:10)(cid:19)(cid:29)(cid:1) (cid:15)(cid:13)(cid:1)
(cid:26)(cid:27)!(cid:5)(cid:10)(cid:19)(cid:29)(cid:1)(cid:5)(cid:6)(cid:16)(cid:15)(cid:27)(cid:9)(cid:6)(cid:1)(cid:3)(cid:13)(cid:15)(cid:6)(cid:19)*(cid:1)(cid:16)(cid:13)(cid:27)(cid:9)(cid:19)(cid:6)(cid:1)(cid:14)(cid:4)(cid:15)(cid:6)(cid:9)(cid:10)(cid:4)(cid:5)(cid:19)*(cid:1)(cid:26)(cid:9)(cid:6)(cid:26)(cid:9)(cid:10)(cid:3)(cid:15)(cid:19)(cid:1)(cid:13)(cid:9)(cid:1),(cid:13)(cid:9)<(cid:19)(cid:1) (cid:10)(cid:3)(cid:1)(cid:26)(cid:9)(cid:13).(cid:9)(cid:6)(cid:19)(cid:19)(cid:7)(cid:1)= (cid:10)(cid:15)(cid:29)(cid:1)
(cid:15)(cid:29)(cid:6)(cid:1)(cid:9)(cid:4)(cid:26)(cid:10)$(cid:5)"(cid:1) (cid:10)(cid:3)(cid:16)(cid:9)(cid:6)(cid:4)(cid:19)(cid:10)(cid:3).(cid:1)(cid:4)(cid:14)(cid:13)(cid:27)(cid:3)(cid:15)(cid:1)(cid:13)(cid:12)(cid:1)(cid:9)(cid:6)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:1)(cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:19)*(cid:1)(cid:4)(cid:1)(cid:3)(cid:6),(cid:1)(cid:16)(cid:29)(cid:4)(cid:5)(cid:5)(cid:6)(cid:3).(cid:6)(cid:1)(cid:16)(cid:4)(cid:14)(cid:6)(cid:1)(cid:27)(cid:26)/(cid:1)
(cid:15)(cid:29)(cid:6)(cid:1) (cid:3)(cid:6)(cid:6)$(cid:1) (cid:13)(cid:12)(cid:1) (cid:19)(cid:15)(cid:13)(cid:9)(cid:4).(cid:6)(cid:1) (cid:13)(cid:12)(cid:1) (cid:14)(cid:4)(cid:3)"(cid:1) (cid:9)(cid:6)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:1) (cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:19)(cid:7)(cid:1) (cid:25)(cid:5)(cid:4)(cid:19)(cid:19)(cid:10)(cid:16)(cid:4)(cid:5)(cid:1) $(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)(cid:19)(cid:1) ,(cid:6)(cid:9)(cid:6)(cid:3)>(cid:15)(cid:1)
(cid:6)(cid:3)(cid:13)(cid:27).(cid:29)(cid:1)(cid:12)(cid:13)(cid:9)(cid:1)(cid:19)(cid:27)(cid:16)(cid:29)(cid:1)(cid:4)(cid:3)(cid:1)(cid:4)(cid:16)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1)!(cid:6)(cid:16)(cid:4)(cid:27)(cid:19)(cid:6)(cid:1)(cid:13)(cid:5)$(cid:6)(cid:9)(cid:1)$(cid:6)(cid:26)(cid:13)(cid:19)(cid:10)(cid:15)(cid:19)(cid:1)(cid:29)(cid:4)$(cid:1)(cid:15)(cid:13)(cid:1)!(cid:6)(cid:1)(cid:6)(cid:4)(cid:19)(cid:10)(cid:5)"(cid:1)(cid:9)(cid:6)(cid:4)(cid:16)(cid:29)(cid:4)!(cid:5)(cid:6)*(cid:1)
(cid:15)(cid:29)(cid:9)(cid:13)(cid:27).(cid:29)(cid:1) (cid:19)(cid:10)(cid:14)(cid:26)(cid:5)(cid:6)(cid:1) (cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:6)(cid:19)(cid:1) (cid:10)(cid:3)(cid:1) !(cid:9)(cid:13),(cid:19)(cid:6)(cid:9)(cid:19)(cid:7)(cid:1) (cid:11)(cid:15)(cid:1) (cid:10)(cid:19)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:14)(cid:13)(cid:14)(cid:6)(cid:3)(cid:15)(cid:1) ,(cid:29)(cid:6)(cid:3)(cid:1) (cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)(cid:1)
$(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)(cid:19)(cid:1) 4(cid:13)(cid:9)(cid:1)(cid:4)(cid:9)(cid:16)(cid:29)(cid:10)((cid:6)(cid:19)7(cid:1)(cid:4)(cid:3)$(cid:1)(cid:9)(cid:6)(cid:26)(cid:13)(cid:19)(cid:10)(cid:15)(cid:13)(cid:9)(cid:10)(cid:6)(cid:19)(cid:1)(cid:4)(cid:26)(cid:26)(cid:6)(cid:4)(cid:9)(cid:1)(cid:4)(cid:3)$*(cid:1)(cid:14)(cid:13)(cid:9)(cid:6)*(cid:1)(cid:15)(cid:29)(cid:6)"(cid:1)(cid:29)(cid:4)$(cid:1)(cid:15)(cid:13)(cid:1)!(cid:6)(cid:1) (cid:10)(cid:3)(cid:1)
(cid:4)(cid:16)(cid:16)(cid:13)(cid:9)$(cid:1) ,(cid:10)(cid:15)(cid:29)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:12)(cid:9)(cid:4)(cid:14)(cid:6)(cid:1) (cid:6)(cid:19)(cid:15)(cid:4)!(cid:5)(cid:10)(cid:19)(cid:29)(cid:6)$(cid:1) !"(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) 0(cid:26)(cid:6)(cid:3)(cid:1) (cid:2)(cid:16)(cid:16)(cid:6)(cid:19)(cid:19)(cid:1) (cid:11)(cid:3)(cid:10)(cid:15)(cid:10)(cid:4)(cid:15)(cid:10)((cid:6)(cid:7)(cid:1) (cid:30)(cid:29)(cid:6)(cid:1)
(cid:4)(cid:26)(cid:26)(cid:9)(cid:13)(cid:26)(cid:9)(cid:10)(cid:4)(cid:15)(cid:6)(cid:1)(cid:16)(cid:13)(cid:3)(cid:16)(cid:6)(cid:26)(cid:15)(cid:1)(cid:15)(cid:13)(cid:1)(cid:29)(cid:4)(cid:3)$(cid:5)(cid:6)(cid:1)(cid:15)(cid:29)(cid:10)(cid:19)(cid:1)(cid:4)(cid:19)(cid:26)(cid:6)(cid:16)(cid:15)(cid:1),(cid:4)(cid:19)(cid:1)(cid:13)(cid:26)(cid:6)(cid:3)(cid:1)(cid:4)(cid:9)(cid:16)(cid:29)(cid:10)((cid:6)(cid:19)(cid:7)(cid:1)(cid:1)
(cid:11)(cid:3)(cid:1) (cid:13)(cid:9)$(cid:6)(cid:9)(cid:1) (cid:15)(cid:13)(cid:1) (cid:13)(cid:12)(cid:12)(cid:6)(cid:9)(cid:1) (cid:4)(cid:3)(cid:1) (cid:13)(cid:26)(cid:6)(cid:3)(cid:1) (cid:4)(cid:16)(cid:16)(cid:6)(cid:19)(cid:19)(cid:1) (cid:16)(cid:29)(cid:4)(cid:9)(cid:4)(cid:16)(cid:15)(cid:6)(cid:9)(cid:1) (cid:15)(cid:13)(cid:1) (cid:19)(cid:16)(cid:29)(cid:13)(cid:5)(cid:4)(cid:9)(cid:5)"(cid:1) %(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)*(cid:1) (cid:15)(cid:29)(cid:6)(cid:1)
(cid:4)(cid:27)(cid:15)(cid:29)(cid:13)(cid:9)(cid:19)(cid:1)(cid:13)(cid:12)(cid:1)(cid:15)(cid:29)(cid:10)(cid:19)(cid:1)(cid:10)(cid:3)(cid:10)(cid:15)(cid:10)(cid:4)(cid:15)(cid:10)((cid:6)(cid:1),(cid:6)(cid:9)(cid:6)(cid:1)(cid:26)(cid:9)(cid:13)(cid:26)(cid:13)(cid:19)(cid:10)(cid:3).(cid:1)(cid:15),(cid:13)(cid:1)(cid:16)(cid:13)(cid:14)(cid:26)(cid:5)(cid:6)(cid:14)(cid:6)(cid:3)(cid:15)(cid:4)(cid:9)"(cid:1)(cid:19)(cid:15)(cid:9)(cid:4)(cid:15)(cid:6).(cid:10)(cid:6)(cid:19)/(cid:1)(cid:19)(cid:6)(cid:5)(cid:12)+
(cid:4)(cid:9)(cid:16)(cid:29)(cid:10)((cid:10)(cid:3).(cid:1)(cid:4)(cid:3)$(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:16)(cid:9)(cid:6)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1)(cid:13)(cid:12)(cid:1)(cid:13)(cid:26)(cid:6)(cid:3)+(cid:4)(cid:16)(cid:16)(cid:6)(cid:19)(cid:19)(cid:1)%(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)(cid:19)(cid:7)(cid:1)(cid:1)
(cid:30)(cid:29)(cid:9)(cid:13)(cid:27).(cid:29)(cid:1) (cid:13)(cid:26)(cid:6)(cid:3)(cid:1) (cid:4)(cid:9)(cid:16)(cid:29)(cid:10)((cid:6)(cid:19)*(cid:1) (cid:13)(cid:3)(cid:6)(cid:1) (cid:10)(cid:19)(cid:1) (cid:6)(cid:3)(cid:4)!(cid:5)(cid:6)$(cid:1) (cid:15)(cid:13)(cid:1) (cid:27)(cid:19)(cid:6)(cid:1) &(cid:21) (cid:2)(cid:22)(cid:23)(cid:10)(cid:16)(cid:16)(cid:2)(cid:24)(cid:24)(cid:12)(cid:22)(cid:7)(cid:2)(cid:8)
(cid:20)(cid:10)(cid:4)(cid:2)(cid:5)(cid:12)(cid:10)(cid:7)(cid:8)
(cid:4)(cid:25)(cid:5)(cid:13)(cid:6)(cid:26)(cid:25)(cid:8) (cid:12)(cid:3)(cid:4)(cid:2)(cid:5)(cid:13)(cid:14)(cid:2)(cid:5)(cid:10)(cid:22)(cid:7)(cid:2)(cid:8) (cid:5)(cid:2)(cid:14)(cid:13)(cid:24)(cid:12)(cid:4)(cid:13)(cid:5)(cid:12)(cid:2)(cid:24)(cid:8) (cid:27)(cid:13)(cid:5)(cid:8) (cid:20)(cid:2)(cid:4)(cid:10)(cid:28)(cid:10)(cid:4)(cid:10)(cid:8) (cid:24)(cid:25)(cid:10)(cid:5)(cid:12)(cid:3)(cid:26)(cid:29)(cid:8)
(cid:1)(cid:2)(cid:4)(cid:3)
(cid:1)

(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)

(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:4)(cid:1)(cid:11)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:16)(cid:17)(cid:7)(cid:1)(cid:18)(cid:13)(cid:5)(cid:7)(cid:1)(cid:18)(cid:11)(cid:11)(cid:1)(cid:12)(cid:4)(cid:19)(cid:16)(cid:7)(cid:1)(cid:20)(cid:1)(cid:21)(cid:1)(cid:22)(cid:23)(cid:23)(cid:24)(cid:1)
(cid:2)(cid:3)(cid:3)(cid:4)(cid:5)(cid:19)(cid:7)(cid:1)(cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:1)(cid:8)(cid:16)(cid:10)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:6)(cid:19)(cid:7)(cid:1)(cid:28)(cid:15)(cid:29)(cid:1)(cid:30)(cid:13)(cid:14)(cid:6)(cid:1)(cid:20)(cid:19)(cid:15)(cid:1)(cid:31)(cid:4)(cid:19)(cid:16)(cid:7)(cid:1)(cid:21)(cid:1)(cid:22)(cid:23)(cid:23)(cid:24)(cid:1)
(cid:1)

(cid:14)(cid:6)(cid:22)(cid:7)(cid:12)(cid:24)(cid:25)(cid:12)(cid:3)(cid:26)(cid:8) (cid:10)(cid:3)(cid:28)(cid:8) (cid:10)(cid:5)(cid:16)(cid:25)(cid:12)(cid:30)(cid:12)(cid:3)(cid:26)(cid:31)(cid:8)  (cid:4)(cid:8) (cid:10)(cid:5)(cid:13)(cid:24)(cid:2)(cid:8) (cid:13)(cid:6)(cid:4)(cid:8) (cid:13)(cid:27)(cid:8) (cid:4)(cid:25)(cid:2)(cid:8) (cid:2)(cid:23)(cid:14)(cid:5)(cid:12)(cid:3)(cid:4)(cid:8) (cid:16)(cid:13)(cid:20)(cid:20)(cid:6)(cid:3)(cid:12)(cid:4)!(cid:29)(cid:8) "(cid:25)(cid:2)(cid:5)(cid:2)(cid:8) (cid:10)(cid:8)
(cid:26)(cid:5)(cid:13)"(cid:12)(cid:3)(cid:26)(cid:8) (cid:3)(cid:2)(cid:2)(cid:28)(cid:8) (cid:27)(cid:13)(cid:5)(cid:8) (cid:10)(cid:8) (cid:7)(cid:13)"(cid:23)(cid:22)(cid:10)(cid:5)(cid:5)(cid:12)(cid:2)(cid:5)(cid:8) (cid:12)(cid:3)(cid:4)(cid:2)(cid:5)(cid:13)(cid:14)(cid:2)(cid:5)(cid:10)(cid:22)(cid:12)(cid:7)(cid:12)(cid:4)!(cid:8) (cid:24)(cid:13)(cid:7)(cid:6)(cid:4)(cid:12)(cid:13)(cid:3)(cid:8) (cid:4)(cid:13)(cid:8) (cid:10)(cid:16)(cid:16)(cid:2)(cid:24)(cid:24)(cid:8) (cid:10)(cid:16)(cid:5)(cid:13)(cid:24)(cid:24)(cid:8)
(cid:27)(cid:10)(cid:12)(cid:5)(cid:7)!(cid:8) (cid:25)(cid:2)(cid:4)(cid:2)(cid:5)(cid:13)(cid:26)(cid:2)(cid:3)(cid:2)(cid:13)(cid:6)(cid:24)(cid:8) (cid:5)(cid:2)(cid:14)(cid:13)(cid:24)(cid:12)(cid:4)(cid:13)(cid:5)(cid:12)(cid:2)(cid:24)(cid:8) (cid:7)(cid:2)(cid:10)(cid:28)(cid:24)(cid:8) (cid:4)(cid:13)(cid:8) (cid:4)(cid:25)(cid:2)(cid:8) (cid:2)(cid:24)(cid:4)(cid:10)(cid:22)(cid:7)(cid:12)(cid:24)(cid:25)(cid:20)(cid:2)(cid:3)(cid:4)(cid:8) (cid:13)(cid:27)(cid:8) (cid:4)(cid:25)(cid:2)(cid:8) #(cid:14)(cid:2)(cid:3)(cid:8)
$(cid:5)(cid:16)(cid:25)(cid:12)(cid:30)(cid:2)(cid:24)(cid:8) (cid:3)(cid:12)(cid:4)(cid:12)(cid:10)(cid:4)(cid:12)(cid:30)(cid:2)(cid:8)%#$ &(cid:31)(cid:8)(cid:8)
’(cid:25)(cid:2)(cid:8) #$ (cid:8) (cid:28)(cid:2)(cid:30)(cid:2)(cid:7)(cid:13)(cid:14)(cid:24)(cid:8) (cid:10)(cid:3)(cid:28)(cid:8) (cid:14)(cid:5)(cid:13)(cid:20)(cid:13)(cid:4)(cid:2)(cid:24)(cid:8) (cid:10)(cid:8) (cid:7)(cid:13)"(cid:23)(cid:22)(cid:10)(cid:5)(cid:5)(cid:12)(cid:2)(cid:5)(cid:8) (cid:12)(cid:3)(cid:4)(cid:2)(cid:5)(cid:13)(cid:14)(cid:2)(cid:5)(cid:10)(cid:22)(cid:12)(cid:7)(cid:12)(cid:4)!(cid:8)
(cid:27)(cid:5)(cid:10)(cid:20)(cid:2)"(cid:13)(cid:5)((cid:8)(cid:10)(cid:3)(cid:28)(cid:8)(cid:10)(cid:24)(cid:24)(cid:13)(cid:16)(cid:12)(cid:10)(cid:4)(cid:2)(cid:28)(cid:8)(cid:24)(cid:4)(cid:10)(cid:3)(cid:28)(cid:10)(cid:5)(cid:28)(cid:24)(cid:29)(cid:8)(cid:13)(cid:5)(cid:12)(cid:26)(cid:12)(cid:3)(cid:10)(cid:7)(cid:7)!(cid:8)(cid:4)(cid:13)(cid:8)(cid:2)(cid:3)(cid:25)(cid:10)(cid:3)(cid:16)(cid:2)(cid:8)(cid:10)(cid:16)(cid:16)(cid:2)(cid:24)(cid:24)(cid:8)(cid:4)(cid:13)(cid:8)(cid:2)(cid:23)(cid:14)(cid:5)(cid:12)(cid:3)(cid:4)(cid:8)
(cid:10)(cid:5)(cid:16)(cid:25)(cid:12)(cid:30)(cid:2)(cid:24)(cid:29)(cid:8) (cid:22)(cid:6)(cid:4)(cid:8) (cid:3)(cid:13)"(cid:8) (cid:4)(cid:10)((cid:12)(cid:3)(cid:26)(cid:8) (cid:12)(cid:3)(cid:4)(cid:13)(cid:8) (cid:10)(cid:16)(cid:16)(cid:13)(cid:6)(cid:3)(cid:4)(cid:8) (cid:10)(cid:16)(cid:16)(cid:2)(cid:24)(cid:24)(cid:8) (cid:4)(cid:13)(cid:8) (cid:13)(cid:4)(cid:25)(cid:2)(cid:5)(cid:8) (cid:28)(cid:12)(cid:26)(cid:12)(cid:4)(cid:10)(cid:7)(cid:8) (cid:20)(cid:10)(cid:4)(cid:2)(cid:5)(cid:12)(cid:10)(cid:7)(cid:24)’(cid:1)
?0(cid:2)(cid:11)(cid:23)(cid:22)@(cid:7)(cid:1) (cid:2)(cid:5)(cid:19)(cid:13)*(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) 0(cid:2)(cid:11)(cid:1) (cid:14)(cid:10)(cid:19)(cid:19)(cid:10)(cid:13)(cid:3)(cid:1) (cid:19)(cid:15)(cid:4)(cid:15)(cid:6)(cid:19)(cid:1) (cid:15)(cid:29)(cid:4)(cid:15)(cid:1) &(cid:15)(cid:29)(cid:6)(cid:1) 0(cid:26)(cid:6)(cid:3)(cid:1) (cid:2)(cid:9)(cid:16)(cid:29)(cid:10)((cid:6)(cid:19)(cid:1) (cid:11)(cid:3)(cid:10)(cid:15)(cid:10)(cid:4)(cid:15)(cid:10)((cid:6)(cid:1)
$(cid:6)((cid:6)(cid:5)(cid:13)(cid:26)(cid:19)(cid:1) (cid:4)(cid:3)$(cid:1) (cid:26)(cid:9)(cid:13)(cid:14)(cid:13)(cid:15)(cid:6)(cid:19)(cid:1) (cid:10)(cid:3)(cid:15)(cid:6)(cid:9)(cid:13)(cid:26)(cid:6)(cid:9)(cid:4)!(cid:10)(cid:5)(cid:10)(cid:15)"(cid:1) (cid:19)(cid:15)(cid:4)(cid:3)$(cid:4)(cid:9)$(cid:19)(cid:1) (cid:15)(cid:29)(cid:4)(cid:15)(cid:1) (cid:4)(cid:10)(cid:14)(cid:1) (cid:15)(cid:13)(cid:1) (cid:12)(cid:4)(cid:16)(cid:10)(cid:5)(cid:10)(cid:15)(cid:4)(cid:15)(cid:6)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1)
(cid:6)(cid:12)(cid:12)(cid:10)(cid:16)(cid:10)(cid:6)(cid:3)(cid:15)(cid:1)$(cid:10)(cid:19)(cid:19)(cid:6)(cid:14)(cid:10)(cid:3)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1)(cid:13)(cid:12)(cid:1)(cid:16)(cid:13)(cid:3)(cid:15)(cid:6)(cid:3)(cid:15)(cid:7)’(cid:1)
(cid:30)(cid:29)(cid:6)(cid:1) 0(cid:2)(cid:11)(cid:1) (cid:10)(cid:19)(cid:1) (cid:4)(cid:3)(cid:1) (cid:10)(cid:3)(cid:10)(cid:15)(cid:10)(cid:4)(cid:15)(cid:10)((cid:6)(cid:1) (cid:15)(cid:13)(cid:1) $(cid:6)((cid:6)(cid:5)(cid:13)(cid:26)(cid:1) (cid:4)(cid:3)$(cid:1) (cid:26)(cid:9)(cid:13)(cid:14)(cid:13)(cid:15)(cid:6)(cid:1) (cid:10)(cid:3)(cid:15)(cid:6)(cid:9)(cid:13)(cid:26)(cid:6)(cid:9)(cid:4)!(cid:10)(cid:5)(cid:10)(cid:15)"(cid:1)
(cid:19)(cid:15)(cid:4)(cid:3)$(cid:4)(cid:9)$(cid:19)(cid:1)(cid:15)(cid:29)(cid:4)(cid:15)(cid:1)(cid:4)(cid:10)(cid:14)(cid:1)(cid:15)(cid:13)(cid:1)(cid:12)(cid:4)(cid:16)(cid:10)(cid:5)(cid:10)(cid:15)(cid:4)(cid:15)(cid:6)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:6)(cid:12)(cid:12)(cid:10)(cid:16)(cid:10)(cid:6)(cid:3)(cid:15)(cid:1)$(cid:10)(cid:19)(cid:19)(cid:6)(cid:14)(cid:10)(cid:3)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1)(cid:13)(cid:12)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:16)(cid:13)(cid:3)(cid:15)(cid:6)(cid:3)(cid:15)(cid:7)(cid:1)(cid:1)
(cid:1)
(cid:1)
-(cid:8).(cid:4)(cid:20)(cid:11)(cid:3)(cid:11)(cid:20)(cid:11)(cid:8)(cid:11)(cid:2)(cid:3)(cid:8)&(cid:20)(cid:11)(cid:2)(cid:3)(cid:11)(cid:12)(cid:3)(cid:10)(cid:8)
(cid:8)
(cid:31)(cid:13)(cid:5)(cid:5)(cid:13),(cid:10)(cid:3).(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) $(cid:6)(cid:12)(cid:10)(cid:3)(cid:10)(cid:15)(cid:10)(cid:13)(cid:3)*(cid:1) (cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1) (cid:9)(cid:6)(cid:26)(cid:9)(cid:6)(cid:19)(cid:6)(cid:3)(cid:15)(cid:19)(cid:1) &(cid:28)(cid:10)(cid:4)(cid:10)(cid:8) (cid:4)(cid:25)(cid:10)(cid:4)(cid:8) (cid:28)(cid:2)(cid:24)(cid:16)(cid:5)(cid:12)(cid:22)(cid:2)(cid:24)(cid:8) (cid:13)(cid:4)(cid:25)(cid:2)(cid:5)(cid:8)
(cid:28)(cid:10)(cid:4)(cid:10)’(cid:7)(cid:1) (cid:31)(cid:13)(cid:9)(cid:1) (cid:9)(cid:6)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:1) (cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:19)*(cid:1) (cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1) (cid:14)(cid:6)(cid:4)(cid:3)(cid:19)(cid:1) (cid:10)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) (cid:13)(cid:3)(cid:1) (cid:15)(cid:10)(cid:15)(cid:5)(cid:6)(cid:19)*(cid:1) (cid:4)(cid:27)(cid:15)(cid:29)(cid:13)(cid:9)(cid:19)(cid:1)
(cid:4)(cid:3)$(cid:1)(cid:15)(cid:29)(cid:6)(cid:10)(cid:9)(cid:1)(cid:4)(cid:12)(cid:12)(cid:10)(cid:5)(cid:10)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)*(cid:1)(cid:16)(cid:13)(cid:3)(cid:15)(cid:4)(cid:16)(cid:15)(cid:1) $(cid:4)(cid:15)(cid:4)*(cid:1)(cid:15)(cid:29)(cid:6)(cid:1) (cid:19)(cid:15)(cid:4)(cid:15)(cid:27)(cid:19)(cid:1) (cid:13)(cid:12)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1),(cid:13)(cid:9)<*(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:5)(cid:4)(cid:3).(cid:27)(cid:4).(cid:6)(cid:1) (cid:27)(cid:19)(cid:6)$*(cid:1)
(cid:15)(cid:29)(cid:6)(cid:1) (cid:3)(cid:27)(cid:14)!(cid:6)(cid:9)(cid:1) (cid:13)(cid:12)(cid:1) (cid:12)(cid:10).(cid:27)(cid:9)(cid:6)(cid:19)(cid:1) (cid:4)(cid:3)$(cid:1) (cid:15)(cid:4)!(cid:5)(cid:6)(cid:19)(cid:1) (cid:10)(cid:3)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:26)(cid:4)(cid:26)(cid:6)(cid:9)*(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:3)(cid:27)(cid:14)!(cid:6)(cid:9)(cid:1) (cid:13)(cid:12)(cid:1) (cid:26)(cid:4).(cid:6)(cid:19)*(cid:1) (cid:15)(cid:29)(cid:6)(cid:1)
(cid:4)!(cid:19)(cid:15)(cid:9)(cid:4)(cid:16)(cid:15)(cid:1)(cid:4)(cid:3)$(cid:1)<(cid:6)",(cid:13)(cid:9)$(cid:19)(cid:7)(cid:1)
8"(cid:1) (cid:27)(cid:19)(cid:10)(cid:3).(cid:1) (cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)*(cid:1) (cid:13)(cid:3)(cid:6)(cid:1) (cid:16)(cid:4)(cid:3)(cid:1) (cid:13)!(cid:15)(cid:4)(cid:10)(cid:3)(cid:1) (cid:4)$$(cid:10)(cid:15)(cid:10)(cid:13)(cid:3)(cid:4)(cid:5)(cid:1) (cid:10)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) (cid:13)(cid:3)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1)
$(cid:6)(cid:26)(cid:13)(cid:19)(cid:10)(cid:15)(cid:7)(cid:1) (cid:11)(cid:3)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:16)(cid:4)(cid:19)(cid:6)(cid:1)(cid:13)(cid:12)(cid:1)(cid:4)(cid:1)%(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)*(cid:1)(cid:15)(cid:29)(cid:10)(cid:19)(cid:1)(cid:16)(cid:4)(cid:3)(cid:1)$(cid:6)(cid:19)(cid:16)(cid:9)(cid:10)!(cid:6)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:16)(cid:13)(cid:3)(cid:12)(cid:6)(cid:9)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1)4(cid:3)(cid:4)(cid:14)(cid:6)(cid:1)(cid:4)(cid:3)$(cid:1)
(cid:5)(cid:13)(cid:16)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)7(cid:1),(cid:29)(cid:6)(cid:9)(cid:6)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:19)(cid:1),(cid:6)(cid:9)(cid:6)(cid:1)(cid:26)(cid:9)(cid:6)(cid:19)(cid:6)(cid:3)(cid:15)(cid:6)$(cid:7)(cid:1)(cid:31)(cid:9)(cid:13)(cid:14)(cid:1)(cid:4)(cid:3)(cid:13)(cid:15)(cid:29)(cid:6)(cid:9)(cid:1)(cid:26)(cid:13)(cid:10)(cid:3)(cid:15)(cid:1) (cid:13)(cid:12)(cid:1)((cid:10)(cid:6),*(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)
(cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1) ,(cid:6)>((cid:6)(cid:1) (cid:27)(cid:19)(cid:6)$(cid:1) (cid:16)(cid:13)(cid:3)(cid:15)(cid:6)(cid:3)(cid:15)(cid:1) (cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1) ,(cid:29)(cid:10)(cid:16)(cid:29)(cid:1) (cid:4)(cid:9)(cid:6)(cid:1) (cid:10)(cid:14)(cid:14)(cid:27)(cid:15)(cid:4)!(cid:5)(cid:6)(cid:1) 4(cid:15)(cid:29)(cid:6)(cid:1) $(cid:4)(cid:15)(cid:4)(cid:1)
(cid:16)(cid:13)(cid:3)(cid:19)(cid:10)$(cid:6)(cid:9)(cid:6)$(cid:1) $(cid:13)(cid:1) (cid:3)(cid:13)(cid:15)(cid:1) (cid:16)(cid:29)(cid:4)(cid:3).(cid:6)(cid:1) (cid:10)(cid:3)(cid:1) (cid:15)(cid:10)(cid:14)(cid:6)(cid:1) (cid:13)(cid:9)(cid:1) (cid:4)(cid:19)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)(cid:1) (cid:10)(cid:19)(cid:1) (cid:9)(cid:6)(cid:4)$7(cid:7)(cid:1) (cid:2)(cid:5)(cid:19)(cid:13)*(cid:1) (cid:15)(cid:29)(cid:6)(cid:1)
(cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1) (cid:4)(cid:19)(cid:19)(cid:13)(cid:16)(cid:10)(cid:4)(cid:15)(cid:6)$(cid:1) ,(cid:10)(cid:15)(cid:29)(cid:1) (cid:4)(cid:1) (cid:19)(cid:16)(cid:10)(cid:6)(cid:3)(cid:15)(cid:10)(cid:12)(cid:10)(cid:16)(cid:1) (cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:1) (cid:16)(cid:4)(cid:3)(cid:1) !(cid:6)(cid:1) (cid:16)(cid:29)(cid:4)(cid:9)(cid:4)(cid:16)(cid:15)(cid:6)(cid:9)(cid:10)#(cid:6)$(cid:1) (cid:4)(cid:19)(cid:1) (cid:4)(cid:16)(cid:15)(cid:10)((cid:6)*(cid:1)
(cid:14)(cid:6)(cid:4)(cid:3)(cid:10)(cid:3).(cid:1)(cid:15)(cid:29)(cid:4)(cid:15)(cid:1)(cid:10)(cid:15)(cid:1)(cid:16)(cid:4)(cid:3)(cid:1)!(cid:6)(cid:1)(cid:16)(cid:13)(cid:3)(cid:19)(cid:27)(cid:5)(cid:15)(cid:6)$(cid:1)!"(cid:1)(cid:4)(cid:1).(cid:6)(cid:3)(cid:6)(cid:9)(cid:10)(cid:16)(cid:1)(cid:16)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:1)(cid:26)(cid:9)(cid:13).(cid:9)(cid:4)(cid:14)(cid:7)(cid:1)(cid:1)
(cid:2)(cid:5)(cid:5)(cid:1) $(cid:10).(cid:10)(cid:15)(cid:4)(cid:5)(cid:1) (cid:5)(cid:10)!(cid:9)(cid:4)(cid:9)(cid:10)(cid:6)(cid:19)(cid:1) (cid:12)(cid:9)(cid:6)1(cid:27)(cid:6)(cid:3)(cid:15)(cid:5)"(cid:1) (cid:27)(cid:19)(cid:6)(cid:1) (cid:4)(cid:1) (cid:19)(cid:6)(cid:15)(cid:1) (cid:13)(cid:12)(cid:1) (cid:10)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) (cid:16)(cid:4)(cid:5)(cid:5)(cid:6)$(cid:1)
(cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)*(cid:1) (cid:10)(cid:3)(cid:1) (cid:13)(cid:9)$(cid:6)(cid:9)(cid:1) (cid:15)(cid:13)(cid:1) $(cid:6)(cid:19)(cid:16)(cid:9)(cid:10)!(cid:6)(cid:1) (cid:15)(cid:29)(cid:6)(cid:10)(cid:9)(cid:1) (cid:13)!%(cid:6)(cid:16)(cid:15)(cid:19)(cid:1) 4(cid:9)(cid:6)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:1) (cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:19)*(cid:1) (cid:5)(cid:6)(cid:16)(cid:15)(cid:27)(cid:9)(cid:6)(cid:1) (cid:3)(cid:13)(cid:15)(cid:6)(cid:19)*(cid:1)
!(cid:13)(cid:13)<(cid:19)*(cid:1)(cid:6)(cid:15)(cid:16)7(cid:7)(cid:1)(cid:30)(cid:29)(cid:10)(cid:19)(cid:1)(cid:10)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1)(cid:16)(cid:4)(cid:3)(cid:1)!(cid:6)(cid:1)(cid:16)(cid:5)(cid:4)(cid:19)(cid:19)(cid:10)(cid:12)(cid:10)(cid:6)$(cid:1)(cid:4)(cid:19)(cid:1)(cid:12)(cid:13)(cid:5)(cid:5)(cid:13),(cid:19)/(cid:1)
(cid:1)(cid:3) A(cid:6)(cid:19)(cid:16)(cid:9)(cid:10)(cid:26)(cid:15)(cid:10)((cid:6)(cid:1) (cid:21)(cid:1) (cid:27)(cid:19)(cid:6)$(cid:1) (cid:10)(cid:3)(cid:1) (cid:9)(cid:6)(cid:5)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) ,(cid:10)(cid:15)(cid:29)(cid:1) !(cid:10)!(cid:5)(cid:10)(cid:13).(cid:9)(cid:4)(cid:26)(cid:29)(cid:10)(cid:6)(cid:19)(cid:1) (cid:4)(cid:3)$(cid:1) (cid:19)(cid:27)!%(cid:6)(cid:16)(cid:15)(cid:6)$(cid:1)
(cid:15)(cid:13)(cid:1)(cid:19)(cid:15)(cid:4)(cid:3)$(cid:4)(cid:9)$(cid:19)(cid:1)(cid:19)(cid:27)(cid:16)(cid:29)(cid:1)(cid:4)(cid:19)(cid:1)B (cid:2)6(cid:25)(cid:1)4B (cid:4)(cid:16)(cid:29)(cid:10)(cid:3)(cid:6)+6(cid:6)(cid:4)$(cid:4)!(cid:5)(cid:6)(cid:1)(cid:25)(cid:4)(cid:15)(cid:4)(cid:5)(cid:13).(cid:10)(cid:3).79(cid:1)
(cid:1)(cid:3) (cid:8)(cid:15)(cid:9)(cid:27)(cid:16)(cid:15)(cid:27)(cid:9)(cid:4)(cid:5)(cid:1) (cid:21)(cid:1),(cid:10)(cid:15)(cid:29)(cid:1)(cid:9)(cid:6)(cid:5)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:19)(cid:1)!(cid:6)(cid:15),(cid:6)(cid:6)(cid:3)(cid:1) $(cid:10)(cid:12)(cid:12)(cid:6)(cid:9)(cid:6)(cid:3)(cid:15)(cid:1)(cid:26)(cid:4)(cid:9)(cid:15)(cid:19)(cid:1) (cid:13)(cid:12)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1) $(cid:6)(cid:26)(cid:13)(cid:19)(cid:10)(cid:15)(cid:1)
4(cid:4)!(cid:19)(cid:15)(cid:9)(cid:4)(cid:16)(cid:15)*(cid:1) (cid:15)(cid:6)-(cid:15)*(cid:1) (cid:12)(cid:10).(cid:27)(cid:9)(cid:6)(cid:19)*(cid:1) (cid:15)(cid:4)!(cid:5)(cid:6)(cid:19)7(cid:1) (cid:4)(cid:3)$(cid:1) ,(cid:10)(cid:15)(cid:29)(cid:1) (cid:5)(cid:10)(cid:3)<(cid:4).(cid:6)(cid:1) (cid:10)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1)
!(cid:6)(cid:15),(cid:6)(cid:6)(cid:3)(cid:1)$(cid:6)(cid:26)(cid:13)(cid:19)(cid:10)(cid:15)(cid:19)(cid:1)4(cid:6)(cid:7).(cid:7)(cid:1)(cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)(cid:19)(cid:1)(cid:10)(cid:3)(cid:1)(cid:4)(cid:1)(cid:26)(cid:9)(cid:13)(cid:16)(cid:6)(cid:6)$(cid:10)(cid:3).(cid:19)(cid:1)((cid:13)(cid:5)(cid:27)(cid:14)(cid:6)79(cid:1)
(cid:1)(cid:3) (cid:2)$(cid:14)(cid:10)(cid:3)(cid:10)(cid:19)(cid:15)(cid:9)(cid:4)(cid:15)(cid:10)((cid:6)(cid:1) (cid:21)(cid:1) (cid:9)(cid:6)(cid:5)(cid:4)(cid:15)(cid:6)$(cid:1) (cid:15)(cid:13)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) $(cid:6)(cid:26)(cid:13)(cid:19)(cid:10)(cid:15)(cid:1) (cid:19)(cid:15)(cid:13)(cid:9)(cid:4).(cid:6)(cid:1) (cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:1) (cid:13)(cid:9)(cid:1) (cid:10)(cid:15)(cid:19)(cid:1)
(cid:13)(cid:9)(cid:10).(cid:10)(cid:3)(cid:4)(cid:5)(cid:1)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)*(cid:1)(cid:4)(cid:19)(cid:26)(cid:6)(cid:16)(cid:15)(cid:19)(cid:1)(cid:13)(cid:3)(cid:1)(cid:5)(cid:10)(cid:16)(cid:6)(cid:3)(cid:19)(cid:6)(cid:1)(cid:4)(cid:3)$(cid:1)(cid:16)(cid:13)(cid:26)"(cid:9)(cid:10).(cid:29)(cid:15)(cid:7)(cid:1)
(cid:11)(cid:3)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:16)(cid:4)(cid:19)(cid:6)(cid:1) (cid:13)(cid:12)(cid:1) (cid:4)(cid:1) (cid:19)(cid:16)(cid:10)(cid:6)(cid:3)(cid:15)(cid:10)(cid:12)(cid:10)(cid:16)(cid:1) %(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)*(cid:1) (cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1) (cid:10)(cid:19)(cid:1) (cid:14)(cid:13)(cid:19)(cid:15)(cid:1) (cid:13)(cid:12)(cid:15)(cid:6)(cid:3)(cid:1) (cid:27)(cid:19)(cid:6)$(cid:1) ,(cid:29)(cid:6)(cid:3)(cid:1)
(cid:16)(cid:4)(cid:15)(cid:4)(cid:5)(cid:13).(cid:27)(cid:10)(cid:3).(cid:1)(cid:4)(cid:3)$(cid:1)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:10)(cid:3).(cid:7)(cid:1)(cid:1)

(cid:1)

(cid:1)(cid:2)(cid:2)(cid:3)

(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)

(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:4)(cid:1)(cid:11)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:16)(cid:17)(cid:7)(cid:1)(cid:18)(cid:13)(cid:5)(cid:7)(cid:1)(cid:18)(cid:11)(cid:11)(cid:1)(cid:12)(cid:4)(cid:19)(cid:16)(cid:7)(cid:1)(cid:20)(cid:1)(cid:21)(cid:1)(cid:22)(cid:23)(cid:23)(cid:24)(cid:1)
(cid:2)(cid:3)(cid:3)(cid:4)(cid:5)(cid:19)(cid:7)(cid:1)(cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:1)(cid:8)(cid:16)(cid:10)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:6)(cid:19)(cid:7)(cid:1)(cid:28)(cid:15)(cid:29)(cid:1)(cid:30)(cid:13)(cid:14)(cid:6)(cid:1)(cid:20)(cid:19)(cid:15)(cid:1)(cid:31)(cid:4)(cid:19)(cid:16)(cid:7)(cid:1)(cid:21)(cid:1)(cid:22)(cid:23)(cid:23)(cid:24)(cid:1)
(cid:1)

(cid:11)(cid:3)(cid:1) (cid:13)(cid:9)$(cid:6)(cid:9)(cid:1) (cid:15)(cid:13)(cid:1) !(cid:27)(cid:10)(cid:5)$(cid:1) (cid:4)(cid:16)(cid:16)(cid:27)(cid:9)(cid:4)(cid:15)(cid:6)(cid:1) (cid:4)(cid:3)$(cid:1) (cid:16)(cid:13)(cid:9)(cid:9)(cid:6)(cid:16)(cid:15)(cid:1) (cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)*(cid:1) (cid:13)(cid:3)(cid:6)(cid:1) (cid:3)(cid:6)(cid:6)$(cid:19)(cid:1) (cid:15)(cid:13)(cid:1)
(cid:10)(cid:14)(cid:26)(cid:5)(cid:6)(cid:14)(cid:6)(cid:3)(cid:15)(cid:1) (cid:12)(cid:9)(cid:13)(cid:14)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) !(cid:6).(cid:10)(cid:3)(cid:3)(cid:10)(cid:3).(cid:1) (cid:19)(cid:13)(cid:14)(cid:6)(cid:1) (cid:19)(cid:15)(cid:4)(cid:3)$(cid:4)(cid:9)$(cid:19)(cid:1) (cid:12)(cid:13)(cid:9)(cid:1) (cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1) (cid:10)(cid:3)(cid:1) $(cid:10).(cid:10)(cid:15)(cid:4)(cid:5)(cid:1)
(cid:5)(cid:10)!(cid:9)(cid:4)(cid:9)(cid:10)(cid:6)(cid:19)*(cid:1)(cid:19)(cid:27)(cid:16)(cid:29)(cid:1)(cid:4)(cid:19)(cid:1)A(cid:27)!(cid:5)(cid:10)(cid:3)(cid:1)(cid:25)(cid:13)(cid:9)(cid:6)*(cid:1)B 5(cid:30)(cid:8)*(cid:1)365B (cid:11)(cid:8)(cid:1)(cid:19)(cid:16)(cid:29)(cid:6)(cid:14)(cid:4)(cid:1)(cid:4)(cid:3)$(cid:1)0(cid:2)(cid:11)+3B C(cid:7)(cid:1)
(cid:30)(cid:29)(cid:6)(cid:1) A(cid:27)!(cid:5)(cid:10)(cid:3)(cid:1) (cid:25)(cid:13)(cid:9)(cid:6)(cid:1) (cid:19)(cid:15)(cid:4)(cid:3)$(cid:4)(cid:9)$(cid:1) )(cid:12)(cid:24)(cid:8) (cid:10)(cid:8) (cid:24)(cid:4)(cid:10)(cid:3)(cid:28)(cid:10)(cid:5)(cid:28)(cid:8) (cid:27)(cid:13)(cid:5)(cid:8) (cid:16)(cid:5)(cid:13)(cid:24)(cid:24)(cid:23)(cid:28)(cid:13)(cid:20)(cid:10)(cid:12)(cid:3)(cid:8)
(cid:12)(cid:3)(cid:27)(cid:13)(cid:5)(cid:20)(cid:10)(cid:4)(cid:12)(cid:13)(cid:3)(cid:8)(cid:5)(cid:2)(cid:24)(cid:13)(cid:6)(cid:5)(cid:16)(cid:2)(cid:8)(cid:28)(cid:2)(cid:24)(cid:16)(cid:5)(cid:12)(cid:14)(cid:4)(cid:12)(cid:13)(cid:3)*(cid:31)(cid:8)(cid:11)(cid:15)(cid:1) (cid:10)(cid:3)(cid:16)(cid:5)(cid:27)$(cid:6)(cid:19)(cid:1)(cid:20)D(cid:1)(cid:6)(cid:5)(cid:6)(cid:14)(cid:6)(cid:3)(cid:15)(cid:19)*(cid:1)(cid:4)(cid:19)(cid:1)(cid:12)(cid:13)(cid:5)(cid:5)(cid:13),(cid:19)/(cid:1)(cid:15)(cid:10)(cid:15)(cid:5)(cid:6)*(cid:1)
(cid:4)(cid:27)(cid:15)(cid:29)(cid:13)(cid:9)*(cid:1) (cid:19)(cid:27)!%(cid:6)(cid:16)(cid:15)*(cid:1) $(cid:6)(cid:19)(cid:16)(cid:9)(cid:10)(cid:26)(cid:15)(cid:10)(cid:13)(cid:3)*(cid:1) (cid:26)(cid:27)!(cid:5)(cid:10)(cid:19)(cid:29)(cid:6)(cid:9)*(cid:1) (cid:16)(cid:13)(cid:3)(cid:15)(cid:9)(cid:10)!(cid:27)(cid:15)(cid:13)(cid:9)*(cid:1) $(cid:4)(cid:15)(cid:6)*(cid:1) (cid:15)"(cid:26)(cid:6)*(cid:1) (cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)*(cid:1)
(cid:10)$(cid:6)(cid:3)(cid:15)(cid:10)(cid:12)(cid:10)(cid:6)(cid:9)*(cid:1)(cid:19)(cid:13)(cid:27)(cid:9)(cid:16)(cid:6)*(cid:1)(cid:5)(cid:4)(cid:3).(cid:27)(cid:4).(cid:6)*(cid:1)(cid:9)(cid:6)(cid:5)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)*(cid:1)(cid:16)(cid:13)((cid:6)(cid:9)(cid:4).(cid:6)(cid:1)(cid:4)(cid:3)$(cid:1)(cid:9)(cid:10).(cid:29)(cid:15)(cid:19)(cid:7)(cid:1)5-(cid:15)(cid:9)(cid:4)(cid:16)(cid:15)(cid:6)$(cid:1)$(cid:10)(cid:9)(cid:6)(cid:16)(cid:15)(cid:5)"(cid:1)
(cid:12)(cid:9)(cid:13)(cid:14)(cid:1)(cid:15)(cid:29)(cid:6)(cid:10)(cid:9)(cid:1)(cid:14)(cid:10)(cid:19)(cid:19)(cid:10)(cid:13)(cid:3)*(cid:1),(cid:6)(cid:1)(cid:16)(cid:4)(cid:3)(cid:1)(cid:9)(cid:6)(cid:19)(cid:27)(cid:14)(cid:6)(cid:1)(cid:15)(cid:29)(cid:10)(cid:19)(cid:1)(cid:10)(cid:3)(cid:10)(cid:15)(cid:10)(cid:4)(cid:15)(cid:10)((cid:6)(cid:1)(cid:4)(cid:19)(cid:1)(cid:4)(cid:1)(cid:14)(cid:13)$(cid:4)(cid:5)(cid:10)(cid:15)"(cid:1)(cid:15)(cid:13)(cid:1)(cid:6)(cid:4)(cid:19)(cid:10)(cid:5)"(cid:1)(cid:12)(cid:10)(cid:3)$*(cid:1)
(cid:19)(cid:29)(cid:4)(cid:9)(cid:6)(cid:1)(cid:4)(cid:3)$(cid:1)(cid:14)(cid:4)(cid:3)(cid:4).(cid:6)(cid:1)(cid:10)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:7)(cid:1)?A(cid:27)!(cid:23)(cid:24)@(cid:1)
B 5(cid:30)(cid:8)(cid:1)(cid:16)(cid:13)(cid:14)(cid:6)(cid:19)(cid:1)(cid:12)(cid:9)(cid:13)(cid:14)(cid:1)B (cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1)5(cid:3)(cid:16)(cid:13)$(cid:10)(cid:3).(cid:1)E(cid:1)(cid:30)(cid:9)(cid:4)(cid:3)(cid:19)(cid:14)(cid:10)(cid:19)(cid:19)(cid:10)(cid:13)(cid:3)(cid:1) (cid:8)(cid:15)(cid:4)(cid:3)$(cid:4)(cid:9)$(cid:1)(cid:4)(cid:3)$(cid:1)
(cid:10)(cid:15)(cid:1) (cid:10)(cid:19)(cid:1) $(cid:6)(cid:12)(cid:10)(cid:3)(cid:6)$(cid:1) (cid:4)(cid:19)(cid:1) )(cid:10)(cid:8) (cid:24)(cid:4)(cid:10)(cid:3)(cid:28)(cid:10)(cid:5)(cid:28)(cid:8) (cid:27)(cid:13)(cid:5)(cid:8) (cid:2)(cid:3)(cid:16)(cid:13)(cid:28)(cid:12)(cid:3)(cid:26)(cid:8) (cid:28)(cid:2)(cid:24)(cid:16)(cid:5)(cid:12)(cid:14)(cid:4)(cid:12)(cid:30)(cid:2)(cid:29)(cid:8) (cid:10)(cid:28)(cid:20)(cid:12)(cid:3)(cid:12)(cid:24)(cid:4)(cid:5)(cid:10)(cid:4)(cid:12)(cid:30)(cid:2)(cid:29)(cid:8) (cid:10)(cid:3)(cid:28)(cid:8)
(cid:24)(cid:4)(cid:5)(cid:6)(cid:16)(cid:4)(cid:6)(cid:5)(cid:10)(cid:7)(cid:8) (cid:20)(cid:2)(cid:4)(cid:10)(cid:28)(cid:10)(cid:4)(cid:10)(cid:8) (cid:5)(cid:2)(cid:26)(cid:10)(cid:5)(cid:28)(cid:12)(cid:3)(cid:26)(cid:8) (cid:13)(cid:22)+(cid:2)(cid:16)(cid:4)(cid:24)(cid:8) "(cid:12)(cid:4)(cid:25)(cid:12)(cid:3)(cid:8) (cid:10)(cid:8) (cid:28)(cid:12)(cid:26)(cid:12)(cid:4)(cid:10)(cid:7)(cid:8) (cid:7)(cid:12)(cid:22)(cid:5)(cid:10)(cid:5)!(cid:29)(cid:8) (cid:2),(cid:14)(cid:5)(cid:2)(cid:24)(cid:24)(cid:2)(cid:28)(cid:8)
(cid:6)(cid:24)(cid:12)(cid:3)(cid:26)(cid:8) (cid:4)(cid:25)(cid:2)(cid:8) -./(cid:8) (cid:24)(cid:16)(cid:25)(cid:2)(cid:20)(cid:10)(cid:8) (cid:7)(cid:10)(cid:3)(cid:26)(cid:6)(cid:10)(cid:26)(cid:2)(cid:8) (cid:13)(cid:27)(cid:8) (cid:4)(cid:25)(cid:2)(cid:8) (cid:21)(cid:13)(cid:5)(cid:7)(cid:28)(cid:8) (cid:21)(cid:12)(cid:28)(cid:2)(cid:8) (cid:21) (cid:2)(cid:22)(cid:8) (cid:1)(cid:13)(cid:3)(cid:24)(cid:13)(cid:5)(cid:4)(cid:12)(cid:6)(cid:20)(cid:31)*(cid:1) (cid:11)(cid:15)(cid:1)
,(cid:4)(cid:19)(cid:1) $(cid:6)((cid:6)(cid:5)(cid:13)(cid:26)(cid:6)$(cid:1) !"(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) F(cid:10)!(cid:9)(cid:4)(cid:9)"(cid:1) (cid:13)(cid:12)(cid:1) (cid:25)(cid:13)(cid:3).(cid:9)(cid:6)(cid:19)(cid:19)(cid:1) (cid:10)(cid:3)(cid:1) = (cid:4)(cid:19)(cid:29)(cid:10)(cid:3).(cid:15)(cid:13)(cid:3)*(cid:1) :(cid:8)(cid:2)(cid:7)(cid:1) (cid:11)(cid:15)(cid:1) (cid:10)(cid:19)(cid:1) (cid:3)(cid:13),(cid:1)
(cid:27)(cid:19)(cid:6)$(cid:1)(cid:10)(cid:3)(cid:1)(cid:14)(cid:4)%(cid:13)(cid:9)(cid:1)(cid:5)(cid:10)!(cid:9)(cid:4)(cid:9)(cid:10)(cid:6)(cid:19)(cid:1)(cid:4)(cid:9)(cid:13)(cid:27)(cid:3)$(cid:1)(cid:15)(cid:29)(cid:6)(cid:1),(cid:13)(cid:9)(cid:5)$(cid:7)(cid:1)?B (cid:6)(cid:15)(cid:23)(cid:24)@(cid:1)
365B (cid:11)(cid:8)(cid:1) +(cid:1) (cid:15)(cid:12)(cid:4)(cid:19)(cid:6)(cid:9)((cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) .(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)/(cid:1) (cid:1)(cid:14)(cid:26)(cid:5)(cid:6)(cid:14)(cid:6)(cid:3)(cid:15)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) &(cid:15)(cid:9)(cid:4)(cid:15)(cid:6).(cid:10)(cid:6)(cid:19)(cid:1) (cid:10)(cid:19)(cid:1) (cid:4)(cid:1)
(cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1) (cid:19)(cid:16)(cid:29)(cid:6)(cid:14)(cid:6)(cid:1) (cid:27)(cid:19)(cid:6)$(cid:1) (cid:15)(cid:13).(cid:6)(cid:15)(cid:29)(cid:6)(cid:9)(cid:1) ,(cid:10)(cid:15)(cid:29)(cid:1) B 5(cid:30)(cid:8)*(cid:1) (cid:4)(cid:19)(cid:1) (cid:4)(cid:3)(cid:1) (cid:4)$(cid:14)(cid:10)(cid:3)(cid:10)(cid:19)(cid:15)(cid:9)(cid:4)(cid:15)(cid:10)((cid:6)(cid:1) (cid:15)(cid:13)(cid:13)(cid:5)(cid:7)(cid:1)
?3(cid:9)(cid:6)(cid:23)D@(cid:1)
0(cid:2)(cid:11)+3B C(cid:1) +(cid:1) 0(cid:26)(cid:6)(cid:3)(cid:1) (cid:2)(cid:9)(cid:16)(cid:29)(cid:10)((cid:6)(cid:19)(cid:1) (cid:11)(cid:3)(cid:10)(cid:15)(cid:10)(cid:4)(cid:15)(cid:10)((cid:6)(cid:1) 3(cid:9)(cid:13)(cid:15)(cid:13)(cid:16)(cid:13)(cid:5)(cid:1) (cid:12)(cid:13)(cid:9)(cid:1) B (cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1)
C(cid:4)(cid:9)((cid:6)(cid:19)(cid:15)(cid:10)(cid:3).(cid:1) (cid:9)(cid:6)(cid:26)(cid:9)(cid:6)(cid:19)(cid:6)(cid:3)(cid:15)(cid:19)(cid:1) )(cid:12)(cid:24)(cid:8) (cid:10)(cid:8)
(cid:7)(cid:13)"(cid:23)(cid:22)(cid:10)(cid:5)(cid:5)(cid:12)(cid:2)(cid:5)(cid:8) (cid:20)(cid:2)(cid:16)(cid:25)(cid:10)(cid:3)(cid:12)(cid:24)(cid:20)(cid:8) (cid:27)(cid:13)(cid:5)(cid:8) (cid:5)(cid:2)(cid:14)(cid:13)(cid:24)(cid:12)(cid:4)(cid:13)(cid:5)!(cid:8)
(cid:12)(cid:3)(cid:4)(cid:2)(cid:5)(cid:13)(cid:14)(cid:2)(cid:5)(cid:10)(cid:22)(cid:12)(cid:7)(cid:12)(cid:4)!*(cid:7)(cid:1) (cid:30)(cid:29)(cid:9)(cid:13)(cid:27).(cid:29)(cid:1) 0(cid:2)(cid:11)+3B C(cid:1) ,(cid:6)(cid:1) (cid:29)(cid:4)((cid:6)(cid:1) (cid:4)(cid:1) (cid:15)(cid:6)(cid:16)(cid:29)(cid:3)(cid:10)(cid:16)(cid:4)(cid:5)(cid:1) (cid:15)(cid:13)(cid:13)(cid:5)(cid:1) (cid:4)!(cid:5)(cid:6)(cid:1) (cid:15)(cid:13)(cid:1)
(cid:29)(cid:4)(cid:9)((cid:6)(cid:19)(cid:15)(cid:1)(cid:6)(cid:3)(cid:15)(cid:9)(cid:10)(cid:6)(cid:19)(cid:1)(cid:16)(cid:13)(cid:3)(cid:15)(cid:4)(cid:10)(cid:3)(cid:10)(cid:3).(cid:1)(cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1) (cid:10)(cid:3)(cid:1)(cid:4)(cid:3)"(cid:1)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:7)(cid:1) (cid:11)(cid:15)(cid:1) (cid:10)(cid:19)(cid:1)!(cid:4)(cid:19)(cid:6)$(cid:1) (cid:13)(cid:3)(cid:1) (cid:13)(cid:15)(cid:29)(cid:6)(cid:9)(cid:1) (cid:13)(cid:26)(cid:6)(cid:3)(cid:1)
(cid:19)(cid:15)(cid:4)(cid:3)$(cid:4)(cid:9)$(cid:19)(cid:1) (cid:19)(cid:27)(cid:16)(cid:29)(cid:1) (cid:4)(cid:19)(cid:1) C(cid:30)(cid:30)3(cid:1) (cid:4)(cid:3)$(cid:1) GB F(cid:7)(cid:1) (cid:11)(cid:15)(cid:1) $(cid:13)(cid:6)(cid:19)(cid:3)>(cid:15)(cid:1) (cid:19)(cid:27)(cid:26)(cid:26)(cid:13)(cid:9)(cid:15)(cid:1) (cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:1) (cid:4)(cid:3)$(cid:1) (cid:9)(cid:6)(cid:15)(cid:9)(cid:10)(cid:6)((cid:4)(cid:5)(cid:1)
(cid:4)(cid:16)(cid:15)(cid:10)((cid:10)(cid:15)(cid:10)(cid:6)(cid:19)(cid:1) !(cid:27)(cid:15)(cid:1) (cid:10)(cid:3)(cid:1) (cid:16)(cid:13)(cid:3)%(cid:27)(cid:3)(cid:16)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) ,(cid:10)(cid:15)(cid:29)(cid:1) (cid:13)(cid:15)(cid:29)(cid:6)(cid:9)(cid:1) (cid:10)(cid:3)(cid:19)(cid:15)(cid:9)(cid:27)(cid:14)(cid:6)(cid:3)(cid:15)(cid:19)(cid:1) (cid:16)(cid:4)(cid:3)(cid:1) (cid:19)(cid:13)(cid:5)((cid:6)(cid:1) (cid:15)(cid:29)(cid:13)(cid:19)(cid:6)(cid:1) (cid:10)(cid:19)(cid:19)(cid:27)(cid:6)(cid:19)(cid:7)(cid:1)
?F(cid:8)(cid:23))@(cid:1)
(cid:1)(cid:1)

(cid:1)
/(cid:8)(cid:9)(cid:4)(cid:10)(cid:31)(cid:22)(cid:20)(cid:10)(cid:8)(cid:8)
(cid:1)
(cid:2)(cid:12)(cid:15)(cid:6)(cid:9)(cid:1) (cid:9)(cid:6)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:1) (cid:4)(cid:3)$(cid:1) (cid:4)(cid:3)(cid:4)(cid:5)"(cid:19)(cid:10)(cid:19)(cid:1) (cid:26)(cid:6)(cid:9)(cid:12)(cid:13)(cid:9)(cid:14)(cid:6)$(cid:1) !"(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) 5$(cid:10)(cid:15)(cid:13)(cid:9)(cid:10)(cid:4)(cid:5)(cid:1) 8(cid:13)(cid:4)(cid:9)$(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) %(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)(cid:1)
&(cid:2)(cid:3)(cid:3)(cid:4)(cid:5)(cid:19)(cid:7)(cid:1) (cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:1) (cid:8)(cid:16)(cid:10)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1) (cid:8)(cid:6)(cid:9)(cid:10)(cid:6)(cid:19)’(cid:1) (cid:10)(cid:19)(cid:1) (cid:3)(cid:13),(cid:1) (cid:10)(cid:3)(cid:16)(cid:5)(cid:27)$(cid:6)$(cid:1) (cid:10)(cid:3)(cid:1) (cid:19)(cid:6)((cid:6)(cid:9)(cid:4)(cid:5)(cid:1) (cid:19)(cid:16)(cid:10)(cid:6)(cid:3)(cid:15)(cid:10)(cid:12)(cid:10)(cid:16)(cid:1)
$(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)(cid:19)*(cid:1) (cid:4)!(cid:19)(cid:15)(cid:9)(cid:4)(cid:16)(cid:15)(cid:1) $(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)(cid:19)(cid:1) (cid:4)(cid:3)$(cid:1) (cid:26)(cid:13)(cid:9)(cid:15)(cid:4)(cid:5)(cid:19)(cid:1) $(cid:6)$(cid:10)(cid:16)(cid:4)(cid:15)(cid:6)$(cid:1) (cid:15)(cid:13)(cid:1) (cid:9)(cid:6)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:1) (cid:4)(cid:19)(cid:1) ,(cid:6)(cid:1) (cid:19)(cid:29)(cid:4)(cid:5)(cid:5)(cid:1)
!(cid:9)(cid:10)(cid:6)(cid:12)(cid:5)"(cid:1)(cid:26)(cid:9)(cid:6)(cid:19)(cid:6)(cid:3)(cid:15)(cid:7)(cid:1)(cid:30),(cid:13)(cid:1) $(cid:10)(cid:12)(cid:12)(cid:6)(cid:9)(cid:6)(cid:3)(cid:15)(cid:1) $(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)(cid:19)(cid:1),(cid:6)(cid:9)(cid:6)(cid:1)(cid:15)(cid:4)<(cid:6)(cid:3)(cid:1) (cid:10)(cid:3)(cid:15)(cid:13)(cid:1)(cid:4)(cid:16)(cid:16)(cid:13)(cid:27)(cid:3)(cid:15)/(cid:1)(cid:4)(cid:9)G(cid:10)((cid:1)(cid:4)(cid:3)$(cid:1)
A0(cid:2)H(cid:7)(cid:1)
(cid:2)(cid:9)G(cid:10)((cid:1) (cid:10)(cid:19)(cid:1) $(cid:6)((cid:6)(cid:5)(cid:13)(cid:26)(cid:6)$*(cid:1) (cid:13),(cid:3)(cid:6)$*(cid:1) (cid:13)(cid:26)(cid:6)(cid:9)(cid:4)(cid:15)(cid:6)$(cid:1) (cid:4)(cid:3)$(cid:1) (cid:12)(cid:27)(cid:3)$(cid:6)$(cid:1) !"(cid:1) (cid:25)(cid:13)(cid:9)(cid:3)(cid:6)(cid:5)(cid:5)(cid:1)
:(cid:3)(cid:10)((cid:6)(cid:9)(cid:19)(cid:10)(cid:15)"(cid:1) F(cid:10)!(cid:9)(cid:4)(cid:9)"(cid:1) (cid:10)(cid:3)(cid:1) 2(cid:6),(cid:1) I(cid:13)(cid:9)<*(cid:1) :(cid:8)(cid:2)(cid:7)(cid:1) = (cid:6)(cid:1) (cid:4)(cid:9)(cid:6)(cid:1) $(cid:6)(cid:4)(cid:5)(cid:10)(cid:3).(cid:1) ,(cid:10)(cid:15)(cid:29)(cid:1) (cid:4)(cid:3)(cid:1) (cid:6)+3(cid:9)(cid:10)(cid:3)(cid:15)(cid:1)
(cid:4)(cid:9)(cid:16)(cid:29)(cid:10)((cid:6)(cid:1) (cid:19)(cid:27)(cid:19)(cid:15)(cid:4)(cid:10)(cid:3)(cid:10)(cid:3).*(cid:1) (cid:15)(cid:13).(cid:6)(cid:15)(cid:29)(cid:6)(cid:9)(cid:1) ,(cid:10)(cid:15)(cid:29)(cid:1) (cid:2)(cid:25)B (cid:1) 4(cid:15)(cid:29)(cid:6)(cid:1) (cid:2)(cid:19)(cid:19)(cid:13)(cid:16)(cid:10)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) (cid:12)(cid:13)(cid:9)(cid:1) (cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:10)(cid:3).(cid:1)
B (cid:4)(cid:16)(cid:29)(cid:10)(cid:3)(cid:6)(cid:9)"7*(cid:1) 2(cid:25)(cid:8)(cid:30)6F(cid:1) 42(cid:6)(cid:15),(cid:13)(cid:9)<(cid:6)$(cid:1) (cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:1) (cid:8)(cid:16)(cid:10)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1) (cid:30)(cid:6)(cid:16)(cid:29)(cid:3)(cid:10)(cid:16)(cid:4)(cid:5)(cid:1) 6(cid:6)(cid:12)(cid:6)(cid:9)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1)
F(cid:10)!(cid:9)(cid:4)(cid:9)"7(cid:1) (cid:4)(cid:3)$(cid:1) (cid:2)(cid:2)(cid:2)(cid:11)(cid:1) 4(cid:2)(cid:19)(cid:19)(cid:13)(cid:16)(cid:10)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) (cid:12)(cid:13)(cid:9)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:2)$((cid:4)(cid:3)(cid:16)(cid:6)(cid:14)(cid:6)(cid:3)(cid:15)(cid:1) (cid:13)(cid:12)(cid:1) (cid:2)(cid:9)(cid:15)(cid:10)(cid:12)(cid:10)(cid:16)(cid:10)(cid:4)(cid:5)(cid:1)
(cid:11)(cid:3)(cid:15)(cid:6)(cid:5)(cid:5)(cid:10).(cid:6)(cid:3)(cid:16)(cid:6)7*(cid:1)(cid:4)(cid:3)(cid:1)(cid:10)(cid:3)(cid:19)(cid:15)(cid:9)(cid:27)(cid:14)(cid:6)(cid:3)(cid:15)(cid:1)(cid:16)(cid:4)(cid:5)(cid:5)(cid:6)$(cid:1)(cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:10)(cid:3).(cid:1)6(cid:6)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:1)6(cid:6)(cid:26)(cid:13)(cid:19)(cid:10)(cid:15)(cid:13)(cid:9)"(cid:1)4(cid:25)(cid:13)667(cid:7)(cid:1)

(cid:1)(cid:2)(cid:5)(cid:3)
(cid:1)

(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)

(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:4)(cid:1)(cid:11)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:16)(cid:17)(cid:7)(cid:1)(cid:18)(cid:13)(cid:5)(cid:7)(cid:1)(cid:18)(cid:11)(cid:11)(cid:1)(cid:12)(cid:4)(cid:19)(cid:16)(cid:7)(cid:1)(cid:20)(cid:1)(cid:21)(cid:1)(cid:22)(cid:23)(cid:23)(cid:24)(cid:1)
(cid:2)(cid:3)(cid:3)(cid:4)(cid:5)(cid:19)(cid:7)(cid:1)(cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:1)(cid:8)(cid:16)(cid:10)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:6)(cid:19)(cid:7)(cid:1)(cid:28)(cid:15)(cid:29)(cid:1)(cid:30)(cid:13)(cid:14)(cid:6)(cid:1)(cid:20)(cid:19)(cid:15)(cid:1)(cid:31)(cid:4)(cid:19)(cid:16)(cid:7)(cid:1)(cid:21)(cid:1)(cid:22)(cid:23)(cid:23)(cid:24)(cid:1)
(cid:1)

(cid:30)(cid:29)(cid:10)(cid:19)(cid:1) (cid:10)(cid:3)(cid:19)(cid:15)(cid:9)(cid:27)(cid:14)(cid:6)(cid:3)(cid:15)(cid:1) (cid:4)(cid:5)(cid:5)(cid:13),(cid:19)(cid:1) (cid:10)(cid:15)(cid:19)(cid:1) (cid:27)(cid:19)(cid:6)(cid:9)(cid:19)(cid:1) (cid:15)(cid:13)(cid:1) (cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)*(cid:1) !(cid:9)(cid:13),(cid:19)(cid:6)(cid:1) (cid:4)(cid:3)$(cid:1) $(cid:13),(cid:3)(cid:5)(cid:13)(cid:4)$(cid:1) (cid:26)(cid:4)(cid:26)(cid:6)(cid:9)*(cid:1)
,(cid:10)(cid:15)(cid:29)(cid:13)(cid:27)(cid:15)(cid:1)(cid:16)(cid:29)(cid:4)(cid:9).(cid:6)(cid:19)(cid:7)(cid:1)(cid:1)
H(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)(cid:1) (cid:13),(cid:3)(cid:6)(cid:9)(cid:19)(cid:1) 4(cid:6)$(cid:10)(cid:15)(cid:13)(cid:9)(cid:19)*(cid:1) (cid:26)(cid:27)!(cid:5)(cid:10)(cid:19)(cid:29)(cid:6)(cid:9)(cid:19)7(cid:1) (cid:4)(cid:3)$(cid:1) (cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)(cid:1) (cid:13),(cid:3)(cid:6)(cid:9)(cid:19)(cid:1) 4(cid:4)(cid:27)(cid:15)(cid:29)(cid:13)(cid:9)(cid:19)(cid:1) (cid:13)(cid:9)(cid:1)
(cid:6)$(cid:10)(cid:15)(cid:13)(cid:9)(cid:19)(cid:1) (cid:13)(cid:12)(cid:1) ((cid:13)(cid:5)(cid:27)(cid:14)(cid:6)(cid:19)7(cid:1) (cid:29)(cid:4)((cid:6)(cid:1) (cid:14)(cid:27)(cid:5)(cid:15)(cid:10)(cid:26)(cid:5)(cid:6)(cid:1) (cid:26)(cid:13)(cid:19)(cid:19)(cid:10)!(cid:10)(cid:5)(cid:10)(cid:15)(cid:10)(cid:6)(cid:19)(cid:1) (cid:15)(cid:13)(cid:1) (cid:27)(cid:19)(cid:6)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:25)(cid:13)66*(cid:1) (cid:4)(cid:12)(cid:15)(cid:6)(cid:9)(cid:1)
(cid:9)(cid:6).(cid:10)(cid:19)(cid:15)(cid:9)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:7)(cid:1)(cid:30)(cid:29)(cid:6)(cid:9)(cid:6)(cid:1)(cid:4)(cid:9)(cid:6)(cid:1)(cid:4)((cid:4)(cid:10)(cid:5)(cid:4)!(cid:5)(cid:6)(cid:1)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:10)(cid:3).*(cid:1)(cid:19)(cid:27)!(cid:19)(cid:16)(cid:9)(cid:10)!(cid:10)(cid:3).(cid:1)(cid:4)(cid:3)$(cid:1)(cid:19)(cid:27)!(cid:14)(cid:10)(cid:15)(cid:15)(cid:10)(cid:3).(cid:1)(cid:15)(cid:13)(cid:13)(cid:5)(cid:19)*(cid:1)
(cid:4)(cid:19)(cid:1),(cid:6)(cid:5)(cid:5)(cid:1)(cid:4)(cid:19)(cid:1) (cid:10)(cid:3)(cid:19)(cid:15)(cid:9)(cid:27)(cid:14)(cid:6)(cid:3)(cid:15)(cid:19)(cid:1)(cid:12)(cid:13)(cid:9)(cid:1)$(cid:13),(cid:3)(cid:5)(cid:13)(cid:4)$(cid:10)(cid:3).(cid:1)(cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:19)*(cid:1)(cid:4)$$(cid:10)(cid:3).(cid:1)(cid:9)(cid:6)(cid:12)(cid:6)(cid:9)(cid:6)(cid:3)(cid:16)(cid:6)(cid:19)(cid:1)(cid:12)(cid:13)(cid:9)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:4)(cid:3)(cid:1)
(cid:6)(cid:3)(cid:15)(cid:10)(cid:9)(cid:6)(cid:1)%(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)(cid:1)(cid:13)(cid:9)(cid:1)(cid:12)(cid:13)(cid:9)(cid:1)(cid:4)(cid:1)(cid:26)(cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:27)(cid:5)(cid:4)(cid:9)(cid:1)(cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:7)(cid:1)
5(cid:4)(cid:16)(cid:29)(cid:1) $(cid:6)(cid:26)(cid:13)(cid:19)(cid:10)(cid:15)(cid:1) (cid:10)(cid:3)(cid:15)(cid:13)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:25)(cid:13)66(cid:1) (cid:10)(cid:19)(cid:1) (cid:6)-(cid:4)(cid:14)(cid:10)(cid:3)(cid:6)$(cid:1) !"(cid:1) (cid:9)(cid:6)((cid:10)(cid:6),(cid:6)(cid:9)(cid:19)(cid:1) (cid:10)(cid:3)(cid:1) (cid:13)(cid:9)$(cid:6)(cid:9)(cid:1) (cid:15)(cid:13)(cid:1)
$(cid:6)(cid:15)(cid:6)(cid:9)(cid:14)(cid:10)(cid:3)(cid:6)(cid:1) (cid:10)(cid:12)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:1) (cid:16)(cid:4)(cid:3)(cid:1) !(cid:6)(cid:1) (cid:4)(cid:16)(cid:16)(cid:6)(cid:26)(cid:15)(cid:6)$(cid:1) (cid:12)(cid:13)(cid:9)(cid:1) (cid:10)(cid:3)(cid:16)(cid:5)(cid:27)(cid:19)(cid:10)(cid:13)(cid:3)(cid:1) (cid:10)(cid:3)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:4)(cid:9)G(cid:10)((cid:1) $(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)(cid:7)(cid:1)
(cid:31)(cid:13)(cid:9)(cid:1) (cid:6)(cid:4)(cid:16)(cid:29)(cid:1) (cid:19)(cid:27)!(cid:14)(cid:10)(cid:15)(cid:15)(cid:6)$(cid:1) (cid:26)(cid:4)(cid:26)(cid:6)(cid:9)*(cid:1) (cid:4)(cid:3)(cid:1) (cid:4)((cid:6)(cid:9)(cid:4).(cid:6)(cid:1) (cid:15)(cid:10)(cid:14)(cid:6)(cid:1) (cid:13)(cid:12)(cid:1) (cid:22)J(cid:1) (cid:29)(cid:13)(cid:27)(cid:9)(cid:19)(cid:1) (cid:10)(cid:19)(cid:1) (cid:3)(cid:6)(cid:6)$(cid:6)$(cid:1) (cid:12)(cid:13)(cid:9)(cid:1)
(cid:4)(cid:3)(cid:4)(cid:5)"(cid:19)(cid:10)(cid:19)(cid:7)(cid:1) (cid:2)(cid:12)(cid:15)(cid:6)(cid:9)(cid:1)!(cid:6)(cid:10)(cid:3).(cid:1)(cid:4)(cid:16)(cid:16)(cid:6)(cid:26)(cid:15)(cid:6)$*(cid:1)(cid:4)(cid:1) $(cid:6)(cid:26)(cid:13)(cid:19)(cid:10)(cid:15)(cid:1)(cid:9)(cid:6)(cid:16)(cid:6)(cid:10)((cid:6)(cid:19)(cid:1)(cid:4)(cid:1)(cid:26)(cid:4)(cid:19)(cid:19),(cid:13)(cid:9)$(cid:1) (cid:27)(cid:19)(cid:6)$(cid:1)(cid:12)(cid:13)(cid:9)(cid:1)(cid:5)(cid:4)(cid:15)(cid:6)(cid:9)(cid:1)
(cid:14)(cid:13)$(cid:10)(cid:12)(cid:10)(cid:16)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1)(cid:13)(cid:3)(cid:1) (cid:10)(cid:15)(cid:19)(cid:1)(cid:16)(cid:13)(cid:3)(cid:15)(cid:6)(cid:3)(cid:15)(cid:1)(cid:4)(cid:3)$(cid:1) (cid:10)(cid:15)(cid:1)(cid:16)(cid:4)(cid:3)(cid:1)!(cid:6)(cid:1)((cid:10)(cid:6),(cid:6)$*(cid:1)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:6)$(cid:1)(cid:4)(cid:3)$(cid:1)$(cid:13),(cid:3)(cid:5)(cid:13)(cid:4)$(cid:6)$(cid:7)(cid:1)
(cid:30)(cid:29)(cid:6)(cid:1)(cid:10)(cid:3)(cid:16)(cid:5)(cid:27)(cid:19)(cid:10)(cid:13)(cid:3)(cid:1)(cid:26)(cid:9)(cid:13)(cid:16)(cid:6)(cid:19)(cid:19)(cid:1),(cid:10)(cid:5)(cid:5)(cid:1)!(cid:6)(cid:1)(cid:6)-(cid:26)(cid:5)(cid:4)(cid:10)(cid:3)(cid:6)$(cid:1)(cid:5)(cid:4)(cid:15)(cid:6)(cid:9)(cid:1)(cid:13)(cid:3)(cid:7)(cid:1)
(cid:30)(cid:29)(cid:6)(cid:1) (cid:14)(cid:6)(cid:15)(cid:29)(cid:13)$(cid:13)(cid:5)(cid:13)."(cid:1) (cid:4)(cid:19)(cid:19)(cid:13)(cid:16)(cid:10)(cid:4)(cid:15)(cid:6)$(cid:1) ,(cid:10)(cid:15)(cid:29)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:19)(cid:27)!(cid:14)(cid:10)(cid:19)(cid:19)(cid:10)(cid:13)(cid:3)(cid:1) (cid:26)(cid:9)(cid:13)(cid:16)(cid:6)(cid:19)(cid:19)(cid:1) (cid:16)(cid:4)(cid:3)(cid:1) !(cid:6)(cid:1)
(cid:19)"(cid:3)(cid:15)(cid:29)(cid:6)(cid:19)(cid:10)#(cid:6)$(cid:1)(cid:4)(cid:19)(cid:1)(cid:10)(cid:3)(cid:1)(cid:31)(cid:10).(cid:27)(cid:9)(cid:6)(cid:1)(cid:20)(cid:7)(cid:1)
(cid:1)

(cid:1)

0(cid:12)(cid:26)(cid:6)(cid:5)(cid:2)(cid:8)1(cid:8). (cid:2)(cid:4)(cid:25)(cid:13)(cid:28)(cid:13)(cid:7)(cid:13)(cid:26)!(cid:8)(cid:27)(cid:13)(cid:5)(cid:8)(cid:12)(cid:3)(cid:16)(cid:7)(cid:6)(cid:24)(cid:12)(cid:13)(cid:3)(cid:8)(cid:13)(cid:27)(cid:8)(cid:10)(cid:3)(cid:8)(cid:10)(cid:5)(cid:4)(cid:12)(cid:16)(cid:7)(cid:2)(cid:8)(cid:12)(cid:3)(cid:8)(cid:10)(cid:5)-(cid:12)(cid:30)(cid:8)(cid:28)(cid:10)(cid:4)(cid:10)(cid:22)(cid:10)(cid:24)(cid:2)(cid:8)

(cid:1)
(cid:30)(cid:29)(cid:6)(cid:1) (cid:13)(cid:15)(cid:29)(cid:6)(cid:9)(cid:1) (cid:19)(cid:26)(cid:6)(cid:16)(cid:10)(cid:12)(cid:10)(cid:16)(cid:1) $(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)(cid:1) (cid:15)(cid:29)(cid:4)(cid:15)(cid:1) ,(cid:4)(cid:19)(cid:1) (cid:4)(cid:3)(cid:4)(cid:5)"#(cid:6)$(cid:1) ,(cid:4)(cid:19)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) A(cid:10)(cid:9)(cid:6)(cid:16)(cid:15)(cid:13)(cid:9)"(cid:1) (cid:13)(cid:12)(cid:1)
0(cid:26)(cid:6)(cid:3)(cid:1) H(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)(cid:19)(cid:1) 4A0(cid:2)H7(cid:1) ?A(cid:13)(cid:4)(cid:23)(cid:24)@*(cid:1) $(cid:6)((cid:6)(cid:5)(cid:13)(cid:26)(cid:6)$(cid:1) (cid:10)(cid:3)(cid:1) (cid:8),(cid:6)$(cid:6)(cid:3)(cid:1) (cid:4)(cid:15)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) F(cid:27)(cid:3)$(cid:1)
:(cid:3)(cid:10)((cid:6)(cid:9)(cid:19)(cid:10)(cid:15)"(cid:1)F(cid:10)!(cid:9)(cid:4)(cid:9)"(cid:7)(cid:1) (cid:11)(cid:3)(cid:1) (cid:13)(cid:9)$(cid:6)(cid:9)(cid:1)(cid:15)(cid:13)(cid:1) (cid:10)(cid:3)(cid:16)(cid:5)(cid:27)$(cid:6)(cid:1) $(cid:4)(cid:15)(cid:4)(cid:1)(cid:15)(cid:13)(cid:1)(cid:15)(cid:29)(cid:10)(cid:19)(cid:1)(cid:4)(cid:9)(cid:16)(cid:29)(cid:10)((cid:6)*(cid:1)(cid:4)(cid:3)(cid:1) (cid:13)(cid:3)+(cid:5)(cid:10)(cid:3)(cid:6)(cid:1)(cid:12)(cid:13)(cid:9)(cid:14)(cid:1)
(cid:29)(cid:4)(cid:19)(cid:1) !(cid:6)(cid:6)(cid:3)(cid:1) (cid:16)(cid:13)(cid:14)(cid:26)(cid:5)(cid:6)(cid:15)(cid:6)$*(cid:1) ,(cid:10)(cid:15)(cid:29)(cid:1) (cid:10)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) (cid:9)(cid:6)(cid:5)(cid:4)(cid:15)(cid:6)$(cid:1) (cid:15)(cid:13)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) %(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)(cid:1) 4(cid:15)(cid:10)(cid:15)(cid:5)(cid:6)*(cid:1) (cid:11)(cid:8)(cid:8)2*(cid:1)
(cid:26)(cid:27)!(cid:5)(cid:10)(cid:19)(cid:29)(cid:6)(cid:9)*(cid:1) (cid:4)(cid:1) (cid:19)(cid:29)(cid:13)(cid:9)(cid:15)(cid:1) $(cid:6)(cid:19)(cid:16)(cid:9)(cid:10)(cid:26)(cid:15)(cid:10)(cid:13)(cid:3)7(cid:7)(cid:1) (cid:30)(cid:29)(cid:6)(cid:1) (cid:12)(cid:13)(cid:9)(cid:14)(cid:1) (cid:10)(cid:19)(cid:1) (cid:19)(cid:6)(cid:3)$(cid:1) (cid:15)(cid:13)(cid:1) A0(cid:2)H(cid:1) C(cid:6)(cid:4)$(cid:1) 0(cid:12)(cid:12)(cid:10)(cid:16)(cid:6)(cid:1)
,(cid:29)(cid:10)(cid:16)(cid:29)(cid:1)(cid:4)(cid:3)(cid:4)(cid:5)"#(cid:6)$(cid:1)(cid:10)(cid:15)(cid:1)!"(cid:1)(cid:15)(cid:4)<(cid:10)(cid:3).(cid:1)(cid:10)(cid:3)(cid:15)(cid:13)(cid:1)(cid:4)(cid:16)(cid:16)(cid:13)(cid:27)(cid:3)(cid:15)(cid:1)(cid:4)(cid:19)(cid:26)(cid:6)(cid:16)(cid:15)(cid:19)(cid:1)(cid:9)(cid:6)(cid:5)(cid:4)(cid:15)(cid:6)$(cid:1)(cid:15)(cid:13)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:19)(cid:27)!%(cid:6)(cid:16)(cid:15)(cid:1)(cid:13)(cid:12)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)
%(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)*(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:16)(cid:13)(cid:3)(cid:15)(cid:6)(cid:3)(cid:15)*(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:5)(cid:4)(cid:3).(cid:27)(cid:4).(cid:6)(cid:1)(cid:4)(cid:3)$(cid:1)(cid:10)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1)(cid:9)(cid:6)(cid:5)(cid:4)(cid:15)(cid:6)$(cid:1)(cid:15)(cid:13)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:9)(cid:6).(cid:27)(cid:5)(cid:4)(cid:9)(cid:10)(cid:15)"(cid:1)(cid:13)(cid:12)(cid:1)
(cid:4)(cid:26)(cid:26)(cid:6)(cid:4)(cid:9)(cid:4)(cid:3)(cid:16)(cid:6)*(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:6)-(cid:10)(cid:19)(cid:15)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1) (cid:13)(cid:12)(cid:1)(cid:4)(cid:3)(cid:1)(cid:6)$(cid:10)(cid:15)(cid:13)(cid:9)(cid:10)(cid:4)(cid:5)(cid:1)!(cid:13)(cid:4)(cid:9)$(cid:1)(cid:4)(cid:3)$(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:6)-(cid:10)(cid:19)(cid:15)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1) (cid:13)(cid:12)(cid:1)(cid:4)(cid:1)(cid:26)(cid:6)(cid:6)(cid:9)+
(cid:9)(cid:6)((cid:10)(cid:6),(cid:1) (cid:19)"(cid:19)(cid:15)(cid:6)(cid:14)(cid:1)(cid:12)(cid:13)(cid:9)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1) (cid:19)(cid:6)(cid:5)(cid:6)(cid:16)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1)(cid:13)(cid:12)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)(cid:19)(cid:7)(cid:1)(cid:2)(cid:5)(cid:19)(cid:13)*(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:14)(cid:4)(cid:10)(cid:3)(cid:1)(cid:9)(cid:6)1(cid:27)(cid:6)(cid:19)(cid:15)(cid:19)(cid:1),(cid:6)(cid:9)(cid:6)(cid:1)
(cid:15)(cid:29)(cid:4)(cid:15)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:12)(cid:27)(cid:5)(cid:5)(cid:1)(cid:15)(cid:6)-(cid:15)(cid:1)(cid:13)(cid:12)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)(cid:1)(cid:29)(cid:4)(cid:19)(cid:1)(cid:15)(cid:13)(cid:1)!(cid:6)(cid:1)(cid:12)(cid:27)(cid:5)(cid:5)(cid:1)(cid:15)(cid:6)-(cid:15)(cid:1)(cid:12)(cid:9)(cid:6)(cid:6)(cid:5)"(cid:1)(cid:4)((cid:4)(cid:10)(cid:5)(cid:4)!(cid:5)(cid:6)(cid:1)(cid:4)(cid:3)$(cid:1)(cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)(cid:19)(cid:1)
(cid:29)(cid:4)((cid:6)(cid:1) (cid:15)(cid:13)(cid:1) !(cid:6)(cid:1) (cid:26)(cid:27)!(cid:5)(cid:10)(cid:19)(cid:29)(cid:6)$(cid:1) (cid:10)(cid:3)(cid:1) 0(cid:26)(cid:6)(cid:3)(cid:1) (cid:2)(cid:16)(cid:16)(cid:6)(cid:19)(cid:19)(cid:1) (cid:19)"(cid:19)(cid:15)(cid:6)(cid:14)(cid:1) ,(cid:10)(cid:15)(cid:29)(cid:13)(cid:27)(cid:15)(cid:1) (cid:4)(cid:3)(cid:1) (cid:6)(cid:14)!(cid:4)(cid:9).(cid:13)(cid:1) (cid:26)(cid:6)(cid:9)(cid:10)(cid:13)$(cid:1)
,(cid:29)(cid:10)(cid:16)(cid:29)(cid:1)(cid:14)(cid:6)(cid:4)(cid:3)(cid:19)(cid:1)(cid:15)(cid:29)(cid:4)(cid:15)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1) (cid:13)(cid:3)+(cid:5)(cid:10)(cid:3)(cid:6)(cid:1)(cid:26)(cid:27)!(cid:5)(cid:10)(cid:16)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) (cid:13)(cid:12)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:1) (cid:10)(cid:19)(cid:1) (cid:3)(cid:13)(cid:15)(cid:1)(cid:16)(cid:13)(cid:3)$(cid:10)(cid:15)(cid:10)(cid:13)(cid:3)(cid:6)$(cid:1)!"(cid:1)
(cid:15)(cid:29)(cid:6)(cid:1) (cid:26)(cid:27)!(cid:5)(cid:10)(cid:16)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) (cid:10)(cid:3)(cid:1) (cid:26)(cid:9)(cid:10)(cid:3)(cid:15)(cid:6)$(cid:1) (cid:12)(cid:13)(cid:9)(cid:14)(cid:1) 4,(cid:29)(cid:10)(cid:16)(cid:29)(cid:1) (cid:16)(cid:4)(cid:3)(cid:1) (cid:5)(cid:4)(cid:19)(cid:15)(cid:1) (cid:4)(cid:1) ((cid:6)(cid:9)"(cid:1) (cid:5)(cid:13)(cid:3).(cid:1) (cid:15)(cid:10)(cid:14)(cid:6)7(cid:7)(cid:1) (cid:30)(cid:29)(cid:6)(cid:1)
(cid:9)(cid:6)(cid:19)(cid:26)(cid:13)(cid:3)(cid:19)(cid:6)(cid:1)(cid:16)(cid:4)(cid:14)(cid:6)(cid:1)(cid:4)(cid:12)(cid:15)(cid:6)(cid:9)(cid:1)K(cid:1),(cid:6)(cid:6)<(cid:19)(cid:1)(cid:19)(cid:10)(cid:3)(cid:16)(cid:6)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:19)(cid:27)!(cid:14)(cid:10)(cid:19)(cid:19)(cid:10)(cid:13)(cid:3)(cid:1)(cid:13)(cid:12)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1):6F(cid:1)(cid:13)(cid:12)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)%(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)(cid:1)
(cid:4)(cid:3)$(cid:1)
(cid:10)(cid:15)(cid:1) ,(cid:4)(cid:19)(cid:1) (cid:4)(cid:1) (cid:12)(cid:4)((cid:13)(cid:9)(cid:4)!(cid:5)(cid:6)(cid:1) (cid:13)(cid:3)(cid:6)/(cid:1) &(cid:2)(cid:3)(cid:3)(cid:4)(cid:5)(cid:19)(cid:7)(cid:1) (cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:1) (cid:8)(cid:16)(cid:10)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1) (cid:8)(cid:6)(cid:9)(cid:10)(cid:6)(cid:19)’(cid:1)
(cid:4)(cid:16)(cid:16)(cid:13)(cid:14)(cid:26)(cid:5)(cid:10)(cid:19)(cid:29)(cid:6)(cid:19)(cid:1)(cid:4)(cid:5)(cid:5)(cid:1)(cid:16)(cid:9)(cid:10)(cid:15)(cid:6)(cid:9)(cid:10)(cid:4)(cid:1)(cid:6)(cid:19)(cid:15)(cid:4)!(cid:5)(cid:10)(cid:19)(cid:29)(cid:6)$(cid:1)!"(cid:1)A0(cid:2)H(cid:1)(cid:4)(cid:3)$(cid:1)(cid:10)(cid:15)(cid:1)(cid:16)(cid:4)(cid:3)(cid:1)!(cid:6)(cid:1)(cid:10)(cid:3)(cid:16)(cid:5)(cid:27)$(cid:6)$(cid:1)(cid:10)(cid:3)(cid:1)(cid:15)(cid:29)(cid:6)(cid:10)(cid:9)(cid:1)
$(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)(cid:7)(cid:1)(cid:30)(cid:29)(cid:6)(cid:1) (cid:19)(cid:27)!(cid:14)(cid:10)(cid:19)(cid:19)(cid:10)(cid:13)(cid:3)(cid:1)(cid:26)(cid:9)(cid:13)(cid:16)(cid:6)(cid:19)(cid:19)(cid:1) (cid:10)(cid:19)(cid:1)(cid:14)(cid:27)(cid:16)(cid:29)(cid:1) (cid:19)(cid:10)(cid:14)(cid:26)(cid:5)(cid:6)(cid:9)(cid:1)(cid:15)(cid:29)(cid:4)(cid:3)(cid:1)(cid:12)(cid:13)(cid:9)(cid:1)(cid:4)(cid:9)G(cid:10)(*(cid:1)(cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1)

(cid:1)

(cid:1)(cid:2)(cid:6)(cid:3)

(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)

(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:4)(cid:1)(cid:11)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:16)(cid:17)(cid:7)(cid:1)(cid:18)(cid:13)(cid:5)(cid:7)(cid:1)(cid:18)(cid:11)(cid:11)(cid:1)(cid:12)(cid:4)(cid:19)(cid:16)(cid:7)(cid:1)(cid:20)(cid:1)(cid:21)(cid:1)(cid:22)(cid:23)(cid:23)(cid:24)(cid:1)
(cid:2)(cid:3)(cid:3)(cid:4)(cid:5)(cid:19)(cid:7)(cid:1)(cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:1)(cid:8)(cid:16)(cid:10)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:6)(cid:19)(cid:7)(cid:1)(cid:28)(cid:15)(cid:29)(cid:1)(cid:30)(cid:13)(cid:14)(cid:6)(cid:1)(cid:20)(cid:19)(cid:15)(cid:1)(cid:31)(cid:4)(cid:19)(cid:16)(cid:7)(cid:1)(cid:21)(cid:1)(cid:22)(cid:23)(cid:23)(cid:24)(cid:1)
(cid:1)

(cid:12)(cid:13)(cid:9)(cid:1)A0(cid:2)H(cid:1)!(cid:6)(cid:10)(cid:3).(cid:1)(cid:16)(cid:9)(cid:6)(cid:4)(cid:15)(cid:6)$(cid:1)(cid:10)(cid:3)(cid:1)(cid:4)(cid:1)(cid:19)(cid:10)(cid:3).(cid:5)(cid:6)(cid:1)(cid:19)(cid:15)(cid:6)(cid:26)(cid:1),(cid:10)(cid:15)(cid:29)(cid:10)(cid:3)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:12)(cid:9)(cid:4)(cid:14)(cid:6),(cid:13)(cid:9)<(cid:1)(cid:16)(cid:9)(cid:6)(cid:4)(cid:15)(cid:6)$(cid:1)!"(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)
0(cid:26)(cid:6)(cid:3)(cid:1)(cid:2)(cid:16)(cid:16)(cid:6)(cid:19)(cid:19)(cid:1)(cid:11)(cid:3)(cid:10)(cid:15)(cid:10)(cid:4)(cid:15)(cid:10)((cid:6)(cid:7)(cid:1)(cid:1)
A(cid:10)(cid:12)(cid:12)(cid:6)(cid:9)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1)(cid:4)(cid:9)(cid:10)(cid:19)(cid:6)(cid:1)(cid:4)(cid:15)(cid:1)(cid:15)(cid:29)(cid:10)(cid:19)(cid:1)(cid:14)(cid:13)(cid:14)(cid:6)(cid:3)(cid:15)/(cid:1),(cid:29)(cid:10)(cid:5)(cid:6)(cid:1) (cid:10)(cid:3)(cid:1)(cid:4)(cid:9)G(cid:10)((cid:1)(cid:15)(cid:29)(cid:6)(cid:1)$(cid:6)(cid:26)(cid:13)(cid:19)(cid:10)(cid:15)(cid:1)(cid:16)(cid:13)(cid:3)(cid:19)(cid:10)(cid:19)(cid:15)(cid:19)(cid:1) (cid:10)(cid:3)(cid:1)
(cid:19)(cid:6)((cid:6)(cid:9)(cid:4)(cid:5)(cid:1) (cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)(cid:19)(cid:1) 4(cid:10)(cid:3)(cid:1) 3A(cid:31)(cid:1) (cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)7(cid:1) (cid:15)(cid:13).(cid:6)(cid:15)(cid:29)(cid:6)(cid:9)(cid:1) ,(cid:10)(cid:15)(cid:29)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1) (cid:4)(cid:19)(cid:19)(cid:13)(cid:16)(cid:10)(cid:4)(cid:15)(cid:6)$(cid:1) (cid:15)(cid:13)(cid:1)
(cid:6)(cid:4)(cid:16)(cid:29)(cid:1)(cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:1)4(cid:10)(cid:3)(cid:16)(cid:5)(cid:27)$(cid:6)$(cid:1)(cid:14)(cid:4)(cid:3)(cid:27)(cid:4)(cid:5)(cid:5)"(cid:1)!"(cid:1)(cid:19)(cid:13)(cid:14)(cid:6)(cid:1)(cid:13)(cid:12)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)5$(cid:10)(cid:15)(cid:13)(cid:9)(cid:10)(cid:4)(cid:5)(cid:1)8(cid:13)(cid:4)(cid:9)$(cid:1)(cid:14)(cid:6)(cid:14)!(cid:6)(cid:9)(cid:19)7*(cid:1)(cid:10)(cid:3)(cid:1)
A0(cid:2)H(cid:1) (cid:10)(cid:15)(cid:1) (cid:10)(cid:19)(cid:1) (cid:10)(cid:3)(cid:16)(cid:5)(cid:27)$(cid:6)$(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:6)(cid:3)(cid:15)(cid:10)(cid:9)(cid:6)(cid:1) (cid:19)(cid:10)(cid:15)(cid:6)(cid:1) (cid:13)(cid:12)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:26)(cid:27)!(cid:5)(cid:10)(cid:16)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:7)(cid:1) B (cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1) (cid:16)(cid:4)(cid:3)(cid:1) !(cid:6)(cid:1)
(cid:13)!(cid:15)(cid:4)(cid:10)(cid:3)(cid:1) (cid:29)(cid:6)(cid:9)(cid:6)(cid:1) (cid:4).(cid:4)(cid:10)(cid:3)*(cid:1) !"(cid:1) (cid:16)(cid:13)(cid:14)(cid:26)(cid:5)(cid:6)(cid:15)(cid:10)(cid:3).(cid:1) (cid:4)(cid:3)(cid:1) (cid:13)(cid:3)+(cid:5)(cid:10)(cid:3)(cid:6)(cid:1) (cid:12)(cid:13)(cid:9)(cid:14)*(cid:1) (cid:3)(cid:13)(cid:15)(cid:1) ((cid:6)(cid:9)"(cid:1) $(cid:10)(cid:12)(cid:12)(cid:6)(cid:9)(cid:6)(cid:3)(cid:15)(cid:1) (cid:12)(cid:9)(cid:13)(cid:14)(cid:1)
(cid:15)(cid:29)(cid:4)(cid:15)(cid:1) (cid:27)(cid:19)(cid:6)$(cid:1) !"(cid:1) (cid:4)(cid:9)G(cid:10)(*(cid:1) ,(cid:29)(cid:10)(cid:16)(cid:29)(cid:1) (cid:10)(cid:19)(cid:1) (cid:26)(cid:9)(cid:13)$(cid:27)(cid:16)(cid:10)(cid:3).(cid:1) (cid:19)(cid:26)(cid:6)(cid:16)(cid:10)(cid:12)(cid:10)(cid:16)(cid:1) (cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1) (cid:16)(cid:4)(cid:5)(cid:5)(cid:6)$(cid:1) A0(cid:2)H(cid:1)
(cid:16)(cid:13)(cid:3)(cid:15)(cid:6)(cid:3)(cid:15)(cid:7)(cid:1)(cid:1)(cid:1)
(cid:1)(cid:30)(cid:29)(cid:6)(cid:1)(cid:4)(cid:9)G(cid:10)((cid:1)$(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)(cid:1)$(cid:13)(cid:6)(cid:19)(cid:1)(cid:3)(cid:13)(cid:15)(cid:1)(cid:10)(cid:3)$(cid:6)-(cid:1)(cid:4)(cid:5)(cid:5)(cid:1)(cid:26)(cid:27)!(cid:5)(cid:10)(cid:19)(cid:29)(cid:6)$(cid:1)(cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:19)(cid:1)4(cid:3)(cid:13)(cid:15)(cid:1)(cid:4)(cid:5)(cid:5)(cid:1)(cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:19)(cid:1)
(cid:16)(cid:4)(cid:3)(cid:1) !(cid:6)(cid:1) (cid:4)(cid:19)(cid:19)(cid:13)(cid:16)(cid:10)(cid:4)(cid:15)(cid:6)$(cid:1) ,(cid:10)(cid:15)(cid:29)(cid:1) (cid:4)(cid:3)(cid:1) (cid:4)(cid:9)G(cid:10)((cid:1) (cid:16)(cid:4)(cid:15)(cid:6).(cid:13)(cid:9)"7(cid:1) (cid:4)(cid:3)$(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:19)(cid:10)(cid:15)(cid:27)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) (cid:12)(cid:13)(cid:9)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:15)(cid:29)(cid:9)(cid:6)(cid:6)(cid:1)
((cid:13)(cid:5)(cid:27)(cid:14)(cid:6)(cid:19)(cid:1) (cid:16)(cid:13)(cid:3)(cid:19)(cid:10)$(cid:6)(cid:9)(cid:6)$(cid:1) (cid:12)(cid:13)(cid:9)(cid:1) (cid:10)(cid:3)(cid:16)(cid:5)(cid:27)(cid:19)(cid:10)(cid:13)(cid:3)(cid:1) (cid:10)(cid:19)(cid:1) (cid:26)(cid:9)(cid:6)(cid:19)(cid:6)(cid:3)(cid:15)(cid:6)$(cid:1) (cid:10)(cid:3)(cid:1) (cid:31)(cid:10).(cid:27)(cid:9)(cid:6)(cid:1) (cid:22)(cid:1) (cid:4)(cid:3)$(cid:1) (cid:6)(cid:4)(cid:16)(cid:29)(cid:1) (cid:13)(cid:12)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1)
(cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)(cid:1) (cid:10)(cid:19)(cid:1) (cid:4)(cid:3)(cid:4)(cid:5)"#(cid:6)$(cid:1) !"(cid:1) (cid:4)(cid:1) (cid:19)(cid:26)(cid:6)(cid:16)(cid:10)(cid:4)(cid:5)(cid:10)(cid:19)(cid:15)(cid:1) (cid:10)(cid:3)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:12)(cid:10)(cid:6)(cid:5)$(cid:7)(cid:1) A(cid:27)(cid:6)(cid:1) (cid:15)(cid:13)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)*(cid:1) (cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)(cid:19)(cid:1)
(cid:16)(cid:4)(cid:3)(cid:1)!(cid:6)(cid:1)(cid:12)(cid:13)(cid:27)(cid:3)$(cid:1)!"(cid:1) (cid:10)(cid:3)(cid:15)(cid:9)(cid:13)$(cid:27)(cid:16)(cid:10)(cid:3).(cid:1) $(cid:10)(cid:12)(cid:12)(cid:6)(cid:9)(cid:6)(cid:3)(cid:15)(cid:1)<(cid:6)",(cid:13)(cid:9)$(cid:19)(cid:1) (cid:10)(cid:3)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1) (cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:1)!(cid:13)-(cid:1) 4(cid:15)(cid:29)(cid:6)(cid:1)(cid:15)(cid:10)(cid:15)(cid:5)(cid:6)*(cid:1)
(cid:15)(cid:29)(cid:6)(cid:1) (cid:3)(cid:4)(cid:14)(cid:6)(cid:1) (cid:13)(cid:12)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:4)(cid:27)(cid:15)(cid:29)(cid:13)(cid:9)(cid:19)*(cid:1) (cid:9)(cid:6)(cid:12)(cid:6)(cid:9)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1) (cid:13)(cid:12)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:16)(cid:13)(cid:3)(cid:12)(cid:6)(cid:9)(cid:6)(cid:3)(cid:16)(cid:6)*(cid:1) (cid:4)(cid:9)G(cid:10)((cid:1) (cid:27)(cid:3)(cid:10)1(cid:27)(cid:6)(cid:1) (cid:11)A(cid:1)
(cid:3)(cid:27)(cid:14)!(cid:6)(cid:9)*(cid:1)(cid:6)(cid:15)(cid:16)7(cid:7)(cid:1)(cid:2)(cid:3)(cid:1)(cid:6)-(cid:4)(cid:14)(cid:26)(cid:5)(cid:6)(cid:1)(cid:10)(cid:19)(cid:1)(cid:26)(cid:9)(cid:6)(cid:19)(cid:6)(cid:3)(cid:15)(cid:6)$(cid:1)(cid:10)(cid:3)(cid:1)(cid:31)(cid:10).(cid:27)(cid:9)(cid:6)(cid:1)K(cid:7)(cid:1)

(cid:5)(cid:1)

(cid:4)(cid:2)

(cid:4)(cid:1)

(cid:3)(cid:2)

(cid:3)(cid:1)

(cid:2)

(cid:1)

(cid:9)(cid:10)(cid:11)(cid:12)(cid:13)(cid:14)(cid:15)(cid:16)(cid:17)(cid:15)(cid:18)(cid:19)(cid:12)
(cid:20)(cid:21)(cid:22)(cid:23)(cid:24) (cid:12)

(cid:9)(cid:10)(cid:11)(cid:12)(cid:13)(cid:15)(cid:10)(cid:25)(cid:25)(cid:12)(cid:11)(cid:18)(cid:12)(cid:26)
(cid:27)(cid:21)(cid:13)(cid:15)(cid:16)(cid:17)(cid:25)(cid:22)(cid:23)(cid:14)(cid:16)(cid:21)(cid:17)(cid:15)(cid:16)(cid:17)
(cid:10)(cid:13)(cid:28)(cid:16)(cid:20)

(cid:4)(cid:1)(cid:1)(cid:6) (cid:4)(cid:1)(cid:1)(cid:7)

(cid:4)(cid:1)(cid:1)(cid:8)

(cid:1)
0(cid:12)(cid:26)(cid:6)(cid:5)(cid:2)(cid:8)2(cid:8)$(cid:16)(cid:16)(cid:2)(cid:14)(cid:4)(cid:10)(cid:3)(cid:16)(cid:2)(cid:8)(cid:5)(cid:10)(cid:4)(cid:2)(cid:8)(cid:13)(cid:27)(cid:8)(cid:10)(cid:5)(cid:4)(cid:12)(cid:16)(cid:7)(cid:2)(cid:24)(cid:8)(cid:12)(cid:3)(cid:8)(cid:10)(cid:5)-(cid:12)(cid:30)(cid:8)(cid:28)(cid:10)(cid:4)(cid:10)(cid:22)(cid:10)(cid:24)(cid:2)(cid:8)

(cid:1)

(cid:1)(cid:2)(cid:7)(cid:3)
(cid:1)

0(cid:12)(cid:26)(cid:6)(cid:5)(cid:2)(cid:8)3(cid:8)4(cid:10)(cid:24)(cid:12)(cid:16)(cid:8)(cid:19)(cid:2)(cid:10)(cid:5)(cid:16)(cid:25)(cid:8)(cid:12)(cid:3)(cid:8)(cid:10)(cid:5)-(cid:12)(cid:30)(cid:8)(cid:28)(cid:10)(cid:4)(cid:10)(cid:22)(cid:10)(cid:24)(cid:2)(cid:8)

(cid:1)

(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)

(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:4)(cid:1)(cid:11)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:16)(cid:17)(cid:7)(cid:1)(cid:18)(cid:13)(cid:5)(cid:7)(cid:1)(cid:18)(cid:11)(cid:11)(cid:1)(cid:12)(cid:4)(cid:19)(cid:16)(cid:7)(cid:1)(cid:20)(cid:1)(cid:21)(cid:1)(cid:22)(cid:23)(cid:23)(cid:24)(cid:1)
(cid:2)(cid:3)(cid:3)(cid:4)(cid:5)(cid:19)(cid:7)(cid:1)(cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:1)(cid:8)(cid:16)(cid:10)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:6)(cid:19)(cid:7)(cid:1)(cid:28)(cid:15)(cid:29)(cid:1)(cid:30)(cid:13)(cid:14)(cid:6)(cid:1)(cid:20)(cid:19)(cid:15)(cid:1)(cid:31)(cid:4)(cid:19)(cid:16)(cid:7)(cid:1)(cid:21)(cid:1)(cid:22)(cid:23)(cid:23)(cid:24)(cid:1)
(cid:1)

(cid:11)(cid:3)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)A0(cid:2)H(cid:1)$(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:10)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1)(cid:16)(cid:4)(cid:3)(cid:1)!(cid:6)(cid:1)(cid:12)(cid:13)(cid:27)(cid:3)$(cid:1)(cid:10)(cid:3)(cid:1)(cid:15),(cid:13)(cid:1),(cid:4)"(cid:19)/(cid:1)
(cid:1)(cid:3) A(cid:10)(cid:9)(cid:6)(cid:16)(cid:15)(cid:1)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:1)(cid:13)(cid:3)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)A0(cid:2)H(cid:1)(cid:19)(cid:10)(cid:15)(cid:6)(cid:1),(cid:10)(cid:15)(cid:29)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)%(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)(cid:1)(cid:15)(cid:10)(cid:15)(cid:5)(cid:6)*(cid:1),(cid:29)(cid:10)(cid:16)(cid:29)(cid:1)
(cid:9)(cid:6)(cid:15)(cid:27)(cid:9)(cid:3)(cid:19)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:13)(cid:9)(cid:10).(cid:10)(cid:3)(cid:4)(cid:5)(cid:1) (cid:19)(cid:10)(cid:15)(cid:6)(cid:1) (cid:13)(cid:12)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) %(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)4(cid:29)(cid:15)(cid:15)(cid:26)/LL(cid:4)(cid:3)(cid:4)(cid:5)(cid:6)+
(cid:10)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:16)(cid:4)(cid:7)(cid:15)(cid:10)!(cid:10)(cid:19)(cid:16)(cid:27)(cid:19)(cid:7)(cid:9)(cid:13)LM(cid:26)(cid:4).(cid:6)N(cid:23)(cid:23)O(cid:26)(cid:9)(cid:10)(cid:14)(cid:4)(cid:26)(cid:4).(cid:10)(cid:3)(cid:4)E(cid:5)(cid:4)(cid:3).N(cid:6)(cid:3)79(cid:1)
(cid:1) (cid:10)(cid:16)(cid:13)(cid:3)(cid:1) ,(cid:29)(cid:10)(cid:16)(cid:29)(cid:1) (cid:5)(cid:6)(cid:4)$(cid:19)(cid:1) (cid:15)(cid:13)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1)
(cid:1)(cid:3) (cid:25)(cid:5)(cid:10)(cid:16)<(cid:1) (cid:13)(cid:3)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1)
(cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1)(cid:19)(cid:6)(cid:16)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1)(cid:19)(cid:15)(cid:9)(cid:27)(cid:16)(cid:15)(cid:27)(cid:9)(cid:6)$(cid:1)(cid:13)(cid:3)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:15)(cid:29)(cid:9)(cid:6)(cid:6)(cid:1)(cid:6)-(cid:10)(cid:19)(cid:15)(cid:6)(cid:3)(cid:15)(cid:1)((cid:13)(cid:5)(cid:27)(cid:14)(cid:6)(cid:19)9(cid:1)
(cid:1)(cid:3) (cid:2)(cid:1) (cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:1) (cid:13)(cid:3)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:26)(cid:6)(cid:2)(cid:3)(cid:8) (cid:18)(cid:12)(cid:20)(cid:6)(cid:13)(cid:22)(cid:4)(cid:10)(cid:1) (cid:19)(cid:6)(cid:16)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) (cid:4)(cid:12)(cid:15)(cid:6)(cid:9)(cid:1) (cid:4)(cid:3)"(cid:1) (cid:13)(cid:12)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1)
(cid:12)(cid:10)(cid:6)(cid:5)$(cid:19)(cid:1) (cid:15)(cid:29)(cid:4)(cid:15)(cid:1) (cid:4)(cid:9)(cid:6)(cid:1) (cid:10)(cid:3)(cid:16)(cid:5)(cid:27)$(cid:6)$(cid:1) (cid:10)(cid:3)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:7)(cid:1) (cid:31)(cid:13)(cid:9)(cid:1) (cid:6)-(cid:4)(cid:14)(cid:26)(cid:5)(cid:6)*(cid:1) (cid:10)(cid:3)(cid:1)
(cid:31)(cid:10).(cid:27)(cid:9)(cid:6)(cid:1)J(cid:1),(cid:6)(cid:1)(cid:26)(cid:9)(cid:6)(cid:19)(cid:6)(cid:3)(cid:15)(cid:1)(cid:4)(cid:1)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:1)(cid:4)(cid:12)(cid:15)(cid:6)(cid:9)(cid:1)(cid:4)(cid:3)(cid:1)(cid:4)(cid:27)(cid:15)(cid:29)(cid:13)(cid:9)>(cid:19)(cid:1)(cid:3)(cid:4)(cid:14)(cid:6)(cid:7)(cid:1)(cid:1)
(cid:1)

(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)

(cid:1)

0(cid:12)(cid:26)(cid:6)(cid:5)(cid:2)(cid:8)5(cid:8)4(cid:10)(cid:24)(cid:12)(cid:16)(cid:8)(cid:24)(cid:2)(cid:10)(cid:5)(cid:16)(cid:25)(cid:8)(cid:13)(cid:3)(cid:8)6#$7(cid:8)(cid:28)(cid:10)(cid:4)(cid:10)(cid:22)(cid:10)(cid:24)(cid:2)(cid:8)

(cid:30)(cid:29)(cid:9)(cid:13)(cid:27).(cid:29)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:10)(cid:3)(cid:16)(cid:5)(cid:27)(cid:19)(cid:10)(cid:13)(cid:3)(cid:1) (cid:13)(cid:12)(cid:1) (cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)(cid:19)(cid:1) (cid:10)(cid:3)(cid:1) (cid:15)(cid:29)(cid:13)(cid:19)(cid:6)(cid:1) (cid:15),(cid:13)(cid:1) $(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)(cid:19)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1)
(cid:10)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) 4(cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)(cid:1) (cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)7(cid:1) (cid:29)(cid:4)(cid:19)(cid:1) (cid:26)(cid:9)(cid:13)(cid:26)(cid:4).(cid:4)(cid:15)(cid:6)$(cid:1) (cid:15)(cid:13),(cid:4)(cid:9)$(cid:19)(cid:1) (cid:13)(cid:15)(cid:29)(cid:6)(cid:9)(cid:1) (cid:10)(cid:3)$(cid:6)-(cid:10)(cid:3).(cid:1)
(cid:19)"(cid:19)(cid:15)(cid:6)(cid:14)(cid:19)*(cid:1)(cid:4)(cid:19)(cid:1)(cid:12)(cid:13)(cid:5)(cid:5)(cid:13),(cid:19)/(cid:1)

(cid:1)

(cid:1)(cid:2)(cid:8)(cid:3)

(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:4)(cid:1)(cid:11)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:16)(cid:17)(cid:7)(cid:1)(cid:18)(cid:13)(cid:5)(cid:7)(cid:1)(cid:18)(cid:11)(cid:11)(cid:1)(cid:12)(cid:4)(cid:19)(cid:16)(cid:7)(cid:1)(cid:20)(cid:1)(cid:21)(cid:1)(cid:22)(cid:23)(cid:23)(cid:24)(cid:1)
(cid:2)(cid:3)(cid:3)(cid:4)(cid:5)(cid:19)(cid:7)(cid:1)(cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:1)(cid:8)(cid:16)(cid:10)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:6)(cid:19)(cid:7)(cid:1)(cid:28)(cid:15)(cid:29)(cid:1)(cid:30)(cid:13)(cid:14)(cid:6)(cid:1)(cid:20)(cid:19)(cid:15)(cid:1)(cid:31)(cid:4)(cid:19)(cid:16)(cid:7)(cid:1)(cid:21)(cid:1)(cid:22)(cid:23)(cid:23)(cid:24)(cid:1)
(cid:1)

(cid:1)(cid:3) A(cid:4)(cid:15)(cid:4)(cid:1) (cid:12)(cid:9)(cid:13)(cid:14)(cid:1) A0(cid:2)H(cid:1) (cid:29)(cid:4)(cid:19)(cid:1) (cid:19)(cid:26)(cid:9)(cid:6)(cid:4)$(cid:1) (cid:15)(cid:29)(cid:9)(cid:13)(cid:27).(cid:29)(cid:1) (cid:10)(cid:3)(cid:15)(cid:6)(cid:9)(cid:3)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:4)(cid:5)(cid:1) (cid:5)(cid:10)!(cid:9)(cid:4)(cid:9)"(cid:1)
(cid:16)(cid:4)(cid:15)(cid:4)(cid:5)(cid:13).(cid:19)*(cid:1)(cid:4)(cid:19)(cid:1)(cid:16)(cid:4)(cid:3)(cid:1)!(cid:6)(cid:1)(cid:10)$(cid:6)(cid:3)(cid:15)(cid:10)(cid:12)(cid:6)$(cid:1)(cid:10)(cid:3)(cid:1)(cid:31)(cid:10).(cid:27)(cid:9)(cid:6)(cid:1)P*(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:1)(cid:4)(cid:12)(cid:15)(cid:6)(cid:9)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)
%(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)(cid:1) (cid:3)(cid:4)(cid:14)(cid:6)(cid:1) (cid:13)(cid:3)(cid:1) (cid:6)(cid:4)(cid:16)(cid:29)(cid:1) (cid:16)(cid:4)(cid:15)(cid:4)(cid:5)(cid:13).(cid:1) (cid:9)(cid:6)(cid:15)(cid:27)(cid:9)(cid:3)(cid:10).(cid:1) (cid:4)(cid:19)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:9)(cid:6)(cid:19)(cid:27)(cid:5)(cid:15)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1)
(cid:13)(cid:9)(cid:10).(cid:10)(cid:3)(cid:4)(cid:5)(cid:1)(cid:29)(cid:13)(cid:14)(cid:6)(cid:26)(cid:4).(cid:6)(cid:1)(cid:13)(cid:12)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)%(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)9(cid:1)(cid:1)

(cid:1)(cid:3) A(cid:4)(cid:15)(cid:4)(cid:1) (cid:12)(cid:9)(cid:13)(cid:14)(cid:1) (cid:4)(cid:9)G(cid:10)((cid:1) ,(cid:4)(cid:19)(cid:1) (cid:10)(cid:3)(cid:16)(cid:5)(cid:27)$(cid:6)$(cid:1) (cid:10)(cid:3)(cid:1) (cid:4)!(cid:19)(cid:15)(cid:9)(cid:4)(cid:16)(cid:15)(cid:1) $(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)(cid:19)(cid:1) (cid:4)(cid:19)(cid:1) (cid:10)(cid:3)(cid:1)
(cid:31)(cid:10).(cid:27)(cid:9)(cid:6)(cid:1) D*(cid:1) (cid:12)(cid:9)(cid:13)(cid:14)(cid:1) ,(cid:29)(cid:6)(cid:9)(cid:6)(cid:1) (cid:10)(cid:15)(cid:1) (cid:16)(cid:4)(cid:3)(cid:1) !(cid:6)(cid:1) (cid:4)(cid:16)(cid:16)(cid:6)(cid:19)(cid:6)$(cid:1) (cid:4)(cid:15)(cid:1) (cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1) (cid:5)(cid:6)((cid:6)(cid:5)(cid:1)
,(cid:10)(cid:15)(cid:29)(cid:1) (cid:10)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1) (cid:13)(cid:3)(cid:1) (cid:4)(cid:27)(cid:15)(cid:29)(cid:13)(cid:9)(cid:19)*(cid:1) (cid:4)(cid:12)(cid:12)(cid:10)(cid:5)(cid:10)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)*(cid:1) (cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:1) (cid:19)(cid:15)(cid:4)(cid:15)(cid:27)(cid:19)*(cid:1)
(cid:4)!(cid:19)(cid:15)(cid:9)(cid:4)(cid:16)(cid:15)(cid:1) (cid:4)(cid:3)$(cid:1) (cid:4)(cid:16)(cid:16)(cid:6)(cid:19)(cid:1) (cid:15)(cid:13)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:12)(cid:27)(cid:5)(cid:5)(cid:1) (cid:15)(cid:6)-(cid:15)(cid:1) (cid:19)(cid:15)(cid:13)(cid:9)(cid:6)$(cid:1) (cid:10)(cid:3)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:4)(cid:9)G(cid:10)((cid:1)
$(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)(cid:7)(cid:1)

(cid:1)

0(cid:12)(cid:26)(cid:6)(cid:5)(cid:2)(cid:8)8(cid:8)(cid:15)(cid:5)(cid:13)(cid:14)(cid:10)(cid:26)(cid:10)(cid:4)(cid:12)(cid:13)(cid:3)(cid:8)(cid:13)(cid:27)(cid:8)(cid:20)(cid:2)(cid:4)(cid:10)(cid:28)(cid:10)(cid:4)(cid:10)(cid:8)(cid:27)(cid:5)(cid:13)(cid:20)(cid:8)(cid:10)(cid:5)-(cid:12)(cid:30)(cid:8)(cid:28)(cid:10)(cid:4)(cid:10)(cid:22)(cid:10)(cid:24)(cid:2)(cid:8)

(cid:1)

(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)

(cid:1)
(cid:1)(cid:1)

(cid:1)(cid:2)(cid:9)(cid:3)
(cid:1)

(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)

(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:4)(cid:1)(cid:11)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:16)(cid:17)(cid:7)(cid:1)(cid:18)(cid:13)(cid:5)(cid:7)(cid:1)(cid:18)(cid:11)(cid:11)(cid:1)(cid:12)(cid:4)(cid:19)(cid:16)(cid:7)(cid:1)(cid:20)(cid:1)(cid:21)(cid:1)(cid:22)(cid:23)(cid:23)(cid:24)(cid:1)
(cid:2)(cid:3)(cid:3)(cid:4)(cid:5)(cid:19)(cid:7)(cid:1)(cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:1)(cid:8)(cid:16)(cid:10)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:6)(cid:19)(cid:7)(cid:1)(cid:28)(cid:15)(cid:29)(cid:1)(cid:30)(cid:13)(cid:14)(cid:6)(cid:1)(cid:20)(cid:19)(cid:15)(cid:1)(cid:31)(cid:4)(cid:19)(cid:16)(cid:7)(cid:1)(cid:21)(cid:1)(cid:22)(cid:23)(cid:23)(cid:24)(cid:1)
(cid:1)

(cid:1)

0(cid:12)(cid:26)(cid:6)(cid:5)(cid:2)(cid:8)9(cid:8)(cid:15)(cid:5)(cid:13)(cid:14)(cid:10)(cid:26)(cid:10)(cid:4)(cid:12)(cid:13)(cid:3)(cid:8)(cid:13)(cid:27)(cid:8)(cid:20)(cid:2)(cid:4)(cid:10)(cid:28)(cid:10)(cid:4)(cid:10)(cid:8)(cid:27)(cid:5)(cid:13)(cid:20)(cid:8)6#$7(cid:8)(cid:28)(cid:10)(cid:4)(cid:10)(cid:22)(cid:10)(cid:24)(cid:2)(cid:8)

(cid:8)
(cid:8)
’(cid:27)(cid:2)(cid:13)(cid:22)(cid:31)(cid:10)(cid:6)(cid:27)(cid:2)(cid:10)(cid:8)(cid:11)(cid:2)(cid:3)(cid:8)0(cid:31)(cid:20)(cid:31)(cid:12)(cid:4)(cid:8)1(cid:27)(cid:12)2(cid:8)
(cid:1)
(cid:11)(cid:3)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:14)(cid:13)(cid:14)(cid:6)(cid:3)(cid:15)(cid:1) (cid:13)(cid:12)(cid:1) (cid:19)(cid:27)!(cid:14)(cid:10)(cid:19)(cid:19)(cid:10)(cid:13)(cid:3)(cid:1) (cid:13)(cid:12)(cid:1) (cid:15)(cid:29)(cid:10)(cid:19)(cid:1) (cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)*(cid:1) (cid:26)(cid:4)(cid:9)(cid:15)(cid:1) (cid:13)(cid:12)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:9)(cid:6)(cid:19)(cid:6)(cid:4)(cid:9)(cid:16)(cid:29)(cid:1) (cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:19)(cid:1)
(cid:10)(cid:3)(cid:16)(cid:5)(cid:27)$(cid:6)$(cid:1) (cid:10)(cid:3)(cid:1)((cid:13)(cid:5)(cid:27)(cid:14)(cid:6)(cid:19)(cid:1)(cid:12)(cid:9)(cid:13)(cid:14)(cid:1) (cid:22)(cid:23)(cid:23)P(cid:1)(cid:15)(cid:13)(cid:1) (cid:22)(cid:23)(cid:23))(cid:1),(cid:6)(cid:9)(cid:6)(cid:1)(cid:4)$$(cid:6)$(cid:1) (cid:10)(cid:3)(cid:15)(cid:13)(cid:1)(cid:15),(cid:13)(cid:1) $(cid:10)(cid:12)(cid:12)(cid:6)(cid:9)(cid:6)(cid:3)(cid:15)(cid:1) (cid:19)(cid:6)(cid:5)(cid:12)+
(cid:4)(cid:9)(cid:16)(cid:29)(cid:10)((cid:10)(cid:3).(cid:1) $(cid:4)(cid:15)(cid:4)!(cid:4)(cid:19)(cid:6)(cid:19)(cid:1) 4(cid:25)(cid:13).3(cid:9)(cid:10)(cid:3)(cid:15)(cid:19)*(cid:1) $(cid:6)((cid:6)(cid:5)(cid:13)(cid:26)(cid:6)$(cid:1) !"(cid:1) :(cid:3)(cid:10)((cid:6)(cid:9)(cid:19)(cid:10)(cid:15)"(cid:1) (cid:13)(cid:12)(cid:1) (cid:8)(cid:13)(cid:27)(cid:15)(cid:29)(cid:4)(cid:14)(cid:26)(cid:15)(cid:13)(cid:3)*(cid:1)
(cid:4)(cid:3)$(cid:1)A(cid:10).(cid:10)(cid:15)(cid:4)(cid:5)(cid:1)F(cid:10)!(cid:9)(cid:4)(cid:9)"(cid:1) (cid:13)(cid:12)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:25)(cid:13)(cid:14)(cid:14)(cid:13)(cid:3)(cid:19)(cid:1) 4AF(cid:25)7*(cid:1)(cid:29)(cid:13)(cid:19)(cid:15)(cid:6)$(cid:1)!"(cid:1) (cid:11)(cid:3)$(cid:10)(cid:4)(cid:3)(cid:4)(cid:1):(cid:3)(cid:10)((cid:6)(cid:9)(cid:19)(cid:10)(cid:15)"7(cid:7)(cid:1)
(cid:8)(cid:13)(cid:14)(cid:6)(cid:1)(cid:13)(cid:12)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)(cid:19)(cid:1)(cid:29)(cid:4)((cid:6)(cid:1)(cid:4)(cid:5)(cid:9)(cid:6)(cid:4)$"(cid:1)!(cid:6)(cid:6)(cid:3)(cid:1)(cid:10)(cid:3)(cid:16)(cid:5)(cid:27)$(cid:6)$(cid:1)!(cid:27)(cid:15)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:4)((cid:6)(cid:9)(cid:4).(cid:6)(cid:1)(cid:15)(cid:10)(cid:14)(cid:6)(cid:1)(cid:12)(cid:13)(cid:9)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)
(cid:6)((cid:4)(cid:5)(cid:27)(cid:4)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1)(cid:26)(cid:9)(cid:13)(cid:16)(cid:6)(cid:19)(cid:19)(cid:1) (cid:10)(cid:19)(cid:1)(cid:4)(cid:1)(cid:14)(cid:13)(cid:3)(cid:15)(cid:29)*(cid:1) (cid:19)(cid:13)(cid:1),(cid:6)(cid:1)(cid:16)(cid:13)(cid:27)(cid:5)$(cid:1) (cid:3)(cid:13)(cid:15)(cid:1)(cid:26)(cid:6)(cid:9)(cid:12)(cid:13)(cid:9)(cid:14)(cid:1)(cid:4)(cid:1)(cid:26)(cid:6)(cid:9)(cid:15)(cid:10)(cid:3)(cid:6)(cid:3)(cid:15)(cid:1)(cid:4)(cid:3)(cid:4)(cid:5)"(cid:19)(cid:10)(cid:19)(cid:1)
(cid:9)(cid:6)(cid:5)(cid:4)(cid:15)(cid:6)$(cid:1) (cid:15)(cid:13)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:9)(cid:4)(cid:15)(cid:6)(cid:1) (cid:13)(cid:12)(cid:1) (cid:10)(cid:3)(cid:16)(cid:5)(cid:27)(cid:19)(cid:10)(cid:13)(cid:3)(cid:1) (cid:4)(cid:3)$(cid:1) (cid:13)(cid:12)(cid:1) (cid:15)(cid:29)(cid:6)(cid:10)(cid:9)(cid:1) (cid:10)(cid:14)(cid:26)(cid:4)(cid:16)(cid:15)(cid:7)(cid:1) (cid:30)(cid:29)(cid:6)(cid:1) (cid:3)(cid:6)-(cid:15)(cid:1) (cid:19)(cid:15)(cid:4).(cid:6)(cid:19)(cid:1) (cid:10)(cid:3)(cid:1) (cid:15)(cid:29)(cid:10)(cid:19)(cid:1)
(cid:4)(cid:16)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1),(cid:10)(cid:5)(cid:5)(cid:1)!(cid:6)(cid:1)(cid:15)(cid:13)(cid:1)(cid:4)$(cid:13)(cid:26)(cid:15)(cid:1)(cid:4)(cid:1)(cid:14)(cid:4)(cid:3)(cid:4).(cid:6)(cid:14)(cid:6)(cid:3)(cid:15)(cid:1) (cid:19)"(cid:19)(cid:15)(cid:6)(cid:14)(cid:1)(cid:12)(cid:13)(cid:9)(cid:1)(cid:4)(cid:9)(cid:15)(cid:10)(cid:16)(cid:5)(cid:6)(cid:19)*(cid:1)(cid:4)(cid:16)(cid:16)(cid:13)(cid:9)$(cid:10)(cid:3).(cid:1)(cid:15)(cid:13)(cid:1)0(cid:2)(cid:11)(cid:1)
(cid:26)(cid:9)(cid:10)(cid:3)(cid:16)(cid:10)(cid:26)(cid:5)(cid:6)(cid:19)(cid:7)(cid:1)(cid:1)
(cid:30)(cid:29)(cid:6)(cid:1)5$(cid:10)(cid:15)(cid:13)(cid:9)(cid:10)(cid:4)(cid:5)(cid:1)8(cid:13)(cid:4)(cid:9)$(cid:1)(cid:10)(cid:3)(cid:15)(cid:6)(cid:3)$(cid:19)(cid:1)(cid:15)(cid:13)(cid:1)$(cid:6)((cid:6)(cid:5)(cid:13)(cid:26)(cid:1)(cid:4)(cid:3)(cid:1)(cid:4)(cid:9)(cid:16)(cid:29)(cid:10)((cid:6)(cid:1)(cid:16)(cid:13)(cid:3)(cid:15)(cid:4)(cid:10)(cid:3)(cid:10)(cid:3).(cid:1)(cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1)
(cid:12)(cid:13)(cid:9)(cid:1)(cid:4)(cid:5)(cid:5)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:6)$(cid:10)(cid:15)(cid:10)(cid:13)(cid:3)(cid:19)(cid:1)(cid:26)(cid:27)!(cid:5)(cid:10)(cid:19)(cid:29)(cid:6)$(cid:1)(cid:19)(cid:10)(cid:3)(cid:16)(cid:6)(cid:1)(cid:22)(cid:23)(cid:23)K(cid:7)(cid:1)(cid:1)(cid:2)(cid:5)(cid:19)(cid:13)*(cid:1),(cid:6)(cid:1),(cid:10)(cid:5)(cid:5)(cid:1)(cid:19)(cid:15)(cid:4)(cid:9)(cid:15)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:10)(cid:3)(cid:16)(cid:5)(cid:27)(cid:19)(cid:10)(cid:13)(cid:3)(cid:1)(cid:13)(cid:12)(cid:1)
(cid:19)(cid:16)(cid:10)(cid:6)(cid:3)(cid:15)(cid:10)(cid:12)(cid:10)(cid:16)(cid:1) (cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:19)(cid:1) (cid:4)(cid:3)$(cid:1) (cid:4)!(cid:19)(cid:15)(cid:9)(cid:4)(cid:16)(cid:15)(cid:19)(cid:1) (cid:10)(cid:3)(cid:1) (cid:19)(cid:13)(cid:14)(cid:6)(cid:1) (cid:13)(cid:26)(cid:6)(cid:3)(cid:1) $(cid:4)(cid:15)(cid:4)+!(cid:4)(cid:19)(cid:6)(cid:19)(cid:1) (cid:9)(cid:6)1(cid:27)(cid:10)(cid:9)(cid:10)(cid:3).(cid:1) (cid:5)(cid:4)!(cid:13)(cid:9)(cid:10)(cid:13)(cid:27)(cid:19)(cid:1)
(cid:4)(cid:3)$(cid:1)(cid:15)(cid:10)(cid:14)(cid:6)(cid:1)(cid:16)(cid:13)(cid:3)(cid:19)(cid:27)(cid:14)(cid:10)(cid:3).(cid:1)(cid:4)(cid:16)(cid:15)(cid:10)((cid:10)(cid:15)(cid:10)(cid:6)(cid:19)(cid:1)4(cid:6)(cid:7).(cid:7)(cid:1)AF(cid:25)(cid:1)(cid:21)(cid:1)A(cid:10).(cid:10)(cid:15)(cid:4)(cid:5)(cid:1)F(cid:10)!(cid:9)(cid:4)(cid:9)"(cid:1)(cid:13)(cid:12)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:25)(cid:13)(cid:14)(cid:14)(cid:13)(cid:3)(cid:19)*(cid:1)
(cid:11)(cid:3)$(cid:10)(cid:4)(cid:3)(cid:4)(cid:1) :(cid:3)(cid:10)((cid:6)(cid:9)(cid:19)(cid:10)(cid:15)"*(cid:1) :(cid:8)(cid:2)*(cid:1) A8F3(cid:1) (cid:21)(cid:1) (cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:1) (cid:8)(cid:16)(cid:10)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1) 8(cid:10)!(cid:5)(cid:10)(cid:13).(cid:9)(cid:4)(cid:26)(cid:29)"*(cid:1) (cid:30)(cid:9)(cid:10)(cid:6)(cid:9)(cid:1)
:(cid:3)(cid:10)((cid:6)(cid:9)(cid:19)(cid:10)(cid:15)"*(cid:1) Q(cid:6)(cid:9)(cid:14)(cid:4)(cid:3)"(cid:1) (cid:4)(cid:3)$(cid:1) (cid:25)550F(cid:1) (cid:21)(cid:1) (cid:25)(cid:6)(cid:3)(cid:15)(cid:9)(cid:4)(cid:5)(cid:1) (cid:4)(cid:3)$(cid:1) 5(cid:4)(cid:19)(cid:15)(cid:6)(cid:9)(cid:3)(cid:1) 5(cid:27)(cid:9)(cid:13)(cid:26)(cid:6)(cid:4)(cid:3)(cid:1) 0(cid:3)(cid:5)(cid:10)(cid:3)(cid:6)(cid:1)
F(cid:10)!(cid:9)(cid:4)(cid:9)"*(cid:1) (cid:31)(cid:9)(cid:4)(cid:3)<(cid:12)(cid:27)(cid:9)(cid:15)*(cid:1) Q(cid:6)(cid:9)(cid:14)(cid:4)(cid:3)"7(cid:7)(cid:1) (cid:31)(cid:13)(cid:9)(cid:1) A8F3(cid:1) (cid:14)(cid:4)(cid:10)(cid:3)(cid:15)(cid:4)(cid:10)(cid:3)(cid:6)(cid:9)(cid:19)(cid:1) (cid:9)(cid:6)1(cid:27)(cid:6)(cid:19)(cid:15)(cid:1) (cid:4)(cid:1) (cid:30)0(cid:25)(cid:1) (cid:6)(cid:3)(cid:15)(cid:9)"(cid:1)
(cid:12)(cid:13)(cid:9)(cid:1)(cid:6)(cid:4)(cid:16)(cid:29)(cid:1)(cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:1) (cid:19)(cid:27)!(cid:14)(cid:10)(cid:15)(cid:15)(cid:6)$*(cid:1),(cid:29)(cid:10)(cid:16)(cid:29)(cid:1) (cid:10)(cid:19)(cid:1)(cid:6)1(cid:27)(cid:10)((cid:4)(cid:5)(cid:6)(cid:3)(cid:15)(cid:1)(cid:15)(cid:13)(cid:1)(cid:4)(cid:1)!(cid:10)!(cid:5)(cid:10)(cid:13).(cid:9)(cid:4)(cid:26)(cid:29)(cid:10)(cid:16)(cid:1) $(cid:6)(cid:19)(cid:16)(cid:9)(cid:10)(cid:26)(cid:15)(cid:10)(cid:13)(cid:3)(cid:1)
(cid:13)(cid:12)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:26)(cid:4)(cid:26)(cid:6)(cid:9)*(cid:1)(cid:4)(cid:3)$(cid:1)(cid:10)(cid:15)(cid:1)(cid:10)(cid:19)(cid:1)(cid:16)(cid:9)(cid:6)(cid:4)(cid:15)(cid:6)$(cid:1)(cid:14)(cid:4)(cid:3)(cid:27)(cid:4)(cid:5)(cid:5)"*(cid:1)(cid:12)(cid:13)(cid:9)(cid:1)(cid:6)(cid:4)(cid:16)(cid:29)(cid:1)(cid:26)(cid:4)(cid:26)(cid:6)(cid:9)(cid:7)(cid:1)
(cid:11)(cid:3)(cid:1) (cid:13)(cid:9)$(cid:6)(cid:9)(cid:1) (cid:15)(cid:13)(cid:1) (cid:16)(cid:13)(cid:14)(cid:26)(cid:5)(cid:6)(cid:15)(cid:6)(cid:1) (cid:15)(cid:29)(cid:10)(cid:19)(cid:1) (cid:15)(cid:4)(cid:19)<(cid:1) (cid:15)(cid:29)(cid:6)(cid:1) (cid:6)$(cid:10)(cid:15)(cid:13)(cid:9)(cid:10)(cid:4)(cid:5)(cid:1) !(cid:13)(cid:4)(cid:9)$(cid:1) ,(cid:10)(cid:5)(cid:5)(cid:1) (cid:4)$(cid:13)(cid:26)(cid:15)(cid:1) (cid:15)(cid:29)(cid:6)(cid:1)
(cid:10)(cid:3)(cid:15)(cid:6)(cid:9)(cid:13)(cid:26)(cid:6)(cid:9)(cid:4)!(cid:10)(cid:5)(cid:10)(cid:15)"(cid:1) (cid:19)(cid:15)(cid:4)(cid:3)$(cid:4)(cid:9)$(cid:19)(cid:1)(cid:4)(cid:19)(cid:1)(cid:14)(cid:6)(cid:3)(cid:15)(cid:10)(cid:13)(cid:3)(cid:6)$(cid:1) (cid:10)(cid:3)(cid:1)(cid:15)(cid:29)(cid:6)(cid:1)(cid:17)(cid:26)(cid:6)(cid:3)(cid:1)(cid:18)(cid:16)(cid:16)(cid:6)(cid:19)(cid:19)(cid:1) (cid:1)(cid:3)(cid:10)(cid:15)(cid:10)(cid:4)(cid:15)(cid:10)((cid:6)(cid:1)(cid:4)(cid:3)$(cid:1)(cid:4)(cid:1)
(cid:26)(cid:9)(cid:13)(cid:15)(cid:13)(cid:16)(cid:13)(cid:5)(cid:1)(cid:12)(cid:13)(cid:9)(cid:1)(cid:14)(cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1)(cid:29)(cid:4)(cid:9)((cid:6)(cid:19)(cid:15)(cid:10)(cid:3).(cid:7)(cid:1)
(cid:1)
(cid:1)

(cid:1)

(cid:1)(cid:2)(cid:10)(cid:3)

(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)

(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:4)(cid:1)(cid:11)(cid:3)(cid:12)(cid:13)(cid:9)(cid:14)(cid:4)(cid:15)(cid:10)(cid:16)(cid:17)(cid:7)(cid:1)(cid:18)(cid:13)(cid:5)(cid:7)(cid:1)(cid:18)(cid:11)(cid:11)(cid:1)(cid:12)(cid:4)(cid:19)(cid:16)(cid:7)(cid:1)(cid:20)(cid:1)(cid:21)(cid:1)(cid:22)(cid:23)(cid:23)(cid:24)(cid:1)
(cid:2)(cid:3)(cid:3)(cid:4)(cid:5)(cid:19)(cid:7)(cid:1)(cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:1)(cid:8)(cid:16)(cid:10)(cid:6)(cid:3)(cid:16)(cid:6)(cid:1)(cid:8)(cid:6)(cid:9)(cid:10)(cid:6)(cid:19)(cid:7)(cid:1)(cid:28)(cid:15)(cid:29)(cid:1)(cid:30)(cid:13)(cid:14)(cid:6)(cid:1)(cid:20)(cid:19)(cid:15)(cid:1)(cid:31)(cid:4)(cid:19)(cid:16)(cid:7)(cid:1)(cid:21)(cid:1)(cid:22)(cid:23)(cid:23)(cid:24)(cid:1)
(cid:1)

(cid:9)(cid:4)0(cid:4)(cid:12)(cid:4)(cid:2)(cid:13)(cid:4)(cid:10)(cid:8)
(cid:1)
?(cid:4)(cid:9)G(cid:23)(cid:24)@(cid:1)(cid:1)(cid:1)(cid:1) (cid:2)(cid:9)G(cid:10)((cid:1) (cid:6)+(cid:26)(cid:9)(cid:10)(cid:3)(cid:15)(cid:1) (cid:4)(cid:9)(cid:16)(cid:29)(cid:10)((cid:6)*(cid:1) (cid:25)(cid:13)(cid:9)(cid:3)(cid:6)(cid:5)(cid:5)(cid:1) :(cid:3)(cid:10)((cid:6)(cid:9)(cid:19)(cid:10)(cid:15)"(cid:1) F(cid:10)!(cid:9)(cid:4)(cid:9)"*(cid:1)
(cid:29)(cid:15)(cid:15)(cid:26)/LL(cid:4)(cid:9)-(cid:10)((cid:7)(cid:13)(cid:9).(cid:1)

(cid:1)
?A(cid:13)(cid:4)(cid:23)(cid:24)@(cid:1)(cid:1)(cid:1) A(cid:10)(cid:9)(cid:6)(cid:16)(cid:15)(cid:13)(cid:9)"(cid:1)(cid:13)(cid:12)(cid:1)0(cid:26)(cid:6)(cid:3)(cid:1)(cid:2)(cid:16)(cid:16)(cid:6)(cid:19)(cid:19)(cid:1)H(cid:13)(cid:27)(cid:9)(cid:3)(cid:4)(cid:5)(cid:19)*(cid:1)(cid:29)(cid:15)(cid:15)(cid:26)/LL,,,(cid:7)$(cid:13)(cid:4)%(cid:7)(cid:13)(cid:9).L(cid:1)
(cid:1)
?A(cid:27)!(cid:23)(cid:24)@(cid:1)(cid:1)(cid:1) (cid:30)(cid:29)(cid:6)(cid:1)A(cid:27)!(cid:5)(cid:10)(cid:3)(cid:1)(cid:25)(cid:13)(cid:9)(cid:6)(cid:1)B (cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1)(cid:11)(cid:3)(cid:10)(cid:15)(cid:10)(cid:4)(cid:15)(cid:10)((cid:6)*(cid:1)(cid:29)(cid:15)(cid:15)(cid:26)/LL$(cid:27)!(cid:5)(cid:10)(cid:3)(cid:16)(cid:13)(cid:9)(cid:6)(cid:7)(cid:13)(cid:9).L(cid:1)
(cid:1)
?3(cid:9)(cid:6)(cid:23)D@(cid:1)(cid:1) 6(cid:10)(cid:4)(cid:10)(cid:8) 6(cid:12)(cid:16)(cid:4)(cid:12)(cid:13)(cid:3)(cid:10)(cid:5)!(cid:8) (cid:27)(cid:13)(cid:5)(cid:8) (cid:15)(cid:5)(cid:2)(cid:24)(cid:2)(cid:5)(cid:30)(cid:10)(cid:4)(cid:12)(cid:13)(cid:3)(cid:8) . (cid:2)(cid:4)(cid:10)(cid:28)(cid:10)(cid:4)(cid:10)*(cid:1) 0(cid:25)F(cid:25)(cid:1) 0(cid:3)(cid:5)(cid:10)(cid:3)(cid:6)(cid:1)
(cid:25)(cid:13)(cid:14)(cid:26)(cid:27)(cid:15)(cid:6)(cid:9)(cid:1)F(cid:10)!(cid:9)(cid:4)(cid:9)"(cid:1)(cid:25)(cid:6)(cid:3)(cid:15)(cid:6)(cid:9)*(cid:1)0(cid:29)(cid:10)(cid:13)*(cid:1):(cid:8)(cid:2)*(cid:1)(cid:22)(cid:23)(cid:23)D(cid:1)

(cid:1)
?(cid:31)(cid:10)(cid:19)(cid:23))@(cid:1)(cid:1)(cid:1)(cid:1) H(cid:27)(cid:5)(cid:10)(cid:4)(cid:3)(cid:7)(cid:1)C(cid:7)(cid:1)(cid:31)(cid:10)(cid:19)(cid:29)(cid:6)(cid:9)(cid:1)(cid:21)(cid:1)(cid:19)(cid:16)(cid:25)(cid:13)(cid:7)(cid:10)(cid:5)(cid:7)!(cid:8)(cid:15)(cid:6)(cid:22)(cid:7)(cid:12)(cid:24)(cid:25)(cid:12)(cid:3)(cid:26)(cid:8):(cid:2)(cid:23)(cid:12)(cid:3)(cid:30)(cid:2)(cid:3)(cid:4)(cid:2)(cid:28);(cid:8):(cid:2)(cid:10)(cid:7)(cid:8)(cid:1)(cid:13)(cid:24)(cid:4)(cid:24)(cid:8)
(cid:10)(cid:3)(cid:28)(cid:8) :(cid:2)(cid:10)(cid:7)(cid:8) 0(cid:5)(cid:2)(cid:2)(cid:28)(cid:13)(cid:20)(cid:24)*(cid:1) (cid:2)(cid:3)(cid:3)(cid:1) (cid:2)(cid:9)!(cid:13)(cid:9)*(cid:1) B (cid:11)/(cid:1) (cid:8)(cid:16)(cid:29)(cid:13)(cid:5)(cid:4)(cid:9)(cid:5)"(cid:1) 3(cid:27)!(cid:5)(cid:10)(cid:19)(cid:29)(cid:10)(cid:3).(cid:1)
0(cid:12)(cid:12)(cid:10)(cid:16)(cid:6)*(cid:1):(cid:3)(cid:10)((cid:6)(cid:9)(cid:19)(cid:10)(cid:15)"(cid:1)(cid:13)(cid:12)(cid:1)B (cid:10)(cid:16)(cid:29)(cid:10).(cid:4)(cid:3)*(cid:1)(cid:22)(cid:23)(cid:23))(cid:1)

(cid:1)
?C(cid:4)(cid:9)(cid:23)(cid:22)@(cid:1)(cid:1) (cid:8)(cid:15)(cid:6)((cid:4)(cid:3)(cid:1) C(cid:4)(cid:9)(cid:3)(cid:4)(cid:9)$(cid:1) (cid:21)(cid:1) ’(cid:25)(cid:2)(cid:8) (cid:19)(cid:2)(cid:7)(cid:27)(cid:23)$(cid:5)(cid:16)(cid:25)(cid:12)(cid:30)(cid:12)(cid:3)(cid:26)(cid:8)  (cid:3)(cid:12)(cid:4)(cid:12)(cid:10)(cid:4)(cid:12)(cid:30)(cid:2)(cid:31)(cid:8) 0(cid:5)(cid:2)(cid:2)(cid:12)(cid:3)(cid:26)(cid:8) (cid:4)(cid:25)(cid:2)(cid:8)
:(cid:2)(cid:27)(cid:2)(cid:5)(cid:2)(cid:2)(cid:28)(cid:8) :(cid:2)(cid:10)(cid:24)(cid:2)(cid:5)(cid:16)(cid:25)(cid:8) /(cid:12)(cid:4)(cid:2)(cid:5)(cid:10)(cid:4)(cid:6)(cid:5)(cid:2)(cid:8) #(cid:3)(cid:7)(cid:12)(cid:3)(cid:2)*(cid:1) (cid:8)(cid:13)(cid:27)(cid:15)(cid:29)(cid:4)(cid:14)(cid:26)(cid:15)(cid:13)(cid:3)(cid:1) :(cid:3)(cid:10)((cid:6)(cid:9)(cid:19)(cid:10)(cid:15)"*(cid:1)
C(cid:10).(cid:29)(cid:12)(cid:10)(cid:6)(cid:5)$*(cid:1):R*(cid:1)(cid:22)(cid:23)(cid:23)(cid:22)(cid:1)

(cid:1)
?C(cid:25)8(cid:23)(cid:22)@(cid:1)(cid:1) (cid:8)(cid:15)(cid:6)((cid:4)(cid:3)(cid:1) C(cid:4)(cid:9)(cid:3)(cid:4)$*(cid:1) F(cid:6)(cid:19)(cid:1) (cid:25)(cid:4)(cid:9)(cid:9)*(cid:1) (cid:30)(cid:10)(cid:14)(cid:1) 8(cid:9)(cid:13)$"(cid:1) +(cid:1) <(cid:13)"(cid:8) (cid:10)(cid:3)(cid:28)(cid:8) (cid:21)(cid:25)!(cid:8) ’(cid:13)(cid:8) 0(cid:5)(cid:2)(cid:2)(cid:8)
$(cid:7)(cid:7)(cid:8) :(cid:2)(cid:27)(cid:2)(cid:5)(cid:2)(cid:2)(cid:28)(cid:8) :(cid:2)(cid:24)(cid:2)(cid:10)(cid:5)(cid:16)(cid:25)(cid:31)(cid:8) 0(cid:5)(cid:13)(cid:20)(cid:8) $(cid:16)(cid:16)(cid:2)(cid:24)(cid:24)(cid:23)(cid:8) (cid:10)(cid:3)(cid:28)(cid:8)  (cid:20)(cid:14)(cid:10)(cid:16)(cid:4)(cid:23)4(cid:10)(cid:5)(cid:5)(cid:12)(cid:2)(cid:5)(cid:24)(cid:8)
#(cid:3)(cid:7)(cid:12)(cid:3)(cid:2)(cid:29)(cid:8)(cid:9)(cid:13),*(cid:1)(cid:8)(cid:13)(cid:27)(cid:15)(cid:29)(cid:4)(cid:14)(cid:26)(cid:15)(cid:13)(cid:3)(cid:1):(cid:3)(cid:10)((cid:6)(cid:9)(cid:19)(cid:10)(cid:15)"*(cid:1)C(cid:10).(cid:29)(cid:12)(cid:10)(cid:6)(cid:5)$*(cid:1):R*(cid:1)(cid:22)(cid:23)(cid:23)(cid:22)(cid:1)

(cid:1)
?F(cid:8)(cid:23))@(cid:1)(cid:1)(cid:1) (cid:25)(cid:4)(cid:9)(cid:5)(cid:1) F(cid:4).(cid:13)#(cid:6)*(cid:1) C(cid:6)(cid:9)!(cid:6)(cid:9)(cid:15)(cid:1) (cid:18)(cid:4)(cid:3)(cid:1) $(cid:6)(cid:1) (cid:8)(cid:13)(cid:14)(cid:26)(cid:6)(cid:5)(cid:1) +(cid:1) ’(cid:25)(cid:2)(cid:8) #(cid:14)(cid:2)(cid:3)(cid:8) $(cid:5)(cid:16)(cid:25)(cid:12)(cid:30)(cid:2)(cid:24)(cid:8)
 (cid:3)(cid:12)(cid:4)(cid:12)(cid:10)(cid:4)(cid:12)(cid:30)(cid:2)(cid:8) (cid:15)(cid:5)(cid:13)(cid:4)(cid:13)(cid:16)(cid:13)(cid:7)(cid:8) (cid:27)(cid:13)(cid:5)(cid:8) . (cid:2)(cid:4)(cid:10)(cid:28)(cid:10)(cid:4)(cid:10)(cid:8) <(cid:10)(cid:5)(cid:30)(cid:2)(cid:24)(cid:4)(cid:12)(cid:3)(cid:26)*(cid:1) (cid:22)(cid:23)(cid:23))*(cid:1) (cid:4)((cid:4)(cid:10)(cid:5)(cid:4)!(cid:5)(cid:6)(cid:1) (cid:4)(cid:15)(cid:1)
(cid:29)(cid:15)(cid:15)(cid:26)/LL,,,(cid:7)(cid:13)(cid:26)(cid:6)(cid:3)(cid:4)(cid:9)(cid:16)(cid:29)(cid:10)((cid:6)(cid:19)(cid:7)(cid:13)(cid:9).L0(cid:2)(cid:11)L(cid:13)(cid:26)(cid:6)(cid:3)(cid:4)(cid:9)(cid:16)(cid:29)(cid:10)((cid:6)(cid:19)(cid:26)(cid:9)(cid:13)(cid:15)(cid:13)(cid:16)(cid:13)(cid:5)(cid:7)(cid:29)(cid:15)(cid:14)(cid:5)(cid:1)

(cid:1)
?B (cid:6)(cid:15)(cid:23)(cid:24)@(cid:1) (cid:1) B (cid:6)(cid:15)(cid:4)$(cid:4)(cid:15)(cid:4)(cid:1) 5(cid:3)(cid:16)(cid:13)$(cid:10)(cid:3).(cid:1) (cid:4)(cid:3)$(cid:1) (cid:30)(cid:9)(cid:4)(cid:3)(cid:19)(cid:14)(cid:10)(cid:19)(cid:19)(cid:10)(cid:13)(cid:3)(cid:1) (cid:8)(cid:15)(cid:4)(cid:3)$(cid:4)(cid:9)$*(cid:1) F(cid:10)!(cid:9)(cid:4)(cid:9)"(cid:1) (cid:13)(cid:12)(cid:1)
(cid:25)(cid:13)(cid:3).(cid:9)(cid:6)(cid:19)(cid:19)*(cid:1)(cid:29)(cid:15)(cid:15)(cid:26)/LL,,,(cid:7)(cid:5)(cid:13)(cid:16)(cid:7).(cid:13)(L(cid:19)(cid:15)(cid:4)(cid:3)$(cid:4)(cid:9)$(cid:19)L(cid:14)(cid:6)(cid:15)(cid:19)L(cid:1)

(cid:1)
?0(cid:2)(cid:11)(cid:23)(cid:22)@(cid:1) 4(cid:6)(cid:28)(cid:10)(cid:14)(cid:2)(cid:24)(cid:4)(cid:8) #(cid:14)(cid:2)(cid:3)(cid:8) $(cid:16)(cid:16)(cid:2)(cid:24)(cid:24)(cid:8)  (cid:3)(cid:12)(cid:4)(cid:12)(cid:10)(cid:4)(cid:12)(cid:30)(cid:2)*(cid:1) (cid:22)(cid:23)(cid:23)(cid:22)*(cid:1) (cid:4)((cid:4)(cid:10)(cid:5)(cid:4)!(cid:5)(cid:6)(cid:1) (cid:4)(cid:15)(cid:1)
(cid:29)(cid:15)(cid:15)(cid:26)/LL,,,(cid:7)(cid:19)(cid:13)(cid:9)(cid:13)(cid:19)(cid:7)(cid:13)(cid:9).L(cid:13)(cid:26)(cid:6)(cid:3)(cid:4)(cid:16)(cid:16)(cid:6)(cid:19)(cid:19)(cid:1)

(cid:1)
(cid:1)
(cid:1)
(cid:1)

(cid:1)(cid:5)(cid:11)(cid:3)
(cid:1)

                          Volume 2, Issue 4, April 2012                              ISSN: 2277 128X  
International Journal of Advanced  Research in  
 Computer Science and Software Engineering  
                                                                  Research Paper 
                                     Available  online  at: www.ijarcsse .com 

A Framework of  Dis tributed  Databas e Managem ent  Sys tems  
in the  Modern En terpris e and the Uncer tainties  removal    

 
                                       Ms .Monik a Tri pathi  
 
Prof . (Dr. ) An an d K. Tri pathi  
                                                   A ss tt . Pro f. , A rya Kanya PG     
Head  o f Dep t t . CSE & IT  
 
 
Co l lege,Jhans i ,Ind ia  
 
SR Group  o f Ins t itu t ions ,CSE,Jhans i ,Ind ia  
                     
 
d r.aktr ipath i@g ma il .co m                                                                  
 
mon ikatr ipath i.d@g ma il .co m 

      

Abstract   :This  research  paper  stud ies  the  use  o f  d istributed   da tabase management   systems  (DDBM Ss)  in  the  in forma t ion 
infrastructure  o f  modern   organiza t ions   to   reduce  the  uncerta int ies  occurring   in   organiza t ion .  The  key   purpose  o f  the  
research  is  to   determine  the  feasib i l i ty  and   appl icab i l ity  o f DDBMS s  for  today's  business  app l ica t ions. The  forces which  
drove  the  selection  o f  this  top ic  were  the  improvements  o f  d istributed   features  in  lead ing   da tabase  management   systems 
(DBMSs )  in   recent   years,   as  wel l   as  the  po tent ia l   o f  d istributed   da tabases  to   provide  compet it ive  advantages  for 
organiza t ions for proper ut i l iza t ion o f infrastructure to  ob ta in the meaning ful   informa t ion.  

 Keywords:  Distributed  Da tabase Management  Systems:  DDBMS,  DBM S.  

1 .  PRES ENT  STATE  O F  KNOWLEDG E:  Today ‟s 
bus iness   env ironmen t   has   an   increas ing   need   fo r  d istribu ted 
databas e  and   clien t /server  app licat ions   as   the  des ire  fo r  
rel iab le,   s calab le  and   access ib le  in fo rmat ion   is   s tead ily   r is ing . 
Dis tribu ted   databas e  s ystems   p rov ide  an   imp rovemen t   on  
commun icat ion   and  data  p rocess ing   due to   its   data d is tribu t ion 
th roughou t   d ifferen t   netwo rk   s ites .  DDS  makes   no t   on ly  
ma kes   data   acces s   fas ter,  bu t   a  s ing le -po in t   o f  fai lu re  is   les s 
like ly   to   occu r,  and   it   p rov ides   loca l  con tro l  o f  data  fo r  us ers . 
However,  there  is   s ome  comp le xity   when   at temp t ing   to  
manage and  con tro l d is tribu ted  databas e s ys tems .  

The  in fo rmat ion   requ ire men ts   o f  o rgan izat ions   and   d istribu ted 
databas e  techno logy   bo th   have  g rown   very   tremendous ly   in 
recen t   years .  In   fact ,  nearly   all  modern  DBM Ss   come  s tandard 
with   powerfu l  d is tribu ted   featu res ,  bu t  thes e  featu res  mus t   be 
imp le men ted   and   admin is tered   by   s kil led   p ro fes s ionals . 
Dis tribu ted   databas es   are  much   mo re  co mp le x  than   their  
cen tralized   databas e  cous in s ,  bu t  when   p roperly   imp le men ted  
in   the  app rop riate  enterp ris e  app licat ions ,  they  can  p rov ide 
g reat  benefits  to  the o rgan izat ions  they  suppo rt .  

Demand s  for DDBMSs  

Pr io r  to   the  popu lar  accep tance  o f  DDBMSs ,  co rpo rat ions 
no rma lly   rel ied   on   cen tralized   databas es   des igned   to   s erve 
very   s tructu red  in fo rmat ion   requ ire men ts .  Thes e  cen tralized  

databas es   had  s ome  characteris t ics   in   common .  F irs t ,  they 
ran   on   powerfu l  and   e xpens ive  hardware  that   cou ld 
hand le  very  large  po rt ions   o f  a  firm's   data  reliab ly .  
Second ,  they   were  ad min is tered   by   a  sma ll   nu mber  o f  
wel l-t rained   peop le  who   cou ld   manage  the  o rgan izat ion 's  
compu ters  
to   reduce 
the  uncertain t ies   occu rring  
in  
o rgan izat ions   [1 ].Th ird ,  the  ded icated   data  lines   fo rming  
the  co rpo rate wide  area  netwo rk  (WAN )  had   to   be  h ig h ly 
rel iab le  and   have  a  large  capacity ,  becaus e  any  down t ime  
wi l l  p reclude  at   leas t   one  s ite  fro m  operat ing ,  and   every 
operat ion   had   to   be  transmit ted   to   and  from  the  cen tral 
databas e  in   real  t ime.   Thes e  cen tralized   databas es   cou ld 
p rov ide  adequate  perfo rmance  to   firms   ab le  to   wo r k  
around   their  s ho rtcomings .  Thes e  sho rtcomings   include 
the  lack  o f   f le xib i l ity   in   the  app l icat ion   o f  the  f irm's  
in fo rmat ion   and   the  requ ire men t   to   imp le men t   a  s ing le  
po in t  o f fai lu re  fo r the en t ire  en terp ris e. 

Th is   s ect ion   exp lo re s   the  les s ons   learned   abou t   the 
limitat ions   o f  cen tralized   databas e s ys tems   over  the  th irty 
years   they   have  been  in   general  us e.  Firs t   the  bus iness 
forces   are  e xp lo red .   Each   o f  thes e  bus ines s   iss ues   has 
generated  
in fo rmat ion  
techno logy  
requ ire men ts  
that 
d is tribu ted   databas e  arch itectu res   are  un iquely   capab le  o f 
s uppo rt ing .  Second ,  the  technol ogy  is s ues   are  e xp lo red .  
Thes e  have  come  abou t   from  advances   in   in fo rmat ion  
techno logy   that  have made  the  cen tralized   databas e model 
less  relevant  in  today 's  o rgan izat ions . 

Vo lu me  2,  Is s ue 4, Ap ri l  2012                                                                                                                                                                www. i jarcs s e.com 

Bus iness  Forces  

Geographic Dispersion 

Geog raph ic  d is pers ion   o f  o rgan izat ions   is   no t   an   en t irely   new  
concept . Large  f irms   have  connected  majo r  reg ional  o ff ices   to 
their  cen tralized   databas es   us ing  ded icated  lines   fo r  years . The 
d iffe rence now  is  that  g eog raph ic d is pers ion  is  taken  to  g reater 
e xtre mes   to   p rov ide  cos t   s av ings   and   imp roved   con tact   with  
the 
reg ional  o ff ices   are 
[10] .  Large 
firm's   cus tomers  
increas ing ly   rep laced  with   smal ler  locat ions   in   all  o f  the  firm's  
ma rkets .  Th is   change  g reat ly  
increas es   the  number  o f 
ded icated   lines wh ich ,  if  p rov ided   at  the s ame  s erv ice  levels   as 
in   the  o lder  cen tralized   s ystems ,  cou ld   add   up  to   an  eno rmous 
e xpens e.  Clea rly ,   the  trad it ional   cen tral ized   database  model  
creates   a  p rob lem  fo r  f irms   w is h ing   to   benefit   by   s uch 
increas ed  geog raph ic d is pers ion . 

Ano ther  aspect   o f  the  geog raph ic  d is pers ion   p rob lem  is   the 
g rowing   abundance  o f  po rtab le  compu ter  us e  by   mob ile  
p ro fes s ionals .  A   common   e xa mp le  o f   th is   is   the  traveling  
s ales pers on   us ing   a  lap top -bas ed   database  to   query   availab le 
inven to ry   and   take  customer  o rders .  The  natu re  o f  th is   wo rk  
p reven ts   a  fu ll-t ime  netwo r k  connect ion ,  and   the  databas e  on 
the  mob i le  s ys tem  mus t   somehow  be  l inked   to   the  f irm's  
mas ter  databas e  at   regu lar  in tervals   to   update  the  d istribu ted 
cop ies   o f  any   data  that   has   been   changed . Th is  is   another  cas e 
where  geog raph ic  d is pers ion   has   rendered   the  cen tralized  
databas e arch itectu re obs o lete [11 ].  

Geog raph ical ly   d is pers ed   o rgan izat ions   requ ire  an   arch itectu re 
that   allows   the  bu lk  o f  data  retrieval  and   updates   to   be 
perfo rmed   on   fas t  and  inexpens ive  local  area  netwo rks  
(LANs ).  Th is   arch itectu re  s hou ld   res erve  the  mo re  expens ive 
WAN  fo r  data  updates   that   are  relevan t   to   o ther s ites . Mob ile 
us ers   shou ld   have  a  copy  o f  the  data  fo r  their  local  us e  and  an 
eff icien t  means  to  update us ing  a part -t ime  connect ion  [12 ].  

 

Informa t ion as a  Resource  

impo rtance  o f 
the 
today   unders tand  
leaders 
Bus iness  
in fo rmat ion   as   a  bus ines s   resou rce. W ith   cen tralized   databas e 
s ys tems ,  an   o rgan izat ion 's   in fo rmat ion   is   ma in tained   an d 
con tro lled   by   a  few  h igh ly   s kil led   ind iv iduals   at   one  locat ion  
[8 ]. T wo   ma jo r  facto rs   have  led   many   bus iness   us ers   to   reject  
the  centralized   databas e  model:  the  natu ral  tendency   fo r 
humans   no t  to  share  and   the  in troduct ion  o f  pers onal  compu ter 
(PC)  -bas ed   DBMSs   powerfu l  enough   to   hand le  many  
concu rren t   us ers .  A rmed   with   s uch   too ls ,  departmen ts   and 
wo rkg roups   can   eas ily   bu ild   their  own   databas es ,  wres t ing 
con tro l  o f  the  in fo rmat ion   res ou rce  fro m  the  ad min is trato rs   o f 

the  o rgan izat ion 's   cen tral  databas es   an d   s at is fy ing   their 
natu ral tendency  no t  to  s hare. 

The  e xp los ion   o f  ind iv idual   databases   runn ing   on   PC 
p latfo rms   can   p rov ide  new  oppo rtun it ies   to   heads   o f 
departmen ts ,  but   may   als o   pos e  p rob lems   fo r 
the 
o rgan izat ion   as   a  who le.  In fo rmat ion   that   cou ld   benefit  
the  en t ire  o rgan izat ion   o ften   becomes   ou t   o f  reach   fo r 
us ers   unab le  to   access   it   o r  unaware  o f  its   e xis tence. 
Add it ionally ,  becaus e  o f  the  cheaper  hardware  and  
s o ftware  us ed ,  and   generally   lowe r  s ki l ls   o f  the  personnel 
admin is tering  
thes e 
s ys tems , 
reliab i l ity  
can   be 
s ign ifican t ly   les s   than   with   cen tralized   s ys tems .  Data 
incons istency   is   another  p rob lem  that   occu rs   in   s uch   an 
env ironmen t ,  as   the s ame  data  is  s to red   in  many   databas es 
with  no  s ystem  fo r manag ing  the mu lt ip le cop ies  [ 12].  

The  centralized   and   decen tralized  models   des cribed   above 
bo th  generate  majo r  p rob le ms   fo r  large  o rgan izat ions . 
Some  type  o f  arch itectu re  that   p rov ides   the  advantages   o f 
bo th  withou t   the  d rawbacks   wou ld   be  idea l[2 ].  Th is  
arch itectu re  s hou ld   allow   decen tralized   us e  o f  data, wh ile  
p rov id ing  
fo r  databas e  admin is trat ion  
that  can   be 
perfo rmed   by   pers onnel  with   the  in terests  o f  the  who le 
firm  in  mind  [ 2] .  

Corpora te Rightsizing 

Modern   co rpo rat ions   expand   and   con tract   frequen t ly   as 
they   res pond   to   chang ing  compet it ive  p res su res .  A  s tud y 
o f  3, 628  co mpan ies   done  by  Cas cio   and   Young   repo rted 
in  Mo rr is ,  and   found   that  one  th ird   had   fired   at   leas t   15%  
o f  their  e mp loyees   du ring   the  period   o f  the  s tudy   .  The 
s tudy   als o   concluded  that   in   mos t   cas es ,  the  compan ies 
had   expanded  to  their  o rig inal  s izes ,  o ften  with in   les s  than 
th ree  years .  Such   act iv ity   is   referred   to   as   co rpo rate 
downs izing   o r  r igh ts izing ,  no t   to   be  con fus ed   with   the 
s ame  terms   app lied   to   in fo rmat ion   techno logy   and   clien t -
s erver  s ys tems .  It   is   o ften   th rough   the  us e  o f  in fo rmat ion  
techno logy  
that   execu t ives  
iden t ify   s uch   bus iness 
oppo rtun it ies   and  transmit   the  decis ions   and   p lans   to 
ma ke  the  changes   very   rap id ly .  Iron ica l ly ,  it   is   o ften   the 
in fo rmat ion   techno logy   res ou rce  o f  an  o rgan izat ion   that  is 
us ually   the  leas t   ab le  to   res pond   t o   such   righ ts izing  
decis ions . 

Cen tral ized   databas es   runn ing   on   comp le x  and   e xpens ive 
ma in f ra mes   and   min ico mpu ters   are  us ually   very   d ifficu lt  
to   s cale  to   h igh   deg rees . Add ing  o r  remov ing   p rocess ing 
capacity   and  s to rage  can  be  expens ive  and  d ifficu lt . Many  
o rgan izat ions   requ ire  a  scalab le  databas e  sys tem  that   can 
allo w  s ys tem  admin is trato rs   to   hand le  chang ing   demand 
with   no th ing  mo re  than   the  incremen tal  pu rchas e  o r 
re moval  o f  commod ity   hardware  and   s o ftware.  Such   a 
s o lu t ion   s hou ld   p rov ide  a  g rowing   firm  w ith   a  s o lu t ion 

© 2012 , IJARCS S E Al l  Righ ts  Res er ve d                                                                                                                                                        Pa ge | 61  

Vo lu me  2,  Is s ue 4, Ap ri l  2012                                                                                                                                                                www. i jarcs s e.com 

that   allows   rap id   in teg rat ion   in to   the  e xis t ing   arch itectu re  and  
a p red ictab le  increas e in  capacity  and  perfo rmance [ 7] .  

Tech nol ogy Forces  

Infu sion o f PCs  and  LA Ns in  the Workp lace: 

The  s tage  fo r  d is tribu ted   databas es  was   s et   in   the  1980s  when  
PCs   began   to   take  ho ld   o f  the  co rpo rate  des ktop   in   large 
numbers .  The  natu ral  extens ion   o f  thes e  mach ines   being   on 
many   des ks   was   to   connect   them  us ing   local  netwo rks   and 
s ervers .  Office  f iles ervers   p rov ided   small  o rgan izat ions   with  
decen tralized   s erver  power.  The  cu ltu re  and   in fras tructu re  o f 
co rpo rate  compu t ing   reflected   an  increas ing ly   decen tralized  
b ias ,  d riven   in   many   cas es   by  end -us ers   who   began   to 
understand  and  exp lo re the power o f  decen tralized  co mpu t ing   

Increasing  De mands o f the  Inter net  

The  g rowth   in   In ternet   us e  and   the  exp los ion   o f  web   pages 
with   rea l-t ime  in fo rmat ion   have  d ramat ica l ly   increas ed   the 
demands   on   bus iness  web  s ites   in   recent   years . Web  pages   fu ll 
o f dynamic    

 BROAD OUTLINES  O F THE WORK:  

Dis tribu ted   databas e  s ys tems   are  bas ed   upon   several  models  
and   their  imp le men tat ions   can   include  a  number  o f  d if feren t  
featu res .  Th is   has  developed   from  the  many   varied   s ituat ions 
and   requ ire men ts   o rgan izat ions   are  faced   w ith   in   pu t t ing   the 
techno logy   to   use.  The  top ics   des cribed   below  are  key   to  
understand ing  the  capabi l ities   an d  l i mit ati ons   of  dis tri bu te d 
da tabas e s ys tems .  

Fragmenta t ion 

The 
fo r  d is tribu ted   databas es 
techn ique 
frag men tat ion  
invo lves   sp lit t ing   the  cen tralized   databas e  in to   po rt ions   and 
mov ing   them  to   d ifferen t   locat ions .  Th is  d istrib u t ion   is 
accomp l is hed   by   ho rizon tal  and /o r  vert ical  part it ion ing .  No  
data  is   s to red   redundan t ly  with   the  e xcep t ion   o f  p r ima ry   keys  
in   the  cas e  o f  vert ical  frag men tat ion .  Us ing   the  relat ional  
model , ho r izon tal  frag men tat ion  is  acco mp l is hed  by  separat ing 
rows   and  vert ical  frag men tat ion   is   accomp lis hed   by  separat ing 
co lumns . Data is  no rma lly  frag men ted  acco rd ing  to  the s ect ion 
o f  the  o rgan izat ion   wh ich   us es   o r  mod if ies   the  data  mos t 
frequen t ly .  Fo r  exa mp le,  a  f irm  may   us e  a  departmen t   code 
fie ld   to   determine  wh ich   departmen t   is   res pons ib le  fo r  each 
reco rd   and   where  the  data  s hou ld   phys ically   res ide  in   a  
ho rizon tal ly  f rag men ted  s ys tem. 

Key   p rinc ip les   o f  the  frag men ted   d is tribu t ion   model   are  that  
on ly   one  copy   o f  the  data  exis ts   in   the  database,  and  that 
owners h ip   and   ab ility   to  update  the  databas e  are  s hared .  Th is 

model  is   s imi lar  to   the  cen tralized   model  in   that   the  data 
is   always   cons is ten t   and   cu rren t .  The  on ly   redundancies 
e xis t   with   p rima ry   key   fie lds   when   us ing   vert ical 
frag men tat ion .  Frag men ted   databas e  s ys tems   are  mo re 
comp le x  than   cen tralized   s ys tems ,  but   s imp ler  than  
rep licated   s ys tems . The  is sue o f  a s ing le  po in t  o f  failu re  is  
reduced ,  bu t   not   eliminated .  Netwo rk   us age  is   generally  
lower  in   frag men ted  s ystems  than  in  cen tralized  s ys tems .  

Fa i lure Recovery 

One  o f  the  advan tages   o f  rep licated   databas e  s ystems   is  
that   they   can   p rov ide  a  level  o f  fau lt -to lerance  beyond 
what   can   be  ach ieved   th rough   mo re  trad it ional  means  
s uch   as   the  us e  o f  redundan t   array   o f  ine xpens ive  d is ks  
(RA ID) .  By   rep l icat ing   the  databas e  s o   that   it   is   on   two 
s eparate  mach ines   in   d ifferen t   phys ical  locat ions   on   the 
netwo rk,  the  p robab ility   that   failu res   wil l  caus e  a  loss   o f 
reduced .  Two   op t ions  
is   s ign ifican t ly  
s erv ice 
fo r 
imp le men t ing  
fai lu re 
recovery  
th rough  
databas e 
rep licat ion  are ava i lab le : warm s tandby  and  hot  s tandby . 

W arm  s tandby   us es   as ynch ronous   rep licat ion   to   main tain  
the s tandby  s erver  in   a  state  nearly   cons is tent  with   that   o f 
the  p rimary   s erver.  Due  to   the  lag  between  trans act ions 
being   commit ted   on   the  p rimary   s erver  and   rep l icat ion   to  
the  s tandby   s erver,  a  sma ll   nu mber  o f   trans act ions   are 
no rma lly  
los t   du ring   a  p rima ry   s erver  failu re  and  
switchover to  the s tandby  s erver. 

Ho t   s tandby   us es  s ynch ronous   rep licat ion   to  ma in tain   the 
s tandby   s erver  in   a  s tate  always   cons is tent   with   the 
p rima ry  s erver. F ro m an  ava ilab il ity  pers pect ive th is  is  the 
p referred   s o lu t ion ,  bu t   the  h igher  cos ts   and   po ten t ial 
lower  perfo rmance  o f  synch ronous  rep licat ion   databas es 
caus e  many   o rgan izat ions   to   s elect   a  warm  s tandby 
s o lu t ion .  Bu ret ta  recommends   a  comb inat ion   o f  local  ho t 
s tandby ,  no rmal ly   RA ID,  and   o ffs ite  warm  s tandby 
s erver. 

PR IMARY W ORK DONE ON THE LINES :  

 In  the ear lies t  days  o f cen tralized  databas es , p ro fess ionals 
no rma lly   us ed   a  one-s ize  fits   all  app roach   to  DBMS  
s o ftware. 

 A s  databas e s ys tems   g rew,  increas ed  in   impo rtance  to   the 
o rgan izat ion ,  and   began   operat ing   in   d ivers e  app licat ions , 
it   beca me  apparen t   that   DBMSs   s hou ld   be  specialized .  
One  o f  the  ma jo r  s h ifts   occu rred   when   data  cen ters 
runn ing   ma in fra mes   w ith  
la rge  re lat ional  databas es 
op t imized   fo r  trans act ion   s peed   began   to   not ice  poo r 
perfo rmance  du ring   t imes  when   repo rts   and   queries  were  
p rocess ed .  It   was   at  
th is   po in t   that  
the  d ifferen t  

© 2012 , IJARCS S E Al l  Righ ts  Res er ve d                                                                                                                                                        Pa ge | 62  

Vo lu me  2,  Is s ue 4, Ap ri l  2012                                                                                                                                                                www. i jarcs s e.com 

requ ire men ts   o f  on line  transact ion   p roces s ing   (OLTP)   and  
on line  analy t ical  p roces s ing   (OLAP )  beca me  apparen t .  Some  
o rgan izat ions  
res ponded  
to  
the  perfo rmance 
is s ues   by 
res trict ing  OLAP  to  late n igh t  and  o ther o ff-peak  t imes . Th is  is  
les s   than   an   ideal  s o lu t ion   as   it   limits   the  us e o f OLAP  fo r  the 
compet it ive  advan tage 
it   shou ld   p rov ide,  and   may   be 
impos s ib le  when   an   o rgan izat ion   operates  round   the  clock  o r 
in  many  t ime   zones . 

Securi ty 

Imp le men t ing   e ffect ive  s ecu rity  
in   a  w idely   d is tr ibu ted 
databas e  is   no  smal l  tas k.  It   is   obs erved   that   pos s ib le  s ecu rity 
s erv ices   in   a  mu lt it ier  a rch itectu re  inc lude  au then t icat ion , 
au tho rizat ion ,  non repud iat ion ,  con fiden t iality ,  and   data 
in teg rity .  Au thent icat ion   is   the  p rocess   o f  hav ing  each   us er, 
host ,  o r  app licat ion   s erver  p rove   it   self  that   who   they   are 
real ly .  Au tho rizat ion   is   the  p rocess   o f  ens u ring   that   each 
au thent icated   us er  has   the  neces s ary   permis s ion   level  to 
perfo rm  the  reques ted   tas ks .  Non repud iat ion   is   ensu ring   that 
au thent icated   and   au tho rized   us ers   may   not   deny   that  they 
us ed  
a  des ignated  
resou rce.  Con fiden t ial ity   p reven ts 
unau tho rized   us ers   from  access ing   s e ns it ive  data.  Data 
in teg rity  p reven ts  data fro m being  mod if ied  in  an  unau tho rized  
manner  (11 ).  

Th is  ma kes   some  reco mmendat ions   fo r  imp le men t ing   s ecu rity 
in  a rep licated  databas e env ironmen t . The  f irs t  is  that  all  s to red 
and /o r  d is p layed   passwo rds   mus t   be  e ncryp ted   s o   that 
unau tho rized   pers ons   and   p rocess es   may   no t   ob tain   them.  
Ps eudo -us er  accoun ts , 
thos e  es tab lis hed   fo r  s ystems  
to 
au tomat ical ly  
in  
the  netwo rk,  are  common  
to 
log   on  
d is tribu ted   databas e  env ironmen ts .  Bu ret ta  po in ts   ou t   that 
thes e  accoun ts   mus t   comp ly   with   the  f irm's   s ecu rity   po licies  
and   knowledge  o f  their  passwo rds   s hou ld   be  limited .  A l l  f ile  
s ys tems ,  raw  dev ices ,  and /o r  databas e  structu res   us ed   to  s to re 
queued  data and/o r mes s ages  mus t  be s ecu re. Th is   item  po in ts 
ou t   the  many   avenues   in   a  d istribu ted   s ys tem  availab le  to  
unau tho rized   us ers ,  wh ich   mus t   be  p ro tected .  Finally ,  
encryp t ion  
techn iques   mus t   be 
in teg rated   with in  
the 
rep licat ion   s erv ice.  Th is   p reven ts   in tercep t ion   o f  the  data 
transmit ted  over the netwo rk  (12) .  

Th is   makes   the  po in t   that   d is tribu ted  databas e  s ys tems   may  
us e  either  app licat ion -  o r  data-level  s ecu rity . App licat ion -level  
s ecu rity ,  as   its   name  s ugges ts ,  is   p rog rammed   in to   the 
app licat ion  
log ic.  Each   app licat ion  
is  
respons ib le 
fo r 
govern ing   us er  acces s   to   the  data.    Data  level  s ecu rity   is  
imp le men ted   in   the  databas e  eng ine.  Pro files   o f  accep tab le 
data  items   and  operat ions  are  sto red   and   checked   by   the 
databas e  eng ine  against   the  end -us er's   permis s ion   level  on  
each   databas e  operat ion .  Bu rles on  
recommends  
that 
app licat ion -leve l  s ecu rity   be  removed   and   rep laced   with   data 
level  s ecu rity   to   make  the  d is tribu ted   database  mo re  s ecu re  . 
The  argumen t   fo r  th is   is   that   a  s ki l led   end -us er  with   a  

wo rks tat ion   and   common ly   availab le  develop men t   too ls 
cou ld   eas ily  w rite  an   app l icat ion   that   does   not   fo llow   the 
o rgan izat ion 's   s ecu rity   po licy   [11 ].  Such   a  s ecu rity   ho le 
may   be  created   either  un in ten t ionally   by   a  well-mean ing  
emp loyee  o r  in tent ionally   by   s omeone  with   mal ic ious 
in ten t .  W hen   data -level  s ecu rity   is  imp le men ted ,  s uch 
s ecu rity  ho les  are n o t  poss ib le (11)  

The  Future  Prospects  for  DDBMSs :  The  is s ues   above 
demons trate  that   a  good   DDBMS  mus t   p rov ide  s ecu rity  
s erv ices ,  and   that   o rgan izat ions   mus t   know  how   to  
p roperly   imp le men t   them  [ 4] .  A s   data  is   d is tribu ted   and 
end -users   are  g iven   mo re  p roces s ing  power,  poten t ial  fo r 
s ecu rity  
p rob lems  
increas es .  Organ izat ions   with  
d is tribu ted   databas es  mus t   be  competen t  and  v ig ilan t   in  
their e xecu t ion  o f s ecu rity .   

DDBMS   techno logy   has   poten t ial,  bu t   its   con t inued 
g rowth   in   popu larity   is   not   guaran teed .  Jus t   as   DDBMSs  
g rew  in   popu larity   w ith   clien t -s erver,  the  po tent ial  fo r  
fu rther  g rowth   in   their  popu lar ity   wi l l  l ikely   be  t ied   to  
clien t -s erver.  The 
fo llo wing   s ect ion   exa mines  
the 
po tent ial  fo r  fu tu re  s uccess  o r  fai lu re  o f DDBMS  s ys tems 
with   a   focus   on   clien t -s erver  trends   as   ind icato rs   o f what  
the fu tu re may  ho ld .  

Growth o f I nternet  Comput ing  

Expe r ience  with   d is tribu ted   databas e 
clien t -s erver 
arch itectu res   has  s hown   that   the  comp le xity   and   expens e 
o f  thes e  app roaches   can   be  overwhelming .  A s   a  resu lt , 
s ome  firms   have  decided  to   go   back  in   the  d irect ion   o f 
cen tralized  databas es . Pro fes s ional  have res ponded  to  th is 
demand   by   p rov id ing   s o lu t ions   us ing  s ervers   bas ed   on 
ma in f ra me  o r  min ico mpu ter  p latfo rms   and   th in   clien ts , 
wh ich   in   mos t   cas es   run   on ly   a  web   b rows er.  T h is  
arch itectu re 
is   s omet imes  
refer red  
to   as  
Internet 
compu t ing .   

Proponen ts   o f  In ternet   compu t ing   claim  that   s imp l ify ing  
the d is tribu ted  components  o f the arch itectu re and  mov ing  
data  to   one  p ro fess ionally -managed   locat ion   p rov ides 
h igher  rel iab i lity   and   lower  operat ing   cos ts .  One  o f  the 
o rig inal   argu men ts   fo r  cl ien t -s erver  was   the  ab il ity   to  
rep lace 
termina ls   with   GUI -bas ed 
character-bas ed 
wo rks tat ions ,  wh ich   are  mo re  f le xib le  and   eas ier  to   us e. 
In ternet   compu t ing   retains   the  benefits   o f  a  cen tral   data 
s to re  and   GU I-bas ed   wo r ks tat ions .  The  benefits   o f 
In ternet   compu t ing   may   generate  s t iff  co mpet it ion   fo r  
wide ly  d is tribu ted  databas e s ys tems . 

Imma turi ty o f Cl ient -Server  

© 2012 , IJARCS S E Al l  Righ ts  Res er ve d                                                                                                                                                        Pa ge | 63  

Vo lu me  2,  Is s ue 4, Ap ri l  2012                                                                                                                                                                www. i jarcs s e.com 

A lthough   clien t -s erver  techno logy   has   been   in  wides p read   us e 
fo r  over  a  decade,  s ome  argu e  that   it   is   no t   yet   developed   to 
the  level  to   p rov ide  s u ff icien t   advan tages   to   bus iness es 
imp le men t ing   new  s ys tems .  A   panel  o f  indus try   experts 
s peaking   at   the Cl ien t -Server  Leaders h ip   Fo ru m  in  To ron to   in  
1996  concluded   that   the  clien t -s erver  mar ket   is   s t ill   in  
ado les cence. The  panel  reiterated   the popu lar  v iew  that   three-
tiered  cl ient -s erver  s ys te ms   are  far  s uperio r  to   two -t iered  
s ys tems .  Th ree-t iered   arch itectu res   requ ire  mo re  res ou rces   to 
imp le men t ,  bu t   are  generally   mo re  s calab le  and   al low   fo r  
th inner,  eas ier  to  main tain   cl ien ts  than  two -t iered   arch itectu res 
does .  The  panel  s aw  the  clien t -s erver  indus try   as   immatu re,  
due 
to  
the 
low  numbers   o f 
th ree -t iered  
s ys tems 
imp le men tat ion . Many   p ro fes s ionals   felt   that   unt il  th ree -t ie red  
s ys tems   become  the  no rm,  th e  benefits   o f  clien t -s erver 
arch itectu res   canno t   be  realized .  So me  o f   the  me mbers   felt  
that   th is  weakness  may   lead   to   clien t -s erver  being   rep laced   by 
In ternet  compu t ing  Lack  o f DDBMS  Standards    :   

A   d is tribu ted   databas e  needs  thes e   fou r  issues  fo r DDBMSs   to 
reach   at   their  fu ll  po ten t ial.  1.  Hardwa re   independence,  2. 
Operat ing   s ystem  independence,  3.  Net wo rk  independence, 
and   4. Databas e   independence. Today 's  DDBMS   p roducts   are 
s t ill do  no t  meet  thes e fou r s tandards . 

 DDBM S  techno logy  is   relat ively   new,  and   is  st ill  s u ffer ing  
fro m  p ro fes s ionals   figh t ing   to   develop   and   ho ld   on   to 
p rop rietary   featu res .  Today   the  s ituat ion   is   imp rov ing ,  bu t  
cross -vendo r  connect iv ity   is   somet imes   l imited ,  es pecial ly   fo r  
legacy  s ys tems  that  do  no t  imp le men t  newer s tandards . 

DDBMS s Cur rent ly Ava i lab le   

Several  years   ago   find ing   the  r igh t   too l  fo r  imp le men t ing  
d is tribu ted   databas es   was   a  challenge  due  to   the  lack  o f 
DDBMSs   availab le . Today   d istribu ted   featu res  are  common   in  
the  lates t  DBMS  o ffer ings   from  all  ma jo r  vendo rs .  In  fact ,  it   is 
rare  fo r  DBM Ss   with   d is tribu ted   featu res   to   be  referred   to   as 
" d is tribu ted"  databas es  at  all  -  the  featu re  is  s o  p revalen t  that   it 
does   not   d is t ingu is h   one  p roduct  from  ano ther.  The  ma jo r  
d iffe rences   between   p roducts  now  are  the  techn ical  details   o f 
how  the data d is tribu t ion   is  perfo rmed   and   the s pecial  featu res 
the DBMS  p rov ides . 

The  DBMS  mar ket   is   fierce ly   compet it ive,  w ith   no   one 
p ro fes s ional  dominat ing   comp lete ly .  A cco rd ing   to   Dataques t 
figu res   repo rted   in   Compu ter  Resel ler  News,  the  1998  
databas e  licens e  revenue  leaders   were  IBM   with   32. 3%,  
Orac le  w ith   29. 4%,  M icros o ft   with   10 .2% ,  In fo rmix  w ith  
4. 4%,  and  Sybas e with  3. 5% . IBM 's  lead   is  due p rimar i ly  to  its  
dominance  in   the  ma in fra me   and   AS/400   p latfo rms ;   on   al l  
o ther  p latfo rms  Oracle  is   the  leader. Th is  s ect ion  firs t   p rov ides 
an   overv iew  o f  featu res  common   among   today 's   lead ing 
d is tribu ted   databas e  p roduct  o fferings .  Later  it   e xa mines   the 
d iffe rences   between   each   vendo r's   p roducts   as   well  as   their 

d ivers e  strateg ies   to   p rov ide  an   ind icat ion   o f  the  fu tu re 
o ffer ings  that  may  beco me avai lab le  in  the fu tu re.    

Ab i l ity o f DDBM Ss to  meet  Bu siness Requireme nts  

Thes e 
recen t ly  
o rgan izat ional 
d is cus es  
s ect ion  
imp le men ted   d is tribu ted  databas es   and  the  res u lts   they 
have ob tained . Thes e cas es  are rep res entat ive o f the us e o f 
d is tribu ted   databas es   in   bus iness   today   [9].  Each   cas e 
il lus trates  s pecific  capab il it ies   o f  today 's  DDBMSs .  Later  
th is   s ect ion   wi ll   analyze   the  capab ilit ies   o f  DDBMS  
p roducts  to  meet  the bus iness  and  techno logy  demands  fo r 
them ou t lined  ear l ie r.  

1 . Ana lysis 

Recen t  developmen ts  in  DDBMS techno logy , many  o f the 
bus iness   and   techno logy   requ ire men ts   fo r  d is tribu ted 
databas es   can   be  met .  Belo w  are   the  bus ines s   and 
techno logy  
requ ire men ts   d is cuss ed   earlier  w ith   an  
analys is   o f  the  ab ility   o f  today 's  DDBMS  p roducts   to 
adequately  meet  the needs .  

2 . Geographic Dispersion 

DDBMS   vendo rs   have  done  a  remar kab le  job   o f  meet ing  
the  demands  o f  bus ines ses  to  s uppo rt  their  geog raph ically  
d is pers ed   operat ions .  Many   o f  the  advances   in   th is   area 
are  due  to  the  wo rk  in   ma k ing   effic ien t   us e  o f  netwo rk 
connect ions .  Netwo rk  loads   resu lt ing   fro m  rep l icat ion  
act iv ity  
is  s ign ifican t ly   reduced . 
in   recen t   vers ions  
Su rr idge  Daws on 's   us e  o f  ISDN  to   rep licate  hund reds   o f 
thous ands   o f  trans act ions   in   on ly   two   hou rs   every   day 
il lus trates   th is   po in t . Rep licat ion   to   smal l  c l ien t   databas es 
us ing   occas ional  d ial-up   connect ions ,  typ ically   w ith  
lap top   compu ters ,  is   als o   an   area  where  recen t   wo rk   on  
ligh twe igh t   rep l icat ing   DBMS   vers ions   has   p rov ided 
o rgan izat ions  w ith  a power fu l  too l fo r   meet ing  the need  to 
s uppo rt   mob ile   wo r kers .  W ith   a  carefu l   analys is   o f 
bus iness  
requ ire men ts   and   p roper  netwo rk  des ign , 
DDBMSs   can   s uppo rt   mos t   geog raph ically   d is pers ed 
bus iness  operat ions . 

3 . Con trol   of  the   In for ma tion  Res ource  

DDBMSs   now  p rov ide  in fo rmat ion   managers   with   a 
means  fo r  cen tral ly  con tro ll ing  and  e xp lo it ing   in fo rmat ion  
s cattered   by   s erver  p ro liferat ion .  Robust  
fo r 
too ls  
hand ling   heterogeneous   s erver  p latfo rms   and   rep licat ion  
that   is   trans parent   to   legacy  app licat ions   are  key   facto rs   in 
th is .  No rthwes t   A irl ines   is   a  good  exa mp le  o f  how 
o rgan izat ions   can   us e  the  latest   d is tribu ted   databas e 
p roducts   to   leverage  exis t ing   hardware  and   s o ftware 
o rig inal ly   mean t   fo r  us e  by  on ly   one  elemen t   o f  the 

© 2012 , IJARCS S E Al l  Righ ts  Res er ve d                                                                                                                                                        Pa ge | 64  

Vo lu me  2,  Is s ue 4, Ap ri l  2012                                                                                                                                                                www. i jarcs s e.com 

o rgan izat ion   to  ma ke  the  en t ire  o rgan izat ion  mo re  co mpet it ive 
[5 ].  Becaus e  the  d istribu ted   databas e  model  wo r ks   we ll  w ith  
cen tralized   p lann ing   and   decen tralized   operat ions ,  databas e 
des igners   and   admin is trato rs   can  main tain   con tro l  o f  the  firm's  
in fo rmat ion  wh i le a l low ing  it  to  be us ed  fle xib ly .  

the  p res en t   and   fu tu re  needs  o f  the  firm  can   be  met .  Th is  
is   ano ther  area where DDBMS  featu res  wi l l  never  rep la ce 
talen ted  peop le. 

Demands o f  the I nternet  

4 . Mergers and  Acquisi t ions 

The  d is tribu ted   databas e  p roducts   availab le  now   can   faci l itate 
me rgers   and   acqu is it ions ,  es pecially   if  the  o rgan izat ion   is  
an t icipat ing   s uch   act iv ity   and   p lans   ahead .  However,  the 
p rev ious ly   cited  exper iences   o f  Pricewaterhous e  and   o ther 
large  co rpo rat ions   attemp t ing   to   merge  in fo rmat ion   res ou rces 
with   o ther  f irms   on   s ho rt   no t ice  h igh ligh ts   the  limitat ions   o f 
DDBMSs   and  midd le ware  to  s o lve  very  comp le x  p rob le ms [6 ].  
Is sues   with   d ifferen t   databas e  s chema,  inco mpat ib le  netwo r k  
in fras tructu re, and  p res su re to  imp le men t  a s o lu t ion  rap id ly  are  
facto rs   that   wil l  pos e  s ign ifican t   challenges   to   a  smoo th 
me rger  o f  in fo rmat ion   res ou rces   fo r  many   years   to   come.  In  
thes e  cases   DDBMS  s o ftware  featu res   are  no   subs t itu te  fo r 
h igh  quality  pers onnel and  p roper p lann ing . 

Sea-Land   Serv ices   is   in   a  bus iness   no rmal ly   cons idered 
low-tech ,  bu t   it   has   exp lo ited   the  In ternet   as   a  s ou rce  o f 
compet it ive  advan tage  th rough   its   web   s ite  that   allows  
customers   to   track  s h ipmen ts   and   en ter  bookings   on line. 
Th is   is   an   exa mp le  o f  ne w  on line  s erv ices   increas ing  
loads   on   databas e  s ervers   as   large  numbers   o f  firms  
leverage  the  In ternet   to   p rov ide  imp roved   s erv ice.  By  
rep licat ing   the  relevan t   data  to   a  server  ded icated   fo r 
p rov id ing   s erv ice  to   the  web   s ite,  firms   can   reduce  the 
impact   o f  th is   increas ed   demand   on   in ternal  operat ions 
wh i le  no t   los ing   on line  customers   as   a  resu lt   o f  e xces s ive 
page  generat ion   t imes . DBM S  developers  have  latched  on 
to   the  In ternet   as   a market   fo r  their  p roducts ,  and  we wil l  
con t inue to  s ee  an   increas e  in   the  power  o f  thes e  p roducts 
to  s uppo rt  e-bus ines s  on  the In ternet . 

Corpora te Rightsizing 

CONCLUS ION :  

DBMS  p ro fes s ionals  cont inue   to   make  advances   in   the 
s calab ility   o f  their  p roducts  -  both   in  the  capacity  o f  ind iv idual 
s ervers   and   the  quan t ity   o f  d is tribu ted   s ervers   that   may   be 
included   in   a  d is tribu ted   databas e  [3].  Modern   databas e 
p roducts   g ive  firms   var ious   op t ions   fo r  g rowing   o r  reducing  
their  dep loyed   databases .  E-Plus   is   an   exa mp le  o f  a  firm  that  
was   ab le  to  manage  exp los ive  g rowth   wh ile  s tay ing   with   one 
DBMS  p roduct   family .  Rep l icat ion   al lows   o rgan izat ions   to 
eas ily   h and le  mov ing   in to   new  ma rket   a reas .  Su rr idge 
Daws on , fo r e xa mp le, cou ld  open  a new warehous e qu ickly  by  
add ing   another  s lave  s erver  iden t ical  to   the  21  it   already   has 
and   connect ing  it   with   comme rcia l ly   availab le  ISDN  s erv ice.  
Cu rren t   DDBMSs   p rov ide  s calab il ity   adequate  fo r  mos t 
bus iness   app licat ions ,  and   the  emphas is   p laced   on   th is   by 
DDBMS  developers  wil l  ens u re  that  thos e  availab le  in   coming  
years  wi ll  al low  h igh  deg rees  o f s calab il ity . 

Cl ient -Server Systems  

A ll  o f  the ma jo r  DBM S  developers   have made  s ign ifican t  
imp rove men ts   to  their  newer  p roducts   in   the  area  o f 
hand ling   h igh   loads   o f  s imu ltaneous   OLTP   and   OLAP  
operat ions   on   the  s ame  s erver.  Recen t   advances   such   as 
imp roved   us e  o f mu lt ip roces s o r hardware,  mu lt ith read ing ,  
and   row-level 
loc king   have  allowed  
th is  
imp roved  
perfo rmance.  However,   there  are   s t il l  OLAP   app licat ions 
that   generate s uch   h igh  s ys tem  de mands   that   they   canno t 
funct ion   together  effect ively   w ith   OLT P  app l icat ions   on 
the  s ame  s erver. The  rep licat ion   featu res   o f  today 's  majo r  
DBMSs   fi l l  th is   need   n icely .  Firms   can   us e  as ynch ronous 
rep licat ion   to  main tain   an  OLA P  s erver  s eparate  from  the  
OLTP  s erver  and   p rov ide  h igh   perfo rmance  fo r  bo th 
app licat ions .  Fu tu re  advances  
in  
ind iv idual  s erver 
capab ilit ies   to   s imu ltaneous ly   s uppo rt   OLTP   and   OLAP  
p lus   imp roved   rep licat ion   perfo rmance  wi l l  mean   that   IT 
managers   wi l l  no t   need   to   comp ro mis e  to   p rov ide  h igh 
perfo rmance in  bo th  thes e areas . 

The  lates t  vers ions   o f  DDBMSs   and   midd le ware  ma ke  a 
developer's  
tas k  o f 
imp le men t ing  
th ree-t ier  cl ien t -s erver 
arch itectu re  much   s imp ler.  Many   o f  the  componen ts   that 
fo rmer ly   requ ired   a  heavy   p rog ra mming   effo rt   are  now  
availab le  in   o ff-the-s helf  vers ions   robust   and   fle xib le  enough 
to   hand le  mos t   tas ks .  Organ izat ions   that  in teg rate  s uch 
p roducts   in to   their  in fo rmat ion   arch itectu re  w il l  reap   the 
benefits   o f  th ree -t ier  cl ien t -s erver.  Thes e  arch itectu res   wil l  
allo w  fo r  mo re  fle xib i lity   and   the  ab ility   to   rap id ly   take 
advan tage  o f  bus iness   and   techno logy   oppo rtun it ies  that   aris e 
in   the  fu tu re.  However,  th ree  t ier  cl ien t   s erver  sys tems   wil l  
always   requ ire   s ki l led   p lann ing   and   imp le men tat ion   to   ens u re 

 

References    

1)  Pro f.  (Dr. )  Anand   K.  Tr ipath i  and   Mrs .  Mon ica 
Tripath i :  “MIS  Uncertain t ies   and   the Compu ter  Suppo rt”: 
An   Analy t ical  App roach”,  Proceed ing   o f  the  Nat ional 
Con ference  on   Ne xt   Generat ion   Co mpu t ing   Techn o logy , 
at   ITS  Ghaziabad   pub licat ion   wis dom  pub l icat ion ,  Delh i-
16 -17 Oct - 2008. ,ed it ion - 3,vo l- 1  
 

© 2012 , IJARCS S E Al l  Righ ts  Res er ve d                                                                                                                                                        Pa ge | 65  

Vo lu me  2,  Is s ue 4, Ap ri l  2012                                                                                                                                                                www. i jarcs s e.com 

 
 
10 .  Cos t   Benefit   Analys is   agains t   Compu terizat ion   o f 
Oran izat ion .”Jou rnal  P res t ige  Ins t itu te  o f  Managemen t , 
Dewas   (MP )  Vo l. - 1  No .  1,MPENG00969/12/1/ 2009-
TC, Jan .  2010 ,  ed it ion - 1,vo l -1 ,,pg .  724- 731  
11 .  “  Data  Secu rity   levels   fo r  Co mpu terized   MIS”  
A rt if icia l  In tel l igence  &  its   App licat ions   (A IA   –   2009 )  ,
 
Depart men t  
o f 
Co mpu ter 
Sc ience  &  
Eng ineer ing ,  Facu lty   o f  Eng ineer ing  & Techno logy , RBS  
Co l lege,  Bichpu ri , Ag ra (UP ),  
Sep te mber  
12 -13 
2009, ed it ion - 1,vo l- 1,  ,pg .  555- 559  
 
 
12 .  Ro le  o f  IT  In f ras tructu re  fo r Bus iness  Trans fo rmat ion
o f  
 
Pro f icien t -An  
In ternat ional 
Jou rnal 
Managemen t ,  Malv iya  Nagar ,  Ja ipu r,Rajas tan  
,IS SN  
No .0975 -475X ,Vo l. -1 ,Ju ly -Dec.- 2009  (Refer red   Bas ed ), 
ed it ion -4,vo l- 1,  ,pg . 789- -793  
 
 

 

2)    P ro f.  (D r.)  Anand   K.  Tr ipath i  and   Mrs .  Mon ica  Tripath i:  
“A   Fra me: W hy   In fo rmat ion   Sys tem  Fa i ls ”,  Proceed ing   o f  the 
“Manag ing   Co mp le xit y  
Nat ional  Con ference  on  
in  
In fo rmat ive  W o r ld . „ ‟  pub licat ion   Bh ila i 
Ins t itu te  o f 
Techno logy , Du rg , Bh i la i  (CG)   dated   7- 8 Nov .- 2008.   ed it ion -
1,vo l- 1,pg . 112 -115  
 
 
3)  Pro f.  (D r. )  Anand   K.  Tripath i  and   Mrs .  Mon ica  Tripath i  ,  
A ICT E  Spons o red ,  Nat ional  Con ference  on   “Next   generat ion  
compu t ing   &  In fo rmat ion   s ys tems ”  at   Model  Ins t itu te  o f 
Eng ineer ing  & Techno logy ,  Jammu ,  Feb .14 -15,  2009.  ed it ion -
2,vo l- 1,pg .  724- 731  
 
 
4)  P ro f.  (D r. )  Anand   K.  Tripath i  and   Mrs .  Mon ica  Tripath i 
,Paper  “A   Fra mewo r k  :A  Ro le  o f  In fo rmat ion  Techno logy   fo r 
Decis ion   Suppo rt   Sys tem”,    CSI  Spons o red   Nat ional  level  
Con ference  on   “Cu t t ing   Edge  Co mpu ter  and   Electron ics  
Techno log ies ”  under  TEQIP   o rgan ized   by  
  Co llege  o f  
Techno logy , GB  Pan t  Un ivers ity ,  Pan t  Nagar, 14 -15  Feb . 2009,  
ed it ion -4,vo l- 1,  ,pg . 915- 919  
 
 
5).   (Dr. )  Anand   K.  Tr ipath i  and   Mrs .  Mon ica  Tripath i  ,  
Nat ional  level   Con fe rence  on   “Co mpu ter  In tel ligence”   at  
Pioneer  Ins t itu te,  Indo re,  May -2009 ,Ed io t ion - 1,Vo l. - 1,  ,pg .  
724- 729  
 
6).   (Dr. )  Anand   K.  Tr ipath i  and   Mrs .  Mon ica  Tripath i  Paper  
“In fo rmat ion   Techno logy  
to   Trans fo rm 
the  Bus iness 
“Proceed ing   o f  Nat ional  Con fe rence  on   Next   Generat ion  
Techno log ies   fo r  In fo rmat ion   Managemen t   (NGT IM - 2009)  
,7t h  Nov .-2009   ,o rgan ized   by   ITS -Managemen t  &  IT  Ins t itu te, 
Gha ziabad   (UP) ,ISBN  :978- 81- 89547- 69 - 1,  ed it ion -1 ,vo l- 1,  
,pg . 1724- 1731  
 
 
7)  “ In fo rmat ion  Techno logy   and   Structu ring  Of O rgan izat ion :  
In fo rmat ion   Sys tem  Res earch”  Pub lis hed  
in  
IMSEC 
In ternat ional  Jou rnal  o f  Res earch   IMS  Co llege  Eng ineering ,  
Gha ziabad ,  Vo l .- 1  Ju ly -Dec.- 2009  (Re ferred   Bas ed )  ed it ion -
1,vo l- ,1 ,  ,pg . 925- 928  
 

 
8)  “ Impact   o f  H igh   P ro fes s ional  Teach ing :  In fo rmat ion  
the  Bus iness ”  Pub lis hed  
to   Global ize 
Techno logy  
in 
In ternat ional 
Jou rnal  on  Compu ter  Eng ineer ing  
and 
In fo rmat ion   Techno logy ,  Bh ila i,   ISSN  0974- 2034  (Re fer red  
Bas ed ), ed it ion - 1,vo l -1 , ,pg .  815 - 818  
 
  Know ledge,  Ski l ls   and  Ab ilit ies :  Rec ru it men t   IS/IT  
9) 
Pro fes s ionals  
in  
 
 
Fas t  
Chang ing  
Bus iness 
Lands cape  Pub lis hed   in   In ternat ional  Jou rnal  on   Compu ter 
Eng ineer ing   and   In fo rmat ion   Techno logy ,  Bh ila i,  ed it ion -
1,vo l- 1,  ,pg .  606 -609  

© 2012 , IJARCS S E Al l  Righ ts  Res er ve d                                                                                                                                                        Pa ge | 66  

System  R:  Relational 
Management 

Approach 

to  Database 

M.  M.  ASTRAHAN, ht.  W.  BLASGEN, D.  D.  CHAMBERLIN, 
K.  P.  ESWARAN,  J.  N.  GRAY,  P.  P.  GRIFFITHS, 
W.  F.  KING,  R.  A.  LORIE,  P.  R.  A&JONES,  J.  W.  MEHL, 
G.  R.  PUTZOLU,  I.  L.  TRAIGER,  B.  W.  WADE,  AND  V.  WATSON 

IBM  Research  Laboratory 

System  R  is a database  management  system  which  provides a high level relational data interface. 
The  system  provides  a  high  level  of  data  independence  by  isolating  the  end  user  as  much  as 
possible from  underlying  storage structures.  The  system  permits  definition  of a variety  of relational 
views  on  common  underlying  data.  Data  control  features  are  provided,  including  authorization, 
integrity  assertions, triggered transactions, a logging and recovery subsystem, and facilities  for 
maintaining  data  consistency  in  a  shared-update  environment. 
This  paper  contains  a  description  of  the  overall  architecture  and  design  of  the  system.  At  the 
present time  the  system is  being implemented and  the  design evaluated. We emphasize that 
System  R  is a vehicle  for  research in  database  architecture,  and  is not  planned  as a product. 
Key  Words  and  Phrases:  database,  relational  model,  nonprocedural  language,  authorization, 
locking, recovery, data structures, index structures 
CR  categories:  3.74, 4.22, 4.33, 4.35 

1.  INTRODUCTION 

in  1970 as  an  approach 
The  relational  model  of  data  was  introduced  by  Codd  [7] 
toward  providing  solutions 
to  various  problems  in  database  management. 
In  par- 
ticular,  Codd  addressed  the  problems  of  providing  a  data  model  or  view  which  is 
considerations 
divorced 
independence 
(the  data 
implementation 
from  various 
problem)  and  also  the  problem  of  providing 
the  database  user  with  a  very  high 
level,  nonprocedural  data  sublanguage  for  accessing  data. 
To  a  large  extent,  the  acceptance  and  value  of  the  relational  approach  hinges  on 
the  demonstration 
that  a  system  can  be  built  which  can  be  used  in  a  real  environ- 
ment  to  solve  real  problems  and  has  performance  at  least  comparable 
to  today’s 
existing  systems.  The  purpose  of  this  paper  is  to  describe  the  overall  architecture 
and  design  aspects  of  an  experimental  prototype  database  management  system 
called  System  R,  which  is  currently  being  implemented  and  evaluated  at  the  IBM 
the  design  has  been 
San  Jose  Research  Laboratory.  At  the  time  of  this  writing, 

- 
Copyright  @  1976, Association  for  Computing  Machinery, 
Inc.  General  permission  to  republish, 
but  not  for  profit,  all  or  part  of  this  material  is  granted  provided  that  ACM’s  copyright  notice  is 
given  and  that  reference is  made  to  the  publication, 
to  its  date  of  issue,  and  to  the  fact  that 
reprinting  privileges  were  granted  by  permission  of  the  Association  for  Computing  Machinery. 
Authors’  address: 
IBM  Research  Laboratory,  San Jose, CA  95193. 

ACM  Transactions  on  Database  Systems,  Vol.  1,  No.  2.  June  1976,  Pages  97-137. 

98 

l 

M.  M.  Astrahan  et  al, 

CONTENTS 
1.  INTRODUCTION 
Architecture  and  System  Structure 
2.  THE  RELATIONAL 
DATA  SYSTEM 
Host  Language  Interface 
Query  Facilities 
Data  Manipulation  Facilities 
Data  Definition  Facilities 
Data  Control  Facilities 
The  Optimizer 
Modifying  Cursors 
Simulation  of  Nonrelational  Data  Models 
3.  THE  RELATIONAL 
STORAGE  SYSTEM 
Segments 
Relations 
Images 
Links 
Transaction  Management 
Concurrency  Control 
System  Checkpoint  and  Restart 
4.  SUMMARY  AND  CONCLUSION 
I.  RDI  Operators 
APPENDIX 
II.  SEQUEL  Syntax 
APPENDIX 
APPENDIX 
III.  RSI  Operators 
ACKNOWLEDGMENTS 
REFERENCES 

completed and major  portions  of  the  system are implemented  and  running.  How- 
ever, the  overall  system is not  completed. We plan  a complete performance evalua- 
tion  of the system which  will  be available  in  later  papers. 
The  System R  project  is not  the  first  implementation  of the  relational  approach 
[12,  301. On the  other  hand, we know  of no other  relational  system which  provides 
a complete database management capability-including 
application  programming 
as well  as query  capability,  concurrent  access support,  system recovery,  etc. Other 
relational  systems have  focused on,  and  demonstrated,  feasibility  of  techniques 
for  solving  various  specific problems. For  example, the  IS/l  system  [22]  demon- 
strated  the  feasibility  of supporting  the  relational  algebra  [S]  and  also developed 
optimization  techniques  for  evaluating  algebraic  expressions [29].  Techniques  for 
optimization  of  the  relational  algebra  have  also  been  developed by  Smith  and 
Chang  at  the  University  of  Utah  [27].  The  extended relational  memory  (XRM) 
system [19]  developed at  the  IBM  Cambridge Scientific  Center  has been used as 
a single user access method by  other  relational  systems [2].  The  SEQUEL prototype 
[l]  was originally  developed as a single-user system to  demonstrate the  feasibility 
of  supporting  the  SEQUEL [5]  language. However,  this  system has been extended 
by  the  IBM  Cambridge Scientific Center and the MIT  Sloan School Energy  Labor- 
atory  to  allow  a simple type  of  concurrency  and  is  being  used as a  component of 
the  Generalized Management  Information  System  (GMIS) 
[9]  being  developed 
at MIT  for energy related applications.  The  INGRES  project  [lS]  being developed 
at  the  University  of California,  Berkeley,  has demonstrated techniques for  the  de- 
composition  of  relational  expressions in  the  QUEL  language  into  “one-variable 

ACM 

Transactions 

on  Database 

Systems, 

Vol. 

1,  No.  2,  June 

1976. 

System  R 

l 

99 

queries.”  Also, this  system has investigated  the  use of query  modification  [28]  for 
enforcing integrity  constraints  and authorization  constraints on users. The problem 
of  translating  a high  level  user language into  lower  level  access primitives  has also 
been studied at  the University  of Toronto  [21,26]. 

Architecture  and  System  Structure 

We will  describe the  overall  architecture  of  System R  from  two  viewpoints.  First, 
we will  describe the  system as seen by  a single  transaction,  i.e.  a monolithic  de- 
scription.  Second, we  will  investigate  its  multiuser  dimensions. Figure  1  gives  a 
functional  view  of the  system including  its  major  interfaces and components. 
The  Relational  Storage Interface  (RSI)  is  an  internal  interface  which  handles 
access to  single tuples  of base relations.  This  interface  and  its  supporting  system, 
the  Relational  Storage System  (RSS) , is actually  a complete storage subsystem in 
that  it  manages devices, space allocation,  storage buffers,  transaction  consistency 
and  locking,  deadlock  detection,  backout,  transaction  recovery,  and  system  re- 
covery.  Furthermore,  it  maintains  indexes on  selected fields of base relations,  and 
pointer  chains across relations. 
The  Relational  Data  Interface  (RDI) 
is  the  external  interface  which  can  be 
called directly  from  a programming  language, or used to  support  various  emulators 
and  other  interfaces.  The  Relational  Data  System  (RDS),  which  supports  the 
RDI,  provides  authorization,  integrity  enforcement, and  support  for  alternative 
views of  data.  The  high  level  SEQUEL  language is  embedded within  the  RDI,  and 
is used as the  basis for  all  data  definition  and manipulation.  In  addition,  the  RDS 
maintains  the  catalogs of external  names, since the RSS uses only  system generated 
internal  names. The  RDS  contains  an  optimizer  which  chooses an  appropriate 
access path  for any given  request from among the paths supported by  the RSS. 

etc. 

Programs 
to  support 
Interfaces: 
+ 
various 
Stand  alone  SEQUEL, 
Query  By  Example, 
P-m 
- 
Relational 
Data 
Interface 
RelatIonal 
(RDII 
DC3 
System 
IRDSI 
storage 
Interface 
(RSll 

RDS 

RSS 

Ml 

I 

I 

: 

’ 

I 

I 

I 

Monitor 

FIQ.  1.  Architecture  of  System  R 

FIG.  2.  Use  of  virtual  machines 
in  System  R 

ACM 

Transactions 

on  Database 

Systems. 

Vol. 

1,  No.  2,  June 

1878. 

100 

l 

M. M.  Astrahan  et  al. 

The  current  operating  system  environment  for  this  experimental  system  is 
VM/370  [lS].  Several extensions to  this  virtual  machine facility  have been made 
[14]  in  order  to  support  the  multiuser  environment  of  System R.  In  particular, 
we have  implemented  a  technique  for  the  selective  sharing  of  read/write  virtual 
memory  across any  number  of  virtual  machines and  for  efficient  communication 
among virtual  machines through  processor interrupts.  Figure  2 illustrates  the  use 
of many  virtual  machines to  support  concurrent  transactions  on  shared data.  For 
each logged-on user there  is  a dedicated database machine.  Each  of  these database 
machines  contains  all  code and  tables  needed to  execute  all  data  management 
functions;  that  is, services are not  reserved to a centralized machine. 
The  provision  for  many  database machines,  each executing  shared,  reentrant 
code and  sharing  control  information,  means that  the  database system need not 
provide  its  own  multitasking 
to  handle  concurrent  transactions.  Rather,  one can 
use  the  host  operating  system  to  multithread  at  the  level  of  virtual  machines. 
Furthermore,  the  operating  system  can  take  advantage  of  multiprocessors  allo- 
cated  to  several virtual  machines, since each machine  is  capable of  providing  all 
data  management services. A  single-server approach would  eliminate  this  advan- 
tage, since most processing activity  would  then  be focused on only  one machine. 
In  addition  to  the  database machines,  Figure  2  also  illustrates  the  Monitor 
Machine, which  contains  many  system  administrator  facilities.  For  example,  the 
Monitor  Machine  controls  logon authorization  and initializes  the  database machine 
for  each  user.  The  Monitor  also  schedules periodic  checkpoints  and  maintains 
usage and performance statistics  for  reorganization  and accounting  purposes. 
In  Sections 2 and 3 we describe the main  components of System R:  the Relational 
Data  System and the  Relational  Storage System. 

2.  THE RELATIONAL DATA  SYSTEM 

The  Relational  Data  Interface  (RDI) 
is the  principal  external  interface  of System 
R.  It  provides  high  level,  data  independent  facilities  for  data  retrieval,  manipula- 
tion,  definition,  and control.  The data definition  facilities  of the RDI  allow a variety 
of  alternative  relational  views  to  be  defined  on  common  underlying  data.  The 
Relational  Data  System  (RDS)  is the  subsystem which  implements  the  RDI.  The 
RDS  contains  an  optimizer  which  plans  the  execution  of  each RDI  command, 
choosing a  low  cost access path  to  data  from  among those provided  by  the  Rela- 
tional  Storage System (RSS) . 
The  RDI  consists of a set of  operators which  may  be called  from  PL/I  or other 
host  programming  languages.  (See Appendix  I  for  a  list  of  these operators.)  All 
the  facilities  of  the  SEQUEL  data  sublanguage  [S]  are  available  at  the  RDI  by 
means of the  RDI  operator  called SEQUEL.  (A  Backus-Naur  Form  (BNF)  syntax 
for  SEQUEL 
language can be supported  as a 
is given  in  Appendix  II.)  The  SEQUEL 
stand-alone  interface  by  a  simple  program,  written  on  top  of  the  RDI,  which 
interface,  called 
handles  terminal  communications.  (Such  a  stand-alone  SEQUEL 
the  User-Friendly  Interface,  or  UFI,  is provided  as a part  of  System R.)  In  addi- 
tion,  programs may be written  on top  of the  RDI  to  support  other  relational  inter- 
faces, such as Query by  Example  [31],  or  to  simulate nonrelational  interfaces. 
ACM  TransactionsonDstabase  Syystans,Vol.  l.No.  2, June 1976. 

System  R 

l 

101 

Host  Language 
Interface 
The  facilities  of the RDI  are basically  those of the SEQUEL data sublanguage, which 
is described in  [5]  and in  Appendix  II.  Several changes have been made to  SEQUEL 
since the  earlier publication  of the  language; they  are described below. 
The illustrative  examples used in  this  section are based on the following  database 
of employees and their  departments: 
EMP(EMPN0, NAME, DNO, JOB, SAL, MGR) 
DEPT(DN0, DNAME, LOC, NEMPS) 
The  RDI  interfaces  SEQUEL to  a  host  programming  language by  means  of  a 
concept called a cursor, A  cursor is a name which  is used at  the  RDI  to  identify  a 
set of tuples called its  active set  (e.g. the result  of a query)  and furthermore  to main- 
tain  a position  on one tuple  of the  set. The  cursor is associated with  a set of tuples 
by means of the RDI  operator SEQUEL;  the  tuples may then  be retrieved,  one at  a 
time,  by  the RDI  operator FETCH. 
Some host  programs may  know  in  advance exactly  the  degree and  data  types 
of the tuples they  wish to  retrieve.  Such a program may specify, in  its  SEQUEL  call, 
the program variables  into  which  the  resulting  tuples  are to  be delivered.  The  pro- 
gram must  first  give  the  system the  addresses of the  program variables  to  be used 
by  means of the  RDI  operator BIND,  In  the  following  example, the  host program 
identifies  variables  X  and  Y  to  the  system and  then  issues a query  whose results 
are to  be placed in  these variables: 
CALL BIND (‘Xl, ADDR(X)) ; 
CALL  BIND(‘Y’, 
ADDR(Y)); 
‘SELECT  NAME:X, 
CALL  SEQUEL(C1, 
FROM  EMP 
WHERE JOB =  ’ ‘PROGRAMMER’ ’ ‘); 
The  SEQUEL  call  has the  effect of associating the  cursor Cl  with  the  set of tuples 
which  satisfy  the  query  and  positioning  it  just  before  the  first  such  tuple.  The 
optimizer  is invoked  to  choose an access path  whereby  the  tuples may be material- 
ized. However, no tuples  are actually  materialized  in  response to  the SEQUEL  call. 
The  materialization  of  tuples  is  done as they  are called  for,  one at  a time,  by  the 
FETCH  operator.  Each  call  to  FETCH  delivers  the  next  tuple  of  the  active  set 
into  program variables X  and  Y, i.e. NAME  to  X  and SAL to  Y: 
CALL FETCH(C1) ; 
A  program  may  wish  to  write  a  SEQUEL predicate  based on  the  contents  of  a 
program  variable-for  example, to  find  the  programmers whose department  num- 
ber  matches the  contents  of program  variable  2.  This  facility  is  also provided  by 
the RDI  BIND  operator, as follows: 

SAL:Y 

; 

ADDR(X)) 
CALL  BIND(‘X’, 
ADDR(Y)); 
CALL  BIND(‘Y’, 
ADDR(2)); 
CALL  BIND(‘Z’, 
‘SELECT  NAME:X, 
CALL  SEQUEL(C1, 
FROM  EMP 
WHERE 
JOB  = 
’  ‘PROGRAMMER’ 
AND  DNO  =  2’); 

SAL:Y 

’ 

CALL  FETCH(C1) 

; 

ACM  Tramactions 

on  Database  System,  Vol.  1,  No.  2,  June  1976. 

102 

l 

M.  M.  Astrahan 

et  al. 

Some programs may not  know  in  advance the  degree and data types of the  tuples 
to  be returned  by  a query.  An  example of such a program  is one which  supports an 
interactive  user by  allowing  him  to  type  in  queries and  display  the  results.  This 
type  of program need not  specify in  its  SEQUEL  call  the  variables  into  which  the 
result, is  to  be delivered.  The  program may  issue a SEQUEL  query,  followed  by  the 
DESCRIBE  operator  which  returns  the  degree and data  types.  The  program  then 
specifies the  destination  of  the  tuples  in  its  FETCH  commands. The  following  ex- 
ample illustrates  these techniques: 

CALL  SEQUEL(C1, 

‘SELECT 
* 
FROM  EMP 
WHERE  DNO  =  50’); 

This  statement  invokes  the  optimizer  to  choose an access path  for  the  given  query 
and associates cursor Cl  with  its  active  set. 

CALL  DESCRIBE(C1, 

DEGREE, 

P); 

P  is  a pointer  to  an  array  in  which  the  description  of the  active  set of  Cl  is  to be 
returned.  The  RDI  returns  the  degree of the  active  set in  DEGREE,  .and the  data 
types  and  lengths  of  the  tuple  components  in  the  elements of  the  array.  If  the 
array  (which  contains  an entry  describing  its  own  length)  is  too  short  to  hold  the 
description  of  a tuple,  the  calling  program must  allocate  a larger  array  and  make 
another  call  to DESCRIBE. 
Having  obtained  a description  of  the  tuples  to  be returned,  the  calling  program 
may proceed to  allocate a structure  to  hold  the  tuples  and may  specify the  location 
of  this  structure  in  its  FETCH  command: 

CALL  FETCH(C1, 

&); 

Q is a pointer  to an array  of pointers which  specify where the individual  components 
of  the  tuple  are  to  be  delivered.  If  this  “destination”  parameter  is  present  in  a 
FETCH  command, it  overrides  any  destination  which  may  have been specified in 
the SEQUEL  command which  defined the active  set of Cl. 
A  special RDI  operator  OPEN  is  provided  as a shorthand  method  to  associate 
a cursor with  an entire  relation.  For  example, the  command 

CALL  OPEN(C1, 

‘EMP’); 

is exactly  equivalent  to 

CALL  SEQUEL(C1, 

‘SELECT 

*  FROM  EMP’); 

The  use of OPEN  is slightly  preferable to  the  use of SEQUEL to  open a cursor on a 
relation,  since OPEN  avoids the  use of the  SEQUEL parser. 
A program may have many  cursors active  at  the  same time.  Each cursor remains 
active  until  an  RDI  operator  CLOSE  or  KEEP  is issued on  it.  CLOSE  simply 
deactivates  a cursor.  KEEP  causes the  tuples  identified  by  a  cursor  to  be  copied 
to  form  a new permanent  relation  in  the  database, having  some specified relation 
name and field names. 
is  included  for  the  support  of  interfaces 
The  RDI  operator  FETCH-HOLD 
which  provide  for  explicit  locking.  FETCH-HOLD 
operates in  exactly  the  same 
ACM  Transactions  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

System  R 

l 

103 

way  as FETCH  except that  it  also acquires a  “hold”  on the  tuple  returned,  which 
prevents  other  users from  updating  or  deleting  it  until  it  is  explicitly  released or 
until  the holding  transaction  has ended. A  tuple  may be released by  the RELEASE 
operator, which  takes as a parameter a cursor positioned on the tuple  to be released. 
If  no cursor is furnished,  t.he RELEASE  operator  releases all  tuples  currently  held 
by  the  user. 

Query  Facilities 
In  this  section we describe only  the  most significant  changes made to  the  SEQUEL 
query  facilities  since their  original  publication 
[5].  The  changes correct  certain 
deficiencies in  the  original  syntax  and  facilitate  the  interfacing  of  SEQUEL  with  a 
host  programming  language.  One  important  change deals with  the  handling  of 
block  labels. The  following  example, illustrating 
the  original  version  of  SEQUEL,  is 
taken  from  [5].  (For  simplicity,  “CALL  SEQUEL (.  . .) ”  has been deleted  from 
the next  several examples.) 
ExumpZe 1 (a).  List  names of employees who earn more than  their  managers. 

Bl:  SELECT  NAME 
FROM 
EMP 
WHERE  SAL  ) 
SELECT  SAL 
FROM 
EMP 
WHERE  EMPNO  =  Bl.MGR 

Experience has shown that  this  block  label  notation  has three  disadvantages: 
(1)  It  is not  possible to  select quantities  from  the  inner  block,  such as: “For  all 
employees who  earn  more  than  their  manager, list  the  employee’s name  and  his 
manager’s name.” 
(2)  Since the  query  is asymmetrically  expressed, the  optimizer  is biased toward 
making  an  outer  loop  for  the  first  block  and  an  inner  loop  for  the  second block. 
Since this  may  not  be the  optimum  method  for  interpreting  the  query,  the  optimi- 
zation  process is made difficult. 
(3)  Human  factors studies have shown that  the  block  label  notation  is hard  for 
nonprogrammers to  learn  [24,25]. 
Because of  these disadvantages, the  block  label  notation  has been replaced by 
the  following  more symmetrical  notation,  which  allows  several tables  to  be listed 
in  the FROM  clause and optionally  referred to by  variable  names. 
Example  1 (b).  For  all  employees who  earn more than  their  managers, list  the 
employee’s name and his manager’s name. 

SELECT  X.NAME,  Y.NAME 
FROM 
EMP  X,  EMP  Y 
WHERE  X.MGR  =  Y.EMPNO 
AND 
X.SAL  >  Y.SAL 

Example  1 (b)  illustrates  the SEQUEL  notation  for  the  JOIN  operator  of the  rela- 
tional  algebra. The  tables to  be joined  are listed  in  the  FROM 
clause.  A  variable 
name may  optionally  be  associated with  each table  listed  in  the  FROM  clause 
(e.g.  X  and  Y  above).  The  criterion  for  joining  rows  is  given  in  the  WHERE 
ACM  Transactiona  on  Database  Systems,  Vol.  1,  No.  2.  June  1976. 

104 

l 

M. M. Astrahan et al. 

clause  (in  this  case, X.MGR  =  Y.EMPNO)  . Field  names appearing  in  the  query 
may  stand  alone  (if  unambiguous)  or  may  be  qualified  by  a  table  name  (e.g. 
EMP.SAL)  or by  a variable  (e.g. X.SAL)  . 
In  the  earlier  report  [5],  the WHERE  clause is used for  two  purposes: it  serves 
both  to  qualify  individual  tuples  (e.g. “List  the  employees who are clerks”)  and to 
qualify  groups  of  tuples  (e.g.  “List 
the  departments  having  more  than  ten  em- 
ployees”).  This  ambiguity  is  now  eliminated  by  moving  group  qualifying  predi- 
cates to  a separate HAVING  clause. Queries are processed in  the  following  order: 
(1)  Tuples  are selected by  the  WHERE  clause; 
(2)  Groups  are formed by  the  GROUP  BY  clause; 
(3)  Groups  are  selected which  satisfy  the  HAVING  clause, as shown  in  the 
example below. 
Example  2.  List  the  DNOs  of departments  having  more than  ten  clerks. 

SELECT  DNO 
FROM 
EMP 
WHERE  JOB  =  ‘CLERK’ 
GROUP  BY  DNO 
HAVING  COUNT(*)  >  10 

Two  more  query  features  have  been added  to  the  ones described  in  [5].  The 
first  allows the user to specify a value ordering  for his query  result. 
Example  3  (Ordering).  List  all  the  employees in  Dept.  50,  ordered  by  their 
salaries. 

* 
SELECT 
FROM 
EMP 
WHERE  DNO  =  50 
ORDER  BY  SAL 

The  other  new  feature,  which  is  useful  primarily  to  host  language users of  the 
RDI,  allows  a  query  to  qualify  tuples  by  comparing  them  with  the  current  tuple 
of some active  cursor: 
Example  4  (Cursor  reference).  Find  all  the  employees in  the  department  indi- 
cated by  cursor C5. 

* 
SELECT 
FROM 
EMP 
WHERE  DNO  =  DNO  OF  CURSOR  C5 ON  DEPT 

The  evaluation  of  this  reference to  the  content  of  cursor  C5  occurs when  the 
query  is executed (by  a SEQUEL  call).  Thereafter,  moving  the  cursor C5 does not 
affect  the  set  of  tuples  defined by  the  query.  The  optional  phrase  “ON  DEPT” 
indicates  to  the  optimizer  that  it  can  expect  the  cursor  C5 to  be positioned  on  a 
tuple  of  the  DEPT  table.  This  information  may  be  useful  in  selecting  an  access 
path  for  the  query. 
Since elimination  of duplicates  from  a query  result  is an expensive process and is 
not  always  necessary, the  RDS  does not  eliminate  duplicates  unless explicitly  re- 
quested to  do so. For  example, “SELECT  DNO,  JOB  FROM  EMP”  may  return 
duplicate  DNO,  JOB  pairs,  but  ‘SELECT  UNIQUE  DNO,  JOB  FROM  EMP” 
will  return  only  unique  pairs.  Similarly,  “SELECT  AVG  (SAL)  FROM  EMP”  al- 
ACM  Transactions  on  Database  Systems.  Vol.  1,  No.  2,  June  1976. 

System R 

9 

105 

lows duplicate  salary values to participate  in  the average, while  “SELECT  COUNT 
(UNIQUE  JOB)  FROM  EMP”  returns  the  count  only  of  different  job  types  in 
the  EMP  relation. 

Data  Manipulation  Facilities 
The  RDI  facilities  for  insertion,  deletion,  and  update  of  tuples  are also provided 
via  the  SEQUEL  data  sublanguage. SEQUEL  can be used to  manipulate  either  one 
tuple  at  a  time  or  a set of  tuples  with  a single  command. The  current  tuple  of  a 
particular  cursor may be selected for  some operation  by  means of the special predi- 
cate CURRENT  TUPLE  OF  CURSOR.  The  values of  a  tuple  may  be set equal 
to  constants, or  to  new values computed from  their  old  values, or  to  the  contents 
of  a  program  variable  suitably  identified  by  a  BIND  command. These facilities 
will  be illustrated  by  a series of examples. Since no result  is returned  to  the  calling 
program in  these examples, no cursor name is included  in  the calls to  SEQUEL. 
Example  5  (Set oriented  update).  Give  a  10 percent  raise to  all  employees in 
Dept.  50. 

CALL  SEQUEL(‘UPDATE  EMP 
SET  SAL  =  SAL  x  1.1 
WHERE  DNO  =  50’); 

Example  6  (Individual  update). 

ADDR(PVSAL)); 
CALL  BIND(‘PVSAL’, 
CALL  SEQUEL(‘UPDATE 
EMP 
SET  SAL  =  PVSAL 
WHERE  CURRENT  TUPLE  OF  CURSOR  C3’); 

Example  7  (Individual 
insertion).  This  example inserts  a new employee tuple 
into  EMP.  The  new  tuple  is  constructed  partly  from  constants and  partly  from 
the  contents of program  variables. 

CALL  BIND(‘PVEMPNO’, 
ADDR(PVEMPN0)); 
CALL  BIND(~PVNAMEI,  ADDR(PVNAME)); 
CALL  BIND(‘PVMGR’ 
ADDR(PVMGR)); 
CALL  SEQUEL(‘INSERT 
INTO  EMP: 
(PVEMPNO,  PVNAME,  50,  ’  ‘TRAINEE’ 

‘,  8500, PVMGR)‘); 

An  insertion  statement  in  SEQUEL  may  provide  only  some of  the  values for  the 
new tuple,  specifying  the  names of the  fields which  are provided.  Fields which  are 
not  provided  are set to  the  null  value.  The  physical  position  of  the  new  tuple  in 
storage  is  influenced  by  the  “clustering”  specification  made  on  associated RSS 
access paths  (see below), 
Example  8  (Set oriented  deletion).  Delete  all  employees who work  for  depart- 
ments in  Evanston. 

CALL  SEQUEL(‘DELETE 
EMP 
WHERE  DNO  = 
SELECT  DNO 
FROM 
DEPT 
WHERE  LOC  =  ’  ‘EVANSTON’ 

’  ‘) ; 

ACM  Transactions  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

106 

* 

M.  M.  Astrahan 

et  al. 

The  SEQUEL assignment statement  allows the  result  of a query  to  be copied into 
a new permanent  or  temporary  relation  in  the  database. This  has the  same effect 
as a query  followed by  the RDI  operator KEEP. 
Example  9  (Assignment).  Create  a  new  table  UNDERPAID 
names and salaries of programmers who earn less than  $10,000. 

consisting  of 

CALL  SEQUEL(‘UNDERPAID(NAME, 
NAME,  SAL 
SELECT 
FROM 
EMP 
JOB  =  ’  ‘PROGRAMMER’ 
WHERE 
AND 
SAL  <  10,000’); 

SAL)  t 

’ 

represents a snapshot taken  from  EMP  at  the  mo- 
The  new table  UNDERPAID 
ment  the  assignment, was executed. UNDERPAID 
then  becomes an  independent 
relation  and does not  reflect any  later  changes to  EMP. 

Data  Definition 
Facilities 
Syst.em R  takes a unified  approach to  data  manipulation,  definition,  and  control. 
Like  queries and  set oriented  updates, the  data  definition  facilities  are invoked  by 
means of the  RDI  operator SEQUEL.  Many  of these facilities  have been described 
in  [4]  and  [15]. 
The  SEQUEL statement  CREATE  TABLE 
is  used  to  create  a  new  base  (i.e. 
physically  stored)  relation.  For  each field  of  the  new relation,  the  field  name and 
data  type  are specified.1 If  desired, it  may  be specified at  creation  time  that  null 
values are not  permitted  in  one or more fields of the new relation.  A  query  executed 
on  the  relation  will  deliver  its  results  in  system determined  order  (which  depends 
upon  the  access path  which  the  optimizer  has  chosen),  unless the  query  has  an 
ORDER  BY  clause. When a base relation  is no longer  useful, it  may  be deleted by 
issuing  a DROP  TABLE  statement. 
System R  currently  relies  on  the  user  to  specify  not  only  the  base tables  to  be 
stored but  also the  RSS access paths  to  be maintained  on them.  (Database design 
facilities  to  automate  and  adapt  some of  these  decisions are  also  being  investi- 
gated.)  Access paths include  images and binary  links,2 described in  Section 3. They 
may  be  specified by  means of  the  SEQUEL verbs  CREATE  and  DROP.  Briefly, 
images are value  orderings maintained  on base relations  by  the  RSS, using  multi- 
level  index  structures.  The  index  structures  associate  a  value  with  one  or  more 
Tuple  Identifiers  ( TIDs)  . A  TID 
is an  internal  address which  allows rapid  access 
to  a  tuple,  as discussed in  Section  3.  Images provide  associative  and  sequential 
access on  one or more fields which  are called the  sort jields  of  the  image. An  image 
may be declared to  be UNIQUE,  which  forces each combination  of sort  field  values 
to  be unique  in  the  relation.  At  most one image per relation  may have the cluster&g 
property,  which  causes tuples  whose sort  field  values  are  close to  be  physically 
stored near each other. 
Binary  links  are  access paths  in  the  RSS which  link  tuples  of  one relation  to 

* The  data  types  of  INTEGER,  SMALL 
INTEGER,  DECIMAL,  FLOAT,  and  CHARACTER 
(both  fixed  and  varying length)  are  supported. 
z Unary  links,  described  in  Section  3,  are  used  for  internal  system  purposes  only,  and  are  not 
exposed  at  the  RDI. 

ACM  Transactions  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

System R 

l 

107 

related  tuples  of  another  relation  through  pointer  chains.  In  System R,  binary 
links  are  always  employed  in  a  value  dependent manner:  the  user specifies that 
each tuple  of  Relation  1  is  to  be  linked  to  the  tuples  in  Relation  2  which  have 
matching  values in  some field(s)  , and  that  the  tuples  on the  link  are to  be ordered 
in  some value  dependent way.  For  example, a user may  specify a link  from  DEPT 
to  EMP  by  matching  DNO,  and that  EMP  t.uples on the  link  are to  be ordered by 
JOB  and  SAL.  This  link  is maintained  automatically  by  the  system. By  declaring 
a link  frem  DEPT  to  EMP  on matching  DNO,  the  user implicitly  declares this  to 
be a one-to-many  relationship  (i.e. DNO  is a key of DEPT)  . Any  attempts to define 
links  or  to  insert  or  update  tuples  in  violation  of this  rule  will  be refused. Like  an 
image, a link  may  be declared to  have  the  clustering  property,  which  causes each 
tuple  to be physically  stored near its neighbor in  t.he link. 
It  should  be  clearly  noted  that  none  of  the  access paths  (images and  binary 
links)  contain  any  logical  information  other  than  that  derivable  from  the  data 
values  themselves. This  is  in  accord with  the  relational  data  model, which  repre- 
sents all  information  as data values. The  RDI  user has no explicit  control  over the 
placement  of  tuples  in  images and  links  (unlike  the  ‘lmanual  sets”  of  the  DBTG 
proposal  [S])  . Furthermore,  the  RDI  user may  not  explicitly  use an image or link 
for  access to  data;  all  choices of  access path  are  made  automatically  by  the 
optimizer. 
The  query  power of  SEQUEL may  be used to  define a view  as a  relation  derived 
from  one or more other  relations.  This  view  may  then  be used in  the  same ways as 
a base table:  queries may  be written  against  it,  other  views may  be defined on  it, 
and  in  certain  circumstances described below,  it  may  be  updated.  Any  SEQUEL 
query may be used as a view  definition  by  means of a  DEFINE  VIEW  statement. 
Views are dynamic  windows  on the  database, in  that  updates made to  base tables 
immediately  become visible  via  the  views  defined on  these base tables. Where up- 
dates  to  views  are  supported,  they  are  implemented  in  terms  of  updates  to  the 
underlying  ba.se tables. The  SEQUEL statement which  defines a view  is  recorded in 
a system maintained  catalog where it  may be examined by  authorized  users. When 
an  authorized  user  issues a  DROP  VIEW  statement,  the  indicated  view  and  all 
other  views  defined in  terms  of  it  disappear from  the  system for  this  user and  all 
other users. 
If  a modification  is  issued against  a view,  it  can be supported  only  if  the  tuples 
of  the  view  are associated one-to-one with  tuples  of  an  underlying  base relation. 
In  general, this  means that  the view must  involve  a single base relation  and contain 
a key  of that  relation;  otherwise, the modification  statement is rejected. If  the  view 
satisfies the  one-to-one rule,  the WHERE  clause of the  SEQUEL modification  state- 
ment  is merged into  the  view  definition;  the  result  is  optimized  and  the  indicated 
update  is made on t,he relevant  tuples of the base relation. 
Two  final  SEQUEL  commands complete  the  discussion  of  the  data  definition 
facility.  The  first  is  KEEP  TABLE,  which  causes a temporary  table  (created, for 
example, by  assignment)  to  become permanent.  (Temporary  tables are destroyed 
when  the  user  who  created  them  logs  off.)  The  second command  is  EXPAND 
TABLE,  which  adds a new field  to  an  existing  table.  All  views,  images, and  links 
defined  on  the  original  table  are  retained.  All  existing  tuples  are  interpreted  as 
having  null  values in  the  expanded fields until  they  are explicitly  updated. 
ACM  Transactions  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

108 

l 

M.  M.  Astrahan 

et  al. 

Data  Control  Facilities 
Data  control  facilities  at  the  RDI  have  four  aspects: transactions,  authorization, 
integrity  assertions, and  triggers. 
A  transaction  is a series of RDI  calls which  the  user wishes to  be processed as an 
atomic  act,  The  meaning of  “atomic”  depends on the  level  of consistency specified 
by  the  user, and is explained  in  Section 3. The highest  level  of consistency, Level  3, 
requires  that  a user’s transactions  appear to  be serialized with  the  transactions  of 
other  concurrent  users.  The  user  controls  transactions  by  the  RDI  operators 
BEGIN 
TRANS  and  END-TRANS. 
The  user may  specify  save points  within 
a  transaction  by  the  RDI  operator  SAVE.  As  long  as a  transaction  is  active,  the 
user may  back up  to  the  beginning  of the  transaction  or  to  any  internal  save point 
by  the  operator  RESTORE.  This  operator  restores all  changes made to  the  data- 
base by  the  current  transaction,  as well  as the  state  of  all  cursors  used  by  this 
transaction.  No  cursors may remain  active  (open)  beyond the  end of a transaction. 
The  RDI  transactions  are implemented  directly  by  RSI  transactions,  so the  RDI 
commands BEGIN-TRANS, 
END-TRANS,  SAVE,  and RESTORE  are passed 
through  to  the  RSI,  with  some RDS  bookkeeping  to  permit  the  restoration  of  its 
internal  state. 
The  System R  approach  to  authorization  is  described in  [15].  System R  does 
not  require  a  particular  individual 
to  be  the  database administrator,  but  allows 
each user  to  create  his  own  data  objects  by  executing  the  SEQUEL  statements 
CREATE  TABLE  and DEFINE  VIEW.  The  creator  of a new object  receives full 
authorization 
to  perform  all  operations  on  the  object  (subject,  of  course, to  his 
authorization  for  the  underlying  tables,  if  it  is  a view).  The  user may  then  grant 
selected capabilities  for his object to other  users by  the SEQUEL  statement GRANT. 
The  following  capabilities  may  be  independently  granted  for  each table  or  view: 
READ,  INSERT,  DELETE,  UPDATE  (by  fields),  DROP,  EXPAND, 
IMAGE 
specification, LINK  specification, and CONTROL  (the  ability  to  specify assertions 
and triggers  on the  table  or view).  For  each capability  which  a user possesses for  a 
given  table,  he may  optionally  have  GRANT  authority 
(the  authority 
to  further 
grant  or  revoke the  capability  to/from  other  users). 
System R  relies primarily  on  its  view  mechanism for  read authorization,  If  it  is 
desired to  allow  a user to  read only  tuples  of employees in  Dept.  50, and not  to  see 
their  salaries,  then  this  portion  of  the  EMP  table  can  be  defined  as a view  and 
granted  to  the  user. No  special statistical  access is  distinguished,  since the  same 
effect  (e.g.  ability 
to  read  only  the  average salary  of  each department)  can  be 
achieved by  defining  a view.  To  make the  view  mechanism more useful for  authori- 
zation  purposes, the  reserved word USER  is always interpreted  as the  user-id  of the 
current  user. Thus  the  following  SEQUEL  statement  defines a view  of  all  those em- 
ployees in  the  same department  as the  current  user: 

D ZFINE 

VIEW  VEMP  AS: 
* 
SELECT 
EMP 
FROM 
DNO  = 
WHERE 
SELECT 
FROM 
WHERE 

DNO 
EMP 
NAME 

=  USER 

ACM  Transactions  on  Database  System,  Vol.  1,  No.  2,  June  1976. 

System  R 

l 

109 

The  third  important  aspect of  data  control  is  that  of  integrhy  assertions. The 
System R  approach  to  data  integrity  is  described in  [lo].  Any  SEQUEL  predicate 
may  be stated  as an  assertion about  the  integrity  of  data  in  a base table  or  view. 
At  the  time  the  assertion is made (by  an ASSERT  st.atement in  SEQUEL), 
its  truth 
is  checked;  if  true,  the  assertion  is  automatically  enforced until 
it  is  explicitly 
dropped  by  a  DROP  ASSERTION  statement.  Any  data  modification,  by  any 
user, which  violates  an active  integrity  assertion is  rejected. Assertions may  apply 
to  individual 
tuples  (e.g.  “NO  employee’s salary  exceeds $50,000”)  or  to  sets of 
tuples  (e.g. ‘(The  average salary  of each department  is less than  $20,000”).  Asser- 
tions  may  describe permissible states of the  database (as in  the  examples above)  or 
permissible  transitions  in  the  database. For  this  latter  purpose the  keywords  OLD 
and NEW  are used in  SEQUEL 
to  denote data values before and after modification, 
as in  the  example below. 
Example  10  (Transition  assertion),  Each  employee’s  salary  must  be  non- 
decreasing. 

ASSERT  ON  UPDATE 

TO  EMP:  NEW  SAL  2  OLD  SAL 

Unless otherwise  specified, integrity  assertions are checked and  enforced at  the 
end of  each transaction.  Transition  assertions compare the  state before the  trans- 
action  began with  the  state  after  the  transaction  concluded.  If  some assertion is 
not  satisfied,  the  transaction  is  backed  out  to  its  beginning  point.  This  permits 
complex updates to  be done in  several steps (several calls to  SEQUEL,  bracketed 
by  BEGIN 
TRANS  and  END  TRANS),  which  may  cause the  database to 
pass throughintermediate  states which  temporarily  violate  one or more assertions. 
However,  if  an  assertion  is  specified as IMMEDIATE, 
it  cannot  be  suspended 
within  a transaction,  but  is enforced after  each data modification  (each RDI  call). 
In  addition,  “integrity  points”  within  a  transaction  may  be  established  by  the 
SEQUEL  command  ENFORCE 
This  command  allows  a  user  to 
INTEGRITY. 
guard  against  having  a  long  transaction  completely  backed  out.  In  the  event  of 
an  integrity 
failure,  the  transaction  is  backed  out  to  its  most  recent  integrity 
point. 
The  fourth  aspect of  data  control,  triggers,  is a generalization  of  the  concept of 
assertions. A  trigger  causes a  prespecified sequence of  SEQUEL  statements  to  be 
executed  whenever  some triggering  event  occurs.  The  triggering  event  may  be 
retrieval,  insertion,  deletion,  or  update  of  a particular  base table  or  view.  For  ex- 
ample, suppose that  in  our  example database, the NEMPS  field  of the DEPT  table 
denotes the  number  of employees in  each department.  This  value might  be kept  up 
to date automatically  by  the following  three triggers  (as in  assertions, the keywords 
OLD  and NEW  denote data  values before and after  the  change which  invoked  the 
trigger)  : 

DEFINE 

EMPINS 
TRIGGER 
OF  EMP: 
ON  INSERTION 
(UPDATE 
DEPT 
NEMPS 
SET 
+  1 
=  NEMPS 
DNO  =  NEW  EMP.DNO) 
WHERE 

ACM  Transaction8 on Database Systems, Vol.  1, No.  2, June 1976. 

110 

’ 

M.  M.  Astrahan  et  al. 

DEFINE 

EMPDEL 
TRIGGER 
OF  EMP: 
ON  DELETION 
DEPT 
(UPDATE 
-  1 
=  NEMPS 
NEMPS 
SET 
DNO  =  OLD  EMP.DNO) 
WHERE 

DEFINE 

TRIGGER 
EMPUPD 
ON  UPDATE  OF  EMP: 
DEPT 
(UPDATE 
NEMPS 
=  NEMPS 
-  1 
SET 
DNO  =  OLD  EMP.DNO; 
WHERE 

UPDATE 
SET 
WHERE 

DEPT 
NEMPS 
+  1 
=  NEMPS 
DNO  =  NEW  EMP.DNO) 

The  RDS  automatically  maintains  a set of  catalog  relations  which  describe the 
other  relations,  views, images, links,  assertions, and  triggers  known  to  the  system. 
Each user may  access a set of views of the  system catalogs which  contain  informa- 
tion  pertinent  to  him.  Access to  catalog relations  is made in  exactly  the  same way 
as other  relations  are accessed (i.e. by  SEQUEL  queries).  Of course, no user is author- 
ized  to  modify  the  contents  of  a  catalog  directly,  but  any  authorized  user  may 
modify  a catalog  indirectly  by  actions such as creating  a  table.  In  addition,  a user 
may  enter  comments into  his various  catalog entries by  means of the  COMMENT 
statement  (see syntax  in  Appendix  II). 

The  Optimizer 

The  objective  of  the  optimizer  is  to  find  a low  cost means of  executing  a  SEQUEL 
statement,  given  the  data  structures  and  access paths  available.  The  optimizer 
attempts  to  minimize  the  expected number  of  pages to  be fetched  from  secondary 
storage into  the  RSS buffers  during  execution  of the  statement.  Only  page fetches 
made under  the  explicit  control  of  the  RSS are considered. If  necessary, the  RSS 
buffers  will  be pinned  in  real  memory  to  avoid  additional  paging  activity  caused 
by  the  VM/370  operating  system. The  cost of  CPU  instructions  is  also taken  into 
account  by  means of an adjustable  coefficient, H,  which  is multiplied  by  the  num- 
ber  of  tuple  comparison operations  to  convert  to  equivalent  page accesses. H  can 
be  adjusted  according  to  whether  the  system  is  compute-bound  or  disk  access- 
bound. 
Since  our  cost  measure for  the  optimizer  is  based on  disk  page  accesses, the 
physical  clustering  of  tuples  in  the  database is of  great  importance.  As mentioned 
earlier,  each relation  may  have  at  most  one clustering  image, which  has the  prop- 
erty  that  tuples  near  each other  in  the  image ordering  are stored  physically  near 
each other  in  the  database. To  see the  importance  of the  clustering  property,  imag- 
ine that  we wish to  scan over the  tuples  of a relation  in  the order of some image, and 
that  the  number  of RSS buffer  pages is much less than  the number  of pages used to 
store the relation.  If  the image is not  the clustering  image, the locations  of the  tuples 
will  be  independent  of  each other  and  in  general  a  page will  have  to  be  fetched 
from  disk  for  each tuple.  On  the  other  hand,  if  the  image is  the  clustering  image, 
each disk  page will  contain  several  (usually  at  least  20)  adjacent  tuples,  and  the 
number  of page fetches will  be reduced by  a corresponding factor. 
on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 
ACM  Tramactions 

System  R 

l 

111 

The  optimizer  begins  by  classifying  the  given  SEQUEL statement  into  one  of 
several statement types, according to  the presence of various  language features such 
as join  and  GROUP  BY.  Next  the  optimizer  examines the  system catalogs to  find 
the  set of  images and  links  which  are pertinent  to  the  given  statement.  A  rough 
decision  procedure  is  then  executed  to  find  the  set  of  “reasonable”  methods  of 
executing  the  statement.  If  there  is  more  than  one  “reasonable”  method,  an  ex- 
pected cost formula  is evaluated  for  each method and the minimum-cost  method is 
chosen. The  parameters of the  cost formulas, such as relation  cardinality  and num- 
ber of tuples per page, are obtained  from  the  system catalogs. 
We illustrate  this  optimization  process by  means of  two  example  queries. The 
first  example involves  selection of tuples  from  a single relation,  and  the  second in- 
volves  joining  two  relations  together  according to  a matching  field.  For  simplicity 
we consider only  methods based on images and  relation  scans. (A  relation  scan in 
the  RSS accesses each of  the  pages in  a data  segment in  turn  (see Section 3))  and 
selects those tuples belonging to  the given  relation.)  Consideration  of links  involves 
a straightforward  extension of the  techniques we will  describe. 
Example  11 will  be used to  describe the  decision process for  a query  involving  a 
single relation: 
Example  11.  List  the  names and  salaries of programmers who  earn more than 
$10,000. 

SELECT  NAME,  SAL 
EMP 
FROM 
JOB  = 
WHERE 
‘PROGRAMMER’ 
AND 
SAL  >  10,000 

In  planning  the  execution  of  this  example, the  optimizer  must  choose whether 
to  access the  EMP  relation  via  an image  (on  JOB, SAL  or some other  field)  or via 
a  relation  scan. The  following  parameters,  available  in  the  system  catalogs,  are 
taken  into  account: 
R 
relation  cardinality  (number  of tuples in  the relation) 
D  number  of data  pages occupied by  the  relation 
T  average number  of tuples  per data  page  (equal  to  R/D) 
image cardinality  (number  of distinct  sort  field  values in  a given  image) 
I 
H  coefficient  of  CPU  cost  (l/H 
is  the  number  of  tuple  comparisons which  are 
considered equivalent  in  cost to  one disk  page access). 
An  image is said to  “match”  a predicate  if  the  sort  field  of  the  image is the  field 
which  is  tested  by  the  predicate.  For  example,  an  image  on  the  EMP  relation 
ordered by  JOB  (which  we will  refer to  as an  “image  on EMP.JOB”)  would match 
the  predicate JOB  =  ‘PROGRAMMER’ 
in  Example  11.  In  order  for  an  image 
to  match  a predicate,  the  predicate must  be a simple comparison of  a field  with  a 
value.  More  complicated  predicates,  such as EMP.DNO  =  DEPT.DNO,  cannot 
be matched by  an image. 
In  the  case of a simple  query  on a single relation,  such as Example  11, the  opti- 
mizer  compares the  available  images with  the  predicates of  the  query,  in  order  to 
determine which  of the  following  eight methods are available: 
Method  1:  Use a clustering  image which  matches a predicate whose comparison- 
ACM  Traneactione  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

112 

l 

M.  M.  Astrahan 

et  al. 

operator  is  ’ = ’  . The  expected cost to  retrieve  all  result  tuples  is  R/  (T  X  I)  page 
accesses (R/I 
tuples  divided  by  T  tuples per page). 
Method  2:  Use a clustering  image which  matches a predicate whose comparison 
operator  is not  ’ =  ’  . Assuming half  the  tuples  in  the  relation  satisfy  the  predicate, 
the  expected cost is R/  (2  X  T)  . 
Method  3:  Use a  nonclustering  image which  matches a  predicate  whose com- 
parison  operator  is  ’ = ’  . Since each tuple  requires  a page access, the  expect.ed cost 
is R/I. 
Method  4:  Use a  nonclustering  image which  matches  a  predicate  whose com- 
parison-operator  is not  ’ = ’  . Expected cost to  retrieve  all  result  tuples  is R/2. 
Method  5:  Use a  clustering  image which  does not  match  any  predicate.  Scan 
the  image and  test  each tuple  against  all  predicates.  Expected  cost  is  (R/T) 
+ 
H  X  R  X  N,  where N  is the number  of predicates in  the  query. 
Method  6:  Use a nonclustering  image which  does not  match  any  predicate.  Ex- 
pected cost is R  +  H  X  R  X  N. 
Method  7:  Use a relation  scan where this  relation  is the  only  one in  its  segment. 
Test  each tuple  against all  predicates. Expected cost is  (R/T)  +  H  X  R  X  N. 
Method  8:  Use a relation  scan where  there  are other  relations  sharing  the  seg- 
ment.  Cost  is  unknown,  but  greater  than  (R/T)  +  H  X  R  X  N,  because some 
pages may be fetched which  contain  no tuples  from  the  pertinent  relation. 
The  optimizer  chooses a method  from  this  set according  to  the  following  rules: 
1.  If  Method  1 is available,  it  is chosen. 
2.  If  exactly  one among Methods  2, 3, 5, and  7 is available,  it  is  chosen. If  more 
than  one  method  is  available  in  this  class, the  expected cost  formulas  for  these 
methods are evaluated  and the method  of minimum  cost is chosen. 
3.  If  none of the  above methods are available,  the  optimizer  chooses Method  4, 
if  available;  else Method  6,  if  available;  else Method  8.  (Note:  Either  Method  7 
or Method  8 is always available  for  any  relation.) 
As  a  second example  of  optimization,  we  consider  the  following  query,  which 
involves  a join  of  two  relations: 
Example  12.  List  the  names, salaries, and  department  names of  programmers 
located in  Evanston. 

SELECT  NAME,  SAL,  DNAME 
EMP,  DEPT 
FROM 
EMP.JOB 
WHERE 
= 
AND 
DEPT.LOC 
AND 
EMP.DNO 

‘PROGRAMMER’ 
= 
‘EVANSTON’ 
=  DEPT.DNO 

Example  12 is  an  instance  of  a  join  query  type,  the  most  general  form  of  which 
involves  restriction,  projection,  and join,  The  general query  has the  form: 
Apply  a given  restriction  to  a  relation  R,  yielding  Rl,  and  apply  a pos- 
sibly  different  restriction  to  a  relation  S, yielding  Sl.  Join  Rl  and  Sl  to 
form  a relation  T,  and project  some fields from  T. 

To  illustrate  the  optimization  of join-type  queries, we will  consider four  possible 
methods for  evaluating  Example  12 : 
Method  1  (use images on join  fields)  :  Perform  a simultaneous  scan of the  image 
ACM  Transactions  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

System R 

. 

113 

and  the  image  on  EMP.DNO.  Advance  the  DEPT  scan  to  obtain 
on  DEPT.DNO 
the  next  DEPT  where  LOC  is  ‘EVANSTON’ 
.  Advance  the  EMP  scan  and  fetch 
tuples  whose  DNO  matches  the  current  DEPT  and  whose  JOB  is 
all  the  EMP 
tuples,  place 
.  For  each  such  matching  pair  of  DEPT,  EMP 
‘PROGRAMMER’ 
the  NAME,  SAL,  and  DNAME 
fields  into 
the  output.  Repeat  until 
the  image 
scans are  completed. 
Method  2  (sort  both  relations) 
:  Scan  EMP  and  DEPT  using  their  respective 
images  and  create  two  files  Wl  and  W2.  Wl  contains  the  NAME,  SAL, 
clustering 
and  DNO  fields  of  tuples  from  EMP  which  have  JOB  =  ‘PROGRAMMER’ 
. W2 
fields  of  tuples  from  DEPT  whose  location  is 
the  DNO  and  DNAME 
contains 
‘EVANSTON’ 
.  Sort  Wl  and  W2  on  DNO. 
(This  process  may  involve 
repeated 
passes  over  Wl  and  W2  if  they  are  too  large  to  fit  the  available  main  memory 
buffers.)  The  resulting  sorted  files  are  scanned  simultaneously 
is 
and  the  join 
performed. 
Method  3  (multiple  passes) :  DEPT 
image,  and  the 
is  scanned  via  its  clustering 
tuples  which  have  LOC  = 
fields  (a  subtuple)  of  those  DEPT 
DNO  and  DNAME 
are  inserted  into  a main  memory  data  structure  called  W.  If  space 
‘EVANSTON’ 
in  main  memory  is  available 
to  insert  a  subtuple 
(say  S) ,  it  is  inserted.  If  there  is 
no  space and  if  S.DNO  is  less than  the  current  highest  DNO  value  in  W,  the  sub- 
tuple  with  the  highest  DNO  in  W   is  deleted  and  S inserted.  If  there  is  no  room  for 
S and  the  DNO  in  S  is  greater  than  the  highest  DNO  in  W,  S  is  discarded.  After 
is  scanned  via  its  clustering 
the  scan  of  DEPT,  EMP 
completing 
image  and  a 
is  obtained.  If  E.JOB  =  ‘PROGRAMMER’ 
tuple  E  of  EMP 
,  then  W   is  checked 
for  the  presence  of  the  E.DNO. 
If  present,  E  is  joined  to  the  appropriate  subtuple 
in  W.  This  process  is  continued  until  all  tuples  of  EMP  have  been  examined. 
If 
any  DEPT  subtuples  were  discarded,  another  scan  of  DEPT 
is made  to  form  a new 
W   consisting  of  subtuples  with  DNO  value  greater  than  the  current  highest.  EMP 
is  scanned  again  and  the  process repeated. 
:  Using  the  image  on  EMP.JOB,  obtain  the  TIDs  of 
Method  4  (TID  algorithm) 
tuples  from  EMP  which  satisfy 
the  restriction  JOB  =  ‘PROGRAMMER’ 
.  Sort 
them  and  store  the  TIDs  in  a file  Wl.  Do  the  same with  DEPT,  using  the  image  on 
DEPT.LOC 
and  testing  for  LOC  =  ‘EVANSTON’ 
,  yielding  a  TID 
file  W2.  Per- 
finding 
form  a simultaneous  scan  over  the  images  on  DEPT.DNO 
and  EMP.DNO, 
the  TID  pairs  of  tuples  whose  DNO  values  match.  Check  each pair  (TIDl, 
TID2) 
is  in  W2.  If  they  are,  the  tuples  are 
to  see if  TIDl 
is  present  in  Wl  and  TID2 
fetched  and  joined  and  the  NAME,  SAL,  and  DNAME 
fields  placed  into 
the 
output. 
These  methods  should  be  considered  as  illustrative 
of  the  techniques  considered 
by  the  optimizer.  The  optimizer  will  draw  from  a  larger  set  of  methods,  including 
methods  which  use  links  to  carry  out  the  join. 
A  method  cannot  be  applied  unless  the  appropriate  access paths  are  available. 
For  example,  Method  4  is  applicable  only  if  there  are  images  on  EMP.DNO 
and 
EMP.JOB,  as  well  as  on  DEPT.DNO 
and  DEPT.LOC. 
In  addition, 
the  perfor- 
mance  of  a method  depends  strongly  on  the  clustering  of  the  relations  with  respect 
to  the  access paths.  We  will  consider  how  the  optimizer  would  choose among  these 
four  methods  in  four  hypothetical 
situations.  These  choices  are  made  on  the  basis 
of  cost  formulas  which  will  be detailed  in  a later  paper. 

ACM  Transactions  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

114 

- 

M.  M.  Astrahan 

et  al. 

Situation  1:  There  are clustering  images on both  EMP.DNO  and DEPT.DNO, 
but  no  images on EMP.JOB  or DEPT.LOC.  In  this  situation,  Method  1 is always 
chosen. 
Situation  2:  There  are unclustered  images on EMP.DNO  and DEPT.DNO,  but 
no  images on  EMP.JOB  or  DEPT.LOC. 
In  this  case, Method  3  is  chosen if  the 
entire  working  file W  fits into  the main memory buffer  at  once; otherwise Method  2 
is  chosen. It  is  interesting  to  note  that  the  unclustered  images on DNO  are never 
used in  this  situation. 
Situation  3  :There  are clustering  images on  EMP.DNO  and  DEPT.DNO,  and 
unclustered  images on  EMP.JOB  and  DEPT.LOC.  In  this  situation,  Method  4 is 
always chosen. 
Situation  4:  There  are  unclustered 
images  on  EMP.DNO,  EMP.JOB, 
DEPT.DNO,  and  DEPT.LOC.  In  this  situation,  Method  3  is  chosen if  the  entire 
working  file  W   fits  into  the  main  memory  buffer.  Otherwise,  Method  2  is  chosen 
if  more than  one tuple  per disk page is expected to  satisfy  the  restriction  predicates. 
In  the remaining  cases, where the restriction  predicates are very  selective, Method  4 
should be used. 

After  analyzing  any  SEQUEL  statement,  the  optimizer  produces  an  Optimized 
Package  (OP)  containing  the  parse tree  and  a  plan  for  executing  the  statement. 
If  the  statement  is a query,  the  OP is used to  materialize  tuples  as they  are called 
for  by  the  FETCH  command  (query  results  are materialized  incrementally  when- 
ever possible).  If  the  statement  is  a  view  definition,  the  OP is  stored  in  the  form 
of a Pre-Optimized  Package (POP)  which  can be fetched and utilized  whenever an 
access is made via  the  specified view.  If  any  change is made to  the  structure  of  a 
base table  or  to  the  access paths  (images and  links)  maintained  on it,  the  POPS of 
all  views defined on that  base table  are invalidated,  and each view  must  be reopti- 
mized from  its  defining  SEQUEL  code to  form  a new POP. 
When  a view  is  accessed via  the  RDI  operators  OPEN  and  FETCH,  the  POP 
for  the  view  can be used directly  to  materialize  the  tuples  of the  view.  Often,  how- 
ever, a query  or another view  definition  will  be written  in  terms of an existing  view. 
If  the  query  or  view  definition  is  simple  (e.g. a  projection  or  restriction), 
it  can 
sometimes be composed with  the  existing  view  (i.e.  their  parse trees can be merged 
and  optimized  together  to  form  a  new  OP  for  the  new  query  or  view).  In  more 
complex cases the  new statement  cannot be composed with  the  existing  view  defini- 
tion.  In  these cases the  POP for  the  existing  view  is  treated  as a formula  for  ma- 
terializing 
tuples.  A  new  OP  is  formed  for  the  new  statement  which  treats  the 
existing  view  as a table  from which  tuples  can be fetched in  only  one way:  by  inter- 
preting  the  existing  POP. Of course, if  views are cascaded on other  views in  several 
levels, there may be several levels of POPS in  existence, each level making  reference 
to  the  next. 

Modifying 

Cursors 

A  number  of  issues are  raised  by  the  use of  the  insertion,  deletion,  and  update 
facilities  of  System R.  When  a modification  is  made  to  one  of  the  tuples  in  the 
active  set of a cursor, the modification  may  change the  ordinal  position  of the  tuple 
or  even  disqualify  it  entirely  from  the  active  set.  It  should  be noted  here  that  a 
ACM Transactions  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

System  R 

- 

115 

user operating  at  Level  3 consistency is automatically  protected  against, having  his 
cursors affected by  the modifications  of other  users. However,  even in  Level  3 con- 
sistency, a user may make a modification  which  affects one of his own active cursors. 
If  the  cursor in  question is open on a base relation,  the  case is simple: t,he modifi- 
cation  is  done and  immediately  becomes visible  via  the  cursor.  Let, us consider a 
case in  which  the  cursor  is  not, on  a  base relation,  but, rather  on  the  result, of  a 
SEQUEL query.  Suppose the  following  query  has been executed: 

SELECT  * 
FROM  EMP 
WHERE  DNO  =50 
ORDERBYSAL 

If  the system has no image ordered on SAL, it  may execute this  query  by  finding 
the  employees where DNO  =  50 and  sorting  them  by  SAL  to  create an  ordered 
list, of  answer tuples.  Along  with  this  list,  the  system will  keep a  list  of  the  base 
relations  from  which  the  list, was derived  (in  this  case, only  EMP).  The  effect re- 
sembles that  of performing  a DBTG  KEEP  verb  [6]  on the  underlying  base rela- 
tions:  if  any  tuple  in  an  underlying  relation  is modified,  the  answer list  is marked 
“potentially 
invalid.”  Now any  fetch from  this  list  will  return  a warning  code since 
the  tuple  returned  may not, be up  to date. If  the calling  program wishes to guarantee 
accuracy of its  results,  it  must  close its  cursor and  reevaluate  the  query  when  this 
warning  code is received. 

Data  Models 
of  Nonrelational 
Simulation 
The  RDI  is  designed in  such a way  that, programs  can  be written  on  top  of  it  to 
simulate  “navigation  oriented”  database  interfaces.  These  interfaces  are  often 
characterized  by  collections  of  records connected in  a  hierarchic  [17]  or  network 
[6]  structure,  and by  the  concept of  establishing  one or more  “current  positions” 
within  the  structure  (e.g. the  currency  indicators  of DBTG)  . In  general our  strat- 
egy will  be to  represent each record type  as a relation  and to  represent information 
about  ordering  and connections between records in  the  form  of explicit  fields in  the 
corresponding relations.  In  this  way  all  information  inserted  into  the  database via 
the  “navigational” 
interface  (including  information  about  orderings  and  connec- 
tions)  is available  to other users who may be using the underlying  relations  directly. 
One or  more  “current  positions”  within  the  database may  then  be  simulated  by 
means of one or more RDI  cursors. 
We will  illustrate  this  simulation  process by  means of  an  example. Suppose we 
wish  to  simulate  the  database structure  8hown in  Figure  3, and wish  to  maintain 
a  “current  position”  in  the  structure.  The  hierarchical  connections from  DEPT  to 

FIG. 3.  Example of a hierarchic data structure 
ACM  Transactions  on  Database  System,  Vol.  1,  No.  2,  June  1976. 

116 

l 

M.  M.  Astrahan  et al. 

EMP  and from  DEPT  to  EQUIP  may  be unnamed in  a hierarchic  system such as 
IMS  [17],  or  they  may  represent  named set types  in  a  network  oriented  system 
such as DBTG  [S]. 
At  database definition  time,  a  relation  is  created to  simulate  each record  type. 
The  DEPT  relation  must  have  a sequence-number field  to  represent the  ordering 
of the  DEPT  records. The  EMP  and  EQUIP  relations  must  have,  in  addition  to  a 
sequence-number field, one or more fields which  uniquely  identify  their  “parent”  or 
“owner”  records  (let  us assume the key  of DEPT  is DNO)  . If  a record had several 
“owners”  in  different  set types,  several “owner’s  key”  fields would  have to  appear 
in  the corresponding relation. 
Also  at  database definition  time,  a  view  definition  is  entered  into  the  system 
which  will  represent the  “currently  visible”  tuples  of  each relation  at  any  point  in 
time.  The  view  definitions  for  our example are given below: 

DEFINE 

VIEW  VDEPT  AS 
SELECT 
* 
DEPT 
FROM 
(sequence field) 
ORDER  BY 

DEFINE 

DEFINE 

VIEW  VEMP  AS 
* 
SELECT 
FROM 
EMP 
DNO  =  DNO  OF  CURSOR  Cl  ON  DEPT 
WHERE 
(sequence field) 
ORDER  BY 
VIEW  VEQUIP  AS 
SELECT 
* 
EQUIP 
FROM 
DNO  =  DNO  OF  CURSOR  Cl  ON  DEPT 
WHERE 
(sequence field) 
ORDER  BY 

The  definitions  of  VEMP  and  VEQUIP  call  for  tuples  of  EMP  and  EQUIP 
which  have the same DNO  as cursor Cl;  furthermore  they  promise that,  when these 
views are used, cursor Cl  will  be active  on  the  DEPT  relation.  These view  defini- 
tions are parsed and optimized,  and stored in  the form  of POPS. During  this  optimi- 
zation  process, any  direct  physical  support  for  the  hierarchy  (such as a link  from 
DEPT  to  EMP  by  matching  DNO)  will  be discovered. 
At  run  time,  when  a position  is  to  be established on a DEPT  record,  the  cursor 
Cl  is opened on the  view  VDEPT.  If  the  “current  position”  then  moves downward 
to  an  EMP  record,  the  view  VEMP  is  opened. The  exact  subset of  EMP  tuples 
made available  by  this  view  opening  depends on  the  location  of  the  cursor  Cl  in 
the  “parent”  relation.  If  the  “current  position”  moves upward  again to  DEPT,  the 
view  VEMP  is  closed, to  be  reopened later  as needed. Any  insertion,  deletion,  or 
update operations  issued against  the  hierarchy  are simulated by  SEQUEL 
INSERT, 
DELETE,  and  UPDATE  operations  on  the  corresponding  relations,  with  appro- 
priate  sequence-number and  parent-key  values  generated,  if  necessary, by  the 
simulator  program. At  the  end of the  transaction,  all  cursors are closed. 
Following  this  general  plan,  it  is  expected that  hierarchic  oriented  or  network 
oriented  interfaces  can be simulated  on  top  of  the  RDI.  It  should  be particularly 
noted that  no parsing or optimization  is done in  response to a command to move the 
“current  position”; 
the  system merely  employs  the  POP  for  the  view  which  was 
ACM  Transactions  on  Database  Systems,  Vol.  1.  No.  2.  June  1976, 

System  R 

l 

117 

time.  For  any  connections  which  are  given  direct 
optimized  at  database  definition 
physical  support  in  the  form  of  a binary 
link,  the  optimizer  will  take  advantage  of 
the  link 
to  provide  good  performance.  The  system  is  also  capable  of  simulating 
connections  which  have  no  direct  physical  support,  since  the  optimizer  will  auto- 
matically 
find  an  appropriate  access path. 

3.  THE  RELATIONAL  STORAGE  SYSTEM 

This  sect,ion  is  concerned  with  the  Relational  Storage  System  or  RSS,  the  database 
for  System  R.  The 
management,  subsystem  which  provides  underlying 
support 
RSS  supports 
the  RSI  which  provides  simple,  tuple-at-a-time 
operators  on  base 
relations.  Operators  are  also  supported  for  data  recovery,  transaction  management, 
and  data  definition. 
III.) 
(A  list  of  all  RSI  operators  can  be  found  in  Appendix 
Calls  to  the  RSI  require  explicit  use of  data  areas called  segments  and  access paths 
called  images  and  links,  along  with 
the  use  of  RSS-generated,  numeric 
identifiers 
for  data  segments,  relations,  access paths,  and  tuples.  The  RDS  handles  the  selec- 
tion  of  efficient  access paths  to  optimize  its  operations,  and  maps  symbolic  relation 
names  to  their  internal  RSS  identifiers. 
In  order  to  facilitate  gradual  database  integration  and  retuning  of  access paths, 
the  RX1  has  been  designed  so  that  new  stored  relations  or  new  indexes  can  be 
created  at  any  time,  or  existing  ones  destroyed,  without  quiescing  the  system  and 
without  dumping  and  reloading 
the  data.  One  can  also  add  new  fields  to  existing 
relations,  or  add  or  delete  pointer  chain  paths  across existing  relations.  This  facility, 
coupled  with  the  ability 
to  retrieve  any  subset. of  fields  in  a  tuple,  provides  a degree 
of  data  independence  at  a  low  level  of  the  system,  since  existing  programs  which 
execute  RSI  operations  on  tuples  will  be  unaffected  by  the  addition  of  new  fields. 
the  RSS  has  many  functions  whidh  can  be  found  in 
As  a  point  of  comparison, 
other  systems,  both  relational  and  nonrelational, 
such  as  the  use  of  index  and 
pointer  chain  structures.  The  areas  which  have  been  emphasized  and  extended  in 
the  RSS  include  dynamic  definition  of  new  data  types  and  access paths,  as described 
above,  dynamic  binding  and  unbinding  of  disk  space to  data  segments,  multipoint 
recovery 
for  in-process  transactions,  a  novel  and  efficient 
technique 
for  system 
checkpoint  and  restart,  multiple 
levels  of  isolation 
from  the  actions  of  other  con- 
current  users,  and  automatic 
locking  at  the  level  of  segments,  relations,  and  single 
tuples.  The  next  several  subsections  describe  all  of  these  RSS  functions  and  include 
a sketch  of  the  implementation. 

Segments 
In  the  RSS,  all  data  is  stored  in  a  collection  of  logical  address  spaces  called  seg- 
ments,  which  are  employed  to  control  physical  clustering.  Segments  are  used  for 
storing  user  data,  access path  structures, 
internal  catalog  information,  and  inter- 
mediate  results  generated  by  the  RDS.  All  the  tuples  of  any  relation  must  reside 
within  a  single  segment  chosen  by  the  RDS.  However,  a  given  segment  may  con- 
tain  several  relations.  A  special  segment  is  dedicated  to  the  storage  of  transaction 
logs  for  backing  out  the  changes  made  by  individual 
transactions. 
Several  types  of  segments  are  supported,  each  with  its  own  combination  of  func- 
tions  and  overhead.  For  example,  one  type  is  intended 
for  storage  of  shared  data, 

ACM  Transactions  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

118 

. 

M.  M.  Astrahan  et  al. 

and has provisions  for  concurrent  access, transaction  backout,  and recovery  of the 
segment’s contents  to  a previous  state.  Another  segment type  is  intended  for  low 
overhead storage of temporary  relations,  and has no provision  for  either  concurrent 
access or  segment recovery.  A  maximum  length  is  associated with  each segment; 
it  is chosen by  a user during  initialization  of the system. 
The  RSS has the  responsibility  for  mapping  logical  segment spaces to  physical 
extents on disk storage, and for  supporting  segment recovery. Within  the RSS, each 
segment consists of  a sequence of  equal-sized pages, which  are referenced and  for- 
matted  by  various  components of  the  RSS. Physical  page slots in  the  disk  extents 
are allocated to segments dynamically  upon first  reference, by  checking and modify- 
ing  bit  maps associated with  the  disk  extents.  Physical  page slots  are  freed when 
access path  structures  are  destroyed  or  when  the  contents  of  a  segment are  de 
stroyed.  This  dynamic  allocation  scheme allows  for  the  definition  of  many  large 
sized segments, to  accommodate large intermediate  results  and growing  databases. 
Facilities  are  provided  to  cluster  pages on  physical  media  so  that  sequential  or 
localized access to  segments can be handled  efficiently. 
The  RSS maintains  a  page map  for  each segment, which  is  used to  map  each 
segment page to  its  location  on  disk.  Such a map  is maintained  as a collection  of 
equal-sized blocks, which  are allocated statically.  A  page request is handled by  allo- 
cating  space within  a main  memory  buffer  shared among all  concurrent  users. In 
fact  two  separate buffers  are managed, one for  the  page map  blocks  and  one  for 
the  segment pages themselves. Both  pages and blocks are fixed  in  their  buffer  slots 
until  they  are explicitly  freed by  RSS components. Freeing  a page makes it  avail- 
able for  replacement, and when space is needed the  buffer  manager replaces which- 
ever freed page was least recently  requested. 
The  RSS provides  a novel  technique  to  handle  segment recovery,  by  associating 
with  each recoverable segment two  page maps,  called  current  and  backup.  When 
the  OPEN-SEGMENT 
operator  is  issued,  to  make  the  segment available  for 
processing, these page maps have  identical  entries. When a component  of  the  RSS 
later  requests access to  a page, with  intent  to update  (after  suitable  locks have been 
acquired),  the  RSS checks whether  this  is  the  first  update  to  the  page since the 
OPEN  or  since the  last  SA.VE-SEGMENT 
operation.  If  so, a new  page slot  is 
allocated  nearby  on  disk,  the  page is  accessed from  its  original  disk  location,  and 
the  current  page map  is  then  modified  to  point  to  the  new  page slot.  When  the 
page is later  replaced from  the  buffer,  it  will  be directed  to  the  new location,  while 
the backup page and backup page map are left  intact. 
When  the  SAVE-SEGMENT 
operator  is  issued, the  disk  pages bound  to  seg- 
ments are brought  up  to  date by  storing  through  all  buffer  pages which  have been 
updated.  Both  page maps are then  scanned, and any  page which  has been modified 
since the  last save point  has its  old page slot released. Finally  the backup  page map 
entries are set equal to  the  current  page map entries, and the  cycle is complete. 
With  this  technique,  the  RESTORE  SEGMENT  operation  is  relatively  sim- 
ple,  since the  backup  page map  points G  a  complete,  consistent  copy  of  the  seg- 
ment.  The  current  page map  is  simply  set  equal  to  the  backup  one,  and  newly 
allocated  page  slots  are  released.  The  SAVE  SEGMENT  and  RESTORE- 
SEGMENT 
functions  are useful  for  recovering aprevious  version  of private  data, 
and  also for  support  of  system checkpoint  and  restart,  as explained  below.  How- 
ACM  Transactions  on  Database  Systems,  Vol.  1.  No.  2,  June  1976. 

System  R 

- 

119 

ever,  the  effect  of  restoring  a  segment of  public  data  segment may  be  to  undo 
changes made by  several transactions,  since each of them  may  have modified  data 
since  the  segment was  last  saved.  An  entirely  different  mechanism  is  therefore 
used to  back out  only  those changes made by  a single transaction,  and is explained 
below. 
Note  that  our  recovery  scheme depends on  the  highly  stylized  management of 
two  page maps per  segment, and  on  our  ability  to  control  when  pages are stored 
through  from  main  memory  to  disk.  These particular  requirements  led  to  the  de- 
cision  to  handle  our  own  storage management and  I/O  for  RSS segments, rather 
than  relying  on the  automatic  paging of virtual  memory in  the operating  system. 

Relations 
The  main  data  object  of  the  RSS is  the  n-ary  relation,  which  consists of  a  time- 
varying  number  of  tuples,  each containing  n  fields. A  new relation  can be defined 
at  any  time  within  any  segment chosen by  the  RDS.  An  existing  relation  and  its 
associated access path  structures  can  be  dropped  at  any  time,  with  all  storage 
space made reusable. Even  after  a relation  is  defined and  loaded, new  fields may 
be added on the  right,  without  a database reload and without  immediate modifica- 
tion  to  existing  tuples. 
Two  field  types  are supported:  fixed  length  and  variable  length.  For  both  field 
types,  a  special protocol  is  used at  the  RSI  to  generate an  undefined  value.  This 
feature  has a number  of  uses, but  a  particularly 
important  one is  that  when  the 
user adds new fields  to  an  existing  relation,  values for  those fields in  each existing 
tuple  are treated  as undefined until  they  are explicitly  updated. 
Operators are available  to  INSERT  and DELETE  single tuples,  and to  FETCH 
and UPDATE  any  combination  of fields in  a tuple.  One can also fetch  a sequence 
of tuples  along an access path  through  the use of an RSS cursor or SCQ~Z. Each scan 
is  created by  the  RSS for  fetching  tuples  on a particular  access path  through  exe- 
cution  of  the  OPEN-SCAN  operator.  The  tuples  along  the  path  may  then  be 
accessed by  a sequence of NEXT  operations on that  scan. The  access paths which 
are  supported  include  a  value  determined  ordering  of  tuples  through  use of  an 
image, an RDS  determined  ordering  of  tuples  through  use of a link  (see below for 
discussions of  images and  links),  and  an  RSS determined  ordering  of  tuples  in  a 
relation.  For  all  of  these access paths  the  RDS  may  attach  a search argument  to 
each NEXT  operation.  The  search argument  may  be any  disjunctive  normal  form 
expression where  each atomic  expression has  the  form  (field  number,  operator, 
value).  The  value  is an explicit  byte  string  provided  by  the  RDS,  and the  operator 
is  ‘~1  ,  I#‘, 
or  ‘2’. 
! >’  ,  ‘I’, 
‘<I, 
Associated with  every  tuple  of a relation  is a tuple  identifier  or  TID.  Each  tuple 
identifier  is  generated by  the  RSS, and  is  available  to  the  RDS  as a  concise and 
efficient means of addressing tuples.  TIDs  are also used within  the  RSS to  refer  to 
tuples  from  index  structures,  and  to  maintain  pointer  chains.  However,  they  are 
not  intended  for  end users above the  RDS,  since they  may  be  reused by  the  RSS 
after  tuple  deletions and are reassigned during  database reorganization. 
The  RSS  stores  and  accesses tuples  within  relations,  and  maintains  pointer 
chains to  implement  the links  described below. Each tuple  is stored as a contiguous 
sequence of  field  values  within  a  single  page. Field  lengths  are  also included  for 
ACM  Transactions  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

120 

l 

M.  M.  Astrahan 

et  al. 

variable  length  fields. A  prefix  is stored with  the  tuple  for  use within  the  RSS. The 
prefix  contains such information  as the  relation  identifier,  the pointer  fields  (!!‘I&) 
for  link  structures,  the  number  of  stored  data  fields,  and  the  number  of  pointer 
fields. These numbers are employed to  support  dynamic  creation  of new fields and 
links  to  existing  relations,  without  requiring  immediate  access or  modification  to 
the  existing  tuples.  Tuples  are found  only  on  pages which  have  been reserved as 
data  pages. Other  pages within  the  segment are reserved for  the  storage of index  or 
internal  catalog entries. A  given  data  page may  contain  tuples  from  more than  one 
relation,  so  that  extra  page accesses can  be  avoided  when  tuples  from  different 
relations  are accessed together.  When a scan is executed on a relation  (rather  than 
an image or  link),  an internal  scan is generated on all  nonempty  data  pages within 
the  segment containing  that  relation.  Each such data page is touched once, and the 
prefix  of each tuple  within  the  page is checked to  see if  it  belongs to  the  relation. 
The  implementation  of  tuple  identifier  access is a hybrid  scheme, similar  to  one 
used in  such systems as IDS  [ll] 
and  RM  [20],  which  combines the  speed of  a 
byte  address pointer  with  the  flexibility  of  indirection.  Each  tuple  identifier  is  a 
concatenation  of a page number  within  the  segment, along with  a byte  offset from 
the bottom  of the  page. The  offset denotes a special entry  or  “slot”  which  contains 
the  byte  location  of  the  tuple  in  that  page. This  technique  allows  efficient  utiliaa- 
tion  of  space within  data  pages, since space can be compacted and  tuples  moved 
with  only  local  changes to  the  pointers  in  the  slots. The  slots themselves are never 
moved from  their  positions  at  the  bottom  of each data  page, so that  existing  TIDs 
can still  be employed to  access the  tuples.  In  the  rare  case when a tuple  is updated 
to  a  longer  total  value  and  insufficient  space is  available  on  its  page, an  overflow 
scheme is provided  to  move the  tuple  to  another  page. In  this  case the  TID  points 
t,o a tagged overflow  record  -which is used to  reference the  other  page. If  the  tuple 
overflows  again,  the  original  overflow  record  is  modified  to  point  to  the  newest 
location.  Thus,  a tuple  access via  a TID  almost always involves  a single page access, 
and never  involves  more than  two  page accesses (plus  possible accesses to  the  page 
map blocks). 
In  order  to  tune  the  database to  particular  environments,  the  RSS accepts hints 
for  physical  allocation  during  INSERT  operations,  in  the  form  of a tentative  TID. 
The  new  tuple  will  be inserted  in  the  page associated with  that  TID,  if  sufficient 
space is  available.  Otherwise,  a  nearby  page is  chosen by  the  RSS. Use of  this 
facility  enables the  RDS  to  cluster  tuples  of a given  relation  with  respect to  some 
criterion  such as a value  ordering  on  one or  more  fields.  Another  use would  be  to 
cluster  tuples  of  one relation  near particular  tuples  of  another  relation,  because of 
matching  values in  some of the  fields. This  clustering  rule  would  result  in  high  per- 
formance  for  relational  join  operations,  as well  as for  the  support  of  hierarchical 
and network  applications. 

Images 
An  image in  the  RSS is  a  logical  reordering  of  an  n-ary  relat.ion  with  respect  to 
values  in  one or  more sort  fields.  Images combined with  scans provide  the  ability 
to  scan relations  along a value  ordering,  for  low level  support  of simple views. More 
importantly,  an image provides associative access capability.  The  RDS  can rapidly 
fetch  a tuple  from  an  image by  keying  on  the  sort  field  values.  The  RDS  can also 
ACM  Transactions  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

System  R 

l  , 

121 

open a scan at  a particular  point  in  the  image, and retrieve  a sequence of tuples  or 
subtuples with  a given  range of sort  values. Since the  image contains all  the  tuples 
and  all  the  fields  in  a  relation,  the  RDS  can  employ  a  disjunctive  normal  form 
search argument  during  scanning  to  further  restrict  the  set of  tuples  which  is  re- 
turned.  This  facility  is  especially useful  for  situations  where SEQUEL search predi- 
cates involve  several fields of a relation,  and at  least one of them has image support. 
A  new  image can be defined at  any  time  on any  combination  of  fields in  a rela- 
tion.  Furthermore,  each of  the  fields may  be specified as ascending or  descending. 
Once defined, an image is maintained  automatically  by  the RSS during  al1 INSERT, 
DELETE,  and UPDATE  operations. An  image can also be dropped at  any  time. 
The  RSS maintains  each image through  the  use of  a multipage  index  structure. 
An  internal  interface  is  used for  associative or  sequential  access along  an  image, 
and  also to  delete or  insert  index  ent,ries when  tuples  are deleted, inserted,  or  up- 
dated.  The  parameters  passed across this  interface  include  the  sort  field  values 
along with  the  TID  of  the  given  tuple.  In  order  to  handle  variable  length,  multi- 
field  indexes efficiently,  a special encoding scheme is  employed on  the  field  values 
so that  the  resulting  concatenation can be compared against others for  ordering  and 
search. This  encoding eliminates  the need for  costly  padding  of each field  and slow 
field-by-field  comparison. 
Each  index  is composed of one or more pages within  the  segment containing  the 
relation.  A  new page can be added to  an  index  when  needed as long  as one of  the 
pages within  the  segment is marked  as available.  The  pages for  a given  index  are 
organiaed into  a  balanced hierarchic  structure,  in  the  style  of  B-trees  [3]  and  of 
Key  Sequenced Data  Sets in  IBM’s  VSAM  access method  [23].  Each  page is  a 
node within  the  hierarchy  and  contains  an  ordered sequence of  index  entries.  For 
nonleaf  nodes, an  entry  consists of  a  (sort  value,  pointer)  pair.  The  pointer  ad- 
dresses another  page in  the  same structure,  which  may  be  either  a  leaf  page or 
another  nonleaf page. In  either  case the  target  page contains entries for  sort  values 
less than  or equal to  the  given  one. For  the  leaf nodes, an entry  is a combination  of 
sort  values  along  with  an  ascending list  of  TIDs  for  tuples  having  exactly  those 
sort  values.  The  leaf  pages are chained  in  a doubly  linked  list,  so that  sequential 
access can be supported from  leaf to  leaf. 

links 
A  link  in  the  RSS is  an  access path  which  is used to  connect tuples  in  one or  two 
relations.  The  RDS  determines which  tuples will  be on a link  and determines their 
relative  position,  through  explicit  CONNECT  and  DISCONNECT  operations. 
The  RSS maintains  internal  pointers  so that  newly  connected tuples  are linked  to 
previous  and  next  twins,  and  so that  previous  and  next  twins  are linked  to  each 
other  when  a  tuple  is  disconnected. A  link  can  be  scanned using  a  sequence of 
OPEN  SCAN  and NEXT  operations, with  the optional  search arguments described 
above. 
A  unary  link  involves  a single relation  and provides  a partially  defined ordering 
of  tuples.  Unary  links  can be used to  maintain  tuple  ordering  specifications which 
are not  supported  by  the  RSS  (i.e.  not  value  ordered).  Another  use is  to  provide 
an  efficient  access path  through  all  tuples  of  a relation  without  the  time  overhead 
of an internal  page scan, 

ACM  Transactions  on  Database  Systems,  Vol.  1.  No.  2,  June  1976. 

122 

* 

M.  M.  Astrohan  et  al. 

The  more  important  access path  is  a binary  link,  which  provides  a  path  from 
single tuples  (parents)  in  one relation  to  sequences of  tuples  (children)  in  another 
relation.  The  RDS  determines which  tuples  will  be children  under  a given  parent, 
and  the  relative  order  of  children  under  a  given  parent,  through  the  CONNECT 
and  DISCONNECT  operators.  Operators  are then  available  to  scan the  children 
of a parent  or  go directly  from  a child  to  its  parent  along a given  link.  In  general, 
a tuple  in  the  parent  relation  may  have  no  children,  and  a  tuple  in  the  child  rela- 
tion  may  have no parent.  Also, tuples  in  a relation  may be parents and/or  children 
in  an arbitrary  number  of different  links.  The  only  restriction  is that  a given  tuple 
can appear only  once within  a given  link.  Binary  links  are similar  to  the  notion  of 
an  owner  coupled set with  manual  membership  found  in  the  DBTG  specifications 
for  a network  model of data  [S]. 
The  main  use of binary  links  in  System R  is to  connect  child  tuples  to  a parent 
based on  value  matches in  one or more fields. With  such a structure  the  RDS  can 
access tuples  in  one relation,  say  the  Employee  relation,  based on  matching  the 
Department  Number  field  in  a  tuple  of  the  Department  relation.  This  function  is 
especially important  for  supporting  relational  join  operations, and also for  support- 
ing  navigational  processing through  hierarchical  and network  models of  data.  The 
link  provides  direct  access to  the  correct  Employee  tuples  from  the  Department 
tuple  (and  vice  versa),  while  use of  an  image may  involve  access to  several pages 
in  the  index.  A  striking  advantage is gained over images when the  child  tuples have 
been clustered  on the  same page as the  parent,  so that  no  extra  pages are touched 
using  the  link,  while  three  or more pages may  be touched  in  a large index. 
Another  important  feature of links  is to provide  reasonably fast associative access 
to  a relation  without  the  use of an extra  index.  In  the  above example, if  the Depart- 
ment  relation  has an image on Department  Number,  then  the  RDS  can gain associ- 
ative  access to  Employee tuples  for  a given  value  of Department  Number  by  using 
the  Department  relation  image and  the  binary  link-even 
if  the  Department  tuple 
is not  being  referenced by  the  end user. 
Links  are maintained  in  the  RSS by  storing  TIDs  in  the  prefix  of  tuples.  New 
links  can be defined at  any  time.  When a new link  is defined for  a relation,  a portion 
of the prefix  is assigned to  hold  the  required  entries.  This  operation  does not  require 
access to  any  of  the  existing  tuples,  since new prefix  space for  an  existing  tuple  is 
formatted  only  when the  tuple  is connected to  the  link.  When necessary, the  prefix 
length  is  enlarged through  the  normal  mechanisms used for  updates and  new data 
fields. An  existing  link  can be dropped at  any  time.  When this  occurs, each tuple  in 
the  corresponding  relation(s) 
is  accessed by  the  RSS, in  order  to  invalidate  the 
existing  prefix  entries and make the  space available  for  subsequent link  definitions. 

Transaction  Mandgement 

A  transaction at  the  RSS is a sequence of RSI  calls issued in  behalf  of  one user. It 
also serves as a  unit  of  consistency  and  recovery,  as will  be  discussed below.  In 
general, an RSS transaction  consists of those calls generated by  the  RDS  to  execute 
all  RDI  operators  in  a  single  System  R  transaction,  including  the  calls  required 
to  perform  such RDS  internal  functions  as authorization,  catalog  access, and  in- 
tegrity  checking.  An  RSS transaction  is  marked  by  the  STARTTRANS 
and 
ACM  Transactions  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

System  R 

l 

123 

END-TRANS 
operators.  Various  resources are  assigned to  transactions  by  the 
RSS, using  the  locking  techniques  described below.  Also,  a  transaction  recovery 
scheme is  provided  which  allows  a  transaction  to  be incrementally  backed out  to 
any  intermediate  save point.  This  multipoint  recovery  function  is important  in  ap- 
plications  involving  relatively  long  transactions  when  backup  is  required  because 
of errors detected by  the user or RDS, because of deadlock detected by  the RSS, or 
because of long periods of inactivity  or system congestion detected by  the  Monitor. 
A  transaction  save point  is marked  using  the  SAVE-TRANS  operator,  which 
returns  a save point  number  for  subsequent reference. In  general, a save point  may 
be generated by  any  one of  the  layers  above the  RSS. An  RDI  user may  mark  a 
save point  at  a convenient  place in  his  transaction  in  order  to  handle backout  and 
retry.  The  RDS  may  mark  a save point  for  each new set oriented  SEQUEL  expres- 
sion,  so that  the  sequence of  RSI  calls  needed to  support  the  expression can be 
backed out  for automatic  retry  if  any  of the RSI  calls faiIs to  complete. 
Transaction  recovery  occurs when  the  RDS  or Monitor  issues the  RESTORE- 
TRANS  operator,  which  has a save point  number  as its  input  parameter,  or when 
the  RSS initiates  the  procedure to  handle  deadlock. The  effect is  to  undo  all  the 
changes made by  that  transaction  to  recoverable data  since the  given  save point. 
Those changes include  all  the  tuple  and  image modifications  caused by  INSERT, 
DELETE,  and  UPDATE  operations,  all  the  link  modifications  caused by  CON- 
NECT  and DISCONNECT  operations, and  even all  the  declarations  for  defining 
new relations,  images, and links.  In  order  to  aid  the  RDS  in  continuing  the  trans- 
action,  all  scan positions  on recoverable data  are automatically  reset to  the  tuples 
they  were pointing  to  at  the  time  of the  save. Finally,  all  locks on recoverable data 
which  have been obtained  since the  given  save point  are released. 
The  transaction  recovery  function  is supported through  the maintenance of time 
ordered lists  of log entries, which  record information  about  each change to  recover- 
able  data.  The  entries  for  each transaction  are chained  together,  and  include  the 
old  and  new  values  of  all  modified  recoverable  objects  along  with  the  operation 
code and  object  identification.  Modifications  to  index  structures  are  not  logged, 
since their  values can be determined from data values and index  catalog information. 
At  each transaction  save  point,  special entries are stored containing  the  state  of 
all  scans in  use by  the  transaction,  and  the  identity  of  the most recently  acquired 
lock.  During  transaction  recovery,  the  log  entries  for  the  transaction  are read  in 
last-in-first-out  order. Special routines  are employed to  undo  all  the listed  modifica- 
tions  back  to  the  recorded save point,  and  also  to  restore  the  scans and  release 
locks acquired after  the  save point. 
The  log  entries  themselves are stored in  a dedicated segment which  is used as a 
ring  buffer.  This  segment is treated  as a simple linear  byte  space wit.h entries span- 
ning  page boundaries. Entries  are also archived  to  tape to  support  audits  and data- 
base reconstruction  after  system failure. 

Concurrency  Control 

Since System R  is a concurrent  user system, locking  techniques must  be employed 
to  solve various  synchronization  problems, both  at  the  logical  level  of objects like 
relations  and tuples  and at  the  physical  level  of pages. 
ACM Transactions  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

124 

. 

M.  M.  Astrahan 

et  al. 

At  the  logical  level,  such  classic  situations  as the  “lost  update”  problem  must  be 
transactions  do  not  read  the  same  value 
to  insure 
handled 
that 
two  concurrent 
and  then  try 
to  write  back  an  incremented  value. 
If  these  transactions  are  not 
the  second  update  will  overwrite 
synchronized, 
the  first,  and  the  effect  of  one  in- 
if  a  user  wishes  to  read  only  “clean”  or  committed 
crement  will  be  lost.  Similarly, 
in  progress 
data,  not  “dirty” 
data  which  has  been  updated  by  a  transaction  still 
and  which  may  be  backed  out,  then  some  mechanism  must  be  invoked 
to  check 
whether 
the  data  is  dirty.  For  another  example,  if  transaction 
recovery  is  to  affect 
only  the  modifications  of  a  single  user,  then  mechanisms  are  needed  to  insure  that 
data  updated  by  some ongoing  transaction,  say  Tl, 
is  not  updated  by  another,  say 
T2.  Otherwise,  the  backout  of  transaction  Tl  will  undo  T2’s  update  and  thus  violate 
our  principle  of  isolated  backout. 
At  the  physical  level  of  pages,  locking 
to  insure  that  in- 
techniques  are  required 
ternal  components  of  the  RSS  give  correct  results.  For  example,  a  data  page  may 
contain  several  tuples  with  each  tuple  accessed through 
its  tuple  identifier,  which 
requires  following  a pointer  within 
the  data  page.  Even  if  no  logical  conflict  occurs 
relation  or  a  differ- 
between  two  transactions,  because  each  is  accessing  a different 
ent  tuple  in  the  same  relation,  a  problem  could  occur  at  the  physical 
level  if  one 
to  a  tuple  on  some  page  while  the  other  transaction 
transaction 
follows  a  pointer 
updates  a  second  tuple  on  the  same  page  and  causes a  data  compaction  routine 
to 
reassign  tuple  locations. 
One basic  decision  in  establishing  System  R  was  to  handle  both  logical  and  physi- 
the  RSS,  rather  than  splitting 
cal  locking  requirements  within 
the  functions  across 
the  RDS  and  RSS  subsystems.  Physical 
locking  is  handled  by  setting  and  holding 
locks  on  one  or  more  pages  during  the  execution  of  a  single  RSI  operation.  Logical 
locks  on  such  objects  as  segments,  relations, 
locking 
is  handled  by  setting 
!!‘I&, 
released  or  to  the 
they  are  explicitly 
and  key  value  intervals  and  holding  them  until 
end  of  the  transaction.  The  main  motivation 
for  this  decision  is  to  facilitate 
the 
(One  particular  alternative  has  al- 
exploration  of  alternative 
techniques. 
locking 
ready  been  included 
in  the  RSS  as  a  tuning  option,  whereby 
the  finest  level  of 
locking  in  a  segment  can  be  expanded  to  an  entire  page  of  data,  rather  than  single 
tuples.  This  option  allows  pages to  be  locked  for  both  logical  and  physical  purposes, 
by  varying 
the  work 
the  duration  of  the  lock.)  Other  motivations  are  to  simplify 
of  the  RDS  and  to  develop  a  complete,  concurrent  user  RSS  which  can  be  tailored 
to  future  research  applications. 
Another  basic  decision  in  formulating  System  R  was  to  automate  all  of  the  lock- 
ing  functions,  both  logical  and  physical,  so  that  users  can  access shared  data  and 
delegate  some  or  all  lock  protocols 
to  the  system,  For  situations  detected  by  the 
end  user  or  RDS  where  locking  large  aggregates  is  desirable,  the  RSS  also  supports 
operators  for  placing  explicit  share  or  exclusive  locks  on  entire  segments  or  relations. 
In  order  to  provide  reasonable  performance 
for  a  wide  spectrum  of  user  require- 
ments,  the  RSS  supports  multiple 
the  isolation 
levels  of  consistency  which  control 
of  a user  from  the  actions  of  other  concurrent  users  (see also  [13]).  When  a  trans- 
is  started  at  the  RSI,  one  of  three  consistency 
action 
levels  must  be  specified. 
(These  same  consistency 
levels  are  also  reflected  at  the  RDI.)  Different  consist- 
transactions.  For  all  of  these 
ency  levels  may  be  chosen  by  different  concurrent 
levels,  the  RSS guarantees  that  any  data  modified  by  the  transaction 
is not  modified 

ACM  Transactions  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

System R 

l 

125 

by  any  other  until  the  given  transaction  ends. This  rule  is  essential to  our  trans- 
action  recovery scheme, where the backout  of modifications  by  one transaction  does 
not  affect modifications  made by  other  transactions. 
The  differences in  consistency levels occur during  read operations.  Level  1 con- 
sistency offers the  least isolation  from  other  users, but  causes the  lowest overhead 
and  lock  contention.  With  this  level,  dirty  data  may  be  accessed, and  one may 
read  different  values  for  the  same data  item  during  the  same transaction.  It  is 
clear that  execution with  Level  1 consistency incurs  the  risk  of reading  data values 
that  violate  integrity  constraints,  and  that  in  some sense never  appeared if  the 
transaction  which  set the  data  values is  later  backed out.  On the  other  hand,  this 
level  may  be entirely  satisfactory  for  gathering  statistical  information  from  a large 
database when  exact  results  are  not  required.  The  HOLD  option  can  be  used 
during  read operations to  insure  against lost  updates or dirty  data values. 
In  a  transaction  with  Level  2  consistency, the  user is  assured that  every  item 
read  is  clean. However,  no guarantee is made that  subsequent access to  the  same 
item  will  yield  the  same values or  that  associative access will  yield  the  same item. 
At  this  consistency level  it  is possible for another  transaction  to modify  a data item 
any  time  after  the given  Level  2 transaction  has read it.  A second read by  the given 
transaction  will  then  yield  the  new value,  since the  item  will  become clean again 
when the other  transaction  terminates. Transactions running  at Level  2 consistency 
still  require  use of the  HOLD  option  during  read operations preceding updates, to 
insure against lost  updates. 
For  the  highest  consistency level,  called Level  3, the  user sees the  logical  equiva- 
lent  of  a single user system. Every  item  read is  clean, and  subsequent reads yield 
the  same values, subject  of course to  updates by  the  given  user. This  repeatability 
feature  applies not  only  to  a specific item  accessed directly  by  tuple  identifier,  but 
even to  sequences of items and  to  items accessed associatively.  For  example, if  the 
RDS  employs an image on the  Employee relation,  ordered by  Employee Name, to 
find  all  employees whose names start  with  ‘B’  ,  then  the  same answer will  occur 
every  time  within  the  same transaction.  Thus,  the  RDS  can effectively  lock  a set 
of items defined by a SEQUEL  predicate and obtained by  any search strategy, against 
insertions  into  or deletions from  the  set. Similarly,  if  the RDS  employs an image to 
access the  unique  tuple  where Name  =  ‘Smith’  , and no such tuple  exists, then  the 
same nonexistence result  is assured for  subsequent accesses. 
Level  3 consistency eliminates  the  problem  of  lost  updates, and  also guarantees 
that  one can  read  a  logically  consistent  version  of  any  collection  of  tuples,  since 
other  transactions  are logically  serialized with  the  given  one. As an example of this 
last point,  consider a situation  where two or more related data items are periodically 
updated,  such  as the  mean and  variance  of  a  sequence of  temperature  measure- 
ments. With  Level  3 consistency, a reader is assured of reading  a consistent pair- 
rather  than,  say,  a  new  variance  and  an  old  mean.  Although  one could  use the 
HOLD  option  to  handle  this  particular  problem,  many  such associations may  not 
be  understood  in  a  more  complex  database environment,  even  by  relatively  ex- 
perienced programmers. 
The  RSS  components set locks  automatically  in  order  to  guarantee the  logical 
functions  of these various  consistency levels. For  example, in  certain  cases the  RSS 
must  set locks on  tuples,  such as when  they  have  been inserted  or  updated.  Simi- 
ACM  Transactions  on  Database  Systems,  Vol.  1.  NO.  2,  June  1976. 

126 

. 

M.  M.  Astrahan 

et  al. 

larly,  in  certain  cases the  RSS must  set locks  on  index  values  or  ranges of  index 
values,  even when  the  values  are  not  currently  present  in  the  index-such  as in 
handling  the  case of  ‘Smith’  described above. In  both  of  these cases the  RSS must 
also acquire  physical  locks  on  one or  more  pages, which  are held  at  least  during 
the  execution  of  each RSI  operation,  in  order  to  insure  that  data  and  index  pages 
are accessed and maintained  correctly. 
The  RSS employs a single  lock  mechanism to  synchronize  access to  all  objects. 
This  synchronization  is  handled  by  a  set of  procedures in  every  activation  of  the 
RSS, which  maintains  a collection  of queue structures  called gales in  shared, read/ 
write  memory. Some of these gates are numbered and are associated by  convention 
with  such resources as the  table  of buffer  contents,  or  the  availability  of  the  data- 
base for  processing. However,  in  order  to  handle  locks on a potentially  huge set of 
objects  like  the  tuples  themselves, the  RSS also  includes  a  named  gate  facility. 
Internal  components can request a lock  by  giving  an  eight-character  name for  the 
object,  using  such names as a  tuple  identifier,  index  value,  or  page number.  If  the 
named resource is already  locked it  will  have a gate. If  not,  then  a named gate will 
be allocated  from  a special pool  of numbered gates. The  named gate will  be deallo- 
cated when its  queue becomes empty. 
An  internal  request  to  lock  an  object  has several parameters:  the  name  of  the 
object,  the  mode  of  the  lock  (such  as shared,  exclusive,  or  various  other  modes 
mentioned  below),  and an indication  of lock  duration,  so that  the  RSS can quickly 
release all  locks held for  a single RSI  call,  or all  locks held for  the entire  transaction. 
The  duration  of  a  lock  is  also used  for  scheduling  purposes, such  as to  select  a 
transaction  for  backout  when deadlock is detected. 
The  choice of  lock  duration  is  influenced  by  several factors,  such as the  type  of 
action  requested by  the user and  the consistency level  of the  transaction.  If  a tuple 
is inserted  or  updated  by  a transaction  at  any  consistency level,  then  an  exclusive 
lock  must  be held  on the  tuple  (or  some superset)  until  the  transaction  has ended. 
If  a tuple  is deleted, then  an  exclusive  lock  must  be held  on  the  TID  of that  tuple 
for  the  duration  of  the  transaction,  in  order  to  guarantee  that  the  deletion  can be 
undone  correctly  during  transaction  backout.  For  any  of these cases,  as well  as for 
the  ones described below,  an  additional  lock  is  typically  set on  the  page itself  to 
prevent  conflict  of  transactions  at  the  physical  level.  However,  these page locks 
are released at  the  end of the  RSI  call. 
In  the  case of a transaction  with  Level  3 consistency, share locks must  be main- 
tained  on all  tuples  and  index  values which  are read, for  the  duration  of  the  trans- 
action,  to  insure  repeatability.  For  transactions  with  Level  2  consistency,  read 
accesses require  a share lock  with  immediate  duration.  Such a lock  request  is  en- 
queued behind  earlier  exclusive lock  requests so that  the  user is assured of reading 
clean data.  The  lock  is then  released as soon as the  request, has been granted,  since 
reads do not  have  to  be repeatable. Finally,  for  transactions  with  Level  1  consis- 
tency,  no  locks are required  for  read  purposes, other  than  short  locks  on  pages to 
insure  that  the  read operation  is correct. 
Data  items  can be locked at  various  granularities,  to  insure  that  various  applica- 
tions  run  efficiently.  For  example, locks on single tuples are effective for transactions 
which  access small  amounts  of  data,  while  locks  on  entire  relations  or  even entire 
segments are more reasonable for  transactions  which  cause the  RDS  to  access large 
ACM  Transactions  on  Database  Systems,  Vol.  1,  NO.  2,  June  1976. 

System  R 

- 

127 

amounts  of  data.  In  order  to  accommodate these differences, a dynamic  lock  hier- 
archy  protocol  has been developed so that  a small number  of  locks can be used to 
lock  both  few and many  objects [13].  The basic idea of the scheme is that  separate 
locks are associated with  each granularity  of object, such as segment, relation,  and 
tuple.  If  the  RDS  requests a lock  on an entire  segment in  share or  exclusive mode, 
then  every  tuple  of  every  relation  in  the  segment is  implicitly 
locked  in  the  same 
mode. If  the  RDS  requests a lock  on  a single relation,  say in  exclusive mode, but 
does not  wish  exclusive access to  the  entire  segment, then  the  RSS first  generates 
an  automatic  request for  a lock  in  intent-exclusive  mode on the  segment, before re- 
questing  an  exclusive lock  on the  relation.  This  intent-exclusive  lock  is compatible 
with  other  intent  locks but  incompatible  with  share and exclusive locks. The  same 
protocol  is extended to include  locks on individual  tuples, through  automatic  acqui- 
sition  of intent  locks on  the  segment and relation,  before a lock  is acquired  on the 
tuple  in  share or exclusive mode. 
Since locks are requested dynamically,  it  is possible for  two  or more concurrent 
activations  of the  RSS to  deadlock. The  RSS has been designed to  check for  dead- 
lock  situations  when  requests are blocked,  and  to  select one or  more victims  for 
backout  if  deadlock is detected. The  detection is done by  the Monitor,  on a periodic 
basis, by  looking  for  cycles in  a user-user matrix.  The  selection of a victim  is based 
on  the  relative  ages of  transactions  in  each deadlock cycle, as well  as on the  dura- 
tions  of  the  locks.  In  general the  RSS selects the  youngest transaction  whose lock 
is  of  short  duration,  i.e.  being  held  for  the  duration  of  a single RSI  call,  since the 
partially  completed call  can easily be undone.  If  none of the  locks in  the  cycle are 
of short  duration,  then  the youngest transaction  is chosen. This  transaction  is then 
backed out  to  the  save point  preceding the  offending  lock  request, using  the  trans- 
action  recovery  scheme described above.  (To  simplify  the  code, special  provisions 
are made for  transactions  which  need locks and are already backing  up.) 

System  Checkpoint 

and  Restart 

The  RSS provides  functions  to  recover  the  database to  a  consistent  state  in  the 
event  of a system crash. By  a consistent state we mean a set of data  values which 
would  result  if  a set of transact.ions had been completed, and no other  transactions 
were in  progress. At  such a state all  image and link  pointers  are correct  at  the  RSS 
level,  and more importantly  all  user defined integrity  assertions on data values are 
valid  at  the  RDS  level,  since the  RDS guarantees all  integrity  constraints  at  trans- 
action  boundaries. 
In  the  RSS, special  attention  has been given  to  reduce  the  need for  complete 
database dumps from  disk  to  tape  to  accomplish a system  checkpoint.  The  data- 
base dump  technique  has several difficulties.  Since the  time  to  copy  the  database 
to  tape may  be long  for  large  databases, checkpoints may  be taken  infrequently, 
such as overnight  or weekly.  System restart  is then  a time  consuming process, since 
many  database changes must  be  reconstructed  from  the  system  log  to  restore  a 
recent  database state.  In  addition,  before the  checkpoint  is performed, all  ongoing 
transactions  must  first  be completed. If  any  of  these are long,  then  no new  trans- 
actions  are  allowed  to  initiate  until  the  long  one is  completed  and  the  database 
dump  is taken. 

ACM  Tranaaetiona  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

128 

. 

M. M.  Astrahan  et  al. 

In  the  RSS, two  system recovery  mechanisms have been developed to  alleviate 
these difficulties.  The  first  mechanism uses disk  storage to  recover  in  the  event  of 
a “soft”  failure  which  causes the  contents of main  memory  to  be lost;  it  is oriented 
toward  frequent  checkpoints  and rapid  recovery.  The  second mechanism uses tape 
storage to  recover  in  the  relatively  infrequent  case that  disk  storage is  destroyed; 
it  is  oriented  toward  less frequent  checkpoints.  In  both  mechanisms, checkpoints 
can be made while  transactions  are still  in  progress. 
The  disk  oriented  recovery  mechanism is heavily  dependent on  the  segment re- 
covery  functions  described above, and  also on  the  availability  of  transaction  logs. 
The  Monitor  Machine  has the  responsibility  for  scheduling  checkpoints,  based on 
parameters set during  system startup.  When a checkpoint  is required,  the  Monitor 
quiesces all  activity  within  the  RSS at  a point  of physical  consistency: transactions 
may  still  be  in  progress, but  may  not, be  executing  an  RSI  operation.  The  tech- 
nique  for  halting  RSS activity 
is  to  acquire  a special RSS lock  in  exclusive  mode, 
which  every  activation  of  the  RSS code acquires  in  share mode before  executing 
an RSI  operation,  and releases at  the end of the  operation.  The  Monitor  then  issues 
the  SAVE-SEGMENT 
operator  to  bring  disk  copies of all  relevant  segments up 
to  date. Finally,  the  RSS lock  is released and transactions  are allowed to  resume. 
When  a soft  failure  occurs, the  RESTORE-SEGMENT 
operator  is used to  re- 
store the  contents  of all  saved segments. Recall  that  the  restore function  is a rela- 
tively  simple  one  involving 
the  setting  of  current  page map  values  equal  to  the 
backup  page map values and  the  releasing of pages allocated  since the  save point. 
The  log  segment, which  is  saved more  frequently  than  normal  data  segments, is 
effectively  saved at  the  end  of  each transaction,  and  contains  “after”  values  as 
well  as “before”  values  of modified  data.  Therefore  transactions  completing  after 
the  last  database save, but  before  the  last  log  save, can be redone automatically. 
In  addition,  the  transaction  logs are used to  back  out  transactions  which  were in- 
complete at  the  checkpoint  and  cannot  be redone, in  order  that  a consistent  data- 
base state is reached. 
Our  tape  oriented  recovery  scheme is an extension  of the  above one. In  order  to 
recover in  the  event  of lost  disk  data,  some technique  is required  to  get a sufficient 
copy of data  and log information  to  tape. The  technique  we have chosen is to  have 
the  Monitor  schedule certain  checkpoints  as  “long”  rather  than  standard  short 
ones. A  long  checkpoint  performs  the  usual  segment  save  operations  described 
above, but  also initiates  a process which  copies the  saved pages from  disk  to  tape. 
Thus  the  checkpoint  to  tape is incremental. 

4.  SUMMARY AND  CONCLUSION 

We  have  described the  overall  architecture  of  System  R  and  also  the  two  main 
components: the  Relational  Data  System  (RDS)  and  the  Relational  Storage Sys- 
tem  (RSS).  The  RSS is  a  concurrent  user,  data  management  subsystem which 
provides  underlying  support  for  System  R.  The  Relational  Storage  Interface 
(RSI)  has operations  at  the  single  tuple  level,  with  automatic  maintenance  of  an 
arbitrary  number  of value  orderings, called  images,  based on values in  one or more 
fields.  Images are implemented  through  the  use of multilevel  index  structures.  The 
ACM  Transactiona  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

System  R 

l 

129 

RSS  also  supports  efficient  navigation  from  tuples  in  one  relation  to  tuples  in 
another,  through  the  maintenance  of pointer  chain  structures  called  linh. 
Images 
and  links,  along with  physical  scans through  RSS pages, constitute  the  access path 
primitives  which  the  RDS  employs for  efficient  support  of  operators  on  the  rela- 
tional,  hierarchical,  and network  models of data. Furthermore,  to  facilitate  gradual 
integration  of data  and  changing performance requirements,  the  RSS supports  dy- 
namic addition  and deletion  of relations,  indexes, and links,  with  full  space reclama- 
tion,  and the addition  of new fields to  existing  relations-all  without  special utilities 
or database reorganization. 
Another  important  aspect of  the  RSS is  full  support  of  concurrent  access in  a 
multiprocessor  environment,  through  the  use of  gate  structures  in  shared, read/ 
write  memory.  Several levels of consistency are provided  to  control  the  interaction 
of  each user with  others. Also  locks are set automatically  within  the  RSS, so that 
even unsophisticated  users can write  transactions without  explicit  lock protocols or 
file  open protocols.  These locks are set on various  granularities  of  data  objects, so 
that  various  types of,application  environments  can be accommodated. 
In  the  area of recovery,  transaction  backout  is  provided  to  any  one of  an  arbi- 
trary  number  of user specified save points,  to  aid in  the  recovery of long application 
programs.  Backout  may  also be initiated  by  the  RSS during  automatic  detection 
of  deadlock. A  new recovery  scheme is  provided  at  the  system level,  so that  both 
checkpoint  and  restart  operations  can be performed  efficiently. 
The  RDS  supports  the  Relational  Data  Interface  (RDI)  , the  external  interface 
of  System R,  and  provides  the  user with  a consistent  set of  facilities  for  data  re- 
trieval,  manipulation,  definition,  and control.  The RDI  is designed as a set of opera- 
tors which may  be called directly  from  a host program. It  is expected that  programs 
will  be  written  on  top  of  the  RDI 
to  implement  various  stand-alone  relational 
interfaces  and  other,  possibly  nonrelational,  interfaces. 
The  most  important  component of  the  RDS  is the  optimizer,  which  makes plans 
for  efficient execution of high  level operations using  the RSS access path  primitives. 
Of  great  importance  in  optimizing  queries is  the  method  by  which  tuples  are  ar- 
ranged in  physical  storage. The  RDS provides the RSS with  clustering  hints  during 
insert  operations, so that  the  tuples  of a relation  are physically  clustered according 
to  some value  ordering,  or placed near associated tuples  along a binary  link.  Given 
the  cluster properties  of stored relations,  the  optimizer  uses an access path  strategy 
with  the  main  emphasis on  reducing  the  number  of  I/O  operations between main 
memory  and  on-line,  direct  access storage. 
In  addition  to  the  optimizer,  the  RDS  contains  components for  various  other 
functions.  The  authorization  component allows the  creator  of a relation  or view  to 
grant  or  revoke  various  capabilities.  The  integrity  system automatically  enforces 
assertions about  database values,  which  are entered  through  SEQUEL commands. 
A  similar  mechanism is  employed to  trigger  one or more database actions when  a 
given  action  is  detected.  The  SEQUEL language  may  also be  used  to  define  any 
query  as a named view.  The  access plan  to  materialize  this  view  is selected by  the 
optimizer,  and  can be stored  away  as a Pre-Optimized  Package (POP)  for  subse- 
quent  execution.  POPS are  especially  important  for  the  support  of  transactions 
which  are run  repetitively,  since they  avoid much of the overhead usually  associated 
with  a high  level  of data  independence. 
ACM  Transactions  on  Database  Systems,  Vol.  1,  No.  2.  June  1976. 

130 

l 

M. M.  Astrahan  et  al. 

APPENDIX I.  RDI OPERATORS 

Square  brackets  [  ]  are  used  below  to  indicate  optional  parameters. 

Operators 

for  data  definition 

and  manipulation: 

SEQUEL  ( 

[  <cursor 

name>,]  <any  SEQUEL statemen 

) 

FETCH  (  <cursor 

name>  [,  <pointers 

to 

I/O 

locations>] 

) 

FETCHJOLD 

(  <cursor 

name>  [,  <pointers 

to  I/O 

locations> 

]  ) 

OPEN  (  <cursor 

name>,  <name  of 

relation 

or  view> 

) 

CLOSE  (  <cursor 

name>  ) 

KEEP  (  <cursor 

name>,  <new  relation 

name>, 

Uist 

of  new  field 

names>  ) 

DESCRIBE  (  <cursor 

name>,  <degree>. 

<pointers 

to 

I/O 

locations> 

) 

BIND  (  <program  variable 

name>,  <program  variable 

address> 

) 

Operators 

on  transactions 

and  locks: 

BEGIN-TRANS  (  <transaction 

id>,  <consistency 

level> 

) 

END-T&INS 

SAVE  (  <save  point 

name>  ) 

RESTORE (  <save  point  name>  ) 

RELEASE  (  <cursor 

name>  ) 

APPENDIX II.  SEQUEL SYNTAX 

The  following 
It  contains 
is  a  shortened  version  of  the  BNF  synt,ax  for  SEQUEL. 
several  minor  ambiguities  and  generates  a  number  of  constructs  with  no  semantic 
support,  all  of  which  are  (hopefully)  missing  from  our  complete,  production  syntax. 
Square  brackets  [  ]  are used  to  indicate  optional  constructs. 

statement ::=  query 
1  dml-statement 
I  ddl-statement 
/  control-statement 

dml-statement 

assignment 
::= 
I 
insertion 
I  deletion 
I  update 

W-Y 

::= 

query-expr 

[  ORDER BY  ord-spec-list 

] 

assignment 

::= 

receiver 

<-  query-expr 

receiver 

::= 

table-name 

[  (  field-name-list 

) 

] 

insertion 

::= 

INSERT 

INTO 

receiver 

: 

insert-spec 

insert-spec 

::= 
I 

query-expr 
literal 
constant 

field-name-list 

::= 

field-name 
field-name-list 

, 

field-name 

ACM  Transactions  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

deletion 

::=  DELETE  table-name 

[  var-name 

] 

[  where-clause 

update 

::=  UPDATE 
table-name 
[  where-clause 

[  "ar-name 
I 

]  set-clause-list 

I 

. 

System  R 

9 

131 

where-clause 

::=  WHERE  boolean 
1  WHERE  CURRENT [  TUPLE  ]  OF 
[  CURSOR ]  cursor-name 

set-clause-list 

::= 

set-clause 
set-clause-list 

, 

set-clause 

set-clause 

SET 
::= 
1  SET 

field-name 
field-name 

=  expr 
(  query-expr 
= 

) 

qlC%ry-eXpr 

::= 
query-block 
1  query-expr 
I 
(  query-expr 

set-op 
) 

query-block 

set-op 

::= 

INTERSECT 

j  UNION  1  MINUS 

query-block 

::= 

FROM  from~list 
select-clause 
[  WHERE boolean 
] 
field-spec-list 
[  GROUP BY 
[  HAVING  boolean 
] 
] 

select-clause 

::= 
SELECT  [  UNIQUE  ]  sel-expr-list 
1  SELECT  [  UNIQUE  ]  * 

eel-expr-list 

::= 

sel-expr 
sel-expr-list 

, 

sel-expr 

Sel-eXpr 

from-list 

::= 

expr 
[ 
var-name 

:  host-location 
. 
* 
I 

] 
table-name 

* 

::= 
I 

table-name 
from-list 

[  var-name 
] 
table-name 
, 

[  var-name 

] 

field-spec-list 

::= 
1 

field-spec 
field-spec-list 

, 

field-spec 

ord-spec-list 

::= 

field-spec 
ord-spec-list 

[  direction 
] 
, 
field-spec 

[  direction 

] 

direction 

::= 

ASC 

I  DESC 

boolean 

boolean-term 
::= 
1  boolean 
OR  boolean-term 

boolean-term 

::= 
boolean-factor 
1  boolean-term 

AND  boolean-factor 

boolean-factor 

::= 

[  NOT  I  boolean-primary 

boolean-primary 

::= 
1 

predicate 
(  boolean 

) 

predicate 

::= 
exp?C 
comparison 
expr 
BETWEEN  expr 
AND  expr 
/  expr 
table-spec 
1  expr 
comparison 
full-table-spec 
>  = 
1  <  field-spec-list 
/  <  field-spec-list 
> 
[  IS 
] 
IN 
full-table-spec 
THEN  predicate 
I 
predicate 
IF 
1  SET  (  field-spec-list 
) 
comparison 
full-table-spec 
1  SET  (  field-spec-list 
) 
SET  (  field-wee-list 
table-spec 
comparison 

comparison 
) 
full-table-spec 

full-table-spec 

table-spec 
::= 
I 
(  entry 
1  constant 

) 

table-spec 

::= 
I 
1 

query-block 
(  query-expr 
literal 

) 

expr 

::= 

arith-term 
expr 
add-op 

arith-term 

ACM  Transactions  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

132 

l 

M.  M.  Astrahan 

et  al. 

srith-term 

::= 

srith-factor 
with-term 

mult-op 

arith-factor 

srith-factor 

::= 

[  add-op 

]  primary 

primary 

::= 

[  OLD  1  NEW I 
field-spec 
(  [  UNIQUE 1  exer 
* 
) 

) 

/  L%~ 
( 
cOnStsnt 
(  expr 

/ 

1 

field-spec 

field-name 
::= 
;  y-;me. 

. fi;;;;t;;m 

comparison 

::= 
camp-op 
1  CONTAINS 
1  DOES NOT  CONTAIN 

i 

i 

t: 

i 

i!T 

IN 

camp-op 

::= 

= 

11  = 

1  > 

/  >= 

1  < 

/  <= 

add-op 

::= 

+ 

1 

- 

mult-op 

::= 

* 

I 

/ 

set-fn 

literal 

::= 

AVG  1  MAX 

/  MIN 

/  SUM  1  COUNT  1 

identifier 

::; 

; 

lit-tup1e-list 
entry-list 
lit-tup1e 

1 

) 

) 

lit-ruple-list 

::= 
j 

lit-tup1e 
lit-nlple-list 

, 

lit-tup1e 

lit-tuple 

: :=  <  entry 
/  <  entry-list 

> 

> 

entry-list 

::= 

entry 
entry-list 

,  entry 
,  entry 

entry 

: := 

[  constant 

] 

constant 

::= 

quoted-string 
number 
1  host-location 

/  zt 
I  DATE 
field-name 
1 
[  ON 

table-name 

image-name 

::= 

::= 

name 

name 

link-name 

::= 

name 

ssrt-name 

trig-name 

::= 

::= 

name 

name 

OF  CURSOR  cursor-osms 
table-name 
] 

name 

::= 

[  creator 

. 

I  identifier 

creator 

::= 

identifier 

user-name 

::- 

identifier 

field-name 

::= 

identifier 

vsr-name 

::= 

identifier 

cursor-name 

::- 

identifier 

host-location 

::= 

identifier 

integer 

::= 

number 

ACM  Transactions  on Databarre Systems, Vol.  1, No.  2, June 1976. 

System  R 

l 

133 

ddl-statement 

::= 

create-table 
expand-table 
I 
keep-table 
1  create-image 
1  create-link 
\  define-view 
I  drop 
1  ccmment 

create-table 

[  per"-spec 
::=  CREATE 
[  share-spec 
] 
field-defn-list 
table-name 
: 

]  TABLE 

per"-spec 

::=  PERMANENT  1  TEMPORARY 

share-spec 

::= 

SHARED  1  PRIVATE 

field-defn-list 

::= 
1 

field-defn 
field-defn-list 

, 

field-defn 

field-defn 

::= 

field-name 

(  type 

[ 

,  NONULL  ]  ) 

type 

) 

::=  CHAR 
(  integer 
/  CHAR(*) 
i 
INTEGER 
,  SMALLINT 
[  DECIMAL  (  integer 
,  FLOAT 

,  integer 

) 

expand-table 

::= 

EXPAND  TABLE 
table-name 
field-defn 
FIELD 

ADD 

keep-table 

::= 

KEEP  TABLE 

table-name 

create-image 

::- 

CREATE 
ON 

[  image-mod-list 
IMAGE 
] 
table-name 
(  ard-spec-list 

image-name 
1 

image-mod-list 

::= 
1 

image-mod 
image-mod-list 

image-mod 

image-mod 

::=  UNIQUE 
1  CLUSTERING 

create-link 

::s 

[  CLUSTERING  ]  LINK 
CREATE 
link-name 
(  field-name-list 
FROM  table-name 
(  field-name-list 
TO 
table-name 
[  ORDER BY  ord-spec-list 
] 

) 

) 

define-view 

::- 

DEFINE 
[  per"-spec 
[  (  field-name-list 

]  VIEW 
table-name 
]  AS  query 

) 

drop 

::=  DROP  system-entity 

name 

cOment 

::=  COMMENT ON  system-entity 
1  COMMENT ON  FIELD 
table-name 
:  quoted-string 

name 
:  quoted-string 
.  field-name 

system-entity 

::- 

TABLE  1  VIEW  1  ASSERTION 
/  TRIGGER  1 
IMAGE 
)  LINK 

control-statement 

::= 
asrt-statement 
I  enforcement 
1  define-trigger 
I  grant 
1 
revoke 

asrt-statement 

::= 

[  INMEDIATE 
ASSERT  asrt-name 
] 
:  boolean 
[  ON asrt-condition 
] 

art-condition 

action-list 

::= 

::- 

action-list 
table-name 

I 
action 
action-list 

I  var-name 

] 

)  action 

action 

table-name 
INSERTION  OF 
::= 
1  DELETION  OF 
table-name 
I  UPDATE OF 
table-name 
[  (  field-name-list 

[  var-name 
[  var-name 
[  var-name 
I 
) 
] 

I 

] 

ACM  Transactions  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

134 

’ 

M.  M.  Astrahan  et  al. 

enforcement 

::= 

ENFORCE  INTEGRITY 
ENFORCE ASSERTION  ssrt-name 

define-trigger 

trig-condition 

::=  DEFINE  TRIGGER 
ON  trig-condition 

trig-name 
: 

(  statement-list 

) 

::= 
action 
j  READ OF 

table-name 

[  vsr-name 

] 

statement-list 

::= 

statement 
statement-list 

; 

statement 

grant 

auth 

user-list 

::=  GRANT  [  auth 
] 
table-name 
TO  user-list 
[  WITH  GRANT OPTION  ] 

::= 
ALL  RIGHTS  ON 
/  operation-list 
ON 
j  ALL  BUT  operation-list 

ON 

::= 
user-name 
I  user-list 
1  PUBLIC 

,  user-name 

operation-list 

operation 

::= 

operation 
operation-list 

,  operation 

::=  READ 
1 
INSERT 
1  DELETE 
/  UPDATE  [  (  field-name-list 
I  DROP 
1  EXPAND 
1 
IMAGE 
1  LINK 
1  CONTROL 

) 

] 

revoke 

::=  REVOKE [  operation-list 
FROM  user-list 

ON  1  table-name 

APPENDIX  III.  RSI  OPERATORS 

The  RSI  operators are oriented  toward  the  use of formatted  control  blocks. Rather 
than  explain  the  detailed  conventions  of  these control  blocks, we list  below  an  ap- 
proximate  but  hopefully  readable form  for  the  operators.  Square brackets  [  ]  are 
used to  indicate  optional  parameters. 

operators 

on  segments: 

OPEN-SEGMENT (  <s&d> 

) 

CLOSE-SEGMENT (  <segid> 

) 

SAVE-SEGMENT  (  <segid> 

) 

RESTORE-SEGMENT (  <segid> 

) 

Operators 

on  transactions 

and  locks: 

STARTJRANS 

(  <consistency 

level> 

) 

END TRANS 
- 

SAVEJRANS,  RETURNS  (  <saveid> 

) 

RESTOREJRANS  (  <saveid> 

) 

LOCK-SEGMENT (  <segid>, 

&ode: 

SHARE or  EXCLUSIVE  or  SIX>  ) 

LOCK-RELATION  (  <segid>, 

<relid>, 

<mode,  ss  above> 

) 

RELEASEJUPLE 

(  <segid>, 

<tld> 

) 

ACM  Transactions  on  Database  Systems,  Vol.  1.  No.  2,  June  1976. 

System  R 

l 

135 

Operators 

on  tuples 

and  scans: 

FETCH  (  <segid>, 

<relid>, 

<identifier: 

tid  or  scanid  or 

imageid, 

key  values>, 

<field 

list>, 

<pointers 

to 

I/O 

locations> 

[,  HOLD]  ) 

INSERT  (  <segid>, 

<relid>, 

<pointers 

to 

I/O 

locations> 

I,  <nearby 

tid> 

I  ), 

RETURNS (  Ctid> 

) 

DELETE  (  Csegid>,  <relid>, 

<identifier, 

as  above> 

) 

UPDATE  (  <s&d>, 

<relid>, 

<identifier, 

a8  above>, 

<field 

list>, 

<pointers 

to 

I/O 

locations> 

) 

OPEN-SCAN  (  <s&d>, 

<path: 

relid 

or 

imageid  or 

linkid>, 

<start-point: 

key  values 

for 

image,  or 

tid 

for 

link, 

or  scanid 

for 

link> 

), 

RETURNS (  <scanid> 

) 

NEXT  (  <se&d,, 

<scanid>, 

<field 

list>, 

<pointers 

to 

I/O 

locations> 

[,  <search  argument>] 

[,  HOLD]  ) 

CLOSE  (  <segid>, 

<scanid> 

) 

PARENT  (  <child 

s&d>, 

<linkid>, 

<identifier 

for  new  tuple, 

as 

above>,  <field 

list>, 

<pointers 

to 

I/O 

locations> 

[,  HOLD1  ) 

CONNECT (  <child 

s&d>, 

<linkid>, 

<identifier 

for  new  tuple, 

as 

above>,  <neighbor 

relid>, 

<neighbor 

tid>, 

<location: 

BEFORE or  AFTER>  ) 

DISCONNECT  (  <child 

s&d>, 

<linkid>, 

<identifier 

for  child, 

as 

above> 

) 

Operators 

for  data  definition: 

CREATE  (  <segid>, 

<object 

type:  REL  or 

IMAGE  or  LINK  >,  <specs> 

), 

RETURNS (  <object 

identifier: 

relid 

or 

imageid  or 

link10 

) 

DESTROY (  <se&d>, 

<object 

identifier, 

88  above> 

) 

CHANGE (  <segid>, 

<object 

identifier, 

a8  above>, 

G-lew  specs> 

) 

RRADSPEC (  <segid>, 

<object 

identifier, 

88  abov&, 

<pointer 

to 

I/O 

locatiol0 

) 

ACKNOWLEDGMENTS 
The  authors  wish  to  acknowledge many  helpful  discussions with  E.F.  Codd, origi- 
nator  of the  relational  model of data,  and with  L.Y.  Liu,  manager of the Computer 
Science Department  of  the  IBM  San Jose Research Laboratory.  We also wish  to 
acknowledge  the  extensive  contributions  to  System  R  of  Phyllis  Reisner,  whose 
human  factors  experiments  (reported  in  [24,  251)  have  resulted  in  significant  im- 
provements in  the SEQUEL language. 
ACM  Transactions  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

136 

l 

M.  M.  Astrahan 

et  al. 

A  relational  system.  Proc.  ACM 

REFERENCES 
1.  ASTRAHAN,  M.M.,  AND  CHAMBERLIN,  D.D. 
Implementation  of  a  structured  English  query 
language.  Comm. ACM  18,  10  (Oct.  1975), 580-588. 
2.  ASTRAHAN,  M.M.,  AND  LORIE,  R.A.  SEQUEL-XRM: 
Pacific  Conf.,  San  Francisco,  Calif.,  April  1975, pp.  34-38. 
3.  BAYER,  R.,  AND  MCCREIGHT,  E.M.  Organization  and  maintenance  of  large  ordered  indexes. 
1  (1972),  173-189. 
Acta  Informatica 
4.  BOYCE,  R.F.,  AND  CHAMBERLIN,  D.D.  Using  a  structured  English  query  language  as  a  data 
definition  facility.  Res. Rep.  RJ  1318, IBM  Res.  Lab.,  San Jose, Calif.,  Dec.  1973. 
5.  CHAMBERLIN,  D.D.,  AND  BOYCE,  R.F.  SEQUEL:  A  structured  English  query  language. 
Proc.  ACM  SIGFIDET  Workshop,  Ann  Arbor,  Mich.,  May  1974, pp.  249-264. 
from  ACM,  New  York.) 
6.  CODASYL  DATA  BASE  TASK  GROUP.  April  1971 Rep.  (Available 
7.  CODD,  E.F.  A  relational  model  of  data  for  large  shared  data  banks.  Comm.  ACM 
IS,  6 
(June  1970), 377-387. 
8.  CODD,  E.F.  Relational  completeness of  data  base sublanguages.  In  Courant  Computer  Science 
Symposia,  Vol.  6:  Data  Base  Systems,  G.  Forsythe,  Ed.,  Prentice-Hall,  Engelwood  Cliffs, 
N.J.,  1971, pp.  65-98. 
9.  DONOVAN,  J.J.,  FESSEL,  R.,  GREENBERG,  S.S.,  AND  GUTENTAG,  L.M.  An  experimental 
VM/370  based  information  system.  Proc.  Internat.  Conf.  on  Very  Large  Data  Bases, 
Framingham,  Mass.,  Sept.  1975, pp.  549-553.  (Available 
from  ACM,  New  York.) 
10.  ESWARAN,  K.P.,  AND  CHAMBERLIN,  D.D.  Functional  specifications  of  a  subsystem  for  data 
base  integrity.  Proc.  Internat.  Conf.  on  Very  Large  Data  Bases,  Framingham,  Mass.,  Sept. 
1975, pp.  48-68.  (Available 
from  ACM,  New  York.) 
11.  Feature  analysis  of  generalized  data  base  management  systems.  CODASYL  Systems  Com- 
mittee  Tech.  Rep.,  May  1971. (Available 
from  ACM,  New  York.) 
12.  GOLDSTEIN,  R.C.,  AND STRNAD,  A.L.  The  MACAIMS  data  management  system.  Proc.  ACM 
SIGFIDET  Workshop  on  Data  Description  and  Access,  Houston,  Tex.,  Nov.  1970,  pp. 
201-229. 
13.  GRAY,  J.N.,  LORIE,  R.A.,  PUTZOLU,  G.R.,  AND  TRAIGER, 
I.L.  Granularity  of  locks  and 
degrees of  consistency  in  a shared  data  base. Proc.  IFIP  Working  Conf.  on  Modelling  of Data 
Base  Management  Systems,  Freudenstadt,  Germany,  Jan.  1976, pp.  695-723. 
14.  GRAY,  J.N.,  AND  WATSON,  V.  A  shared  segment  and  inter-process  communication  facility 
VM/370.  Res.  Rep.  RJ  1579, IBM  Res.  Lab.,  San  Jose, Calif.,  Feb.  1975. 
15.  GRIFFITHS,  P.P.,  AND  WADE,  B.W.  An  authorization  mechanism  for  a  relational  data  base 
system.  Proc.  ACM  SIGMOD  Conf.,  Washington,  D.C.,  June  1976 (to  appear). 
INGRES:  A  relational  data  base  system. 
16.  HELD,  G.D.,  STONEBRAKER,  M.R.,  AND  WONG,  E. 
Proc.  AFIPS  1975 NCC,  Vol.  44, AFIPS  Press, Montvale,  N.J.,  pp.  409-416. 
IBM  Pub.  No.  GH20-1260, 
17.  Information  Management  Sy,stem, General  Information  Manual. 
IBM  Corp.,  White  Plains,  N.Y.,  1975. 
to  VM/370.  Pub.  No.  GC20-1800,  IBM  Corp.,  White  Plains,  N.Y.,  Jan.  1975. 
18.  Introduction 
19.  LORIE,  R.A.  XRM-An 
extended  (n-ary)  relational  memory.  IBM  Scientific  Center  Rep. 
G320-2096, Cambridge,  Mass.,  Jan.  1974. 
20.  LORIE,  R.A.,  AND  SYMONDS,  A.J.  A  relational  access method  for  interactive  applications. 
In  Courant  Computer  Science  Symposia,  Vol.  6:  Data  Base  Systems,  G.  Forsythe,  Ed.,  Prentice- 
Hall,  Engelwood  Cliffs,  N.J.,  1971, pp.  99-124. 
21.  MYLOPOULOS,  J.,  SCHUSTER,  S.A.,  AND  TSICHRITZIS,  D.  A  multi-level 
relational  system. 
Proc.  AFIPS  1975 NCC,  Vol.  44,  AFIPS  Press,  Montvale,  N.J.,  pp.  403408. 
22.  NOTLEY,  M.G.  The  Peterlee  IS/l  System.  IBM  UK  Scientific  Center  Rep.  UKSC-0018, 
March  1972. 
23.  Planning  for  Enhanced  VSAM  under  OS/VS.  Pub.  No.  GC26-3842, IBM  Corp.,  White  Plains, 
N.Y.,  1975. 
24.  REISNER,  P.  Use  of  psychological  experimentation  as  an  aid  to  development  of  a  query 
language.  Res.  Rep.  RJ  1707, IBM  Res.  Lab.,  San  Jose, Calif.,  Jan.  1976. 
25.  REISNER,  P.,  BOYCE,  R.F.,  AND  CHAMBERLIN,  D.D.  Human  factors  evaluation  of  two  data 
base  query  languages:  SQUARE  and  SEQUEL.  Proc.  AFIPS  1975 NCC,  Vol.  44,  AFIPS 
Press, Montvale,  N.J.,  pp.  447-452. 
ACM  Transactions  on Database Systems, Vol.  1, No.  2, June  1976. 

for 

System  R 

l 

137 

26.  SCHMID,  H.A.,  AND  BERNSTEIN, 
for  relational  data  base 
P.A.  A  multi-level  architecture 
systems.  Proc.  Internat.  Conf.  on  Very  Large  Data  Bases, Framingham,  Mass.,  Sept.  1975, 
pp.  202-226.  (Available  from  ACM,  New  York.) 
27.  SMITH,  J.M.,  AND  CHANG,  P.Y.  Optimizing 
the  performance  of  a relational  algebra  database 
interface.  Comm. ACM  18,  10 (Oct.  1975), 568-579. 
28.  STONEBRAKER,  M. 
Implementation  of  integrity  constraints  and  views  by  query  modification. 
Proc.  ACM  SIGMOD  Conf.,  San Jose, Calif.,  May  1975, pp.  65-78. 
29.  TODD,  S.  PRTV:  An  efficient  implementation 
for  large  relational  data  bases.  Proc.  Internat. 
Conf.  on Very  Large  DataBases,  Framingham,  Mass., Sept.  1975, pp.  554-556.  (Available  from 
ACM,  New  York.) 
30.  WHITNEY,  V.K.M.  RDMS:  A  relational  data  management  system.  Proc.  Fourth  Internat. 
Symp.  on  Computer  and  Information  Sciences, Miami  Beach,  Fla.,  Dec.  1972, pp.  55-66. 
31.  ZLOOF,  M.M.  Query  by  Example.  Proc. AFIPS  1975 NCC,  Vol.  44, AFIPS  Press, Montvale, 
N.J.,  pp.  431-437. 

Received  November  1975; revised  February  1976 

ACM  Transactions  on  Database  Systems,  Vol.  1,  No.  2,  June  1976. 

RELATIONAL 

COMPLETENESS  OF  DATA  BASE  SUBLANGUAGES 

E.  F.  Codd 

IBM  Research 
San  Jose, 

Laboratory 
California 

near 
future, 
ABSTRACT: 
In 
the 
interrogating 
to  be  proposed 
for 
a 
theoretical 
to  provide 
attempts 
capability 
a  selection 
complete 
of  any  host 
independently 
language 

we   can  expect 
a  great 
variety 
and  updating 
data 
bases. 
which  may  be  used 
basis 
in  a  proposed 
is  provided 
in  which 
the 
sublanguage 

of 
languages 
This 
paper 
to  determine 
how 
data 
sublanguage 
may  be  embedded. 

A  relational 
algorithm 
(based 
relational 

on 

algebra 
is  presented 
the 
calculus) 
algebra. 

are  defined. 
calculus 
and  a  relational 
relation-defining 
an  arbitrary 
reducing 
for 
equivalent 
a  semantically 
into 
expression 

Then, 

an 
expression 
of 
the 

Finally, 
oriented 
optimal 

regarding 
the 
some  opinions 
are 
sublanguages 
algebra-oriented 
versus 
data 
discriminating 
search 
and  highly 
authorization 

stated 

relative 
from 

merits 
of 
the 
standpoint 
schemes. 

calculus- 
of 

RJ  987 
March 
Computer 

Hl7041) 
6,  1972 
Sciences 

1 

1. 

INTRODUCTION 

In 

the 

near 

future 

we   can  expect 

a  great 

variety 

of 

languages 

to  be 

proposed 

for 

interrogating 

and  updating 

data 

bases. 

When 

the 

computation- 

oriented 

components 

of 

such  a 

language 

are 

removed, 

we   refer 

to 

the 

remaining 

storage 

and 

retrieval 

oriented 

sublanguage 

as  a  data 

sublanguaqe. 

A  data 

sublanguage 

may  be  embedded 

in  a  general 

purpose 

programming 

language, 

or 

it  may  be  stand-alone 

-- 

in  which 

case, 

it 

is 

commonly 

called 

a  query 

language 

(even 

though 

it  may  contain 

provision 

for 

simple 

updating 

as  well 

as  querying). 

This 

paper 

attempts 

to  establish 

a 

theoretical 

basis 

which  may  be 

used 

to  determine 

how  complete 

a  selection 

capability 

is  provided 

in  a 

proposed 

data 

sublanguage 

independently 

of  any  host 

language 

in  which 

the 

sublanguage 

may  be  embedded. 

The 

selection 

capability 

under 

discussion 

is 

a  basic 

non-statistical 

one. 

In  a  practical 

environment 

it  would 

need 

to 

be  augmented 

by  a  counting 

and 

summing 

capability, 

together 

with 

the 

capability 

of 

invoking 

any  one  of  a 

finite 

set  of 

library 

functions 

tailored 

to 

that 

environment. 

In  previous 

papers  Cl  4 

we   proposed 

a  relational 

model 

of  data. 

With 

this  model 

any 

formatted 

data 

base 

is 

viewed 

as  a  collection 

of 

time-varying 

relations 

of  assorted 

degrees. 

In  Section 

2  of 

this 

paper, 

we   define 

a 

collection 

of  operations 

on 

relations 

,  and 

this 

collection 

is 

called 

a 

relational 

algebra. 

This 

algebra 

may  be  used 

for 

a  variety 

of  purposes. 

For 

example, 

a  query 

language 

could 

be  directly 

based 

on 

it 

(however, 

we   would 

propose 

that 

domain 

names 

be  used 

instead 

of  domain 

numbers). 

Later 

sections 

of 

this 

paper 

support 

its 

use  as  a  yardstick 

of 

selective 

power  of  algebra- 

oriented 

data 

sublanguages. 

For  each 

such 

language, 

one  would 

investigate 

,whether 

there 

is  any  operation 

of 

the 

relational 

algebra 

which 

cannot 

be 

defined 

in 

the 

candidate 

language. 

An 

information 

proposed 

by  R.  Bosak. 

algebra 
t-51 

with 

a  rather 

different 

orientation 

was  

In  Section 

3,  we   define 

an  applied 

predicate 

calculus--the 

relational 

calculus-- 
---- 

and 

introduce 

a  number 

of 

concepts 

related 

to  meaningful 

and 

reasonable 

queries. 

These 

concepts 

are 

somewhat 

related 

to 

those 

of  J.  L. 

Kuhns. 

[6,7,81 

However, 

his 

relational 

data 

file 

is 

less 

structured 

than 

this 

author's 

relational 

model. 

A  data 

sublanguage 

(called 

ALPHA), 

founded 

directly 

on 

the 

relational 

calculus, 

has  been 

informally 

described 

in 

[4]. 

This 

calculus 

can  also 

be 

used 

as  a  means 

of  comparing 

calculus-oriented 

data 

sublanguages 

with 

one 

another. 

In  Section 

4,  we   provide 

an  algorithm 

for 

translating 

an  arbitrary 

alpha 

expression 

into 

a  semantically 

equivalent 

sequence 

of  operations 

in 

the 

relational 

algebra. 

This 

algorithm 

demonstrates 

that 

the 

relational 

algebra 

has  at 

least 

the 

selective 

power 

of 

the 

relational 

calculus. 

As  a 

consequence, 

we   may  shortcut 

the  work  of 

comparing 

any  given 

algebra-oriented 

data 

sublanguage 

LA  with 

any  given 

calculus-oriented 

language 

LC 

by 

comparing 

L A  with 

the 

relational 

algebra 

and 

LC  with 

the 

relational 

calculus, 

as 

indicated 

in  Fig. 

1. 

In 

this 

figure, 

the  Project 

MAC  system 

called 

MACAIMS 

is 

cited 

as  an  example 

of  an  algebra-oriented 

language 

bee  Dl>. 

In 

section 

5,  we   consider 

the 

pros 

and  cons 

of  data 

sublanguages 

founded 

on  a  relational 

algebra 

versus 

those 

founded 

on  a  relational 

calculus. 

CALCULUS-ORIENTED  LANGUAGES 

Fig.  1: 

COMPARISON %-lEME  FOR DATA  %J?al ANGUAm 

4 

2. 

A  RELATIONAL 

ALGEBRA 

2.1 

Objective 

The  primary 

purpose 

of 

this 

algebra 

is 

to  provide 

a  collection 

of 

operations 

on 

relations 

of  all 

degrees 

(not 

necessarily 

binary) 

suitable 

for 

selecting 

data 

from 

a  relational 

data 

base. 

The 

relations 

to  be 

operated 

upon  are 

assumed 

to  be  normalized; 

that 

is, 

the 

domains 

on  which 

they 

are  defined 

are 

simple 

(see 

[2,3] 

and  below). 

In  Section 

4,  we   shall 

discuss 

the 

selective 

power  of 

this 

collection 

of  operations. 

&Data 

selection 

is 

viewed 

as 

the 

formation 

(by 

some  operation 

of 

the 

algebra) 

of  a  new  normalized 

relation 

from 

the 

existing 

collection 

of 

relations. 

Presentation 

operations 

such  as  ordering 

a  relation 

by  values 

in  one  or  more 

of 

its 

domains 

and 

factoring 

a  normalized 

relation 

into 

un- 

normalized 

form 

are  discussed 

elsewhere 

(see 

[4] 

and  Appendix). 

These 

latter 

operations 

have  no  effect 

on 

the 

information 

content 

of 

retrieved 

data. 

For  notational 

and  expository 

convenience, 

we   deal  with 

domain-ordered 

relations; 

that 

is, 

the 

individual 

domains 

of  a  given 

relation 

can  be 

identified 

as 

the 

first, 

second, 

third, 

and 

so  on. 

As  pointed 

out 

in 

[l], 

however, 

in  many  practical 

data 

bases 

the 

relations 

are  of 

such 

high 

degree 

that 

names 

rather 

than 

position 

numbers 

would 

be  used 

to 

identify 

domains 

when  actually 

storing 

or 

retrieving 

information. 

2.2 

Introductory 

Definitions 

Our  aim 

in 

this 

section 

is 

to  define 

the 

kinds 

of  domains 

(simple 

and 

compound) 

and 

the 

kinds 

of 

relations 

(normalized) 

which 

are  operands 

for 

the  operations 

to  be  subsequently 

defined. 

5 

The  Cartesian 

product 

of 

two  sets 

C,  D 

is  denoted 

C  x  D,  and 

is 

defined 

by: 

C  x  D  = 

{(c,d): 

c  E  C  A  d  E  D}. 

The  expanded 

Cartesian 

product 

x 

of 

n 

sets 

D,,  D2, 

.  .  .  .  Dn 

is 

defined 

by: 

x(D,,D2,...,D,) 

=  C(dl,d2,...,dn): 

dj  E  Dj 

for 

j  =  1,  2, 

.  .  .  ,  nl. 

The  elements 

of 

such  a  set 

are 

called 

n-tuples, 

or 

just 

tuples 

for 

short. 

When 

n  =  1, 

~$1 

=  D, 

since 

no  distinction 

is  made  between 

a 

l-tuple 

and 

its 

only 

component. 

Suppose 

d  = 

(d,, 

d2, 

.  .  .  .  dm) 

and 

e  = 

(e,, 

e2, 

.  .  .  .  en). 

The 

concatenation 

of 

d  with 

e 

is 

the 

(m  +  n)-tuple 

defined 

by 

dne= 

(d,,d2 

,...,  dm,e,,e2 

,...,  enI. 

R 

is  a  relation 

on 

the 

sets 

D,,  D2, 

a.., 

x(+ 

D2, 

.  .  .  .  D,,). 

A  relation 

is  accordingly 

if 

Dn 
a  special 

it 

is  a  subset 

kind 

of 

set. 

of 

Its 

members 

are  all 

n-tuples 

where 

n 

is  a  constant 

called 

the 

degree 

of 

the 

relation. 

Relations 

of  degree 

1  are 

called 

unary, 

degree 

2  binary, 

degree 

3 

ternary, 

degree 

n  n-ary. 

The 

sets 

on  which 

a  relation 

is  defined 

are 

called 

its 

underlying 

domains. 

For  data 

base 

purposes, 

we   are 

concerned 

with 

data 

consisting 

of 

integers 

and  character 

strings 

(other 

types 

of  primitive 

elements 

may  be 

included 

in 

this 

definition 

if 

desired, 

with 

only  minor 

changes 

in 

some 

of 

the 

definitions 

below). 

A  simple 

domain 

is  a  set 

all 

of  whose  elements 

are 

integers, 

or  a  set 

all 

of  whose  elements 

are 

character 

strings. 

A  relation 

defined 

on  simple 

domains 

alone 

is 

said 

to  be  simple 

normal. 

In 

the 

remainder 

of 

this 

paper, 

whenever 

the 

term 

relation 

is  used  without 

further 

qualification, 

it  means 

simple 

normal 

relation. 

A  compound 

domain 

is 

the 

expanded 

Cartesian 

product 

of  a 

finite 

number 

(say 

k, 

k  2  1)  of 

simple 

domains; 

k 

is 

called 

the 

degree 

of 

the 

compound 

domain. 

Two  simple 

domains 

are 

union-compatible 

if 

both 

are  domains 

of 

integers 

or  both 

are  domains 

of  character 

strings. 

Two  compound 

domains 

D,  E 

are 

union-compatible 

if 

they 

the 

same  degree 

(say 

m)  and 

for 

every 

j 

the 

simple 

domain 

of 

D 

is  union-compatible 

with 

simple 

domain 

of 

E. 

Two  relations 

R,  S 

are 

union-compatible 

if 

(j=l,Z,...,m) 

the 

jth 

are  of 
.th 
J 

the 

compound 

domains 

of 

which 

R 

and 

S 

are 

subsets 

are  union-compatible. 

2.3 

Definitions 

of 

the  Operations 

The  operations 

to  be  defined 

fall 

naturally 

into 

two  classes: 

the 

traditional 

set 

operations 

(Cartesian 

product, 

union, 

intersection, 

difference) 

and 

less 

traditional 

operations 

on 

relations 

(projection, 

join, 

division, 

restriction). 

We  consider 

the 

traditional 

set 

operations 

first. 

2.3.1 

Traditional 

Set  Operations 

-  The  usual 

Cartesian 

product 

R  x  S 

relation 

R 

(degree 

m) 

with 

relation 

S 

(degree 

n) 

is  a  relation 

of 

of 

degree 

2,  using 

the 

definition 

given 

in  Section 

2.2 

above. 

The  Cartesian 

product 

employed 

in 

the 

relational 

algebra, 

however, 

yields 

an  expanded 

product, 

, 

a  relation 

R  @  S,  whose  degree 

is 

m  +  n. 

This 

product 

is  defined 

by 

R  a  S  =  {(rns): 

r  E  R  A  s  E  Sl. 

Union 

(u), 

intersection 

(n), 

difference 

(-) 

are 

defined 

in 

the 

usual 

way,  except 

that 

they 

are  applicable 

only 

to  pairs 

of  union-compatible 

normal 

relations. 

2.3.2 

Projection 

-  Suppose 

r 

is  a 

tuple 

of 

the  m-ary 

j  =  1,  2, 

.  .  .  . 

m 

the 

notation 

r[j] 

designates 

the 

relation 
.th 
J 

R. 

For 

component 

of 

r. 

For  other 

values 

of 

j, 

r[j] 

is  undefined. 

We  extend 

the 

notation 

to  a 

list 

A  = 

(j,, 

j,, 

.  .  .  , 

jk) 

of 

integers 

(not 

necessarily 

distinct) 

from 

the 

set 

(1, 

2, 

.  .  .  .  m) 

as 

follows 

rl31  =  bCj,l, 

r&l, 

. . .  ,  r[jk]). 

When 

the 

list 

A 

is  empty, 

r[A] 

=  r. 

Let 

R 

be  a  relation 

of  degree 

m,  and 

A 

a 

list 

of 

integers 

(not 

necessarily 

distinct) 

from 

the 

set 

(1, 

2, 

.  .  .  .  m}. 

Then, 

the 

projection 

of 

R 

on 

A 

is  defined 

by 

RCA]  =  {r[A]: 

r  E  R}. 

Note 

that 

when 

A 

is  a  permutation 

of 

the 

list 

(1, 

2, 

.  .  .  ,  m-1,  R[Al 

is  a  relation 

whose  domains 

are 

the 

same  as 

those 

of 

R 

except 

for 

a  change 

in  order 

of  appearance. 

In  Fig. 

2,  we   exhibit 

some  examples 

of  projection. 

Later 

we   shall 

make 

use  of 

the 

fact 

that 

projection 

provides 

an  algebraic 

counterpart 

to 

the 

existential 

quantifier. 

. 

. 

R(D,  D2  D3) 

a 

b 

C 

d 

e 

2 

1 

3 

3 

2 

f  

9 

f  

g 

f  

RI1 I@,  > 

R[zl(D, > 

R[31 (D, > 

f  

9 

R[Wl(D, 

f  

9 

f  

9 

D2) 

2 

1 

3 

3 

R[3;2,21@, 

D2 

O3) 

f  

9 

f  

9 

2 

1 

3 

3 

2 

1 

3 

3 

Figure 

2 

A  ternary 

relation 

R 

and 

five 

of 

its  many  projections. 

9 

2.3.3 

Join 

-  Let 

8  denote 

any  of 

the 

relations 

=, 

f, 

<,  5,  >,  and 

2. 

The 

o-join 

of 

relation 

R 

on  domain 

A  with 

relation 

S 

on  domain 

B 

is 

defined 

by 

R[A  8  B]S  =  {(r?): 

r  c  R  A  s  E  S  A  (r[A] 

0  s[bl)L 

providing 

every 

element 

of 

RCA] 

is  e-comparable 

with 

every 

element 

of 

S[B]. 

Note 

that 

x 

is  B-comparable 

with 

y 

if 

xey 

is  either 

true 

or 

false 

(not 

undefined). 

In  Fig. 

3,  we   exhibit 

some  examples 

of 

joins. 

R(A 
a 
a 

b 

c 
c 

B 
11 
2 

12 

2 
3 

C) 

1 

5 
3 

S(D 
2 
3 

4 

E) 
u 
v 
u 

R[C  =  C]S(A 
bl 
c 

B 

3 

C 
2 
3 

D 
2 
3 

E) 
u 
v 

R[B  =  D]S(A 
a 
c 
c 

B 
212 
2 
3 

C 

D 

5 
3 

2 
3 

E) 
u 
u 
v 

R[C  >  D]S(A 

c 
c 
c 
c 

B 

3 
2 
2 
2 

C 

3 
5 
5 
5 

D 

2 
2 
3 
4 

E) 

u 
u 
v 
u 

Figure 

3 

Relations 

R,S 

and 

three 

joins 

10 

Note 

that 

R[C  <  D]S  u  R[C  =  D]S  u  R[C  >  D]S  =  R  QD S. 

The  most 

commonly 

needed 

join 

is 

the 

join 

on 

=,  which  we   call 

the 

equi-join. 

In 

the 

case 

of 

the 

equi-join, 

two  of 

the 

domains 

of 

the 

resulting 

relation 

are 

identical 

in 

content. 

If  one  of 

the 

redundant 

domains 

is 

removed 

by  projection, 

the 

resu 

It 

is 

the 

natural 

join 

of 

the 

given 

relations 

as  defined 

in 

[2]. 

2.3.4 

Division 

-  Suppose 

T 

is  a  binary 

relation. 

The 

image 

set  of 

x 

under 

T 

is  defined 

by 

gT(‘)  =  {y:  b,y>  E  J-1. 

Consider 

the 

question 

of  dividing 

a  relation 

R 

of  degree 

m 

by  a  relation 

S 

of  degree 

n. 

Let 

A  be  a  domain-identifying 

for 

R,  and 

let 

?i 

denote 

the 

domain-identifying 

list 

list 

(without 

repetitions) 

that 

is 

complementary 

to 

A  and 

in  ascending 

order. 

For  example, 

if 

the 

degree 

m  of 

R  were  5 

and 

A  =  (2,5), 

then 

A  = 

(1,3,4). 

We  treat 

the 

dividend 

R 

as 

if 

it  were  a 

binary 

relation 

with 

the 

(possibly 

compound) 

domains 

K,  A 

in 

that 

order. 

Accordingl.y, 

given 

any 

tuple 

r  E  R,  we   can  speak 

of 

the,image 

set 

g,(r[K]), 

and  we   note 

that 

this 

is  a  subset 

of 

RCA]. 

Providing 

R[A] 

and 

S[B] 

are 

union-compatible, 

the  division 

of 

R  on 

. 

A 

by 

S 

on 

B 

is  defined 

by 

R[A 

t  B]S  = 

Ir[m: 

r  E  R  A  S[B] 

c_  g,(r[K])}. 

11 

Note 

that, 

when 

R 

is  empty, 

R  divided 

by 

S 

is  empty, 

even 

if 

S 

is 

also 

empty. 

In  Fig. 

4,  we   exhibit 

two  examples 

of  division. 

These 

examples 

show 

that 

projection 

on 

the 

dividend 

preceding 

division 

can  have  a  different 

effect 

from 

division 

followed 

by  projection 

on 

the 

quotient. 

R(A 
1 
2 

3 
4 

P 
11 
'11 

11 
12 

C) 
x 
y 

z 
x 

S(D 

X 

X 

Y 

0 
1 
2 

1 

R[B,C][C 

t  D]S  =  (111. 

Figure 

4 

Division 

of 

R 

by 

S 

Later 

we   shall 

see 

that 

division 

provides 

an  algebraic 

counterpart 

to 

the 

universal 

quantifier. 

operations 

already 

introduced: 

Actually, 
t 

division 

is  definable 

in 

terms 

of 

the 

R[C  +  D]S  =  R[a 

-((R[a 

@  S[D])- 

R)[a. 

2.3.5 

Restriction 

-  Suppose 

R 

is  a  relation 

and 

A,  B 

are  domain-identifying 

lists 

for 

R. 

Let 

8 

denote 

any  of 

the 

relations 

=, 

f, 

<, 

s,  >,  and 

2. 

The  e-restriction 

of 

R 

on  domains 

A,  B 

is  defined 

by 

R[A  8  B]  =  {r: 

r  E  R  A  (r[A] 

8  r[B])>, 

t 

This 

observation 

klas  made  by  Paul  Healey 

of 

IBY  Research, 

San 

Jose. 

12 

providing 

every 

element 

of 

R[A] 

is  &comparable 

with 

every 

element 

of 

R[B]. 

In  Fig. 

5,  we   exhibit 

two  examples 

of 

restriction. 

. 

RjA 

P 

9 

q 

r 

R[B  =  C](A 

r 

R[B  >  C](A 

P 

9 

B 

2 

2 

5 

3 

B 

3 

B 

2 

5 

C) 

1 

3 

4 

3 

C) 

3 

C) 

1 

4 

Figure 

5 

A  relation 

R 

and 

two  of 

its 

restrictions. 

This 

operation 

is 

introduced 

because 

of 

its 

direct 

use 

in  Section 

4. 

It 

is  definable 

in 

terms 

of 

the  B-join 

already 

introduced. 

Thus, 

R[A  0  B]  = 

(R& 

=A??](R[A][A 

8  B]R[B]))[L], 

where 

L 

is  a 

list 

identifying 

all 

the 

domains 

of 

R 

in  ascending 

order, 

and  A% 

denotes 

the 

concatenation 

of 

list 

A  with 

list 

B. 

The  e-join 

of 

R 

with 

S 

is 

likewise 

definable 

in 

terms 

of  Cartesian 

product 

and  e-restriction: 

R[A  8  B]S  = 

(R  8  S)[A  8  B]. 

13 

2.4 

Sample  Queries 

Suppose 

a  data 

base 

includes 

the 

following 

two 

relations: 

Symbol 

Relation 

Name 

Domain 

1 

Domain 

2 

Domain 

3 

S 

T 

suppliers 

SUPPlY 

supplier 

supplier 

f  

# 

supplier 

name 

location 

part 

# 

Table 

1  below 

lists 

nine 

queries, 

along 

with 

appropriate 

algebraic 

expressions 

E 

for 

them. 

n 

Find 

the 

supplier 

numbers 

of 

the 

suppliers 

each  of  whom  supplies: 

j  

1. 

2. 

3. 

4. 

5. 

6. 

7. 

8. 

9. 

Item 

j 

Something 

Nothing 

Part 

15 

Something, 

but 

not 

part 

15 

riot 

part 

15 

A  part 

other 

than 

15 

Part 

15  only 

At 

least 

parts 

12, 

13, 

15 

All 

parts 

supplied 

T[ll 
SC1 1  -  T[ll 

(T[2=1]{15} 

T[ll 
-0 
SD1  -0 

(T[Z=l](T[Z] 
043 
T[Z+l]{lZ, 

T[W]T 

Ej 

1 

-  115 ~>>>rN 

13, 

15) 

Table 

1 

Examples 

of  Algebraic 

Expressions 

14 

n 

Find 

the 

locations 

of 

those 

suppliers 

each  of  whom  supplies 

item 

j 

in 

the 

table 

above 

(S[l 

= 

lIEj)['I. 

These 

examples 

demonstrate 

that 

reasonably 

complicated 

queries 

can  be  concisely 

expressed 

in 

terms 

of 

the 

relational 

algebra. 

15 

3. 

RELATIONAL 

CALCULUS 

Having 

defined 

a  relational 

algebra, 

we   now  consider 

an  applied 

predicate 

calculus 

which  may  also 

be  used 

in 

the 

formulation 

of  queries 

on  any  data 

base 

consisting 

of  a 

finite 

collection 

of 

relations 

in 

simple 

normal 

form. 

3.1 

Alphabets, 

Terms, 

and  Formulae 

The  alphabets 

for 

this 

calculus 

are 

listed 

in  Table 

2  below: 

Individual 

Constants 

Index 

Constants 

Tuple 

Variables 

Predicate 

Constants 

monadic 

d,yadic 

Logical 

Symbols 

Delimiters 

a,, 

a2, 

a3¶ 

..+ 

1,  2,  3,  4, 

.  .  . 

r,, 

r2, 

r3, 

.  .  . 

P,' 

P*, 

P3' 

**a 

=, 

<,  >, 

I, 

2,  # 

"91 

3,  v,  A, 
Cl 
0 

9 

Table 

2 

The  Alphabets 

of 

the  Relational 

Calculus 

Under 

the 

intended 

interpretation, 

a  one-to-one 

correspondence 

is 

established 

between 

the  monadic 

predicates 

(as  many  as  are  needed) 

and 

the 

relations 

in 

the 

given 

data 

base. 

Suppose 

the 

relations 

are 

R,,  R2, 

Then, 

Pj 

indicates 

membership 

of 

tuples 

in 

relation 

Rj 

(j 

=  1,  2, 

A  monadic 

predicate 

followed 

by  a 

tuple 

variable 

is 

called 

a  range 

term. 

The 

range 

term 

Pjr 

is 

interpreted 

as  stating 

that 

tuple 

variable 

r 

has 

relation 

as 

its 

range. 

R. 
J 

.  .  .  .  RN' 
.  .  .  .  N). 

16 

An 

indexed 

tuple 

has 

the 

form 

r[N] 

where 

r 

is  a 

tuple 

variable 

and 

N 

is  an 

index 

constant. 

Its 

purpose 

is 

to 

identify 

the 

Nth 

component 

of  a 

tuple 

r. 

Let 

6 

be  one  of 

the 

predicate 

symbols 

=, 

f, 

<,  5,  >,  and 

2. 

Let 

X,n 

be 

indexed 

tuples 

and 

cx  an 

individual 

constant. 

Then, 

A@J  and 

XBa 

are 

called 

join 

terms. 

The 

terms 

of 

the 

relational 

calculus 

are  of  only 

two 

types: 

range 

terms 

and 

join 

terms. 

The  well-formed 

formulae 

(abbreviated 

WFF)  of 

the 

relational 

calculus 

are  defined 

recursively 

as 

follows: 

1. 

2. 

3. 

4. 

Any 

term 

is  a  WFF; 

If 

If 

If 

r 

is  a  WFF,  so 

is 

1I'; 

I-1, 

r2 

are  WFFs, 

so  are 

(T, 

v  r2) 

and 

(r, 

A  r2); 

r 

is  a  WFF  in  which 

r 

occurs 

as  a 

free 

variable, 

then 

3r(r) 

and  Wr(r) 

are  WFFs; 

5. 

No  other 

formulae 

are  WFFs. 

The  usual 

conventions 

are 

adopted 

for 

saving 

parentheses 

and  avoiding 

duplicate 

use  of  bound 

variables. 

Table 

3  gives 

examples 

of  WFFs  of 

the 

relational 

calculus. 

17 

WFFs  with 

no 

range 

terms 

r,Dl  > al 

3r,  (r,  C31  >  al  1 
3q  (r,  i31  =  r&W 
A (r&l1  =  a$) 
Vr,3r2((r, 
IiS1  =  r$l) 
(r,C31  =  r,CW  A 3r3h$11  =  al > 

WFFs  with 

range 

terms 

only 

‘gr3 

‘gr3  A  P7r2 

‘f3 
P5r3 

” 
‘sr3 
A  lP6r3 

Range-Separable 

WFFs 

P8r, 

*  (r, 

[31  =  al  > 

P7r2 

*  C-y-, 

(r,  C31  =  r2K-4 

WFFs  not  Range-Separable 

b-g, 

v 

(r,  C31  =  al  1 

P7r2 

A  3r,Ur, 

[31  =  r21N) 

v  Qf,) 

lP8r, 

*  (r,C31 

=  al  1 

Free  Variables 

rl 
none 

r2 
none 

'v2 

rl 

r2 

rl 

r2 

rl 

Table 

3 

Examples 

of  WFFs  of 

the  Relational 

Calculus 

18 

3.2 

Range  Separability 

With 

each 

tuple 

variable 

in  a  WFF,  we   need 

to  associate 

a  clearly 

defined 

' 

range. 

The 

following 

definitions 

are 

aimed 

at 

this 

goal. 

A  range  WFF  is  a  quantifier-free 

WFF,  all 

of  whose 

terms 

are 

range 

terms. 

A  range  WFF  over 
-- 

r 
- 

is  a  range  WFF  whose  only 

free 

variable 

is 

r. 

A 

proper 

range  WFF  over 

r 

is  a  range  WFF  over 

r 

satisfying 

two  constraints: 

the 

syntactic 

constraint 

that 

either 

1 

does 

not  occur 

at  all 

or 

that 

it 

immediately 

follows 

A;  and 

the 

semantic 

constraint 

that, 

whenever 

r 

occurs 

in 

two  or 

more 

range 

terms, 

the 

range 

predicates 

in 

those 

terms  must 

be  associated 

with 

relations 

which 

are  union-compatible. 

The 

syntactic 

constraint 

prohibits 

specifying 

the 

range 

of  a 

tuple 

variable 

r 

by  merely 

stating 

that 

relation 

R 

(say) 

is  not 

the 

range 

of 

r. 

The 

two  constraints 

together 

prohibit 

tuple 

variables 

from 

having 

ranges 

which 

are  other 

than 

the 

given 

relations 

or 

rela- 

tions 

which 

can  be  generated 

from 

them 

by  applying 

union, 

intersection, 

and 

difference 

to  union-compatible 

pairs 

of 

relations. 

Both 

bound 

and 

free 

variables 

must 

have 

clearly 

defined 

ranges. 

Suppose 

A 

is  a  WFF  having 

r 

as  a 

free 

variable, 

but 

containing 

no 

range 

term 

in 

r. 

Let 

r 

be  a  proper 

range  WFF  over 

r. 

To 

introduce 

r 

into 

Ir(A) 

or 

Vr(A), 

we   replace 

3r 

by 

3rr, 

and 

Vr 

by  Wrr. 

These 

are 

called 

range-coupled 

quantifiers 

and  are  defined 

by 

the  equations: 

W(A)  =  3r(r  A a) 

VI’(A) 

=  Wr(lr 

v  A). 

Now,  we   can  define 

a  class 

of  WFFs  having 

clearly 

defined 

ranges 

for 

all 

its 

variables. 

A  WFF  is 

range-separable 

if 

it 

is  a  conjunction 

of 

the 

form 

19 

where 

1) 

2) 

u,  A u* A  . . .  A un A  v, 

nzl; 

u, 

through 

Un 

are 

proper 

range  WFFs  over 

n 

distinct 

tuple 

variables; 

3) 

V 

is  either 

null 

(in  which 

case 

the 

formula 

is 

simply 

u, 

*  u2" 

.  .  .  A  un), 

or 

it 

is  a  WFF  with 

the 

three 

properties: 

a) 

b) 

every 

quantifier 

in 

V 

is 

range-coupled; 

every 

free 

variable 

in 

V  belongs 

to 

the 

set  whose 

ranges 

are 

specified 

by  U,,  U2, 

.  .  .  ,  un; 

c) 

V 

is  devoid 

of 

range 

terms. 

One  consequence 

of 

these 

requirements 

if 

that 

a  range-separable 

wFF  

has  at 

least 

one 

free 

variable. 

3.3 

Alpha 

Expressions 

If 

the 

range-separable 

WFFs  of 

the 

relational 

calculus 

were  used  as 

relation-defining 

expressions 

without 

further 

augmentation, 

they  would 

lack 

the  much-needed 

capability 

of  defining 

projections 

of 

relations. 

Accordingly, 

we   consider 

simple 

alpha 

expressions 

of 

the 

form 

(t,, 

t2’ 

***,  $1 

:  w 

where 

1) 

2) 

w  

is  a  range-separable 

WFF  of 

the 

relational 

calculus; 

t,, 

tp 

.  .  .  , 

tk 

are  distinct 

terms, 

each 

consisting 

of  a 

tuple 

variable 

or  an 

indexed 

tuple 

variable; 

20 

3) 

the 

set 

of 

tuple 

variables 

occurring 

in 

t,, 

t2, 

.  .  .  . 

tk 

is 

precisely 

the 

set  of 

free 

variables 

in 

w .  

Set 

brackets 

{  1 

are  omitted 

because 

they 

are 

syntactically 

superfluous. 

The 

list 

(t,, 

t2, 

.  .  .  . 

tk) 

is 

called 

the 

target 

list 

and 

w  

the  qualification 

expression. 

Suppose 

pl  y  p2, 

their 

first 

occurrence 

.  .  .  ,  on 
in 
the 

are 

the 

distinct 

tuple 

variables 

in  order 

of 

target 

list 

of  a  simple 

alpha 

expression 

z: 

z  =  (t,, 

t2’ 

***, 

t,) 

:  w .  

Suppose 

that 

relations 

S,, 

S2, 

.  .  .  .  Sn 

(not 

necessarily 

distinct) 

are 

the 

ranges 

of 

q, 

p2, 

.  .  .  , 

jection 

of 

that 

subset 

'rt' 
of 

respectively. 

Then, 

z 

denotes 

a  certain 

pro- 

S,  @  S2  @I  .  .  .  @  Sn  whose  elements 

satisfy 

the 

qualification 

expression 

w .  

The  projection 

in  question 

is 

indicated 

in  an 

obvious 

way   by 

the 

indices 

associated 

with 

the 

tuple 

variables. 

Now  follow 

examples 

of  queries 

in 

the 

form 

of  simple 

alpha 

expressions. 

The  data 

base  of  Section 

2.4 

is  assumed. 

Predicates 

pl' 

p2 

are 

the 

range 

predicates 

for 

relations 

S  (suppliers) 

and 

T 

(supply), 

respectively. 

8 

8 

Find 

the 

supplier 

number 

of 

those 

suppliers 

who  supply 

part 

15. 

r2D  1  :  P,r2 
,_ 

A  (r,[2] 

=  15). 

Find 

the 

supplier 

numbers 

of 

those 

suppliers 

who  supply 

something 

other 

than 

part 

15. 

r2D  1  :  P2r2 

h  (r2[2] 

#  15). 

21 

8 

Find 

the 

supplier 

names 

and 

locations 

of 

those 

suppliers 

who  supply 

part 

15. 

(r,[Z], 

r,[3]): 

P,r, 

A  JP2r2(r2[2] 

=  15  A  r,[lJ 

=  r,[l]). 

n 

Find 

the 

locations 

of  suppliers 

and 

the  parts 

being 

supplied 

b.v 

them 

(omitting 

those 

suppliers 

who  are 

supplying 

no  parts 

at 

this 

time). 

(r,[3], 

r,[Z]): 

P,r, 

A  P2r2 

A  (r,[l] 

=  r2[1]). 

The 

concept 

of 

simple 

alpha 

expression 

can  be  generalized 

without 

losing 

its 

desirable 

range 

properties. 

An  alpha 

expression 

is 

recursively 

defined 

as 

follows: 

1) 

2) 

Every 

simple 

alpha 

expression 

is  an  alpha 

expression; 

If 

t:  w ,  

and 

t:  w2  

are  alpha 

expressions, 

so  are 

t: 

t: 

t: 

(w ,  

v  w2 )  

(w ,   A  lw2) 

(w ,   A  w,); 

3) 

No  other 

expressions 

are  alpha 

expressions. 

While 

it 

is  doubtful 

that  many  queries 

will 

attain 

the 

complexity 

of  alpha 

expressions 

of 

the 

non-simple 

kind, 

it  would 

be  artificial 

to  exclude 

them 

from 

the 

theory. 

3.4 

Relational 

Completeness 

Now  we   can 

introduce 

a  basic 

notion 

of  selective 

power. 

An  algebra 

or 

calculus 

is 

relationally 

complete 

if, 

given 

any 

finite 

collection 

of 

relations 

22 

R,,  R2, 

calculus 

. .  . .  RN 
permit 

in 

simple 

normal 

form, 

the 

expressions 

of 

the 

algebra 

or 

definition 

of  any 

relation 

definable 

from 

R,,  R2, 

.  .  .  .  RN 

by  alpha 

expressions 

(using 

a  set 

of 

N 

range 

predicates 

in  one-to-one 

correspondence 

with 

R,,  R2, 

.  .  .  ,  RN). 

We  shall 

apply 

this 

notion 

in  Section 

4 

to 

the 

algebra 

of  Section 

2. 

Foundations and Trends R(cid:1) in
Databases
Vol. 1, No. 2 (2007) 141–259
c(cid:1) 2007 J. M. Hellerstein, M. Stonebraker
and J. Hamilton
DOI: 10.1561/1900000002

Architecture of a Database System

Joseph M. Hellerstein1 , Michael Stonebraker2
and James Hamilton3

1 University of California, Berkeley, USA, hel lerstein@cs.berkeley.edu
2 Massachusetts Institute of Technology, USA
3 Microsoft Research, USA

Abstract

Database Management Systems (DBMSs) are a ubiquitous and critical
component of modern computing, and the result of decades of research
and development in both academia and industry. Historically, DBMSs
were among the earliest multi-user server systems to be developed, and
thus pioneered many systems design techniques for scalability and relia-
bility now in use in many other contexts. While many of the algorithms
and abstractions used by a DBMS are textbook material, there has been
relatively sparse coverage in the literature of the systems design issues
that make a DBMS work. This paper presents an architectural dis-
cussion of DBMS design principles, including process models, parallel
architecture, storage system design, transaction system implementa-
tion, query processor and optimizer architectures, and typical shared
components and utilities. Successful commercial and open-source sys-
tems are used as points of reference, particularly when multiple alter-
native designs have been adopted by diﬀerent groups.

1
Introduction

Database Management Systems (DBMSs) are complex, mission-critical
software systems. Today’s DBMSs embody decades of academic
and industrial research and intense corporate software development.
Database systems were among the earliest widely deployed online server
systems and, as such, have pioneered design solutions spanning not only
data management, but also applications, operating systems, and net-
worked services. The early DBMSs are among the most inﬂuential soft-
ware systems in computer science, and the ideas and implementation
issues pioneered for DBMSs are widely copied and reinvented.
For a number of reasons, the lessons of database systems architec-
ture are not as broadly known as they should be. First, the applied
database systems community is fairly small. Since market forces only
support a few competitors at the high end, only a handful of successful
DBMS implementations exist. The community of people involved in
designing and implementing database systems is tight: many attended
the same schools, worked on the same inﬂuential research pro jects, and
collaborated on the same commercial products. Second, academic treat-
ment of database systems often ignores architectural issues. Textbook
presentations of database systems traditionally focus on algorithmic

142

1.1 Relational Systems: The Life of a Query

143

and theoretical issues — which are natural to teach, study, and test —
without a holistic discussion of system architecture in full implementa-
tions. In sum, much conventional wisdom about how to build database
systems is available, but little of it has been written down or commu-
nicated broadly.
In this paper, we attempt to capture the main architectural aspects
of modern database systems, with a discussion of advanced topics. Some
of these appear in the literature, and we provide references where appro-
priate. Other issues are buried in product manuals, and some are simply
part of the oral tradition of the community. Where applicable, we use
commercial and open-source systems as examples of the various archi-
tectural forms discussed. Space prevents, however, the enumeration of
the exceptions and ﬁner nuances that have found their way into these
multi-million line code bases, most of which are well over a decade old.
Our goal here is to focus on overall system design and stress issues
not typically discussed in textbooks, providing useful context for more
widely known algorithms and concepts. We assume that the reader
is familiar with textbook database systems material (e.g., [72] or [83])
and with the basic facilities of modern operating systems such as UNIX,
Linux, or Windows. After introducing the high-level architecture of a
DBMS in the next section, we provide a number of references to back-
ground reading on each of the components in Section 1.2.

1.1 Relational Systems: The Life of a Query

The most mature and widely used database systems in production
today are relational database management systems (RDBMSs). These
systems can be found at the core of much of the world’s application
infrastructure including e-commerce, medical records, billing, human
resources, payroll, customer relationship management and supply chain
management, to name a few. The advent of web-based commerce and
community-oriented sites has only increased the volume and breadth of
their use. Relational systems serve as the repositories of record behind
nearly all online transactions and most online content management sys-
tems (blogs, wikis, social networks, and the like). In addition to being
important software infrastructure, relational database systems serve as

144 Introduction

Fig. 1.1 Main components of a DBMS.

a well-understood point of reference for new extensions and revolutions
in database systems that may arise in the future. As a result, we focus
on relational database systems throughout this paper.
At heart, a typical RDBMS has ﬁve main components, as illustrated
in Figure 1.1. As an introduction to each of these components and the
way they ﬁt together, we step through the life of a query in a database
system. This also serves as an overview of the remaining sections of the
paper.
Consider a simple but typical database interaction at an airport, in
which a gate agent clicks on a form to request the passenger list for a
ﬂight. This button click results in a single-query transaction that works
roughly as follows:

1. The personal computer at the airport gate (the “client”) calls
an API that in turn communicates over a network to estab-
lish a connection with the Client Communications Manager
of a DBMS (top of Figure 1.1). In some cases, this connection

1.1 Relational Systems: The Life of a Query

145

is established between the client and the database server
directly, e.g., via the ODBC or JDBC connectivity protocol.
This arrangement is termed a “two-tier” or “client-server”
system. In other cases, the client may communicate with
a “middle-tier server” (a web server, transaction process-
ing monitor, or the like), which in turn uses a protocol to
proxy the communication between the client and the DBMS.
This is usually called a “three-tier” system. In many web-
based scenarios there is yet another “application server” tier
between the web server and the DBMS, resulting in four
tiers. Given these various options, a typical DBMS needs
to be compatible with many diﬀerent connectivity protocols
used by various client drivers and middleware systems. At
base, however, the responsibility of the DBMS’ client com-
munications manager in all these protocols is roughly the
same: to establish and remember the connection state for
the caller (be it a client or a middleware server), to respond
to SQL commands from the caller, and to return both data
and control messages (result codes, errors, etc.) as appro-
priate. In our simple example, the communications manager
would establish the security credentials of the client, set up
state to remember the details of the new connection and the
current SQL command across calls, and forward the client’s
ﬁrst request deeper into the DBMS to be processed.
2. Upon receiving the client’s ﬁrst SQL command, the DBMS
must assign a “thread of computation” to the command. It
must also make sure that the thread’s data and control out-
puts are connected via the communications manager to the
client. These tasks are the job of the DBMS Process Man-
ager (left side of Figure 1.1). The most important decision
that the DBMS needs to make at this stage in the query
regards admission control : whether the system should begin
processing the query immediately, or defer execution until a
time when enough system resources are available to devote
to this query. We discuss Process Management in detail in
Section 2.

146 Introduction

3. Once admitted and allocated as a thread of control, the gate
agent’s query can begin to execute. It does so by invoking the
code in the Relational Query Processor (center, Figure 1.1).
This set of modules checks that the user is authorized to run
the query, and compiles the user’s SQL query text into an
internal query plan. Once compiled, the resulting query plan
is handled via the plan executor. The plan executor consists
of a suite of “operators” (relational algorithm implementa-
tions) for executing any query. Typical operators implement
relational query processing tasks including joins, selection,
pro jection, aggregation, sorting and so on, as well as calls
to request data records from lower layers of the system. In
our example query, a small subset of these operators — as
assembled by the query optimization process — is invoked to
satisfy the gate agent’s query. We discuss the query processor
in Section 4.
4. At the base of the gate agent’s query plan, one or more
operators exist to request data from the database. These
operators make calls to fetch data from the DBMS’ Trans-
actional Storage Manager (Figure 1.1, bottom), which man-
ages all data access (read) and manipulation (create, update,
delete) calls. The storage system includes algorithms and
data structures for organizing and accessing data on disk
(“access methods”), including basic structures like tables
and indexes. It also includes a buﬀer management mod-
ule that decides when and what data to transfer between
disk and memory buﬀers. Returning to our example, in the
course of accessing data in the access methods, the gate
agent’s query must invoke the transaction management code
to ensure the well-known “ACID” properties of transactions
[30] (discussed in more detail in Section 5.1). Before access-
ing data, locks are acquired from a lock manager to ensure
correct execution in the face of other concurrent queries. If
the gate agent’s query involved updates to the database, it
would interact with the log manager to ensure that the trans-
action was durable if committed, and fully undone if aborted.

1.1 Relational Systems: The Life of a Query

147

In Section 5, we discuss storage and buﬀer management in
more detail; Section 6 covers the transactional consistency
architecture.
5. At this point in the example query’s life, it has begun to
access data records, and is ready to use them to compute
results for the client. This is done by “unwinding the stack”
of activities we described up to this point. The access meth-
ods return control to the query executor’s operators, which
orchestrate the computation of result tuples from database
data; as result tuples are generated, they are placed in a
buﬀer for the client communications manager, which ships
the results back to the caller. For large result sets, the
client typically will make additional calls to fetch more data
incrementally from the query, resulting in multiple itera-
tions through the communications manager, query execu-
tor, and storage manager. In our simple example, at the end
of the query the transaction is completed and the connec-
tion closed; this results in the transaction manager cleaning
up state for the transaction, the process manager freeing
any control structures for the query, and the communi-
cations manager cleaning up communication state for the
connection.

Our discussion of this example query touches on many of the key
components in an RDBMS, but not all of them. The right-hand side
of Figure 1.1 depicts a number of shared components and utilities
that are vital to the operation of a full-function DBMS. The catalog
and memory managers are invoked as utilities during any transaction,
including our example query. The catalog is used by the query proces-
sor during authentication, parsing, and query optimization. The mem-
ory manager is used throughout the DBMS whenever memory needs
to be dynamically allocated or deallocated. The remaining modules
listed in the rightmost box of Figure 1.1 are utilities that run indepen-
dently of any particular query, keeping the database as a whole well-
tuned and reliable. We discuss these shared components and utilities in
Section 7.

148 Introduction

1.2 Scope and Overview

In most of this paper, our focus is on architectural fundamentals sup-
porting core database functionality. We do not attempt to provide a
comprehensive review of database algorithmics that have been exten-
sively documented in the literature. We also provide only minimal dis-
cussion of many extensions present in modern DBMSs, most of which
provide features beyond core data management but do not signiﬁcantly
alter the system architecture. However, within the various sections of
this paper we note topics of interest that are beyond the scope of the
paper, and where possible we provide pointers to additional reading.
We begin our discussion with an investigation of the overall archi-
tecture of database systems. The ﬁrst topic in any server system archi-
tecture is its overall process structure, and we explore a variety of viable
alternatives on this front, ﬁrst for uniprocessor machines and then for
the variety of parallel architectures available today. This discussion of
core server system architecture is applicable to a variety of systems,
but was to a large degree pioneered in DBMS design. Following this,
we begin on the more domain-speciﬁc components of a DBMS. We start
with a single query’s view of the system, focusing on the relational query
processor. Following that, we move into the storage architecture and
transactional storage management design. Finally, we present some of
the shared components and utilities that exist in most DBMSs, but are
rarely discussed in textbooks.

2
Process Models

When designing any multi-user server, early decisions need to be made
regarding the execution of concurrent user requests and how these are
mapped to operating system processes or threads. These decisions have
a profound inﬂuence on the software architecture of the system, and on
its performance, scalability, and portability across operating systems.1
In this section, we survey a number of options for DBMS process mod-
els, which serve as a template for many other highly concurrent server
systems. We begin with a simpliﬁed framework, assuming the availabil-
ity of good operating system support for threads, and we initially target
only a uniprocessor system. We then expand on this simpliﬁed discus-
sion to deal with the realities of how modern DBMSs implement their
process models. In Section 3, we discuss techniques to exploit clusters
of computers, as well as multi-processor and multi-core systems.
The discussion that follows relies on these deﬁnitions:
• An Operating System Process combines an operating system
(OS) program execution unit (a thread of control) with an

1 Many but not all DBMSs are designed to be portable across a wide variety of host operating
systems. Notable examples of OS-speciﬁc DBMSs are DB2 for zSeries and Microsoft SQL
Server. Rather than using only widely available OS facilities, these products are free to
exploit the unique facilities of their single host.

149

150 Process Models

address space private to the process. Included in the state
maintained for a process are OS resource handles and the
security context. This single unit of program execution is
scheduled by the OS kernel and each process has its own
unique address space.
• An Operating System Thread is an OS program execution
unit without additional private OS context and without a
private address space. Each OS thread has full access to the
memory of other threads executing within the same multi-
threaded OS Process. Thread execution is scheduled by the
operating system kernel scheduler and these threads are often
called “kernel threads” or k-threads.
• A Lightweight Thread Package is an application-level con-
struct that supports multiple threads within a single OS
process. Unlike OS threads scheduled by the OS, lightweight
threads are scheduled by an application-level thread sched-
uler. The diﬀerence between a lightweight thread and a
kernel thread is that a lightweight thread is scheduled in
user-space without kernel scheduler involvement or knowl-
edge. The combination of the user-space scheduler and all of
its lightweight threads run within a single OS process and
appears to the OS scheduler as a single thread of execution.
Lightweight threads have the advantage of faster thread
switches when compared to OS threads since there is no
need to do an OS kernel mode switch to schedule the next
thread. Lightweight threads have the disadvantage, how-
ever, that any blocking operation such as a synchronous
I/O by any thread will block all threads in the process.
This prevents any of the other threads from making progress
while one thread is blocked waiting for an OS resource.
Lightweight thread packages avoid this by (1) issuing only
asynchronous (non-blocking) I/O requests and (2) not
invoking any OS operations that could block. Generally,
lightweight threads oﬀer a more diﬃcult programming model
than writing software based on either OS processes or OS
threads.

151
• Some DBMSs implement their own lightweight thread
(LWT) packages. These are a special case of general LWT
packages. We refer to these threads as DBMS threads
and simply threads when the distinction between DBMS,
general LWT, and OS threads are unimportant to the
discussion.
• A DBMS Client is the software component that implements
the API used by application programs to communicate with
a DBMS. Some example database access APIs are JDBC,
ODBC, and OLE/DB. In addition, there are a wide vari-
ety of proprietary database access API sets. Some programs
are written using embedded SQL, a technique of mixing pro-
gramming language statements with database access state-
ments. This was ﬁrst delivered in IBM COBOL and PL/I
and, much later,
in SQL/J which implements embedded
SQL for Java. Embedded SQL is processed by preproces-
sors that translate the embedded SQL statements into direct
calls to data access APIs. Whatever the syntax used in
the client program, the end result is a sequence of calls
to the DBMS data access APIs. Calls made to these APIs
are marshaled by the DBMS client component and sent to
the DBMS over some communications protocol. The proto-
cols are usually proprietary and often undocumented. In the
past, there have been several eﬀorts to standardize client-to-
database communication protocols, with Open Group DRDA
being perhaps the best known, but none have achieved broad
adoption.
• A DBMS Worker is the thread of execution in the DBMS
that does work on behalf of a DBMS Client. A 1:1 map-
ping exists between a DBMS worker and a DBMS Client:
the DBMS worker handles all SQL requests from a single
DBMS Client. The DBMS client sends SQL requests to the
DBMS server. The worker executes each request and returns
the result to the client. In what follows, we investigate the
diﬀerent approaches commercial DBMSs use to map DBMS
workers onto OS threads or processes. When the distinction is

152 Process Models

signiﬁcant, we will refer to them as worker threads or worker
processes. Otherwise, we refer to them simply as workers or
DBMS workers.

2.1 Uniprocessors and Lightweight Threads

In this subsection, we outline a simpliﬁed DBMS process model taxon-
omy. Few leading DBMSs are architected exactly as described in this
section, but the material forms the basis from which we will discuss cur-
rent generation production systems in more detail. Each of the leading
database systems today is, at its core, an extension or enhancement of
at least one of the models presented here.
We start by making two simplifying assumptions (which we will
relax in subsequent sections):

1. OS thread support : We assume that the OS provides us with
eﬃcient support for kernel threads and that a process can
have a very large number of threads. We also assume that
the memory overhead of each thread is small and that the
context switches are inexpensive. This is arguably true on
a number of modern OS today, but was certainly not true
when most DBMSs were ﬁrst designed. Because OS threads
either were not available or scaled poorly on some platforms,
many DBMSs are implemented without using the underlying
OS thread support.
2. Uniprocessor hardware : We will assume that we are design-
ing for a single machine with a single CPU. Given the ubiq-
uity of multi-core systems, this is an unrealistic assumption
even at the low end. This assumption, however, will simplify
our initial discussion.

In this simpliﬁed context, a DBMS has three natural process model
options. From the simplest to the most complex, these are: (1) process
per DBMS worker, (2) thread per DBMS worker, and (3) process pool.
Although these models are simpliﬁed, all three are in use by commercial
DBMS systems today.

2.1 Uniprocessors and Lightweight Threads

153

2.1.1 Process per DBMS Worker

The process per DBMS worker model (Figure 2.1) was used by early
DBMS implementations and is still used by many commercial systems
today. This model is relatively easy to implement since DBMS work-
ers are mapped directly onto OS processes. The OS scheduler man-
ages the timesharing of DBMS workers and the DBMS programmer
can rely on OS protection facilities to isolate standard bugs like mem-
ory overruns. Moreover, various programming tools like debuggers and
memory checkers are well-suited to this process model. Complicating
this model are the in-memory data structures that are shared across
DBMS connections, including the lock table and buﬀer pool (discussed
in more detail in Sections 6.3 and 5.3, respectively). These shared data
structures must be explicitly allocated in OS-supported shared memory
accessible across all DBMS processes. This requires OS support (which
is widely available) and some special DBMS coding. In practice, the

Fig. 2.1 Process per DBMS worker model: each DBMS worker is implemented as an OS
process.

154 Process Models

required extensive use of shared memory in this model reduces some of
the advantages of address space separation, given that a good fraction
of “interesting” memory is shared across processes.
In terms of scaling to very large numbers of concurrent connections,
process per DBMS worker is not the most attractive process model. The
scaling issues arise because a process has more state than a thread and
consequently consumes more memory. A process switch requires switch-
ing security context, memory manager state, ﬁle and network handle
tables, and other process context. This is not needed with a thread
switch. Nonetheless, the process per DBMS worker model remains pop-
ular and is supported by IBM DB2, PostgreSQL, and Oracle.

2.1.2 Thread per DBMS Worker

In the thread per DBMS worker model (Figure 2.2), a single multi-
threaded process hosts all the DBMS worker activity. A dispatcher

Fig. 2.2 Thread per DBMS worker model: each DBMS worker is implemented as an OS
thread.

2.1 Uniprocessors and Lightweight Threads

155

thread (or a small handful of such threads) listens for new DBMS client
connections. Each connection is allocated a new thread. As each client
submits SQL requests, the request is executed entirely by its corre-
sponding thread running a DBMS worker. This thread runs within the
DBMS process and, once complete, the result is returned to the client
and the thread waits on the connection for the next request from that
same client.
The usual multi-threaded programming challenges arise in this
architecture: the OS does not protect threads from each other’s mem-
ory overruns and stray pointers; debugging is tricky, especially with
race conditions; and the software can be diﬃcult to port across OS due
to diﬀerences in threading interfaces and multi-threaded scaling. Many
of the multi-programming challenges of the thread per DBMS worker
model are also found in the process per DBMS worker model due to
the extensive use of shared memory.
Although thread API diﬀerences across OSs have been minimized
in recent years, subtle distinctions across platforms still cause hassles in
debugging and tuning. Ignoring these implementation diﬃculties, the
thread per DBMS worker model scales well to large numbers of con-
current connections and is used in some current-generation production
DBMS systems, including IBM DB2, Microsoft SQL Server, MySQL,
Informix, and Sybase.

2.1.3 Process Pool

This model is a variant of process per DBMS worker. Recall that the
advantage of process per DBMS worker was its implementation sim-
plicity. But the memory overhead of each connection requiring a full
process is a clear disadvantage. With process pool (Figure 2.3), rather
than allocating a full process per DBMS worker, they are hosted by a
pool of processes. A central process holds all DBMS client connections
and, as each SQL request comes in from a client, the request is given to
one of the processes in the process pool. The SQL Statement is executed
through to completion, the result is returned to the database client, and
the process is returned to the pool to be allocated to the next request.
The process pool size is bounded and often ﬁxed. If a request comes in

156 Process Models

Fig. 2.3 Process Pool: each DBMS Worker is allocated to one of a pool of OS processes
as work requests arrive from the Client and the process is returned to the pool once the
request is processed.

and all processes are already servicing other requests, the new request
must wait for a process to become available.
Process pool has all of the advantages of process per DBMS worker
but, since a much smaller number of processes are required, is consid-
erably more memory eﬃcient. Process pool is often implemented with
a dynamically resizable process pool where the pool grows potentially
to some maximum number when a large number of concurrent requests
arrive. When the request load is lighter, the process pool can be reduced
to fewer waiting processes. As with thread per DBMS worker, the pro-
cess pool model is also supported by a several current generation DBMS
in use today.

2.1.4 Shared Data and Process Boundaries

All models described above aim to execute concurrent client requests
as independently as possible. Yet, full DBMS worker independence and
isolation is not possible, since they are operating on the same shared

2.1 Uniprocessors and Lightweight Threads

157

database. In the thread per DBMS worker model, data sharing is easy
with all threads run in the same address space. In other models, shared
memory is used for shared data structures and state. In all three mod-
els, data must be moved from the DBMS to the clients. This implies
that all SQL requests need to be moved into the server processes and
that all results for return to the client need to be moved back out.
How is this done? The short answer is that various buﬀers are used.
The two ma jor types are disk I/O buﬀers and client communication
buﬀers. We describe these buﬀers here, and brieﬂy discuss policies for
managing them.
Disk I/O buﬀers : The most common cross-worker data dependencies
are reads and writes to the shared data store. Consequently, I/O inter-
actions between DBMS workers are common. There are two sepa-
rate disk I/O scenarios to consider: (1) database requests and (2) log
requests.
• Database I/O Requests: The Buﬀer Pool. All persistent
database data is staged through the DBMS buﬀer pool
(Section 5.3). With thread per DBMS worker, the buﬀer
pool is simply a heap-resident data structure available to
all threads in the shared DBMS address space. In the other
two models, the buﬀer pool is allocated in shared memory
available to all processes. The end result in all three DBMS
models is that the buﬀer pool is a large shared data struc-
ture available to all database threads and/or processes. When
a thread needs a page to be read in from the database, it
generates an I/O request specifying the disk address, and a
handle to a free memory location (frame ) in the buﬀer pool
where the result can be placed. To ﬂush a buﬀer pool page
to disk, a thread generates an I/O request that includes the
page’s current frame in the buﬀer pool, and its destination
address on disk. Buﬀer pools are discussed in more detail in
Section 4.3.
• Log I/O Requests: The Log Tail. The database
log
(Section 6.4) is an array of entries stored on one or
more disks. As log entries are generated during transaction

158 Process Models

processing, they are staged to an in-memory queue that
is periodically ﬂushed to the log disk(s) in FIFO order.
This queue is usually called the log tail. In many systems,
a separate process or thread is responsible for periodically
ﬂushing the log tail to the disk.
With thread per DBMS worker, the log tail is simply
a heap-resident data structure. In the other two models,
two diﬀerent design choices are common. In one approach,
a separate process manages the log. Log records are com-
municated to the log manager by shared memory or any
other eﬃcient inter-process communications protocol. In the
other approach, the log tail is allocated in shared memory
in much the same way as the buﬀer pool was handled
above. The key point is that all threads and/or processes
executing database client requests need to be able to
request that log records be written and that the log tail be
ﬂushed.
An important type of log ﬂush is the commit transaction
ﬂush. A transaction cannot be reported as successfully
committed until a commit log record is ﬂushed to the log
device. This means that client code waits until the commit
log record is ﬂushed, and that DBMS server code must
hold all resources (e.g., locks) until that time as well. Log
ﬂush requests may be postponed for a time to allow the
batching of commit records in a single I/O request (“group
commit”).

Client communication buﬀers : SQL is typically used in a “pull” model:
clients consume result tuples from a query cursor by repeatedly issuing
the SQL FETCH request, which retrieve one or more tuples per request.
Most DBMSs try to work ahead of the stream of FETCH requests to
enqueue results in advance of client requests.
In order to support this prefetching behavior, the DBMS worker
may use the client communications socket as a queue for the tuples
it produces. More complex approaches implement client-side cursor
caching and use the DBMS client to store results likely to be fetched

2.2 DBMS Threads

159

in the near future rather than relying on the OS communications
buﬀers.

Lock table : The lock table is shared by all DBMS workers and is
used by the Lock Manager (Section 6.3) to implement database lock-
ing semantics. The techniques for sharing the lock table are the same
as those of the buﬀer pool and these same techniques can be used
to support any other shared data structures needed by the DBMS
implementation.

2.2 DBMS Threads

The previous section provided a simpliﬁed description of DBMS process
models. We assumed the availability of high-performance OS threads
and that the DBMS would target only uniprocessor systems. In the
remainder of this section, we relax the ﬁrst of those assumptions and
describe the impact on DBMS implementations. Multi-processing and
parallelism are discussed in the next section.

2.2.1 DBMS Threads

Most of today’s DBMSs have their roots in research systems from the
1970s and commercialization eﬀorts from the 1980s. Standard OS fea-
tures that we take for granted today were often unavailable to DBMS
developers when the original database systems were built. Eﬃcient,
high-scale OS thread support is perhaps the most signiﬁcant of these.
It was not until the 1990s that OS threads were widely implemented
and, where they did exist, the implementations varied greatly. Even
today, some OS thread implementations do not scale well enough to
support all DBMS workloads well [31, 48, 93, 94].
Hence for legacy, portability, and scalability reasons, many widely
used DBMS do not depend upon OS threads in their implementa-
tions. Some avoid threads altogether and use the process per DBMS
worker or the process pool model. Those implementing the remaining
process model choice, the thread per DBMS worker model, need a solu-
tion for those OS without good kernel thread implementations. One
means of addressing this problem adopted by several leading DBMSs

160 Process Models

was to implement their own proprietary, lightweight thread package.
These lightweight threads, or DBMS threads, replace the role of the
OS threads described in the previous section. Each DBMS thread is
programmed to manage its own state, to perform all potentially block-
ing operations (e.g., I/Os) via non-blocking, asynchronous interfaces,
and to frequently yield control to a scheduling routine that dispatches
among these tasks.
Lightweight threads are an old idea that is discussed in a retro-
spective sense in [49], and are widely used in event-loop programming
for user interfaces. The concept has been revisited frequently in the
recent OS literature [31, 48, 93, 94]. This architecture provides fast
task-switching and ease of porting, at the expense of replicating a good
deal of OS logic in the DBMS (task-switching, thread state manage-
ment, scheduling, etc.) [86].

2.3 Standard Practice

In leading DBMSs today, we ﬁnd representatives of all three of the
architectures we introduced in Section 2.1 and some interesting varia-
tions thereof. In this dimension, IBM DB2 is perhaps the most interest-
ing example in that it supports four distinct process models. On OSs
with good thread support, DB2 defaults to thread per DBMS worker
and optionally supports DBMS workers multiplexed over a thread pool.
When running on OSs without scalable thread support, DB2 defaults
to process per DBMS worker and optionally supports DBMS worker
multiplexed over a process pool.
Summarizing the process models supported by IBM DB2, MySQL,
Oracle, PostgreSQL, and Microsoft SQL Server:

Process per DBMS worker :
This is the most straight-forward process model and is still heavily used
today. DB2 defaults to process per DBMS worker on OSs that do not
support high quality, scalable OS threads and thread per DBMS worker
on those that do. This is also the default Oracle process model. Oracle
also supports process pool as described below as an optional model.
PostgreSQL runs the process per DBMS worker model exclusively on
all supported operating systems.

Thread per DBMS worker : This is an eﬃcient model with two ma jor
variants in use today:

2.3 Standard Practice 161

1. OS thread per DBMS worker : IBM DB2 defaults to this
model when running on systems with good OS thread sup-
port and this is the model used by MySQL.
2. DBMS thread per DBMS worker : In this model, DBMS
workers are scheduled by a lightweight thread scheduler on
either OS processes or OS threads. This model avoids any
potential OS scheduler scaling or performance problems at
the expense of high implementation costs, poor development
tools support, and substantial long-standing software main-
tenance costs for the DBMS vendor. There are two main
sub-categories of this model:
on OS
a. DBMS
process :
scheduled
threads
A lightweight
thread scheduler
is hosted by
one or more OS processes. Sybase supports this
model as does Informix. All current generation
systems using this model
implement a DBMS
thread scheduler that schedules DBMS workers
over multiple OS processes to exploit multiple
processors. However, not all DBMSs using this
model have implemented thread migration : the
ability to reassign an existing DBMS thread to a
diﬀerent OS process (e.g., for load balancing).
b. DBMS threads scheduled on OS threads : Microsoft
SQL Server supports this model as a non-default
option (default is DBMS workers multiplexed over
a thread pool described below). This SQL Server
option, called Fibers, is used in some high scale
transaction processing benchmarks but, otherwise,
is in fairly light use.

Process/thread pool :
In this model, DBMS workers are multiplexed over a pool of processes.
As OS thread support has improved, a second variant of this model

Cryptography and Relational Database Management Systems

Jingmin He and Min Wang

IBM T. J. Watson Research Center
  Saw Mill River Road
Hawthorne, NY  , USA
fjingmin, ming@us.ibm.com

Abstract
Security is becoming one of the most urgent chal-
lenges in database research and industry, and the chal-
lenge is intensifying due to the enormous popularity
of e-business. In this paper we study database secu-
rity from a cryptographic point of view. We show how
to integrate modern cryptography technology into a re-
lational database management system to solve some
major security problems. Our study shows that cryp-
tographic support is an indispensable ingredient for a
modern RDBMS to provide a secure environment for
storing and processing huge amount of business data.



Introduction
Sur ng the net has become part of the daily life of
our society. Internet shopping has become very popu-
lar and e-business is reshaping the way we do business.
In the mean time, when using all the old and new ser-
vices, people are worried about the privacy and in-
tegrity of their business data. Recently, there was an
attack on a popular web site which resulted in the
possible stealing of the credit card numbers of several
thousand customers :

The safety of online commerce su ered an-
other blow with the disclosure that the credit
card database of a health products supplier
was opened to hackers for a few hours this
week. Word of the security breach at Global
Health Trax Inc. comes as credit card com-
panies are canceling thousands of cards be-
cause someone pilfered their numbers from
CD Universe, a Web music seller. The card
companies say the CD Universe case, un-
covered Monday, has resulted in the largest
mass-cancellation of cards they can recall.

Security is the primary concern of companies that
want to do business on the Word Wide Web 	. By de-
sign, internet is a free and open system, but it should

also be a society where people can still maintain pri-
vacy and feel safe about their internet properties".
A Relational DataBase Management System
RDBMS plays a critical role in the new business.
Huge amount of business data are gathered, stored
and processed, which demands more powerful support
from the backend database DB server. If we look at
a purchase activity of a web customer and trace the
data  ow, we can see that there are two security issues
to be addressed:
. Secure data transmission: When a customer sub-
mits herhis con dential information e.g., credit
card number through herhis web browser, the
information should remain con dential on its way
to the web server, the application server, and the
backend DB server.
. Secure data storage and access: When the con -
dential customer data arrive at the DB server, the
data should be stored in such a way that only peo-
ple with proper authorization can access them.

The secure transmission of data is well studied and
well supported in today’s e-business market. Almost
all web browsers and web servers support SSL Se-
cure Socket Layer  or TLS Transport Layer Se-
curity . A credit card number is well protected
on its way from a web browser to a web server via
an SSL connection. However, once the data arrive at
the backend, there is no su cient support in storing
and processing them in a secure way. For example, an
RDBMS might not even provide an encryption mech-
anism to securely store the credit card numbers. Al-
though the general problem of secure data storage is
well studied, the importance of secure data storage in
an RDBMS has not been ful ly understood, and no se-
rious work has been done on how to encrypt DB data.
We believe that it is vital to integrate cryptographic
support into RDBMSs. Cryptographic support is an-
other important dimension of database security. It is

complementary to access control and both should be
used to guide the storage and access of con dential
data in a database system.
When we consider integrating cryptographic sup-
port into an RDBMS, there are three general ap-
proaches. The  rst approach is loose coupling. A
third-party crypto service can be consulted by a
database server and there are only minor changes on
the server side. For example, a set of stored procedures
can be pre-installed in the server. Each stored proce-
dure provides a special crypto service to the database
users by calling the crypto primitives supplied by the
third party package. One example is an encryption
PLSQL package that encrypts a table column with a
user supplied encryption key 	.
The second approach is tight coupling. A com-
plete set of basic crypto primitives are built into the
database server as a set of new SQL statements, to-
gether with the necessary control and execution con-
text to ensure that those new SQL statements can be
executed securely. This approach is a much harder
task than the previous one in terms of implementa-
tion, but it is preferable in the long run. The reason
is simple: loose coupling is likely to open many secu-
rity holes.
The third approach is somewhere in between of the
above two. To accommodate the urgent need for secu-
rity enhancement, only a small subset of crypto primi-
tives are integrated into the database server, based on
which other services can be built using other database
utilities such as user de ned functions and stored pro-
cedures.
In this paper we take the third approach. We focus
on two problems: how to enhance the access control
mechanism to make user management more secure and
close some ma jor security holes of current RDBMSs,
and how to support database encryption.
The contribution of this paper can be summarized
as follows:
. We introduce the important concept of security
dictionary that can serve as the basis for many
security services in a database system.
. Based on the new concept of security dictionary,
we show how to enhance the security of the cur-
rent user management mechanism deployed in all
RDBMSs.
. We propose several database encryption methods
and show how to do key management, again based
on the security dictionary.

The rest of the paper is organized as follows: In Sec-
tion  we analyze the security features implemented
in current RDBMSs and point out their weakness. In

Section  we introduce the important concept of se-
curity dictionary. Based upon the new concept, in
Section  we show how the security of the user man-
agement subsystem can be enhanced. We propose sev-
eral secure database encryption methods in Section 
and make concluding remarks in Section .

 The Problem
Although access control has been deployed as a
security mechanism almost since the birth of large
database systems, for a long time security of a DB
was considered an additional problem to be addressed
when the need arose, and after threats to the secrecy
and integrity of data had occurred . Now many
ma jor database companies are adopting the loose cou-
pling approach and adding optional" security support
to their products. The approach of adding security
support as an optional feature is not very satisfactory,
since it would always penalize the system performance,
and more importantly, it is likely to open new security
holes.
Database security is a wide research area ,  and
includes topics such as statistical database security ,
intrusion detection , and most recently privacy-
preserving data mining . In this section we focus
on the topics of user management, access control and
database encryption. We brie y review how they are
supported in current RDBMSs, analyze their security,
and point out the potential problems.

. Use Management
The  rst security-related component in an RDBMS
and actually in most systems is user management.
A user account needs to be created for anyone who
wants to access database resources. However, how to
maintain and manage user accounts is not a trivial
task.
User management includes user account creation,
maintenance, and user authentication.
A DBA
DataBase Administrator is responsible for creating
and managing user accounts. When a DBA creates an
account for user Alice, shehe also speci es how Al-
ice is going to be authenticated, for example, by using
a database password. The accounts and the related
authentication information are stored and maintained
in system catalog tables. When a user logs in, shehe
must be authenticated in the exact way as speci ed in
herhis account record. However, there is a security
hole in this process.
Let us look at a concrete example from a ma-
jor commercial RDBMS product Oracle. Suppose
a DBA creates an account for user Alice by doing the
following:

CREATE USER Alice
IDENTIFIED BY  mypass ;

 mypass 
is
of
value
hash
the
Suppose
 ABC DE F GH  .
is the hash value
It
of a password that is stored in the database catalog
table. The DBA can become" user Alice anytime by
going through the following steps:
. Query the data dictionary to obtain the current
encrypted password for Alice.
. Change Alice’s password by running the following
command:

ALTER USER Alice
IDENTIFIED BY  temppass ;

. Access Alice’s account using the temporary pass-
word  temppass .
. Reset Alice’s password back to its original value
obtained in Step  by running the following com-
mand:

ALTER USER Alice
IDENTIFIED BY VALUES
  ABC DE F GH  ;

In other words, a DBA can impersonate any other
user by changing implicitly or explicitly the system
catalogs and shehe can do things on a user’s behalf
without being authorizeddetected by the user, which
is a security hole. As we will see in Section ., a
DBA’s capability to impersonate other users would
allow herhim to access other users’ con dential data
even if the data are encrypted.
. Access Control
Access control is the ma jor security mechanism de-
ployed in all RDBMSs. It is based upon the concept of
privilege. A sub ject i.e., a user, an application, etc.
can access a database ob ject if the sub ject has been
assigned the corresponding privilege. Access control
is the basis for many security features. Special views
and stored procedures can be created to limit users’
access to table contents.
However, a DBA has all the system privileges. Be-
cause of herhis ultimate power, a DBA can manage
the whole system and make it work in the most ef-
 cient way.
In the mean time, shehe also has the
capability to do the most damage to the system.
. Encryption
Current RDBMSs provide limited support for data
encryption. Data are stored in tables in the form they
are loaded, mostly in their plaintext form, which is
not su cient to meet high level security and privacy
requirement.

Let us consider the following example. Suppose
there is a database table Customer created by the fol-
lowing SQL statement:

CREATE TABLE Customer
integer PRIMARY KEY
userid
varchar,
lastname
varchar,
firstname
char
ccnum
;

where column ccnum records customers’ credit card
numbers. The following statement creates a new
record for customer John Smith whose credit card
number is :

INSERT INTO Customer VALUES
  ,  Smith ,  John  ,    ;

The credit card number will be stored in its original
plain-text form. The owner of table Customer or any-
one with appropriate privilege can read this number
with a simple SELECT statement. For convenience,
we assume user Alice is the owner of table Customer.
Note that Alice might be a pseudouser whose existence
is to ensure that an application can run smoothly and
her account is created by a DBA.
If the table Customer is stored in operating system
 les, the whole table can be protected by using the  le-
permission mechanism of the operating system. Only
users with the correct permissions can access the  le
and thus the table  . The problem with this approach
is that  le protection restricts the access to the whole
table, not just a particular column, and thus would
make the database hard to use. Another problem is
that database security is tied up with the underly-
ing operating system which itself is rather vulnerable
to both insider and outsider attacks. For example, a
DBA, with the help of a system administrator, can
still gain access to any data.
A variation of the above approach is to detach the
physical medium that is used for storing the data from
the system and keep it in a safe place. A similar ap-
proach is to encrypt the whole operating system  le
for the table plus possible index  les. Obviously nei-
ther of them is an attractive alternative, and we will
not elaborate on them in this paper.
Recently a ma jor database vendor has started
to support database encryption 	.
It provides a
PLSQL package to encryptdecrypt data. In using
the package, key management must be handled pro-
grammatically by an outside application server. This

 In some cases the database server itself manages its own disk
space, and the operating system mechanism cannot be used.

is a loose-coupling approach, and a standard PLSQL
package su ers from the same drawback as any other
database ob ject, that is, a DBA can drop it  rst, and
recreate one with the same name but with built-in
trapdoors. Through those trapdoors, a DBA can eas-
ily get hold of any con dential information. There-
fore, the PLSQL package can not support truly se-
cure database encryption.
Another more serious problem with the loose cou-
pling approach is that a database is used only as a pas-
sive data repository. When encrypted data need to be
processed, they need to be fetched out of the database
by another application server  rst. The database en-
gine itself can do nothing useful about them. For ex-
ample, indexing on an encrypted column is impossible,
and no useful database operation can be performed
against encrypted data.
. The Role of DBAs
From an administration point of view, a DBA is
playing an important and positive role. However,
when security and privacy become a big issue, we can-
not simply trust particular individuals to have total
control over other people’s secrecy. This is not just a
problem of trustiness, it is a principle.
Technically, if we allow a DBA to control security
without any restriction, the whole system becomes
vulnerable because if the DBA is compromised, the
security of the whole system is compromised, which
would be a disaster. On the other hand, if we have
a mechanism in which each user could have control
over hisher own secrecy, the security of the system
is maintained even if some individuals do not manage
their security properly.
. Notations
To simplify subsequent discussions, we introduce
some notations. We use E and D to represent en-
cryption and decryption operation, respectively. We
will not specify what particular encryptiondecryption
functions are used. The pair E ; D might be a sym-
metric cryptosystem like DES  or a public key
system like RSA . For any plaintext m and key
k , E k ; m is the ciphertext after applying encryption
operation to m with the key k , and Dk ; c is the result
after applying decryption operation to the ciphertext
c with a key k .
We use H to denote a secure hash function, e.g., H
might be SHA  or MD . For an input x of arbi-
trary length, H x will produce an output y of a speci-
 ed length. Usually the length of y is smaller than that
of x. We use RAND to denote a pseudorandom num-
ber generator that is cryptographically strong , .
Given a seed s, RAND s will produce a random num-

ber whose length can be speci ed in advance. Usually
the length of the random number is larger than that
of the seed s. When no seed is given, RAND  also re-
turns a pseudorandom number. Please refer to 
for more details.

 Concepts
In this section we introduce several important con-
cepts that are the basis of our database security study.
. Secure Operating Environment
If an operation involves any secret data, that op-
eration should be conducted in an environment that
would not cause secret leak. We call such an environ-
ment a Secure Operating Environment SOE. A good
example of SOE is any smart card application where
a user’s private secret stays in and never gets out of
a tamper-free card  ,  . If an operation involves
the secret, the operation itself will be done inside the
card and only the operation result will be output to
the outside world.
However, for an RDBMS, things are much more
complicated because a database system is much more
complicated than a simple smart card application
where only a small amount of data is involved. A
smart card is not adequate for an RDBMS. A better
choice would be a secure processor such as the IBM
Programmable Secure Coprocessor.
The current database engine internal can also be
considered as a relatively good SOE. In general,
database server processes are OS ob jects and are pro-
tected only by OS itself. If the server is running on a
machine where a strong security policy has been im-
plemented, then the database engine as a whole can
be treated as an SOE.
There are obviously many issues surrounding SOE.
For the purpose of this paper, we assume that the
current database server processes form an SOE and is
where our trust lies.
. Security Dictionary
A traditional data dictionary stores all of the in-
formation that is used to manage the ob jects in a
database. A data dictionary consists of many catalog
tables and views.
It is generally recommended that
users including DBAs do not change the contents of
a catalog table manually. Instead, those catalogs will
be maintained by the DB server and updated only
through the execution of system commands. How-
ever, a DBA can still make changes in a catalog table
if shehe wants to do so.
to important
To prevent unauthorized access
security-related information, we introduce the concept
of security catalog. A security catalog is like a tradi-
tional system catalog but with two security properties:

a It can never be updated manually by anyone, and
b Its access is controlled by a strict authentication
and authorization policy.
One example would be a table SEC USER that
records user account information. Some columns in
the table store security-related information and are
called security columns security  elds . Each secu-
rity  eld has a corresponding security  ag  eld that
speci es how the value of the  eld can be accessed
particularly updated. For example, a password  eld
could be a security  eld, and its security  ag could be
set to updatable by anyone with appropriate access
privilege to the SEC USER table", updatable by the
de ned user only", or never updatable by anyone".
In the second case, only a user herselfhimself can
change herhis password. We will discuss the detail
in Section .
A security dictionary consists of all the security cat-
alogs. Security dictionary is an important security
concept. Basically, it provides a secure and reliable
repository where information can be safely stored. It
is not a secret box that people cannot have a glance
into its content since that would be too much for
any system to support. However, its update is under
strict security control.
The implementation of a security dictionary is  ex-
ible. One approach is to implement it within a
database server. The server internally control the
access to the security dictionary, probably based on
some system security con guration that is derived
from an enterprise security policy, which is not nec-
essarily done by a DBA. Another approach is to im-
plement the security dictionary as a service outside of
the database server. For the sake of simplicity and
convenience, we assume the  rst approach. Again, we
emphasize that the access to a security catalog is con-
trolled by a speci c security policy associated with it.
The concept of security dictionary is di erent from
that of a virtual private database 	. A virtual pri-
vate database is actually a loose way to shift the re-
sponsibility of re ning access control from an applica-
tion server to the database server, and everything in
the database server is still under the control of a tradi-
tional access control mechanism. A DBA still has all
the system privileges. By deploying a security dictio-
nary, everyone including DBAs can be restricted in
accessing other people’s critical security information,
and only in this way can an RDBMS provide a real
secure operating environment for all users.
The integrity of secure catalogs can be well main-
tained. First of all, the access to a security  eld is
strictly controlled by its corresponding security  ag,

and its content cannot be modi ed without its secu-
rity  ag be changed  rst. Second, a security  ag can
be put under the control of an SOE. Or, a security pol-
icy can be established that does not allow the change
of a security  ag after it is  rst created see Section .
Third, the hash value of a security column or even the
security  ag column can be computed and stored in
an SOE so that any accidental change e.g., caused by
physical disk damage can be detected.
Another issue is backup. Critical security informa-
tion should be backed up so that a reasonable recovery
can be expected. An SOE should have its own backup
mechanism. A subtle problem is that of a lost secret
key. For example, some data are protected by a secret
key: either they are encrypted using the key, or the
hash value of the data is computed using the secret
key. If the key is lost, the data become useless. This
is the typical key recovery problem in cryptography
and many approaches can be taken.
In the next two sections, we elaborate on the use of
security catalogs with two important database security
tasks: a user management, and b encryption and
key management. We discuss relevant security issues
and outline the general design principles.

 User Management
To access database resources, a user must have an
account with the database. User account manage-
ment is the basis for the overall database system se-
curity. A DBA has the responsibility to create and
maintain all DB user accounts, which is a large por-
tion of herhis system administration e ort. At the
account creation time, the DBA speci es how the
newly created user will be authenticated, and what
system resources the user can use. When a user wants
to connect to a database, shehe must identify her-
selfhimself to the server and the server will verify
herhis identity using the pre-speci ed authentica-
tion method. Current commercial RDBMSs support
many di erent kinds of identi cation and authenti-
cation methods, among them are password-based au-
thentication , host-based authentication , , ,
PKI Public Key Infrastructure based authentica-
tion 	, and other third party-based authentications
such as Kerberos , DCE Distributed Computing
Environment  and smart card  . Essentially, all
methods rely on a secret known only to the connecting
user.
It is vital that a user should have total control over
herhis own secret. For example, only shehe should
be able to change herhis password. Other people can
change a user’s password only if they are authorized to
do so. In a DB system, a DBA can reset a user’s pass-

word upon the user’s request, probably because the
user might have forgotten herhis password. However,
as we have noticed before, the DBA can temporar-
ily change a user’s password without being detected
and caught by the user, because the DBA has the ca-
pability to update directly or indirectly the system
catalogs.
By using a security catalog, no one including the
DBA would be able to manipulate other users’ impor-
tant security information, and no one can imperson-
ate other people without being detected and caught.
When a DBA creates a user account, besides spec-
ifying the usual account information, the DBA must
also specify some security characteristics whether and
how this account can be modi ed so that a speci c
security policy is associated with this account. All the
account information is stored in a security catalog ta-
ble SEC USER that contains the following columns,
among others:
userid User login name. No one is allowed to change
this  eld.
auth type How this user is authenticated. Possible
values: db, os, sc smart card, or any other sup-
ported authentication methods.
auth  ag Security  ag, indicating if other users are
allowed to update auth type  eld of this record.
Possible values:  yes  ,  no  , or  never .
passwd Hash value of password.
passwd  ag Security  ag for passwd, indicating if
other users are allowed to update passwd  eld
 yes  ,   no  , or
of this record. Possible values:
 never  .
updateby The userid who updated the passwd  eld
most recently.
The default user for any SEC USER record is the user
whose identi er is speci ed in the userid  eld. The
auth  ag security  ag  eld takes three possible val-
ues:  yes,  no  , or  never . Value   yes  means anyone
with the privilege to access the table SEC USER can
update this record; value  no  means only the default
user has the update privilege; value   never  means no
one including the default user can update the record.
Let us consider a concrete example. Suppose a
DBA creates an account for user Alice by running the
following SQL statement:

CREATE USER Alice
IDENTIFIED BY db UPDATE never
PASSWORD  mypass  UPDATE no;

login is to use the database password and the authen-
tication method cannot be changed. No one except
Alice herself can change her login password. The se-
curity portion of the SEC USER record for Alice con-
tains the following information, among others:

userid = Alice, auth type = db,
auth flag = never, passwd = H  mypass ,
  .
passwd flag = no, updateby = 

An empty updateby  eld means this record is newly
created. Alice can change her password if a password
utility is provided, or she can do so by using the fol-
lowing SQL statement:

ALTER USER Alice
PASSWORD  newpass ;

The server will check the identity of the command
issuer Alice against the SEC USER record for the
user speci ed in the statement Alice and decide if
the command is authorized. Since the passwd flag
value is   no  which means Alice herself can update
her own password, the command is executed and Al-
ice will have a new database password. However,
if a DBA assuming shehe is not Alice issues the
above statement, after checking the record for Alice
in SEC USER, the server knows the change is not
authorized and thus the command is rejected.
In
case the passwd flag value for Alice is  never , even
Alice herself is not allowed to change her password,
which is usually not recommended because changing
password periodically is considered a good security
practice. Another interesting and troublesome case
is what if Alice forgets her password. On the one
hand, password management is a big topic on the
users’ side and many assistant tools can be utilized
like smart card, wallet manager, etc.. On the other
hand, the database server does need to handle the case
when it happens. One possible solution is to allow a
DBA to change a user’s password. When shehe cre-
ates the user account, shehe can specify the value of
passwd flag for Alice to be   yes  . In this case, be-
sides Alice herself, the DBA is also allowed to alter
her password. However, whenever someone changes
Alice’s password, that person’s userid will be recored
in Alice’s SEC USER record and Alice can query that
record to make sure any update is authorized. Later,
Alice may choose to change her passwd flag to   no 
by issuing the following statement:

The statement creates a user with userid  Alice 
and the newly created user will be authenticated by
database password  mypass . The only way Alice can

ALTER USER Alice
PASSWORD UPDATE no;

After that, no one except Alice can change her pass-
word and in case Alice forgets her password, there is
no recovery for it.
Another possibly better solution is to use secret
sharing . When creating a user account, the DBA
could specify a threshold value t. Whenever a pass-
word is createdchanged, the new password will be
protected with n shadows n  t. The shadows will
be kept by n security o cers. Later, when it becomes
necessary to recover a lost password, t or more shad-
ows can be gathered and used together to recover the
secret password.
Although a DBA might not have the authority
to alter a user’s security characteristics, shehe can
change other non-security parameters as usual. Fur-
thermore, shehe can drop a user account. If shehe
runs the command DROP USER Alice;", the
SEC USER record for Alice will be deleted. The
DBA may recreate another user with the name Al-
ice, however, this Alice has no relationship whatso-
ever to any previous existing Alice. Especially, the
new Alice cannot read any con dential data encrypted
by the previous Alice. This will guarantee that a
DBA cannot intrude Alice’s privacy by recreating her
pseudoidentity in the server. See Section  for more
details.

 Encryption and Key Management
In this section we propose several database encryp-
tion methods and analyze their security. Please note
that the encryption techniques we discussed here are
all standard ones. We only adapt them for our use in a
database environment based on the central mechanism
of security catalogs.
The most important problem in using encryp-
tiondecryption is key management. When we con-
sider incorporating encryption in a database server,
there are two design issues:
. There should be a way for a user to indicate that
some data should be encrypted before storage.
. There should be a way for a user to specify ex-
plicitly or implicitly a key that will be used for
data encryption.

The two issues are not totally separated. When
a user indicates that a table column should be en-
crypted, shehe may supply an encryption key at the
same time, or supply the key later when actual data
are loaded. The second issue is more important. It
basically reduces to the problem of key management.
When de ning a table, a user may specify explic-
itly that shehe wants the content of some columns to
be encrypted when the data are loaded. SheHe can

do this by issuing the following CREATE TABLE
statement:

CREATE TABLE Customer
userid
integer PRIMARY KEY
lastname varchar,
firstname varchar,
char ENCRYPTION
ccnum
UPDATE no

;

Whenever a credit card number is inserted into the
table, it will be encrypted by the database server
 rst and the encrypted version will be stored in the
database. We assume user Alice is the creator and
thus the owner of table Customer.
catalog
We
need
a
new
security
SEC ENCRYPTION. Whenever a user creates a
database ob ject that is to be encrypted, a corre-
sponding record is created in the security catalog
SEC ENCRYPTION. Each catalog record speci es a
database ob ject, its owner the ob ject creator, and
a security  ag that indicates how the ob ject is to be
updated. There is also an updateby  eld that store
the identi er of the user who updated this record
most recently. The pair owner; object forms a
primary key. For example, for the above CREATE
TABLE statement, the following record is inserted
in SEC ENCRYPTION:

Alice, table  Customer , column   ccnum ,
enc flag, updateby = Alice.

The enc flag speci es whether any user can update
 yes  ,  no  , or
the record, and can take the values:
 never . The value  yes  means any user with the priv-
ilege to access table Customer can change the de ni-
tion of the ccnum column;   no  means only Alice the
  never 
owner can change the de nition of ccnum;
means nobody can make the change. In the above ex-
ample, only Alice can change the de nition of column
ccnum e.g., she can drop the encryption requirement
for this column.
Before any database ob ject is altered, the security
dictionary will be checked  rst. If the change violates
the security speci cation for that ob ject, the change
request will be rejected. For example, if a DBA wants
to change the de nition of column Customerccnum
by issuing the following SQL statement:

ALTER TABLE Customer
MODIFY ccnum DROP ENCRYPTION;

the
the
because
rejected
be
command will
SEC ENCRYPTION record for Customer shows

that Alice is the owner of the table and only the
owner can change the de nition of column ccnum.
However, if it is Alice who issues the above statement,
the change will be made. There is one question
that needs to be answered here. When the column
de nition changes, what about those credit card
numbers that were already inserted and stored in
encrypted form? There are two alternatives. One
is that the old column values remain unchanged
in the encrypted form. The other alternative is to
decrypt all the old values, which would require Alice
to provide correct decryption keys. Similarly, when
Alice changes a column by enabling the encryption
option, she could either leave the old column values
alone, or provide a key to encrypt them. Again, we
will not elaborate on this in much detail here.
In the following subsections, we will show how to
manage keys used for database encryption.
. Password Based Encryption
All RDBMSs in the market can authenticate a user
through a password mechanism. When a user types
in the correct user name with a matching password,
shehe is connected to the server and can start using
any database resources shehe is granted privilege to.
The server can always keep a copy of the user pass-
word in memory during the session when a user is
connected. This password will be used to do any nec-
essary encryption for this particular user.
For example, suppose Alice’s password is   mypass .
When Alice logs in, the database server will get a
memory copy of this password. When Alice creates
a new customer record by issuing

INSERT INTO Customer VALUES
  ,  Smith ,  John  ,   ;

the database server will  rst encrypt the credit card
number with key  mypass  and then store the cipher-
text in the table Customer.
Later, when Alice wants to get John Smith’s credit
card number, she runs the command

SELECT ccnum FROM Customer
WHERE userid =   ;

Since Alice must have logged in to run the SELECT
statement, the server must have already obtained a
copy of Alice’s password  mypass . The server will
 rst decrypt the content of column Customerccnum
with  mypass  and then return the original card num-
ber D mypass , Customerccnum.
A much better approach is to use a variation of the
user password. When a user logs in, herhis password
is used as a seed to generate a working key that is used

in all encryption operations. The advantage of this ap-
proach is that the user password is not used directly
in the possibly frequent encryption operations. This
approach can be pushed even further. For each col-
umn, a combination of the table name, column name
and the password can serve as the seed for working
key generation and thus di erent columns are pro-
tected with di erent keys. Furthermore, a unique row
identi er can be incorporated into the working key
generation process so that identical value appeared
in the same column but di erent rows will be en-
crypted to di erent ciphertexts. For example, a work-
ing key for Customerccnum can be generated by
k = H  mypass ;  Customer ; userid;  ccnum .

Security The password based approach is secure.
Once the encrypted version of a credit card number
is stored in the table Customer, only a user with the
correct password i.e., Alice can decrypt and thus ac-
cess the original card number. A DBA might be able
to temporarily replace the encrypted password with
another one, but shehe still does not know Alice’s
password and thus still unable to read the credit card
numbers.
One drawback of the password based approach is
that when a user changes herhis password, all the
encrypted data need to be decrypted with the old pass-
word and re-encrypted using the new password, which
is a big performance overhead. Notice that chang-
ing password periodically is considered a good prac-
tice from the password security point of view. In the
case when a user forgets herhis password, there is no
way to recover unless the password has been guided
by some secret recovery mechanism.
Password-based encryption relies on the fact that
the database server can grab a user’s login password.
However, a database server might rely on the underly-
ing operating system entirely for user authentication.
The database server might direct the user login to the
OS without bothering to get a copy of his password.
In this case, the approach cannot be used.
. Public Key Based Encryption
Public key and PKI can be used to do database
encryption in a more robust and e cient way.
A PKI infrastructure is the basis for the e ective
use of public key technology. We assume there is a
directory service e.g., an LDAP server that is con-
sulted by the database server. Whenever needed, the
database server can consult with the directory server
to obtain a certi cate of a public key for a particular
user. Stored together with the public key certi cate is
the matching private key that is encrypted using the

user’s password.
For example, suppose Alice has a certi cate CERTA
stored in the directory server. The certi cate CERTA
certi es a public key PKA with a matching private key
SKA . In the directory server, the following record has
all the key information for user Alice:

Alice, CERTA , E  mypass  ; SKA

When Alice issues the following statement:

INSERT INTO Customer VALUES
  ,   Smith ,  John ,   ;

the database server queries the directory server and
obtains CERTA and thus the public key PKA . PKA can
be used to encrypt a working key K that is generated
by the system. The working key K is used to encrypt
John Smith’s credit card number, and K itself is en-
crypted using PKA . The encrypted working key might
be stored in the directory server if its generation in-
volves randomness. For example, the working key can
be simply generated as K = RAND and E PKA ; K 
will be stored in the directory server.
Later, when Alice wants to read John Smith’s credit
card number, she  rst needs to login to the database
server. If the login is successful, the database server
has a copy of Alice’s password that can then be used to
fetch her private key SKA , which in turn can be used
to decrypt the encrypted working key. Finally, the
working key can be used to decrypt the stored version
of the credit card number.
When Alice creates another customer record, de-
pending on the design, the DB server can use the
same working key generated before to encrypt the new
credit card number, or it generates a new working key.
In the former case, the server can use Alice’s password
to decrypt and obtain the old working key K . In the
later case, the server does key generation and encryp-
tion as before.
When Alice changes her password, only her private
keys need to be re-encrypted and this can be done
e ciently.
In the above approach, we use user passwords to
encrypt private keys. Following is a modi ed approach
that does not use user passwords.
In the directory server, user Alice’s key record con-
tains the following information:

Alice, CERTA.

When Alice inserts John Smith’s record into the
Customer table, a working key K is generated to en-
crypt the column Customerccnum, and a record of
the following form is stored in the directory server:

Alice,  Customer ;  ccnum ; E PKA ; K :

When Alice wants to access John Smith’s credit card
number, she issues the following statement:

SELECT ccnum FROM Customer
WHERE userid =    PRIVATE KEY SKA ;

That is, Alice explicitly supplies her private key. The
database server  rst fetches the encrypted working key
E P KA ; K  from the directory server, then uses the
user supplied private key SKA to decrypt it to obtain
K , uses K to decrypt the encrypted credit card num-
ber E K;     and  nally returns the
result.
When Alice creates a new customer record, if the
design is such that the previously generated working
key should be used, Alice needs to supply her private
key when doing any insertion:

INSERT INTO Customer VALUES
  ;   Case ;  Steve ;   
PRIVATE KEY SKA ;

The DB server will fetch E PKA ; K  from the directory
server, decrypt it using the matching private key SKA
to obtain K , and then use K to encrypt the new credit
card number.

Security The secure use of the private key SKA guar-
antees the security of the approach. When Alice’s
password is used to protect her private key SKA , no one
can get hold of it except Alice herself, and therefore
no one except Alice can obtain the original working
key to decrypt the credit card number.
In the non-password version, Alice dynamically
supplies her private key SKA and SKA will never be
stored in the database even in an encrypted form.
Therefore, the method is secure.
If we store Alice’s certi ed public key in a tradi-
tional database table or system catalog, a DBA might
easily break in. For example, if the following record is
stored in the database:

Alice, CERTA

the DBA can update the second component and re-
place it with herhis own certi cate that contains
herhis public key, say PKC . Later, when Alice cre-
ates a new customer record, the credit card number
will be encrypted using PKC , not PKA , and the DBA
can easily read the encrypted credit card number.

. Encryption Based on User-Supplied
Keys
The most  exible database encryption approach is
using keys dynamically supplied by the users. To ac-
commodate this case, we extend the previous CRE-
ATE TABLE statement and add one more option:

CREATE TABLE Customer
integer PRIMARY KEY
userid
varchar,
lastname
varchar,
firstname
char ENCRYPTION
ccnum
WITH KEY key value

;

When WITH KEY key value is present, key value
will be the default encryption key when any credit card
number is inserted into the table. If a user supplies
another key, that key will be used instead. The new
SQL statement for this is:

INSERT INTO table name VALUES
value specification KEYS key list

where key list is a list of keys separated by comma.
The list elements correspond to the columns that are
to be encrypted. For example, to create a new record
for John Smith, Alice would use the following state-
ment:

INSERT INTO Customer VALUES
  ;  Smith  ;  John  ;   
KEYS  	  ;

The database server will use the string  	  
as key to encrypt the credit card number and store
the encrypted version in the database.
When Alice wants to access John Smith’s credit
card number, she issues the following statement:

SELECT ccnum FROM Customer
WHERE userid =    KEYS   	  ;

The general form of the extended SELECT statement
is as follows:

SELECT projection list ... other clauses
KEYS key list;

One main advantage of this approach is that it is
much easier to integrate with an existing database
product. All the ma jor commercial database server
products in the market are very large software prod-
uct. Any big change to their architecture would not be
easily acceptable to the R&D teams very soon. How-
ever, adding or extending several SQL statements is a
much easier task.

Security. Since a user dynamically supplies herhis
working key, there is no chance for any other people
to decrypt an encrypted credit card number and the
method is secure.

. Group Encryption

In this subsection we consider the case when a
group of users want to share access to an encrypted
column.
For
example, when Alice
creates
the
table
Customer, she may want to allow Bob to read user
credit card numbers also. One obvious solution is that
Alice gives the working keys directly to Bob. If a work-
ing key is protected by Alice’s publicprivate keys,
there would be no way for Bob to gain access unless
Alice also gives out her private key, which Alice would
almost de nitely refuse to do if her publicprivate key
pair is used in any other business.
To allow group access to encrypted columns, we
can generalize the public key based approach of Sec-
tion ..
First, when Alice creates the table Customer, she
could explicitly specify who will be allowed to access
the unencrypted credit card numbers:

CREATE TABLE Customer
INT PRIMARY KEY
userid
varchar,
lastname
varchar,
firstname
char ENCRYPTION
ccnum
USER user list
UPDATE no

;

where the elements of the key list correspond to the
encrypted columns in the pro jection list.
The approach is self-contained. No directory ser-
vice or certi cate is needed. Basically, the task of key
management is shifted to the application server, and
the database server only provides the framework to do
encryptiondecryption.

where user list lists the names of all user that are
allowed to access the unencrypted credit card num-
bers. For simplicity, we assume the user list contains
only Bob.
The security catalog SEC ENCRYPTION is ex-
tended to record this extra information, that is, a
record in SEC ENCRYPTION contains the following

information, among others:

record  to the following

userid = Alice; table = Customer;

column = ccnum; enc flag = no;

updateby = Alice; user list = fBobg;

userid = Alice; table = Customer;

column = ccnum; enc flag = no;

updateby = Alice; user list = fBob; Clarkg;

user flag = no:



user flag = no



When Alice creates John Smith’s record in table
Customer, the encryption is done the same way as be-
fore, except that the working key K will be encrypted
twice, once using Alice’s public key P KA and once
using Bob’s public key P KB , and the following two
entries will be stored in the directory server:

Alice,  Customer ,  ccnum , E PKA ; K 
Bob,  Customer ,   ccnum , E PKB ; K 

Alice can access the credit card number as before.
For Bob, he can supply his own matching private
key when issuing the following SELECT statement:

SELECT ccnum FROM Customer
WHERE userid =    PRIVATE KEY SKB ;

The
check
 rst
will
server
database
SEC ENCRYPTION to see if Bob is the owner
of table Customer or listed as a sharing user for
Customer, ccnum.
If so, the database server will
fetch E PKB ; K  from the directory server, decrypt it
using the user supplied SKB , and use the recovered
working key K to decrypt the encrypted credit card
number.
Alice can also update the sharing user list later
using ALTER TABLE statement because she has
speci ed user flag = no. When she issues the AL-
TER TABLE statement, she needs to supply her
private key. Similarly, she can grant Bob access to the
encrypted column. All the engine needs to do is en-
crypting the working data encryption key K with the
new user’s public key.
The new catalog SEC ENCRYPTION and our
enhanced user management mechanism together
improve
the
system security.
For
example,
suppose user f lag =no and Alice the owner
of
table Customer
is allowed to change
the
SEC ENCRYPTION record to add new sharing users
for column ccnum. We  rst consider the case with
the old user management mechanism. As explained in
Section ., suppose a DBA resets Alice’s password so
that shehe can login as Alice and change the above

where Clark" is the name of another user whose pri-
vate key is known to the DBA. After the update, the
DBA logs o  and restores Alice’s old password. Later,
when Alice creates a record for a new customer Frank
in table Customer, Frank’s credit card number will be
encrypted with a working key K that is in turn en-
crypted by the public keys of Alice, Bob, and Clark
separately, which means Clark and thus the DBA
will be able to obtain the working key K to decrypt
the new customer’s credit card number.
However, if our enhanced user management mech-
anism is in place, a DBA will not be able to obtain
information shehe is not supposed to obtain. In the
above example, after reseting Alice’s password, the
DBA will not be able to restore Alice’s original pass-
word. The next time when Alice tries to login, she
will fail and she immediately knows that someone has
changed her password without her authorization. The
detection of unauthorized password change serves as
the basis for starting any further security management
process.
In the above discussion we assume that users’ pub-
lic key certi cates, encrypted private keys and en-
crypted working keys are stored in a directory ser-
vice. A better way is to store them locally in the
security dictionary. We can use a security cata-
log SEC CERT to store all certi cates, use a secu-
rity catalog SEC WORKINGKEY to store all en-
crypted working keys, and use a security catalog
SEC PRIVATEKEY to store all encrypted private
keys if necessary. The advantage of doing this is two
folds. First, a user’s public key certi cate stored in an
independent PKI directory service might change dy-
namically, but his public key for database encryption
is relatively static. Therefore, there is a need for syn-
chronization which might be di cult. Besides, once
a public key P KA is used to encrypt a working key,
that working key must be decrypted using a private
key that must exactly match P KA , not any newly up-
dated public key. Thus it is a good practice for the
database server to store those public key certi cates
used for database encryption locally. Second, local
storage is good for e ciency reason. Frequent access
to an outside directory service would slow down the
whole system signi cantly.

 T. F. Lunt. A survey of intrusion detection tech-
niques. Computer & Security, , 		.

 National Bureau of Standards FIPS Publication
 . Secure Hash Standard, 		.

 National Bureau of Standards FIPS Publication
. Data Encryption Standard DES, 	.

 B. C. Neuman and T. Ts’o. Kerberos: An au-
thentication service for computer networks. IEEE
Communications, 	:, 		.

 San Jose Mercury News. Web site hacked; cards
being canceled, Jan.  ,    .

	 Oracle Technical White Paper. Database Security
in Oraclei, November 			.

  W. Rankl and W. E ng. Smart Card Handbook.
John Wiley & Sons Ltd, 		.

 R. Rivest. The MD Message-Digest Algorithm,
RFC I. April 		.

 R. L. Rivest, A. Shamir, and L. Adleman. A
method for obtaining digital signature and public
key cryptosystems. Communications of the ACM,
: , February 	.

 W. Rosenberry, D. Kenney, and G. Fisher. Un-
derstanding DCE. O’Reilly & Associates, Inc.,
		.

 A. Shamir. How to share a secret. Communica-
tion of the ACM, :, 		.

 D. R. Stinson. Cryptography; Theory and Prac-
tice. CRC Press, Inc., 		.

 Conclusions
In this paper we investigate the role cryptography
can play in database security. We analyze the secu-
rity features of current RDBMSs and point out their
weaknesses. We introduce the key concept of security
dictionary and proposed several secure user manage-
ment and encryption methods based upon the new
concept.
Another important research problem is how to do
database operation against encrypted columns, such
as indexing and join. We will discuss this in a forth-
coming paper.

References
 N. R. Adam and J. C. Wortmann. Security-
control methods for statistical databases:
a
comparative study. ACM Computing Surveys,
:, 		.

 R. Agrawal and R. Srikant. Privacy-preserving
data mining.
In Proceedings of the     ACM
SIGMOD International Conference on Manage-
ment of Data, Dallas, Texas,    .

 S. Castano, M. Fugini, G. Martella, and P. Sama-
rati. Database Security. Addison-Wesley, 		.

 J. Cook, R. Harbus, and T. Shirai. DB Universal
Database v., rd Edition. Prentice Hall,    .

 D. Coppersmith, H. Krawczyz, and Y. Mansour.
The shrinking generator.
In Lecture Notes in
Computer Science , pages 	, 		.

 D. E. Denning. Cryptography and Data Security.
Addison-Wesley Publishing Company, Inc., 	.

 T. Dierks and C. Allen. The TLS Protocol - Ver-
sion . , Internet-Draft. November 		.

 A. Freier, P. Karlton, and P. Kocher. The SSL
Protocol Version . , Internet-Draft. November
		.

	 S. Gar nkel and G. Spa ord. Web Security &
Commerce. O’Reilly & Associates, Inc., 		.

  S. B. Guthery and T. M. Jurgensen. Smart Card
Developer’s Kit. Macmillan Technical Publishing,
		.

 Informix. Informix-Online Dynamic Server Ad-
ministrator’s Guide, Version ..
INFORMIX
Software, Inc., 		.

 G. Koch and K. Loney. Oracle: The Complete
Reference. OsborneMcGraw-Hill, 		.

 J. C. Lagarias. Pseudo-random number genera-
tors in cryptography and number theory. In Cryp-
tology and Computational Number Theory, pages
. American Mathematical Society, 		 .

L ink öp ing  S tud ies   in  Sc ience  and  T echno logy

D isser ta t ion  No .  494

Act ive  Database  Management
Systems  for  Mon itor ing  and
Contro l

Mart in  Sk ö ld

Depar tmen t  of  Compu ter  and  Informa t ion  Sc ience
L ink öp ing  Un ivers i ty ,  L ink öp ing ,  Sweden

L ink öp ing  1997

ii

Abstract
Ac t ive  Da tabase  Managemen t  Sys tems  (ADBMSs)  have  been  deve loped  to  sup-
por t  app l ica t ions  w i th  de tec t ing  changes  in  da tabases .  Th is  inc ludes  suppor t  for
spec ify ing ac t ive   ru les   tha t mon i tor   changes   to   da ta   and   ru les   tha t   perform
some con tro l  tasks  for  the  app l ica t ions .  Ac t ive  ru les  can  a lso  be  used  for  spec i-
fy ing   cons tra in ts   tha t   mus t   be   me t   to   ma in ta in   the   in tegr i ty   of   the   da ta ,   for
ma in ta in ing   long-runn ing   transac t ions ,  and  for  au thor iza t ion  con tro l .

Th is   thes is  beg ins  w i th  presen t ing  case   s tud ies  on  us ing  ADBMSs   for  mon i tor-
ing   and   con tro l .   The   areas   of   Compu ter   In tegra ted   Manufac tur ing   (CIM)   and
Te lecommun ica t ion   Ne tworks   have   been   s tud ied   as   poss ib le   app l ica t ions   tha t
can   use   ac t ive   da tabase   techno logy.   These   case   s tud ies   have   served   as   requ ire-
men ts   on   the   func t iona l i ty   tha t   has   la ter   been   deve loped   in   an   ADBMS .   Af ter
an   in troduc t ion   to   the   area   of   ac t ive   da tabase   sys tems   i t   is   exemp l i ﬁed   how
ac t ive   ru les   can   be   used   by   the   app l ica t ions   s tud ied .   Severa l   requ iremen ts   are
iden t i ﬁed   such   as   the  need   for   ef ﬁc ien t   execu t ion  of   ru les  w i th   comp lex   cond i-
t ions   and   suppor t   for   access ing   and   mon i tor ing   ex terna l   da ta   in   a   transparen t
manner.

The  ma in  body  of  work  presen ted  is  a  theory  for  incremen ta l  eva lua t ion ,  named
par t ia l   d i f ferenc ing .   I t   is   shown   how   the   theory   is   used   for   imp lemen t ing   ef ﬁ-
c ien t   ru le  cond i t ion  mon i tor ing   in   the  AMOS  ADBMS .  The  cond i t ion  mon i tor-
ing  is  based  on  a func t iona l  mode l  where  changes  to  ru le  cond i t ions  are  de ﬁned
as  changes   to  func t ions .  Ex terna l  da ta   is   in troduced  as fore ign   func t ions   to  pro-
v ide   transparency   be tween   access   and  mon i tor ing   of   changes   to   loca l   da ta   and
ex terna l  da ta .

The   thes is   inc ludes   severa l   pub l ica t ions   from   bo th   in terna t iona l   journa ls   and
in terna t iona l   conferences .   The   papers   and   the   thes is   dea l   w i th   issues   such   as   a
sys tem  arch i tec ture  for  a  CIM  sys tem  us ing  ac t ive  da tabase  techno logy,  ex tend-
ing  a  query  language  w i th  ac t ive  ru les ,  us ing  ac t ive  ru les  in  the  s tud ied  app l ica-
t ions ,   group ing   ru les   in to   modu les   (ru le   con tex ts) ,   ef ﬁc ien t   imp lemen ta t ion   of
ac t ive   ru les   by   us ing   incremen ta l   eva lua t ion   techn iques ,   in troduc ing   fore ign
da ta  in to  da tabases ,  and  tempora l  suppor t  in  ac t ive  da tabase  sys tems  for  s tor ing
even ts   mon i tored   by   ac t ive   ru les .   The   papers   are   comp lemen ted   w i th   back-
ground  informa t ion  and  work  done  af ter  the  papers  were  pub l ished ,  bo th  by  the
au thor  and  by  co l leagues .

v

Preface

Thes is  Out l ine
Th is   thes is   is   based   on   severa l   conference   and   journa l   papers   pub l ished   dur ing
a   per iod   of   four   years .   Each   chap ter   usua l ly   con ta ins   background   informa t ion
for  one  or   two  papers  and  work  done  af ter   the  pub l ica t ions .  A   l is t  of   the  papers
can   be   found   in   the   nex t   sec t ion   and   the   ac tua l   papers   can   be   found   in   the   las t
chap ter  of   the   thes is .
Chap ter   1   presen ts   the   ma in   d ifferences   be tween   ac t ive   da tabase   sys tems
and   “pass ive ”   da tabase   sys tems ,   and   compares   ac t ive   da tabase   sys tems   w i th
o ther  ru le-based  sys tems .
Chap ter   2   presen ts   the   areas   of   Compu ter   In tegra ted   Manufac tur ing   (CIM)
and   Te lecommun ica t ion   Ne tworks   and   how   da tabase   sys tems   can   be   used   to
suppor t   d ifferen t   func t ions   in   them .   Paper   I   is   presen ted   as   a   sys tem   arch i tec-
ture  for  a  CIM  sys tem   tha t  uses  ac t ive  da tabase   techno logy.
Chap ter   3   g ives   an   overv iew   of   Ac t ive   Da tabase   Managemen t   Sys tems
(ADBMSs)   and   in troduces   the   AMOS   ADBMS .   The   ac t ive   ru les   in   AMOSQL
are   presen ted   in   Paper   II   a long   w i th   changes   and   ex tens ions   made   s ince   the
paper  was  pub l ished .
Chap ter   4   d iscusses   he terogeneous   da ta   managemen t   in   the   app l ica t ions
s tud ied  in  chap ter  2 .  The  chap ter  a lso  br ie ﬂy  presen ts  the  area  of  he terogeneous
da tabase   sys tems   and   w i th   the   he terogeneous   da tabase   arch i tec ture   of   AMOS
presen ted   in  Paper  III .
In  chap ter  5  Paper  IV  is  presen ted  as  work  on  app ly ing  ac t ive  da tabase  tech-
no logy   on   a   spec i ﬁc   app l ica t ion ,   or  more   spec i ﬁca l ly   us ing  AMOS   in   the  CIM
arch i tec ture   presen ted   in   Paper   I .   In   Paper   V   a   techn ique   for   organ iz ing   ru les
by   group ing   them   in to ru le   con tex ts   is   presen ted .   Severa l   scenar ios   for   us ing
ac t ive  ru les   in  CIM  and  Te lecommun ica t ions  are  a lso  presen ted .
Chap ter   6   presen ts  work   on   ef ﬁc ien t   execu t ion   of   ac t ive   ru les .  Th is   chap ter
is   based   on   Paper  VI  wh ich   presen ts   a   techn ique   for   incremen ta l   eva lua t ion   of
ru le   cond i t ions , par t ia l   d i f ferenc ing .   Chap ter   6   a lso   presen ts   a   compar ison
be tween  even t  propaga t ion  and   incremen ta l  cond i t ion  eva lua t ion .
Chap ter  7  d iscusses   imp lemen ta t ion   issues  of  d ifferen t   aspec ts  of   the   ac t ive
ru les   and   spec i ﬁca l ly   the   managemen t   of   the
propaga t ion   ne twork   and   the
propaga t ion  a lgor i thm  used  for  par t ia l  d ifferenc ing .
In  chap ter  8   t ime  ser ies  are  presen ted   for  s tor ing  even t  h is tor ies   in   tempora l
func t ions  tha t  are  mon i tored  by  ac t ive  ru les .  The  area  of  tempora l  and  sc ien t i ﬁc
da tabases   are   a lso   br ie ﬂy   presen ted .   Paper   VII   presen ts   a   techn ique   for   au to-
ma t ica l ly  bu i ld ing  secondary   indexes  on   t ime  ser ies .
Chap ter   9   presen ts   the   concep t   of fore ign   da ta   sources   as   a   way   to   access

vi

Preface

da ta   or ig ina t ing   ou ts ide   the   da tabase .   D ifferen t   sys tems   and   pro toco ls   for
access ing   fore ign   da ta   sources   are   d iscussed .   Techn iques   for   mon i tor ing
changes   to   fore ign  da ta  sources  and  poss ib le  ex tens ions   to  AMOS  are  a lso  pre-
sen ted .
Chap ter  10  conc ludes  w i th  a  summary  of  the  con tr ibu t ions  in  th is  thes is  and
presen ts  poss ib le  fu ture  research  d irec t ions .
In   the   append ix   (chap ter   14)   the   comp le te   syn tax   of   the   ac t ive   ru les   in   the
AMOS   sys tem   is  presen ted  and   the   re la t ion  be tween  Da ta log  and   the   re la t iona l
opera tors .  A  forma l   jus t i ﬁca t ion  for  par t ia l  d if ferenc ing   is  a lso  presen ted .
In  chap ter  15   the  d ifferen t  papers   tha t   the   thes is   is  based  on  are  presen ted .

L ist  of  Papers
Here   fo l lows   a   l is t   of   the   pub l ished   papers   tha t   th is   thes is   is   based   on .   The
au thor  has  been   a  ma jor   con tr ibu tor   to   and   ed i tor  of   a l l  papers   excep t  Paper   III
and  Paper  VII .
Paper  I
P.  Loborg ,  P.  Ho lmbom ,  M .  Sk ö ld ,  and  A .  T örne :  A  Mode l  for   the  Execu t ion  of
Task   Leve l   Spec i ﬁca t ions   for   In te l l igen t   and   F lex ib le  Manufac tur ing   Sys tems ,
in   Proceed ings   of   the   V th   In terna t iona l   Sympos ium   on   Ar t i ﬁc ia l   In te l l igence ,
ISAI92 ,   Cancun ,   Mex ico ,   December   7-11 ,   1992 .   A lso   pub l ished   in   Journa l   of
In tegra ted  Compu ter-A ided  Eng ineer ing   (spec ia l   issue   on  AI   in  Manufac tur ing
and  Robo t ics) .
Paper  II
T.  R isch  and  M .  Sk ö ld :  Ac t ive  Ru les  based  on  Ob jec t-Or ien ted  Quer ies ,  in  spe-
c ia l   issue  on  Ac t ive  Da tabases   in  Da ta  Eng ineer ing  Bu l le t in  15(1-4) ,  Pages  27-
30 ,  1992 .
Paper  III
G .   Fah l ,   T.   R isch ,   and   M .   Sk ö ld :   AMOS   -   An   Arch i tec ture   for   Ac t ive   Med ia-
tors ,  in  Proceed ings  of  the  Workshop  on  Nex t  Genera t ion  Informa t ion  Techno l-
og ies  and  Sys tems  (NGITS ’92) ,  Ha ifa ,  Israe l ,  June  1993 .
Paper  IV
P.  Loborg ,  T.  R isch ,  M .  Sk ö ld ,  and  A .  T örne :  Ac t ive  Ob jec t-Or ien ted  Da tabases
in   Con tro l   App l ica t ions ,   in   Proceed ings   of   the   19 th   Eurom icro   Conference ,
Barce lona ,  Sep tember  1993 .
Paper  V
M .   Sk ö ld ,   E .   Fa lkenro th ,   and   T .   R isch :   Ru le   Con tex ts   in  Ac t ive  Da tabases   -  A
Mechan ism  for  Dynam ic  Ru le  Group ing ,  in  the  Second  In terna t iona l  Workshop
on   Ru les   in   Da tabase   Sys tems   (RIDS ’95) ,   A thens ,   Greece ,   Sep tember   25-27 ,
1995 ,   Spr inger   Lec ture   No tes   in   Compu ter   Sc ience ,   ISBN   3-540-60365-4 ,

vii

Pages  119-130 ,  1995 .
Paper  VI
M .   Sk ö ld   and   T .   R isch :   Us ing   Par t ia l   D ifferenc ing   for   Ef ﬁc ien t  Mon i tor ing   of
Deferred  Comp lex  Ru le  Cond i t ions ,  presen ted  a t  the  12 th  In terna t iona l  Confer-
ence  on  Da ta  Eng ineer ing   (ICDE ’96) ,  New  Or leans ,  Lou is iana ,  USA ,  February
1996 .
Paper  VII
L .  L in ,  T.  R isch ,  M .  Sk ö ld ,   and  D .  Bada l :   Index ing  V a lues   of  Time  Sequences ,
presen ted   a t   the  F if th   In terna t iona l  Conference   on   Informa t ion   and  Know ledge
Managemen t  (CIKM ’96) ,  Rockv i l le ,  Mary land ,  USA ,  November  12-16 ,  1996 .

F inanc ia l  Support
Th is   work   has   been   suppor ted   by   NUTEK   (The   Swed ish   Na t iona l   Board   for
Indus tr ia l  and  Techn ica l  Deve lopmen t) ,  TFR  (The  Swed ish  Techn ica l  Research
Counc i l) ,  CENIIT   (The  Cen ter   for   Indus tr ia l   Informa t ion  Techno logy) ,   and   the
ISIS   pro jec t   (Informa t ion   Sys tems   for   Indus tr ia l   Con tro l   and   Superv is ion) ,
L ink öp ing  Un ivers i ty .

Acknow ledgements
I   wou ld   l ike   to   thank   my   superv isor   Professor   Tore   R isch   for   h is   con t inuous
suppor t   and   for   in troduc ing   me   to   the   area   of   ac t ive   da tabase   sys tems .   Tore
brough t   the   WS-Ir is   sys tem   w i th   h im   from   HP- labs   and   h is   sys tem   has   now
become   the  AMOS  sys tem .  Because  of   th is  my  research  go t  a  runn ing  s tar t .
I   a lso   wou ld   l ike   to   thank   a l l   the   o ther  members   of   the   lab   for   Eng ineer ing
Da tabases   and   Sys tems   (EDSLAB)   for   insp ira t ion   and   for   fru i tfu l   d iscuss ions
on   the  deve lopmen t  of   the  AMOS  sys tem .
I  a lso  wou ld  l ike  to  thank  the  peop le  in  the  robo t ics  and  measuremen t  group
a t   the   Depar tmen t   of   Phys ics   and  Measuremen t   Techno logy   (IFM) ,   the   s taff   a t
Er icsson  Deve lopmen t ,  and   the  s taff  a t  Te l ia  Research   for  prov id ing  equ ipmen t
and  shar ing   the ir  know ledge .
F ina l ly  I  wou ld  l ike  to  thank  my  fam i ly  and  fr iends  for  a l l  the ir  suppor t  over
the  years  of  my  research  s tud ies .

To  my  paren ts  for   love  and  encouragemen t .

Mar t in  Sk ö ld

L ink öp ing ,  Ju ly ,  1997

viii

Preface

ix

Tab le  of  Con ten ts

1 Introduction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
1.1 Database Management Systems (DBMSs)  . . . . . . . . . . . . . . . . . . . . . . . . . . 1
1.2 Active DBMSs (ADBMSs) versus Passive DBMSs . . . . . . . . . . . . . . . . . . . 2
1.3 Using Rules as a Complement to Traditional Coding . . . . . . . . . . . . . . . . . . 3
1.4 Rule-Based Systems and Active Database Systems  . . . . . . . . . . . . . . . . . . . 4
1.5 DBMSs in Large Complex Systems  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
1.6 ADBMSs in Large Complex Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
1.7 Summary of Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7

2 Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
2.1 Application Studies  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
2.2 Computer Integrated Manufacturing (CIM)  . . . . . . . . . . . . . . . . . . . . . . . . . 9
2.3 DBMSs in CIM  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
2.4 About Paper I . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
2.5 Telecommunication Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
2.6 DBMSs in Telecommunication Networks . . . . . . . . . . . . . . . . . . . . . . . . . . 15

3 Active Database Management Systems  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
3.1 An Overview of Active Database Management Systems (ADBMSs) . . . . . 25
3.2 ADBMS Classifications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
3.3 AMOS  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
3.4 The Rule Processor and the Event Manager  . . . . . . . . . . . . . . . . . . . . . . . . 33
3.5 The Iris Data Model and OSQL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
3.6 About Paper II  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
3.7 The AMOS Data Model and AMOSQL  . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
3.8 ECA-rules  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
3.9 ECA-rules in AMOS  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49

4 Heterogeneous Data Management  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
4.1 DBMSs in Networks  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
4.2 Distributed v.s. Multidatabases Database Systems  . . . . . . . . . . . . . . . . . . . 53

x

Table of Contents

4.3 About Paper III  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
4.4 Active Multidatabase Systems  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
4.5 Heterogeneous Databases in CIM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
4.6 Heterogeneous Databases in Telecommunication Networks  . . . . . . . . . . . 55

5 Applying Active Database Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
5.1 Applications and Active Database Systems  . . . . . . . . . . . . . . . . . . . . . . . . 59
5.2 Scenarios for an ADBMSs in CIM Systems . . . . . . . . . . . . . . . . . . . . . . . . 59
5.3 About Paper IV  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
5.4 About Paper V . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
5.5 Monitoring Long-running Transactions  . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
5.6 Scenarios for ADBMSs in Telecommunication Networks . . . . . . . . . . . . . 64

6 Efficient Rule Execution Using Partial Differencing  . . . . . . . . . . . . . . . . . . . 77
6.1 Efficiency Problems in ADBMSs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
6.2 Partial Differencing of Rule Conditions  . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
6.3 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
6.4 An Example Rule with Efficiency Problems . . . . . . . . . . . . . . . . . . . . . . . . 82
6.5 CA-rule Semantics and Function Monitoring . . . . . . . . . . . . . . . . . . . . . . . 83
6.6 ObjectLog  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
6.7 The Calculus of Partial Differencing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
6.8 The Propagation Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
6.9 Performance Measurements  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
6.10 Optimization Techniques for Partial Differencing  . . . . . . . . . . . . . . . . . 111
6.11 Strict and Nervous Rule Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
6.12 Bag-oriented and Set-oriented Semantics . . . . . . . . . . . . . . . . . . . . . . . . 115
6.13 Partial Differencing of Overloaded Functions . . . . . . . . . . . . . . . . . . . . . 116
6.14 ECA-rule Semantics  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
6.15 Propagating Events of ECA-rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
6.16 Event Propagation vs. Partial Differencing of Rule Conditions  . . . . . . . 122
6.17 Extended Partial Differencing Calculus for Updates  . . . . . . . . . . . . . . . 126
6.18 Partial Differencing of Aggregates  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
6.19 Rule Termination Analysis  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
6.20 Real-time Aspects of Rule Execution  . . . . . . . . . . . . . . . . . . . . . . . . . . . 130

7 The Propagation Network . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
7.1 Implementing Active Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133

xi

7.2 Capturing and Storing Events  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
7.3 The Propagation Network  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134
7.4 Accessing Event Functions in Conditions and Actions . . . . . . . . . . . . . . . 146
7.5 Creation and Deletion of Rules  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
7.6 The Algorithms for Activating and Deactivating Rules  . . . . . . . . . . . . . . 146
7.7 The Event and Change Propagation Algorithm . . . . . . . . . . . . . . . . . . . . . 148
7.8 The Check Phase and Propagating Rule Contexts . . . . . . . . . . . . . . . . . . . 153
7.9 Event Consumption  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154

8 Time Series and Event Histories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157
8.1 Time in Applications and ADBMSs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157
8.2 Temporal Databases and Scientific Databases  . . . . . . . . . . . . . . . . . . . . . 157
8.3 Supporting Time in Databases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
8.4 Time Stamps  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
8.5 Time Intervals  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
8.6 Time Series  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
8.7 Temporal Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
8.8 Time Stamped Events  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
8.9 About Paper VII . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161
8.10 Temporal Event Specifications and Temporal Conditions  . . . . . . . . . . . 161

9 Foreign Data Sources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163
9.1 Introduction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163
9.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166
9.3 Accessing Foreign Data Sources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
9.4 Monitoring Foreign Data Sources  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172
9.5 Implementation Issues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176
9.6 Foreign Data Sources in AMOS  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186

10 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189
10.1 Summary  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189
10.2 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190

13 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191

14 Appendix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199
14.1 The Current Rule Syntax in AMOS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199
14.2 The Relational Operators in Datalog . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202
14.3 Justification for Partial Differencing . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203

xii

Table of Contents

15 The Papers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209
15.1 Paper I  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209
15.2 Paper II  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
15.3 Paper III . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232
15.4 Paper IV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244
15.5 Paper V  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258
15.6 Paper VI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271
15.7 Paper VII . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272

1

1

In troduc t ion

1 .1 Database  Management  Systems  (DBMSs)

A   Da tabase   Managemen t   Sys tem   (DBMS)   [39]   is   a   genera l   informa t ion   man-
agemen t   sys tem   tha t   can   manage   many   d ifferen t   k inds   of   da ta ,   s tored   in   the
da tabase .  By  DBMS  we  here  mean  more  than  jus t  a  sys tem  tha t  manages  var ia-
b les  or   ﬁ les  of  da ta .  The  da ta  can  be  bo th  app l ica t ion  da ta  of  d if feren t types  and
me ta-da ta   used   by   the   DBMS   to   de ﬁne   the   da tabase   layou t ,   the   da tabase
schema .  In  re la t iona l  DBMSs  (RDBMSs)  da ta  is  de ﬁned  w i th  re la t ions  be tween
da ta  wh ich   are   s tored   in tab les   and   can   be   accessed   through   log ica l   quer ies ,   or
re la t iona l  v iews .
The  DBMS  prov ides  suppor t  for log ica l  v iews  of  da ta  tha t  are  separa te  from
the  phys ica l  v iews ,  i .e .  how  the  da ta  is  ac tua l ly  s tored  in  the  da tabase .  Th is  sep-
ara t ion   is   accomp l ished   by   a l low ing   app l ica t ions   to   de ﬁne ,   access ,   and   upda te
da ta  through  a  Da ta  De ﬁn i t ion  Language  (DDL)  and  Da ta  Man ipu la t ion  Langu-
age   (DML)   comb ined   in to   a dec lara t ive   query   language such   as   the   re la t iona l
query   language  SQL  [6] .
The   DBMS   prov ides pers is tency   of   da ta   by   ensur ing   tha t   no   da ta   is   los t   in
the  case  of  sys tem  fa i lures .  The  pers is tency  can  be  ach ieved  in  many  ways ,  e .g .
by  s tor ing  da ta  and  a   log  of  uncomm i t ted  changes   to  da ta  on  d isk .
DBMSs   are   trad i t iona l ly   se lf-con ta ined   sys tems   (servers)   and   users   or
app l ica t ions   (c l ien ts)   execu te   in   separa te   processes   (of ten   on   separa te
mach ines)   and   are   prov ided   access   to   the   DBMS   through   a c l ien t /server   in ter-
face .   For   many   techn ica l   app l ica t ions   the   performance   requ iremen ts   forces   a
t igh ter   in tegra t ion   be tween   the   app l ica t ion   and   the   DBMS .   The   DBMS   is   then
embedded   w i th   the   app l ica t ions   and   execu tes   in   the   same   process   (or   a t   leas t
shares   the   same   address   space) .   App l ica t ions   w i th   embedded   DBMSs   are   pro-
v ided  fas t  access   to  da ta   through  a fas t-pa th   in ter face .
Ano ther   impor tan t  aspec t  of   func t iona l i ty  suppor ted  by  a  DBMS   is transac-
t ion   managemen t .   Transac t ions   prov ide   a   mechan ism   for   organ iz ing   and   syn-
chron iz ing   da tabase   opera t ions .   D ifferen t   users   and   app l ica t ions   can   use
transac t ions   for   de ﬁn ing   sequences   of   da tabase   opera t ions   w i thou t ,   more   or
less ,   hav ing   to   cons ider   poss ib le   in terac t ion   w i th   o ther   users   and   app l ica t ions .
If ,   for   some   reason ,   some th ing  goes  wrong  dur ing  a   transac t ion ,   the  user  or   the
app l ica t ion   can   choose   to abor t   the   transac t ion   and   a l l   the   da tabase   opera t ions
are  undone .   If   a   transac t ion   is   ﬁn ished   successfu l ly ,   the  DBMS   can comm i t the
transac t ion  and  make  a l l   the  changes   in   the  da tabase  permanen t .
In  recen t  years   there  has  been  deve lopmen t  of  DBMSs  w i th  more  da ta  mod-

2

Introduction

e l l ing   suppor t .   Th is   is   of ten   needed   in   techn ica l   and   sc ien t i ﬁc   app l ica t ions
where   the   schemas   can   be   h igh ly   comp lex .   In   Ob jec t   Or ien ted   Da tabase  Man-
agemen t   Sys tems   (OODBMSs)   OO   programm ing  
languages   have   been
ex tended   to   suppor t   da tabase  managemen t   through   pers is ten t   ob jec t   c lasses .   A
s tandard   query   language ,  OQL   [20] ,   has   been   de ﬁned   for   dec lara t ive   access   to
the   da ta .   The   OODBMS   mode l   does   no t ,   however,   prov ide   a   fu l ly   dec lara t ive
query   language   for   bo th   de ﬁn ing ,   access ing ,   and   upda t ing   da ta   (ob jec t   de ﬁn i-
t ions  w i th   a t tr ibu tes   and  me thods   are   s t i l l   de ﬁned   in   the  OO   programm ing   lan-
guage) .  OO  programm ing  languages  such  as  C++  a l low  low- leve l  opera t ions  on
ob jec ts  wh ich  makes  the  separa t ion  be tween  a  log ica l  and  phys ica l  v iew  of  da ta
in  OODBMSs  d if ﬁcu l t   to  suppor t .
In  Ob jec t  Re la t iona l  Da tabase  Managemen t  Sys tems   (ORDBMSs)   [118]   the
da ta   mode ls   from   the   re la t iona l   DBMS   and   the   OODBMS   have   been   merged .
ORDBMSs   prov ide   dec lara t ive   OO   query   languages   such   as   OSQL   [85]   and
SQL3   [90]   for   de ﬁn ing ,   access ing ,   and   upda t ing   ob jec ts .   Ob jec t   c lasses   are
de ﬁned   as   types ,   and   ob jec t   a t tr ibu tes   and   me thods   are   de ﬁned   as   func t ions .
Func t ions   are   a lso   equ iva len t   to   tab les   (or   tab le   a t tr ibu tes)   and   v iews   in   the
re la t iona l  mode l .   The   tab les   themse lves   are   some t imes   cons idered   as   a   spec ia l
abs trac t   type  [10] ,  bu t  wh ich   is  accessed   through  func t ions .

1 .2 Act ive  DBMSs  (ADBMSs)  versus  Pass ive  DBMSs

Trad i t iona l   DBMSs   are pass ive   in   the   sense   tha t   they   are   exp l ic i t ly   and   syn-
chronous ly   invoked  by  user  or  app l ica t ion  program   in i t ia ted  opera t ions .  App l i-
ca t ions  send  reques ts  for  opera t ions  to  be  performed  by  the  DBMS  and  wa i t  for
the   DBMS   to   con ﬁrm   and   re turn   any   poss ib le   answers .   The   opera t ions   can   be
de ﬁn i t ions   and   upda tes   of   the   schema ,   as   we l l   as   quer ies   and   upda tes   of   the
da ta .   Ac t ive   Da tabase Managemen t   Sys tems   (ADBMSs)   are   even t   dr iven   sys-
tems   where   opera t ions   such   as   schema   changes   and   changes   to   da ta   genera te
even ts   tha t   can   be  mon i tored   by ac t ive   ru les .  An  ADBMS   can   be   invoked ,   no t
on ly   by   synchronous   even ts   tha t   have   been   genera ted   by   users   or   app l ica t ion
programs ,   bu t   a lso   by   ex terna l   asynchronous   even ts   such   as   changes   of   sensor
va lues   or   t ime .  When   mon i tor ing   even ts   in   a   pass ive   da tabase ,   a po l l ing   tech-
n ique  or opera t ion   ﬁ l ter ing   can  be  used   to  de term ine   changes   to  da ta .  Wi th   the
po l l ing  me thod  the  app l ica t ion  program  per iod ica l ly  po l ls  the  da tabase  by  p lac-
ing   a   query   abou t   the   mon i tored   da ta .   The   prob lem   w i th   th is   approach   is   tha t
the   po l l ing   has   to   be   ﬁne- tuned   so   as   no t   to   ﬂood   the  DBMS  w i th   too   frequen t
quer ies   tha t   mos t ly   re turn   the   same   answers ,   or   in   the   case   of   too   infrequen t
po l l ing ,   the  app l ica t ion  m igh t  m iss   impor tan t  changes  of  da ta .  Opera t ion   ﬁ l ter-
ing  is  based  on  the  fac t  tha t  a l l  change  opera t ions  sen t  to  the  DBMS  are   ﬁ l tered
by   an   app l ica t ion   layer   tha t   performs   the   s i tua t ion   mon i tor ing   before   send ing
the   opera t ions   to   the   DBMS .   The   prob lem   w i th   th is   approach   is   tha t   i t   grea t ly
l im i ts   the  way   ru le   cond i t ion   eva lua t ion   can   be   op t im ized .   I t   is   des irab le   to   be
ab le   to   spec ify   the   cond i t ions   to   mon i tor   in   the   query   language   of   the   DBMS .
By   check ing   the   cond i t ions   ou ts ide   the   da tabase   the   comp le te   quer ies   repre-
sen t ing   the   cond i t ions   w i l l   have   to   be   sen t   to   the   DBMS .  Many   DBMSs   a l low

3

precomp i led s tored  procedures  tha t  can  upda te  the  da tabase .  The  effec ts  of  ca l l-
ing  such  a  procedure  canno t  be  de term ined  ou ts ide  of   the  da tabase .
If   the  cond i t ion  mon i tor ing   is  used   to  de term ine   incons is tenc ies   in   the  da ta-
base ,   i t   is   ques t ionab le   whe ther   th is   shou ld   be   performed   by   the   app l ica t ions ,
ins tead   of   by   the   DBMS   i tse lf .   In   an   in tegra ted   ADBMS   cond i t ion  mon i tor ing
is   in tegra ted   in to   the   da tabase .   Th is   makes   i t   poss ib le   to   ef ﬁc ien t ly   mon i tor
cond i t ions  and   to  no t ify  app l ica t ions  when  an  even t  occurred   tha t  caused  a  ru le
cond i t ion   to   become   true   and   tha t   is   of   in teres t   to   the   app l ica t ion .   Mon i tor ing
of   spec i ﬁc   cond i t ions ,   represen ted   as   da tabase   quer ies ,   can   be   performed  more
ef ﬁc ien t ly  s ince  the  ADBMS  has  more  con tro l  of  how  to  eva lua te  the  cond i t ion
ef ﬁc ien t ly   based   on   know ledge   of   wha t   has   changed   in   the   da tabase   s ince   the
cond i t ion  was   las t  checked .   I t  a lso   le ts   the  ADBMS  perform  cons is tency  ma in-
tenance  as  an   in tegra ted  par t  of   the  da ta  managemen t .
In terna l  ADBMS  func t ions  tha t  can  use  da ta  mon i tor ing  inc ludes ,  for  exam-
p le , cons tra in t   managemen t , managemen t   o f   long-runn ing   transac t ions ,   and
au thor iza t ion   con tro l .   In   cons tra in t   managemen t ,   ru les   can   mon i tor   and   de tec t
incons is ten t   upda tes   and   abor t   any   transac t ions   tha t   v io la te   the   cons tra in ts .   In
some   cases   compensa t ing   ac t ions   can   be   performed   to   avo id   incons is tenc ies
ins tead   of   perform ing   an   abor t ion   of   the   comp le te   transac t ion .   In   the   manage-
men t   of   long-runn ing   transac t ions ,   ru les   can   be   used   to   ef ﬁc ien t ly   de term ine
synchron iza t ion   po in ts   of   d ifferen t   ac t iv i t ies   and   a lso   whe ther   if   one   transac-
t ion   has   performed   upda tes   tha t   have   in terfered  w i th   ano ther   [32] .   Th is   can   be
used ,   for  examp le ,   in  coopera t ion  w i th sagas [51]  where   sequences  of  comm i t-
ted   transac t ions   are   cha ined   toge ther  w i th   informa t ion   on   how   to   execu te   com-
pensa t ing   transac t ions   in   case   of   a   saga   ro l l-back .   Groups   of   ru les   can   be
assoc ia ted  w i th  a  saga  to  de tec t  any  in terference  w i th  the  opera t ions  in  the  saga
and  tha t  can  redo  the  opera t ions  or  ro l l-back  the  saga  to  undo  the  opera t ions .  In
au thor iza t ion  con tro l  ru les  can  be  used   to  check   tha t   the  user  or  app l ica t ion  has
perm iss ion   to  do  spec i ﬁc  upda tes  or  schema  changes   in   the  da tabase .
App l ica t ions  wh ich  depend  on  da ta  mon i tor ing  ac t iv i t ies  such  as  CIM ,  Te le-
commun ica t ions   Ne twork   Managemen t ,   Med ica l   [66]   and   F inanc ia l   Dec is ion
Suppor t  Sys tems  [26]  can  grea t ly  bene ﬁ t  from   in tegra t ion  w i th  ADBMSs .

1 .3 Us ing  Ru les  as  a  Comp lement  to  Trad it iona l  Cod ing

Ac t ive   ru les   can   serve   as   a   comp lemen t   to   trad i t iona l   cod ing   techn iques  where
a l l   the   func t iona l i ty  of   the   sys tem   is   spec i ﬁed   in  a lgor i thms  wr i t ten   in  modu les
and  func t ions .  Ac t ive  ru les  prov ide  a  more  dynam ic  way  of  hand l ing  new  s i tua-
t ions   and   are   of ten   be t ter   a l terna t ives   to   mod ify ing   o ld   func t ions   to   cope   w i th
new   s i tua t ions .  Grea t   care  has   to  be   taken ,  however,  when  us ing   ac t ive   ru les   to
avo id   in troduc ing   unan t ic ipa ted   behav iour   in to   the   sys tem .   M isuse   of   ru les ,
such   as   us ing   too  many   leve ls   of   ru les   tha t   can   affec t   each   o ther   in   unpred ic ta-
b le  ways  or   a t temp ts   to  use   ru les  where   trad i t iona l   func t ions   are  more   su i ted   is
one   reason   why   the   use   of   ac t ive   ru les   in   sof tware   deve lopmen t   has   on ly   had
l im i ted   success .  A  common   techn ique   tha t   is  used   is   to  use   ru les   for   spec ify ing
par ts  of  the  sys tem  dur ing  the  des ign  phases  and  to  use  these  ru les  as  gu ide l ines

4

Introduction

for   the   ac tua l   cod ing   phases   or   to   comp i le   the   ru les   in to   correspond ing   func-
t ions   to   s imp l ify   the   cod ing .   Th is   las t   techn ique   is   some t imes   found   d irec t ly
suppor ted   in   some   programm ing   languages   such   as   E iffe l   [88]   where   pre-   and
pos t-cond i t ions  on  da ta   can  be   spec i ﬁed .   If   the   cond i t ions   are  v io la ted   an   error
is   genera ted .   Ru les   can ,   however,   spec ify   pre-   or   pos t-cond i t ions   tha t   shou ld
app ly   in   many   d ifferen t   s i tua t ions   no t   jus t   in   one   p iece   of   code .   The   ru les   can
s igna l   to   the  user  or   some   app l ica t ion   tha t   a   cond i t ion  has  been  v io la ted .  Ru les
can   a lso   spec ify   ac t ions   to   be   taken ,   such   as   remov ing   incons is tenc ies   by
chang ing   i l lega l  va lues  of  da ta .
In   mos t   programm ing   languages   and   query   languages   such   as   SQL3   [90]
fau l t   or   s igna l   hand lers   can   be   de ﬁned   tha t   ca tches   error
s igna ls .   Ru les   in   an
ADBMS   can   be   seen   as   hav ing   s im i lar   behav iour,   bu t   ca tches   da tabase even ts
such  as  upda tes .
Ru les  can  a lso  be  used  for  mon i tor ing  changes  to  da ta .  These  are  of ten  spec-
i ﬁed  as  cond i t iona l  express ions  ( i f- then-e lse ,  or case  express ions)  in  trad i t iona l
cod ing .   These   are   s ta t ic   express ions   tha t   canno t   be   changed   un less   the   code   is
changed   and   recomp i led .   In   da tabases   tha t   suppor t   incremen ta l   recomp i la t ion
of   func t ions   and   ru les   (such   as   the   AMOS   ADBMS) ,   the   ru les   can   be   dynam i-
ca l ly  changed .  New  s i tua t ions  can  a lso  be  mon i tored  by  add ing  new  ru les .

1 .4 Ru le-Based  Systems  and  Act ive  Database  Systems

In   ru le-based   sys tems   the   ru les   can   be   used   for   d ifferen t   purposes .   In   ﬁg .   1 .1
the  d is t inc t ion  is  made  be tween  us ing  ru les  for mon i tor ing , con tro l ,  and reason-
ing .  We  here  make  a  d is t inc t ion  be tween ac t ive  da tabase  sys tems [92]  and  o ther
ru le   based   sys tems   such   as reac t ive   sys tems [87]   (some t imes   ca l led   rea l- t ime
exper t   sys tems) and know ledge-based   sys tems   [68]   (of ten   jus t   referred   to   as
exper t  sys tems) .
Ac t ive   da tabase   sys tems   are   pr imar i ly   da tabase   managemen t   sys tems   w i th
the  ma in   task  of   s tor ing   large  amoun ts  of  da ta  and  prov id ing  ef ﬁc ien t  access   to
th is  da ta  through  a  query  language .  In  ac t ive  da tabase  sys tems  the  ru les  are  pr i-
mar i ly   used   for  mon i tor ing   changes   to   the   da ta   s tored   in   the   da tabase .   In   reac-
t ive   sys tems   the   ru les   are   used   for   reac t ing   to   changes   of   some   ex terna l
env ironmen t   and   perform ing   ac t ions   on   (con tro l l ing)   the   env ironmen t   in
response  to  the  changes .  In  know ledge-based  sys tems  the  ru les  are  usua l ly  used
for   reason ing   us ing   s tored   fac ts   and   by   deduc ing   new   fac ts   by   us ing   the   ru les .
As  can  be  seen   in   ﬁg .  1 .1   there   is  no  sharp  d is t inc t ion  be tween   the   three  d if fer-
en t   k inds   of   ru le   sys tems .   An   ac t ive   da tabase   sys tem   can   do   l im i ted   reason ing
by  us ing  ru les  w i th  more  comp l ica ted  ru le  cond i t ions  and  wh ich  s tore  new  da ta
in  the  da tabase  as  new  fac ts  tha t  s ign ify  tha t  the  ru les  have  tr iggered .  Con tro l  of
the   env ironmen t   represen ted   by   the   da ta   in   the   da tabase   i tse lf   can   a lso   be   per-
formed ,   e .g .   w i th   cons tra in t   ru les   tha t   mod ify   the   da tabase   to   remove   any
incons is tenc ies .  By   a l low ing   the   ac t ive   da tabase  manager   to   access   an   ex terna l
env ironmen t  tha t  can  be  bo th  accessed  and  upda ted ,  the  ru les  in  the  ac t ive  da ta-
base   can   be   used   for   con tro l   of   an   ex terna l   env ironmen t   as   we l l .   The   pr imary
use   of   ac t ive   ru les   in   an   ac t ive   da tabase   sys tem   as   presen ted   in   th is   thes is   is   to

reasoning

knowledge-based
systems

5

active database
systems

monitoring

control

reactive syste ms
F igure  1 .1: The   re la t ion  be tween   ac t ive  da tabase   sys tems   and  o ther   ru le-
based  sys tems

mon i tor  changes   to   the  da ta   tha t  can  be  accessed   in   the  da tabase .

1 .5 DBMSs   in  Large  Comp lex  Systems

DBMSs   prov ide   suppor t   for   hand l ing   informa t ion   in   large   comp lex   sys tems .
In tegra t ing  a  sys tem  w i th  a  DBMS  prov ides  shor ter  deve lopmen t  t imes  (assum-
ing   the   DBMS   is   a lready   ava i lab le) ,   reduced   comp lex i ty,   re l iab i l i ty,   and   sup-
por t  for  ex tens ib i l i ty.
When   comp lex   sys tems   are   des igned ,   the   informa t ion   or   da ta   tha t   they
shou ld  hand le  has   to  be  cons idered  ear ly   in   the  des ign  process .  Da ta  mode l l ing
is   of ten   performed   a t   an   ear ly   des ign   phase   toge ther   w i th   func t iona l i ty  mode l-
l ing .   In   th is   phase   spec i ﬁc   mode l l ing   techn iques   such   as   Ob jec t-Or ien ted   da ta
mode l l ing   are   of ten   used .   In   la ter   phases   the   ac tua l   da ta   s truc tures   are   chosen
for   s tor ing   the   da ta .   An   OODBMS   can   suppor t   da ta   mode l l ing   and   se lec t   ef ﬁ-
c ien t   da ta   s truc tures   a lready   prov ided   by   the   OODBMS .   If   an   RDBMS   (non-
OO)   is   used ,   then   any   OO   mode ls   have   to   be   trans la ted   in to   tab les   and   v iews .
Inher i tance   of   a t tr ibu tes   in   tab les   and   v iews   w i l l   then   have   to   be   hand led   ou t-
s ide   the  DBMS .  DBMSs   usua l ly   suppor t   a   separa t ion   be tween   the   log ica l   v iew
of   the   da ta   seen   by   the   sys tem   func t ions   and   the   phys ica l   v iew,   i .e .   wha t   da ta
s truc tures  are  used  to  s tore  the  da ta  phys ica l ly.  Th is  makes  i t  poss ib le  to  change

6

Introduction

the  da ta  s truc tures   in   the  da tabase  w i thou t  affec t ing   the  app l ica t ions .
Large   comp lex   sys tems   usua l ly   cons is t   of   many   func t ions   tha t   a l l   ca l l   for
da ta  managemen t .  Hav ing  a  DBMS  tha t  can  suppor t  the  func t ions  w i th  th is ,  the
comp lex i ty   of   the   sys tem   can   be   reduced .   For   examp le ,   if   two   func t ions   use
s im i lar   da ta   s truc tures ,   there   is   no   need   to   imp lemen t   these   da ta   s truc tures   for
each   func t ion .   By   imp lemen t ing   them   us ing   abs trac t   da ta   types   or   ob jec t
c lasses   they   can   be   reused   by   each   func t ion .   In   ORDBMSs   [118]   abs trac t   da ta
types   are   prov ided   through   an   Ob jec t-Or ien ted   ex tens ion   of   the   re la t iona l
mode l .
Ano ther   prob lem   is   tha t   the   re l iab i l i ty   of   these   sys tems   is   of ten   dependen t
on   no   da ta   be ing   los t ,   i .e .   even   if   the   sys tem   fa i ls   due   to   power   loss   or   fau l ty
hardware ,   the   da ta   shou ld   be   ava i lab le   aga in   as   soon   as   the   sys tem   recovers .
Th is   is   a   common   tra i t   in   bo th  Te lecommun ica t ion   Sys tems   and  many  Compu-
ter   In tegra ted  Manufac tur ing   (CIM)   sys tems .  A   so lu t ion   to   these   prob lems   has
been  to  in troduce  a  DBMS  in to  the  sys tem  tha t  suppor ts  pers is tency  of  da ta  and
transac t ions  for  organ iz ing  da tabase  opera t ions .
A   common   prob lem   in   des ign ing   large   comp lex   sys tems   is   tha t   the   sys tems
mus t  suppor t  mod i ﬁca t ion  w i thou t  too  much  redes ign .  Of ten  i t  mus t  be  poss ib le
to  mod ify   da ta   s truc tures  w i thou t   recomp i l ing   app l ica t ion   programs   and   some-
t imes   even   w i thou t   tak ing   the   sys tem   ou t   of   serv ice .   I t   cou ld   be   the   case   tha t
some   da ta   s truc tures   are   too   sma l l   or   perhaps   lack   some   da ta   ﬁe lds   tha t   are
needed   to   suppor t   new   func t iona l i ty.   Such   mod i ﬁca t ions   are   usua l ly   d irec t ly
suppor ted  by  a  DBMS .

1 .6 ADBMSs   in  Large  Comp lex  Systems

The  in troduc t ion  of  a  DBMS  in to  a  sys tem  prov ides  a  good  p la tform  for  des ign-
ing   ru les   tha t   access   da ta   from   d ifferen t   par ts   of   the   sys tem .  Ru les   are   depend-
en t   on   the   fac t   tha t   a l l   the   informa t ion   tha t   is   needed   to   check   the   ru les   is
ava i lab le .   In   a   sys tem   w i thou t   a   genera l   mechan ism   for   s tor ing   da ta   the   ru les
have  to  be  comp i led  in to  each  modu le  or  func t ion  tha t  can  affec t  the  ru le  cond i-
t ion .   Th is   l im i ts   the   ru le   to   jus t   re la t ing   to   da ta   ava i lab le   in   tha t   modu le   or
func t ion .
In   an   ADBMS   ac t ive   ru les   are   managed   by   the   ADBMS   and   the   ru les   can
thus   d irec t ly   access   da ta   s tored   in   the   da tabase .   Ru les   spec i ﬁed   in   a   da tabase
can   have   cond i t ions   tha t   span   over   da ta   be long ing   to   severa l   modu les   of   the
sys tem .   The   ac t ive   ru les   can   be   used   for   d irec t ly   suppor t ing   var ious   app l ica-
t ions   w i th   mon i tor ing   of   changes   to   da ta   in   the   da tabase ,   w i th   synchron iz ing
ac t iv i t ies   in   the   sys tem ,   and   w i th  ma in ta in ing   the   in tegr i ty   of   da ta   in   the   da ta-
base .
Care   has   to   be   taken   when   des ign ing   these   sys tems   to   no t   in troduce
unwan ted   or   unspec i ﬁed   commun ica t ion   be tween   modu les   through   the   da ta-
base .  A   common   and   successfu l   techn ique   in   des ign ing   large   sys tems   has   been
to   carefu l ly   des ign   the   in terac t ion   be tween   d ifferen t   modu les   or   processes   by
spec ia l   in terfaces ,   i .e .  by   expor ted   in terface   func t ions  or  by   in ter-process   com-
mun ica t ion .  The  des ign  phase  now  has  to  take  in to  cons idera t ion  wha t  da ta  tha t

7

is  go ing   to  be   s tored   in   the  da tabase   for   each  modu le   and  wha t  da ta   is  go ing   to
be  v is ib le   to  o ther  modu les .
By  s tor ing  informa t ion  abou t  the  s ta te  of  the  sys tem  in  the  da tabase ,  e .g .  the
s ta te   of   d ifferen t   hardware   and   sof tware   componen ts ,   ac t ive   ru les   can   be   used
to  mon i tor   the   s ta te   of   the   sys tem   i tse lf .   If   the   sys tem   is   in terac t ing  w i th   some
ex terna l   env ironmen t ,   e .g .   a   te lecommun ica t ion   ne twork   or   a   manufac tur ing
p lan t ,   s ta te   informa t ion   of   these   env ironmen ts   can   be   made   ava i lab le   in   the
da tabase   as  we l l .  Th is   cou ld   be   done   by  mapp ing   sensor   da ta   in to   the   da tabase
and   mak ing   i t   ava i lab le   in   quer ies   and   ru les .   Th is   does   no t   have   to   mean   tha t
the  sensor  da ta  is  a lways  s tored  permanen t ly  in  the  da tabase .  I t  may  be  the  case
tha t   the   sensor   da ta   is   ava i lab le   to   read   as   if   i t   was   s tored   d irec t ly   in   the   da ta-
base   and   tha t   the   ADBMS   is   informed   when   the   sensor   da ta   changes .   In  many
cases  i t  makes  no  sense  to  s tore  the  da ta  permanen t ly  s ince  i t  changes  qu i te  fre-
quen t ly.  The  sensor  da ta  can  some t imes  be  s tored  for  logg ing  purposes ,  bu t  th is
m igh t  a lready  be  done  in  some  o ther  sys tem  tha t  is  par t  of  the  ex terna l  env iron-
men t .   A l low ing   access   to   the   s ta te   of   the   ex terna l   env ironmen t   through   the
da tabase  makes  i t  poss ib le  to  use  ac t ive  ru les  to  mon i tor  changes  in  the  ex terna l
env ironmen t .

1 .7 Summary  of  Contr ibut ions

Th is   thes is   presen ts   some   case   s tud ies   from   the   app l ica t ion   areas   of   Compu ter
In tegra ted   Manufac tur ing   (CIM)   and   Te lecommun ica t ion   Ne twork   Manage-
men t   (TNM) .  These   app l ica t ion   s tud ies   serve   as   requ iremen ts   for   the  des ign  of
the   AMOS   ADBMS   and   espec ia l ly   the   ac t ive   func t iona l i ty   of   AMOS   tha t   is
presen ted   in   th is   thes is .   The   thes is   is   based   on   severa l   pub l ica t ions   such   as
papers   a t   in terna t iona l   conferences   and   ar t ic les   in   in terna t iona l   journa ls .   The
ma jor  con tr ibu t ions  w i th in   the   ﬁe ld  of  ac t ive  da tabase  sys tems  are :

• Identifying the need of ADBMSs through the case   s tud ies  of CIM and TNM. In
the application studies the requirements for efficient execution of rules with com-
plex  conditions  and  the  need  for  transparent  access  of  external  data were  identi-
fied.

• Using active rules for mon i tor ing  and con tro l  in CIM and TNM.

• Identifying the need for med ia tors  in CIM and TNM.

• Defining an ADBMS architecture.

• Identifying the need for generalizing the architecture towards ac t ive  med ia tors .

• Adding active rules to an Object-Relational DBMS.

• Integrating (E)CA-rules into a query language.

• Rule modularization by grouping rules into ru le  con tex ts .

• Efficient rule evaluation techniques based on par t ia l  d i f ferenc ing .

• Defining  external  data  in  a  transparent  manner  through  the  concept  of fore ign

8

da ta  sources .

Introduction

• Defining external events  through  the concept of fore ign   even ts  of fore ign   func-
t ions .

• Work on introducing t ime  ser ies  for storing event histories.

• Work on new index ing   techn iques  for inverse queries over time series.

9

2

Background

2 .1 App l icat ion  Stud ies

Th is   chap ter   presen ts   app l ica t ion   s tud ies   done   as   background   research   to   ﬁnd
wha t   requ iremen ts   there   are   on   an   ADBMS   for   suppor t ing   var ious   techn ica l
app l ica t ions .  The  goa l  is  to  prov ide  the  ADBMS  w i th  genera l  func t iona l i ty  tha t
is   su i tab le   for   the   var ious   needs   of   d ifferen t   app l ica t ions .   Some   func t iona l i ty
m igh t  no t  be  as   impor tan t   for  one  app l ica t ion  as   for  ano ther,  bu t  a l l   func t iona l-
i ty   shou ld   be   as   genera l   as   poss ib le   ins tead   of   imp lemen t ing   very   spec ia l ized
func t iona l i ty   ta i lored  for   jus t  one  spec i ﬁc  app l ica t ion .
Two  app l ica t ion  areas  were  s tud ied  and  are  presen ted   in   th is   thes is :

• Computer Integrated Manufacturing (CIM)

• Telecommunication Networks

2 .2 Computer  Integrated  Manufactur ing  (CIM)

Compu ter   In tegra ted   Manufac tur ing   (CIM)   is   a   broad   term   tha t   covers   a l l
aspec ts  of  au toma ted  manufac tur ing  from  us ing  we ld ing  robo ts  in  car  manufac-
tur ing   to  us ing  spec ia l ized  equ ipmen t  for  mak ing   in tegra ted  c ircu i ts  or  con tro l-
l ing   a   s tee l-   or   paper-m i l l .   There   are   usua l ly   many   compu ter   sys tems   used   in
manufac tur ing  p lan ts   and   the  number  of   sys tems   and   leve l  of   au toma t iza t ion   is
cons tan t ly  increas ing .  Mos t  sys tems  tha t  are  cons idered  are  d irec t ly  invo lved  in
con tro l l ing   the   manufac tur ing   process ,   usua l ly   ca l led process   con tro l   sys tems .
These  sys tems con tro l  a  manufac tur ing  process  us ing ac tua tors  (e .g .  conveyor-
be l ts ,  feeders ,  robo ts ,  la thes ,  or  bo i lers)  and mon i tor  the  progress  us ing sensors
(e .g .   speedome ters ,   pos i t ion   sensors ,   force   sensors ,   image   process ing   sys tems ,
thermome ters ,  or  pressure  gauges) .
Some   o ther   sys tems   tha t   are   a lso   some t imes   covered   by   CIM   inc lude   var i-
ous  sys tems   tha t  are  be ing  used  w i th in  manufac tur ing  compan ies .  These  can  be
sys tems   invo lved   in   the  des ign  process   such   as  produc t   spec i ﬁca t ion   and  Com-
pu ter   A ided   Des ign   (CAD)   sys tems ,   sys tems   tha t   hand le   par ts   and   produc ts   in
s tock ,  and  econom ic  informa t ion  sys tems  such  as  produc t  cos ts  and  sa les  infor-
ma t ion .  A  curren t   trend   in  many  manufac tur ing  compan ies   is   to   in tegra te  a l l  of
these  sys tems  to  prov ide  be t ter  con tro l  of  the  who le  manufac tur ing  process ,  no t
jus t   the  process  con tro l .

10

2 .3 DBMSs   in  CIM

Background

CIM   sys tems   hand le   many   d ifferen t   k inds   of   informa t ion   for   con tro l l ing   the
manufac tur ing   process   such   as   produc t   da ta   (e .g .  wha t   par ts   a   produc t   cons is ts
of) ,   par ts   da ta   (e .g .   phys ica l   da ta   such   as   s ize ,   we igh t ,   and   number   of   par ts
ava i lab le   in   s tock) ,   da ta   re la ted   to   the   manufac tur ing   equ ipmen t   (e .g .   con ﬁgu-
ra t ion  da ta) ,   sensor  and  ac tua tor  da ta .  O ther  da ta   tha t  can  be  hand led  by  a  CIM
sys tem ,   bu t   wh ich   is   no t   d irec t ly   used   in   the   process   con tro l   can   be   produc t
spec i ﬁca t ion   da ta   (e .g .   CAD-draw ings) ,   econom ic   da ta   (e .g .   produc t   and   par t
cos ts) ,  and   sa les  da ta   (e .g .  how  many  produc ts  have  been   so ld  and   thus  have   to
be  manufac tured) .  The  types  of  CIM  app l ica t ions  tha t  can  be  cons idered  as  can-
d ida tes   for   the   use   of   (ac t ive)   da tabase   techno logy   are   app l ica t ions   where   a
fa ir ly  large  amoun t  of  da ta  access  is  needed  dur ing  the  au toma ted  process .  Th is
cou ld  be  da ta   such   as   informa t ion   abou t   the   componen ts   invo lved   in   an   assem-
b ly,   da ta   abou t   the   mach ines   invo lved   and   sensor   da ta   s tored   or   da ta   d irec t ly
access ib le  in  the  da tabase .  The  da ta  cou ld  a lso  be  informa t ion  abou t  the  number
of   componen ts   in   s tock .   Th is   of ten   invo lves   app l ica t ions   where   the   leve l   of
au tonomy   has   to   be   h igh   and   thus   a l low ing   the  CIM   sys tem   to   opera te  w i thou t
too  much  human  in terven t ion .  Th is  cou ld  be  in  a  sys tem  tha t  is  more  fau l t  to ler-
an t ,   e .g .   by   us ing   sensors   to   de tec t   abnorma l   s i tua t ions   and   to   dea l   w i th   them
w i thou t  an  opera tor  hav ing   to  res tar t   the  sys tem ,  and   tha t  can  a lso   in terac t  w i th
o ther   sys tems ,   e .g .   to   au toma t ica l ly   order   more   componen ts   when   the   s tock   is
runn ing   low.

The  ARAMIS  Project
2 .3 .1
The  ARAMIS  pro jec t  [83][123]  was  the  con t inua t ion  of  a  jo in t  research  pro jec t
be tween   the   Depar tmen t   of   Compu ter   and   Informa t ion   Sc ience   (IDA)   a t
L ink öp ing   Un ivers i ty ,   ABB   Corpora te   Research   and   ABB   Robo t ics   in
V äs ter ås ,   Sweden .   The   pro jec t   con t inued   as   coopera t ion   be tween   IDA   and   the
Depar tmen t   of   Phys ics   and  Measuremen t   Techno logy   (IFM) .   The  work   a t   IDA
cons is ted   of   deve lop ing   the   sof tware   p la tform   for   the   targe t   hardware   (a   rea l-
t ime   sys tem   and   robo t   w i th   a   gr ipper   and   var ious   sensors)   be ing   deve loped   a t
IFM .  The  sof tware  p la tform  was  deve loped   in  a   three- layered  arch i tec ture .  The
layers  are :   the task   leve l ,   the con tro l   leve l ,  and   the phys ica l   leve l .
On   the   task   leve l ,   task   programs   can   be   wr i t ten   tha t   spec ify   the   ma in   tasks
of   the   app l ica t ion   in   a   dec lara t ive   ru le-based   language .   The   task   programs   are
wr i t ten   us ing   a   graph ica l   no ta t ion   and   us ing   spec ia l   programm ing   too ls .   In   the
task- leve l   programs   low- leve l   de ta i ls   can   be   ignored   such   as   how   the   ac tua l
con tro l   a lgor i thms   w i l l   perform   d ifferen t   h igh- leve l   opera t ions .   The   task   pro-
grams  opera te  on  ob jec ts  in  a  Wor ld  Mode l  (WM)  wh ich  is  s tored  in  a  da tabase .
Ob jec ts   (ca l led   componen ts)   in   the  WM   can   be   ac t ive ,  wh ich  means   tha t   if   the
task   leve l   changes   a t tr ibu tes   of   ac t ive   componen ts ,   the   WM   can   issue   ca l ls   to
the   con tro l   leve l   tha t   execu tes   a lgor i thms   tha t   perform   the   correspond ing
changes   to   the   phys ica l   ob jec t   tha t   is   represen ted   by   the   ac t ive   componen t   in
the  WM .  The  arch i tec ture   is  presen ted  more   thorough ly   in  Paper  I .

11

Th is   work   uses   an   ADBMS   for   con tro l   of   manufac tur ing   equ ipmen t   w i th
obv ious   rea l- t ime   requ iremen ts ,   bu t   the   focus   was   no t   on   rea l- t ime   da tabases
[101] .  One   bas ic   idea   in   the   arch i tec ture   is   to   push   rea l- t ime   requ iremen ts   in to
the   con tro l   a lgor i thms   as   much   as   poss ib le ,   i .e .   ou t   of   the   da tabase   and   the
ac t ive   ru les .   The   con tro l   a lgor i thms   can   be   cyc l ic   opera t ions   w i th   ﬁxed   cyc le
t imes   tha t  can  be  ad jus ted   to  mee t  hard   rea l- t ime   requ iremen ts .  Some   sof t   rea l-
t ime  requ iremen ts  can  s t i l l  be  presen t  on   the  da tabase .
The   ADBMS   shou ld   prov ide   h igh-performance   transac t ion   process ing
through  ef ﬁc ien t  ru le /query  process ing  and  ef ﬁc ien t  upda tes  of  the  da tabase .  T o
mee t   these   requ iremen ts   a   ma in-memory   DBMS   [34][38][52]   was   cons idered
as   the  mos t   l ike ly  cand ida te .
My   work   cons is ted   of   deve lop ing   the   con tro l   sof tware   wh ich   inc luded
deve lop ing   languages   and   too ls   for   spec ify ing   ac t ive   componen ts   tha t   perform
the   con tro l   of   the   phys ica l   hardware   (see   Paper   I) .   Th is   work   was   the   in i t ia l
incen t ive   to  focus  my  research  on   the  area  of  ac t ive  da tabase  sys tems .

2 .4 About  Paper  I

Th is   paper   presen ts   the  ARAMIS   arch i tec ture  w i th   an   emphas is   on   the   con tro l
leve l  and  the  spec i ﬁca t ion  of ac t ive  componen ts .  The  mode l  chosen  for  de ﬁn ing
componen ts   was   based   on   Ob jec t-Or ien ted   (OO)   techn iques .   The   componen ts
can  be  e i ther pass ive  or ac t ive .  Pass ive  componen ts  represen t  modu les  con ta in-
ing   func t ions   tha t   have   some   common   func t iona l i ty   such   as   spec ia l ized   a lgo-
r i thms   for   3D-ro ta t ion   of   ob jec ts .   The   inher i tance   s truc ture   of   pass ive
componen ts   represen ts spec ia l iza t ion   (or   genera l iza t ion)   of   func t iona l i ty   such
as   a   3D-ro ta t ion   componen t   can   be   de ﬁned   as   a   spec ia l iza t ion   of   a   2D-ro ta t ion
componen t .   Ac t ive   componen ts   represen t   ob jec ts   w i th   a   s ta te   and   are   used   for
represen t ing   ob jec ts   in   the   rea l-wor ld   such   as   equ ipmen t   in   the   manufac tur ing
p lan t  and  the  par ts  be ing  assemb led .  The  inher i tance  s truc ture  of  ac t ive  compo-
nen ts   represen ts   an is-a   (or   ins tance-of)   h ierarchy.   In   [120]   genera l   de ﬁn i t ions
of   d ifferen t   inher i tance   mode ls   can   be   found .   The   OO   mode l   chosen   for   the
componen ts   la ter   in ﬂuenced   the   cho ice   of   us ing   an   OODBMS   to   represen t   the
WM .   The   ARAMIS   sys tem   had   a   pr im i t ive  ma in-memory   ac t ive   da tabase   sys-
tem   tha t  was  used   for   s tor ing   the   ac t ive   componen ts ,  bu t   i t   lacked  we l l-de ﬁned
transac t ions   and   a   query   language .   Th is   da tabase   sys tem   was   la ter   subs t i tu ted
w i th   the   AMOS   ADBMS   [43] .   AMOS   is   presen ted   in   chap ter   3 .   In   chap ter   5
the  use  of  an  ADBMS   in  CIM  app l ica t ions   is  more  d iscussed .

2 .5 Te lecommun icat ion  Networks

Te lecommun ica t ion   ne tworks   cons is t   of   the   infras truc ture   and   the   equ ipmen t
needed   to   prov ide   d ifferen t   te lephony   serv ices .   Trad i t iona l   te lecommun ica t ion
ne tworks  prov ide   transfer  of   low  bandw id th  ana log  da ta  such  as  vo ice  da ta   in  a
po in t- to-po in t   manner.   The   serv ices   prov ided   by   the   te lecommun ica t ion   ne t-
work   can   be   d iv ided   in to   serv ices   prov ided   to   the   end   user   and   serv ices   pro-

12

Background

v ided   to   the   ne twork   opera tor.  Trad i t iona l   user   serv ices   inc lude  P la in  Ord inary
Te lephony   Serv ice   (POTS) ,   i .e .   bas ic   po in t- to-po in t   vo ice-based   commun ica-
t ion   w i thou t   opera tor   ass is tance ,   d ifferen t   subscr iber   serv ices   such   as   ca l l
transfer,   ca l l   wa i t ing ,   and   number   presen ta t ion   of   who   is   ca l l ing .   Trad i t iona l
opera tor   serv ices   inc lude   mon i tor ing   ne twork   usage   and   b i l l ing   subscr ibers ,
add ing /remov ing   subscr ibers ,   load   ba lanc ing   the   ne twork   (e .g .   transferr ing
traf ﬁc   from   heav i ly   used   sec t ions   to   less   used   sec t ions ,   some t imes   by   sp l i t t ing
one   h igh   bandw id th   connec t ion   in to   severa l   connec t ions) ,   recon ﬁgur ing   the
ne twork   w i thou t   d isrup t ing   ne twork   traf ﬁc ,   and   ne twork   superv is ion   func t ions
(e .g .   mon i tor ing   ne twork   over load   and   equ ipmen t   fa i lure) .   Fu ture   te lecommu-
n ica t ion   ne tworks   w i l l   prov ide   transfer   of   h igh   bandw id th   d ig i ta l   da ta   in   bo th
po in t- to-po in t  and  in  a  broadcas t  (one  to  many)  manner.  Today ’ s   ﬁxed  ne tworks
are   d ig i ta l   be tween   the   exchanges ,   bu t   usua l ly   no t   a l l   the  way   to   the   end   users
(subscr ibers) .
In   ISDN   (In tegra ted   Serv ices   D ig i ta l   Ne tworks)   subscr ibers   can   be   g iven   a
ﬁxed   med ium   bandw id th   transfer .   The   bas ic   idea   in   ISDN   is   tha t   a   d ig i ta l b i t-
p ipe   through   an   In tegra ted   ISDN   Transpor t   Ne twork   is   se t   up   be tween   users
( ﬁg .  2 .1) .  The  b i ts  can  or ig ina te   from  any  d ig i ta l   ISDN  dev ice  such  as  a  d ig i ta l
te lephone ,   a   d ig i ta l   fax ,   or   a   term ina l   (or   any   genera l   compu ter) .   The   connec-

ISDN
Devices

ISDN
Exchange

ISDN
Exchange

ISDN
Devices

Integrated
ISDN
Transport
Network

F igure  2 .1: The  bas ic  ISDN  ne twork

t ions   to   the  end  users  are  de ﬁned   to  use  ex is t ing   tw is ted  pa ir  connec t ions  us ing
spec ia l   ISDN   in terface   hardware .  Wi th in   the   transpor t   ne twork   any   med ia   can
be  used  such  as  op t ica l   ﬁber  cab les .  The  ISDN  b i t-p ipe  suppor ts  mu l t ip le  chan-
ne ls   in ter leaved   by   t ime   d iv is ion   mu l t ip lex ing .   Severa l   channe ls   have   been
de ﬁned :
A  -  4  kHz  ana log   te lephone  channe l
B  -  64  Kb i t /sec  d ig i ta l  PCM  channe l  for  vo ice  da ta
C  -  8  or  16  Kb i t /sec  d ig i ta l  channe l
D  -  16  or  64  Kb i t /sec  d ig i ta l  channe l  for  ou t-of-band  s igna l l ing
E-  64  Kb i t /sec  d ig i ta l  channe l  for   in terna l  ISDN  s igna l l ing
H  -  384 ,  1536 ,  or  1920  Kb i t /sec  d ig i ta l  channe l

D ifferen t   comb ina t ions   of   these   channe ls   have   been   de ﬁned   such   as   the   bas ic
ra te   2B+1D   wh ich   can   be   v iewed   as   a   rep lacemen t   for   the   commun ica t ion   in
POTS .  The   ISDN  s tandard  as   i t  was   in i t ia l ly  de ﬁned  has  never  been   rea l ized   in

13

in tegra ted   large-sca le   pub l ic   ne tworks .   ISDN   is   usua l ly   prov ided   through   spe-
c ia l  ne tworks  tha t  work  in  para l le l  w i th  the  pub l ic  te lecommun ica t ion  ne tworks
or  in  loca l  ne tworks  through  a  Pr iva te  Branch  eXchange  (PBX) .  A  ma jor  reason
why   the   ISDN   s tandard   has   no t   been   w ide ly   imp lemen ted   is   tha t   many   new
app l ica t ions   requ ire   ne twork   performance   above   tha t   wh ich   an   ISDN   ne twork
can   prov ide .   App l ica t ions   such   as   transfer   of   images ,   v ideo ,   or   h igh- ﬁde l i ty
sound   have   a   very burs ty   na ture ,   i .e .   low   da ta   transfer   can   be   fo l lowed   by   sud-
den   burs t   of   h igh   da ta   transfers .   The   bas ic   ISDN   s tandard   prov ides   a   s ta t ica l ly
a l loca ted   bandw id th   and   app l ica t ions   mus t   a l loca te   enough   bandw id th   to   sup-
por t   the  max imum   bandw id th   tha t   they   need .  For   burs ty   app l ica t ions   th is   leads
to  a  lo t  of  was te  of  bandw id th  s ince  the  who le  a l loca ted  bandw id th  is  on ly  used
par ts  of  the  t ime .  To  suppor t  these  k ind  of  app l ica t ions  the  bas ic  ISDN  s tandard
was   ex tended   and   was   named   Broadband   ISDN   (B-ISDN) .   B-ISDN   suppor ts
dynam ic   bandw id th   a l loca t ion   by   us ing   the   ATM   (Asynchronous   Transfer
Mode)   techno logy   to   imp lemen t   the  In tegra ted  B-ISDN  Transpor t  Ne twork .
The   ATM   ne twork   s tandard   has   been   de ﬁned   to   suppor t   in tegra t ion   of   bo th
loca l   and   pub l ic   ne tworks   cons is t ing   of   d ifferen t   transpor t   med ia   such   as
unsh ie lded   tw is ted   pa irs ,   sh ie lded   coax ia l   cab les ,   and   op t ica l   ﬁbers   us ing   d if-
feren t   k inds   of   broadband   sw i tches   such   as   loca l   ATM   PBXs   and   large   pub l ic
ATM   exchanges .   The   broadband   ATM   dev ices   in   an   of ﬁce   or   a   home   can   be
de ﬁned   to  be long   to  A TM  workgroups   tha t   are   connec ted   to  ATM  PBXs   in  pr i-
va te   (corpora te /en terpr ise)   ne tworks   or   d irec t ly   to   loca l   ATM   exchanges   in   a
pub l ic  carr ier ’ s  ATM  ne twork  ( ﬁg .  2 .2) .  The  pr iva te  A TM  ne tworks  can  cons is t
of   severa l   ATM   PBXs   in   a   Loca l   Exchange   Carr ier   Ne twork   and   the   pub l ic
ATM   ne twork   can   cons is t   of   severa l   ne tworks   w i th   ATM   Exchanges   in   In ter
Exchange   Carr ier   Ne tworks   tha t   are   be ing   managed   by   d ifferen t   ne twork   pro-
v iders .

Ofﬁce/Home
ATM
Devices

Private Network

Public Network

ATM
Exchange

ATM
Exchange

ATM
Exchange

ATM
Exchange

ATM Workgroup

Local Exchange
Carrier Network

Inter Exchange
Carrier Network

F igure  2 .2: The  ATM  (B-ISDN)  ne twork  ma in   layou t

In   an   ATM-ne twork   users   can   be   g iven   dynam ic   h igh   bandw id th   transfer.   The
phys ica l  commun ica t ion  layer  is  ac tua l ly  no t  par t  of  the  ATM  spec i ﬁca t ion ,  bu t
s tandards  for  op t ica l  ne tworks  such  as  SONET /SDH  (Synchronous  Op t ica l  Ne t-
work /Synchronous   D ig i ta l   H ierarchy)   spec ify   the   speeds ,   155 .5   Mb i t /sec ,   622
Mb i t /sec ,  2 .4  Gb i t /sec .  ATM  ne tworks  transfer  da ta  as  d ig i ta l  packages  con ta in-
ing   par ts   of   the   da ta   a long   w i th   the   des t ina t ion   address   and   con tro l   da ta   (e .g .

14

Background

for   error   check ing) .   The   packages   can   be   rou ted   d ifferen t   ways   depend ing   on
the  curren t  load  s i tua t ion .  The  exchanges  d isassemb le  the  da ta  from  the  send ing
par ty   in to   a   sequence   of   packages   and   perform package   sw i tch ing   by   rou t ing
the   packages   to   the ir   correc t   des t ina t ion   and   assemb le   them   in   the   correc t
sequence   and   send   the   da ta   to   the   rece iv ing   par ty.   How   connec t ions   are   se t-up
be tween  the  users  and  how  the  connec t ions  are  con tro l led  is  d ifferen t  from  how
connec t ions   are  managed   in   trad i t iona l   te lecommun ica t ion   ne tworks .   The   con-
nec t ions   in  ATM  ne tworks  mus t  have  h igher   re l iab i l i ty  and   th is  w i l l  make  bo th
the   con tro l   and   managemen t   of   these   ne tworks   more   comp l ica ted .   In   sec t ion
2 .6 .1   the   con tro l   of   these   ne tworks   and   how   connec t ions   are   se t-up   are   d is-
cussed .   In   sec t ion   2 .6 .2   the  managemen t   of   these   ne tworks   and   se t-up   connec-
t ions   is   d iscussed .   The   ma in   d ifference   to   the   users   of   the   ne tworks   w i l l   be
increased   performance   through   a   h igh   bandw id th   ne twork ,  more   user   serv ices ,
and   the   fac t   tha t   the   commun ica t ion   is   d ig i ta l   a l l   the   way   mak ing   modems
redundan t  for  d ig i ta l  da ta   transfer.
Today ’ s   second   genera t ion   mob i le   te lecommun ica t ion   ne tworks ,   i .e .   GSM /
TDMA1  or   CDMA2  ce l lu lar   phone   ne tworks   [67] ,   are   a lready   d ig i ta l   a l l   the
way   ( the   ﬁrs t  genera t ion  was  ana log) ,  bu t  do  no t  prov ide  very  much  bandw id th
to   the   subscr ibers .   When   ATM-ne tworks   are   w ide ly   ava i lab le ,   ce l lu lar   phone
ne tworks   w i l l   probab ly   be   upgraded   to   bene ﬁ t   from   the   h igher   broad   band
capab i l i ty,  bu t   there  w i l l  probab ly  s t i l l  be  a   l im i ta t ion  on   the  bandw id th  ava i la-
b le   in   the   mob i le   phone   -   base   s ta t ion   connec t ion   because   the   rad io   band   w i l l
a lways   be   cramped .   In   the   Un iversa l   Mob i le   Te lecommun ica t ions   Sys tem
(UMTS) ,   de ﬁned   in   an  EU  RACE-program   (Research   on  Advanced  Commun i-
ca t ions) ,   a   th ird   genera t ion   mob i le   te lecommun ica t ions   ne twork   has   been
de ﬁned .   In   UMTS   the   mob i le   ne twork   has   been   in tegra ted   w i th   a   broad-band
package  sw i tched  ne twork  such  as  ATM3.  Mob i le  phones  are  a lready  beg inn ing
to  be  in tegra ted  w i th  hand-he ld  compu ters  to  become mob i le  works ta t ions  [72] .
Users  w i th  mob i le   term ina ls  w i l l   thus  be  mob i le  and  have  access   to  broad  band
serv ices  (a  bandw id th  of  2  Mb i t /sec .  has  been  de ﬁned) .  W ork  is  a lso  in  progress
on mob i le   ATM   [127]   where   users   can   access   an   ATM   ne twork   d irec t ly   from
mob i le  term ina ls .  One  comp l ica t ion  w i th  us ing  the  ATM  pro toco l  a l l  the  way  to
the  mob i le   users   is   tha t   there   are   no   sequence   numbers   in   ATM   packages .   In   a
w ire less   ne twork  ATM   packages   can   become  m isordered   and   there   are   propos-
a ls   for   add ing   sequence   numbers   to   he lp   reorder ing   ATM   packages   a t   the
rece iv ing  end  [127] .
Fu ture   user   serv ices   o ther   than   POTS   and   the   s tandard   subscr iber   serv ices
(e .g .  ca l l  transfer  and  ca l l  wa i t ing)  w i l l  inc lude  d irec t ,  rea l- t ime ,  transfer  of  any
d ig i ta l   da ta   (e .g .   d ig i ta l   te lev is ion   and   te leconferenc ing) ,   and   o ther   serv ices

1 .  In   the  G loba l  Sys tem  of  Mob i le  commun ica t ions  (GSM)  a  Time  D iv is ion  Mu l t ip le
Access   is  used  for  mu l t ip lex ing  severa l   log ica l  channe ls  on to  each  phys ica l  carr ier
channe l .
2 .  Code  D iv is ion  Mu l t ip le  Access  (CDMA)   is  a  fu ture  Nor th  Amer ican  mob i le   te lecom-
mun ica t ion  sys tem .
3 .  In i t ia l ly  UMTS  was   to  be   in tegra ted  w i th  B-ISDN ,  bu t   th is   is  no t  cons idered  a  good
techn ica l  so lu t ion  anymore .

15

us ing   non-rea l- t ime   da ta   transfers   such   as   e lec tron ic   ma i l ,   news   serv ices   such
as   e lec tron ic   newspapers   and   s tock  marke t   informa t ion ,   access ing   the   In terne t ,
and   v ideo-on-demand   serv ices .   Mon i tor ing   serv ices   such   as   a   serv ice   tha t
a l lows   users   to   d irec t ly   mon i tor   how   much   money   he /she   has   spen t   m igh t   be
poss ib le .   Fu ture   opera tor   serv ices   m igh t   inc lude   be t ter   mon i tor ing   of   ne twork
use  and  m isuse  (e .g .  by  us ing  encryp t ion  and  au thor iza t ion  con tro l) ,  con tro l l ing
how   much   bandw id th   is   g iven   to   d ifferen t   users ,   b i l l ing   accord ing   to   used
bandw id th ,   be t ter   suppor t   for   load   ba lanc ing   the   ne twork   (e .g .   au toma t ic   sp l i t-
t ing   of   h igh   bandw id th   connec t ions   through   package   sw i tch ing   and   de lay ing
transfer   of   non-rea l- t ime   da ta   un t i l   low   traf ﬁc   per iods) ,   be t ter   suppor t   for
dynam ic  recon ﬁgura t ion  w i thou t  d isrup t ing  ne twork   traf ﬁc  (e .g .  by  hav ing  be t-
ter   suppor t   for   rerou t ing   da ta   away   from   equ ipmen t   tha t   is   be ing   rep laced   or
upgraded) .

2 .6 DBMSs   in  Te lecommun icat ion  Networks

In   the   area   of   te lecommun ica t ions   there   are   many   d ifferen t   needs   for   DBMS
suppor t .   Te lecommun ica t ion   ne tworks   a lready   have   DBMSs   in tegra ted   w i th
them   and   w i l l   have   even   more   so   in   the   fu ture .   Te lecommun ica t ion   ne tworks
are   large   he terogeneous   sys tems   w i th   many,   some t imes   con ﬂ ic t ing ,   needs   tha t
the   DBMSs   mus t   fu l ﬁ l   [58] .   When   d iscuss ing   DBMSs   in   te lecommun ica t ion
ne tworks   i t   is   impor tan t   to   separa te   be tween ne twork   tra f ﬁc   con tr o l , ne twork
managemen t ,  and ne twork  app l ica t ions .
The   ne twork   traf ﬁc   con tro l   invo lves   the   ac tua l   opera t ion   of   the   ne twork   in
terms  of   se t t ing  up   commun ica t ion  pa ths ,  ma in ta in ing   them ,   and  d isconnec t ing
them .   In   th is   thes is   POTS   ( i .e .   po in t- to-po in t   commun ica t ion)   and   s tandard
subscr iber   serv ices   (e .g .   wake-up   ca l l ,   ca l l   d ivers ion ,   ca l l   wa i t ing ,   ma l ic ious
ca l l  trac ing)  are  cons idered  to  be long  to  ne twork  traf ﬁc  con tro l .  Ne twork  traf ﬁc
con tro l   have   requ iremen ts   on   DBMSs   to   prov ide   h igh   throughpu t   and   a   large
number   of   para l le l   transac t ions ,   ma in-memory   s torage ,   fas t-pa th   in terfaces   to
programm ing   languages ,   and   rea l- t ime   suppor t .   In   ne twork   traf ﬁc   con tro l ,
ava i lab i l i ty   and   re l iab i l i ty   is   impor tan t   [122] ,   bu t   los ing   a   s ing le   connec t ion   is
no t  a  ca tas trophe .
Ne twork   managemen t [59]  invo lves   mon i tor ing   ne twork   traf ﬁc   in   terms   of
performance   (ne twork   throughpu t) ,   fau l t   managemen t ,   and   con ﬁgura t ion   man-
agemen t .  Ne twork  managemen t  makes   requ iremen ts   on   the  DBMSs   to   prov ide
suppor t   for   in terconnec t ing   w i th   o ther   DBMSs   and   w i th   o ther   sys tems   and   to
prov ide   suppor t   for   mon i tor ing   connec t ions ,   a larms   in   the   ne twork ,   and   ne t-
work   con ﬁgura t ion   changes .   Co l lec t ing   accoun t ing   da ta   to   suppor t   b i l l ing   of
ne twork   use   is   a lso   a   task   for   ne twork   managemen t .   The   DBMSs   for   ne twork
managemen t   have   a   h igh   requ iremen t   on   re l iab i l i ty   s ince   los ing ,   for   examp le ,
accoun t ing   da ta   is   unaccep tab le   to   a   ne twork   opera tor.   The   ne twork   manage-
men t  a lso   requ ires   suppor t   for  more  comp lex  da ta  mode ls   to   suppor t  mode l l ing
the   layou t   of   the   ac tua l   ne twork   (such   as   ne twork   e lemen ts   and   the ir   connec-
t ions)  w i th in   the   da tabase .   The  DBMSs   need   to   s tore   accoun t ing   da ta   secure ly
on   d isk ,   bu t   m igh t   s t i l l   be   ma in-memory   based   to   mee t   some   of   the   perform-

16

Background

ance  requ iremen ts  and  w i th  a  d isk  for  backup  on ly.
Ne twork   app l ica t ions   tha t   use   a   DBMS   can   inc lude   app l ica t ions   o ther   than
trad i t iona l   te lephone   ca l ls   such   as   In terne t   access   (e-ma i l ,   news ,   WWW,   ﬁ le
transfer,   and   remo te   sys tem   access) ,   tex t   and   vo ice   ma i l ,   mu l t i-med ia ,   and
v ideo-on-demand .   Ne twork   app l ica t ions   w i l l   requ ire   suppor t   from   a   h igh-per-
formance   DBMS   tha t   can   hand le   a   large   number   of   s imu l taneous   transac t ions .
To   mee t   these   requ iremen ts   ma in-memory   DBMSs   can   be   cons idered .   D isk
based  DBMSs   tha t   can   s tore   large   amoun ts  of  da ta  w i l l   a lso  be  needed   for   log-
g ing  purposes  and  for  app l ica t ions  need ing   to  s tore   large  vo lumes  of  da ta .  Sup-
por t  for  new  da ta  s truc tures  w i l l  be  needed  for  s tor ing ,  for   ins tance ,  vo ice  da ta ,
graph ica l   da ta ,   and   v ideo   da ta   in   the   da tabases .   To   suppor t   quer ies   over   these
new  da ta   s truc tures   the  DBMSs  mus t   suppor t   ef ﬁc ien t   index ing   techn iques   and
op t im iza t ion  of  quer ies   tha t  access   them .

Te lecommun icat ion  Network  Traf ﬁc  Contr o l
2 .6 .1
Ne twork   traf ﬁc   con tro l   is   probab ly   the   area   w i th in   te lecommun ica t ions   where
there   are   the   mos t   manufac turer-spec i ﬁc   so lu t ions .   Each   te lecommun ica t ion
exchange   (sw i tch)   deve loper   has   i ts   own   so lu t ions   of   how   to   hand le   da ta .
DBMSs   are   be ing   in tegra ted   in to   the   sof tware   p la tforms   for   the   sw i tch ing   sys-
tems .  In  an  ATM  exchange  the  da ta  be ing  s tored  can  be  connec t ion  da ta ,  sys tem
managemen t  da ta ,  and  con ﬁgura t ion  da ta .
Connec t ions  in  an  ATM  ne twork  are  assoc ia ted  w i th  each  o ther  through Vir-
tua l  C ircu i t  Iden t i ﬁers  (VCIs)  tha t  are  sen t  a long  w i th  da ta  packages  to  iden t ify
where   they   come   from   and   where   they   shou ld   be   rou ted .   Two   k inds   of   v ir tua l
c ircu i ts  have  been  de ﬁned , Permanen t  Vir tua l  C ircu i ts  (PVC)  and Sw i tched  Vir-
tua l  C ircu i ts   (SVC) .  PVCs   requ ire   tha t   the   cus tomer   de ﬁnes   the   charac ter is t ics
of   the   connec t ion ,   inc lud ing   the   end-po in ts .   SVCs   a l low   connec t ions   to   be
es tab l ished  on-demand  be tween  any   two  po in ts   in   the  ne twork .  SVCs  are  go ing
to  be  needed   in   a  dynam ic  pub l ic  ATM  ne twork   and   are   assumed   in   the   con t in-
ued  d iscuss ion .  When  new  connec t ions  are  es tab l ished ,  new  VCIs  are  a l loca ted
and   are   ma in ta ined   un t i l   the   connec t ion   is   term ina ted   caus ing   the   VCI   to   be
dea l loca ted  (and  be  reused  by  new  connec t ions) .
Connec t ions   ( tra i ls)   rou ted   through   severa l   exchanges   w i l l   have   severa l
VCIs   for   each   sub-connec t ions   (segmen ts)   through   the   ne twork .   Each   ATM
exchange   w i l l   keep   records   on   how   each   incom ing   and   ou tgo ing   sub-connec-
t ion   is   connec ted   by   record ing   the   assoc ia ted   VCIs .   Each   sub-connec t ion   w i l l
be   mon i tored   by   the   ATM-exchanges   mak ing   sure   tha t   the   connec t ions   ge t   the
good   throughpu t   by   vary ing   the   ac tua l   bandw id th   acqu ired   dur ing   ﬂuc tua t ions
(burs ts)   in   the   transm i t ted   da ta .   Da ta   abou t   se tup   connec t ions ,   i .e .   assoc ia ted
VCIs ,   can   be   s tored   in   loca l   da tabases .   Ne twork   usage   can   be   temporar i ly
s tored   for   each   sub-connec t ion ,   bu t  w i l l   be   forwarded   to   ne twork  managemen t
sys tems   for   mon i tor ing   the   overa l l   performance   and   for   ca lcu la t ing   the   to ta l
ne twork   usage   for   b i l l ing .   Ma in ta in ing   the   comp le te   connec t ions   through   the
ne twork   is  par t  of   the  ne twork  managemen t .
Sys tem   managemen t   such   as   mon i tor ing   the   performance   of   the   who le

17

exchanges ,   d ifferen t   phys ica l   l inks ,   and   logg ing   of   a larms   w i l l   need   DBMS
suppor t .   Such   a   DBMS   mus t   be   access ib le   from   or   have   d irec t   con tac t   w i th   a
ne twork   managemen t   cen ter   tha t   mon i tors   the   larger   par t   of   the   ne twork   tha t
the  exchange  be longs  to .  Sys tem  con ﬁgura t ion  da ta ,  such  as  hardware  and  sof t-
ware   con ﬁgura t ion ,   w i l l   probab ly   be   hand led   by   a   DBMS   as   we l l .   Sys tem
recon ﬁgura t ion   can   be  managed  more   secure ly   by   us ing  DBMS   transac t ions   to
a tom ica l ly  change  many  parame ters  s imu l taneous ly.
In   loca l   exchanges   (w i th   d irec t ly   connec ted   subscr ibers)   a   DBMS   can   be
used   to   s tore   subscr iber   informa t ion   such   as   subscr iber   numbers ,   subscr iber
serv ices ,   accoun t ing   informa t ion .   For   fas t   number   ana lys is   spec ia l   da ta   s truc-
tures   for   fas t   look   up   and   w i th   poss ib ly   incomp le te   keys   (par ts   of   subscr iber
numbers)   are   usua l ly   imp lemen ted .   The   search ing   can   usua l ly   s tar t   before   the
subscr iber   has   d ia l led   a l l   the   d ig i ts .   Subscr iber   numbers   are   usua l ly   de ﬁned   in
number  ser ies  accord ing  to  a  number  p lan  tha t  spec i ﬁes  coun try  and  area  codes .
These  are  usua l ly  de ﬁned  and   s tored   in  a  h ierarch ica l   s truc ture   tha t   is   searched
for   ﬁnd ing   where   incom ing   ca l ls   shou ld   be   rou ted .   Usua l ly   no   s ing le   da tabase
con ta ins   a l l   the   numbers ,   bu t   each   exchange   DBMS   can   de term ine   where   ( in
wha t   o ther   exchange)   the   number   ana lys is   shou ld   be   con t inued .   In   fu ture
mob i le   te lecommun ica t ion  ne tworks   the   subscr iber  numbers  w i l l  be  g loba l ,   i .e .
w i thou t   any   ﬁxed   assoc ia t ion   w i th   where   the   subscr iber   is   phys ica l ly   loca ted .
Th is  w i l l   change   how   subscr iber   numbers   are   looked   up   in   the   da tabase .   S ince
mob i le   subscr ibers   usua l ly   type   in   the   who le   number   they   are   ca l l ing ,   there   is
no  need   for   incomp le te   search  keys .  Some  h ierarch ica l  de ﬁn i t ion  w i l l  probab ly
s t i l l  be  needed   to  avo id  fu l l  rep l ica t ion  of  a l l  numbers   in   the   loca l  exchanges .
The   loca l   exchanges   usua l ly   have   charg ing   func t ions   tha t   mon i tor   the
number  of  t ime  per iods  used  in  ca l ls  se t-up  by  loca l  subscr ibers .  Loca l  accoun t-
ing   informa t ion   is  usua l ly  s tored   temporar i ly  before   i t   is  forwarded  as  charg ing
records   to   some   ex terna l   DBMS   in   the   ne twork   managemen t   sys tem .   In   the
fu ture   such   charg ing   w i l l   a lso   inc lude   the   use   of   ne twork   serv ices   no t   hand led
by   the   loca l   exchanges .   On- l ine   b i l l ing   of   ne twork   serv ices   w i l l   probab ly   be
performed  by  DBMSs  of   the  ne twork  managemen t  sys tem .
Subscr iber  serv ices  usua l ly  have  spec i ﬁc  func t ions  or  modu les  in  the  sys tem
tha t   need   to   s tore   the ir   own   informa t ion   in   the   da tabase   (such   as   to  wha t   num-
bers   to   transfer   ca l ls   to   subscr ibers   tha t   have   ac t iva ted   the   ca l l   d ivers ion   serv-
ice) .  In  In te l l igen t  Ne twork  Serv ices  some  new  serv ices  such  as  rou t ing  ca l ls  to
d ifferen t   loca t ions   a t   d ifferen t   t imes   of   the   day,   trans la t ion   of   numbers ,   and
red irec t ing   of   charg ing   have   been   de ﬁned .   T o   suppor t   such   serv ices   Serv ice
Con tro l   Po in ts   (SCPs)   have   been   de ﬁned   tha t   w i l l   use   ne twork   DBMSs   for
look ing  up  da ta .
In   th ird   genera t ion   mob i le   te lecommun ica t ion   ne tworks   such   as   UMTS
users   w i l l   no t   be   phys ica l ly   connec ted   to   a   par t icu lar   loca l   exchange   and   w i l l
probab ly   have   por tab le   subscr iber   numbers   tha t   can   be   used   to   ﬁnd   them   any-
where   in   the   ne twork .   Home   Loca t ion   Reg is ters   (HLRs)   and   Vis i ted   Loca t ion
Reg is ters   (VLRs)   are   spec ia l ized   DBMSs   used   in   second   genera t ion   mob i le
ne tworks  for   ﬁnd ing  the  loca t ion  ( loca l  home  exchange  and  curren t  loca t ion)  of
mob i le   users .   In   UMTS   HLR /VLRs   w i l l   probab ly   use   SCPs   and   ne twork

18

Background

DBMSs   to  suppor t  por tab le  subscr iber  numbers .
In   sec t ion   5 .6 .1   the   use   of   ADBMSs   in   te lecommun ica t ion   ne twork   traf ﬁc
con tro l   is  d iscussed .

2 .6 .2

Te lecommun icat ion  Network  Management

Telecommunication networks are large hierarchical networks consisting of subscrib-
ers  connected  to  local  exchanges,  local  exchanges  connected  to  transit  exchanges,
and  network  supervision  centers  that  monitor  the  traffic  between  the  exchanges.
DBMSs  for  network  management  are  integrated  parts  of  these  networks  to  some
extent and will be even more so in the future [59].

The tasks of network management are the following:

• Performance Management.
To  monitor  the  status  of  network  resources,  traffic  load,  equipment  utilization,
and identify exceptional conditions.

• Fault Management.
To detect alarms, diagnose problems, and apply control.

• Configuration Management.
To  provide  support  for  installation  of  new  equipment  or  services,  audit,  and
reconfigure network resources.

• Accounting Management.
To provide billing data, resource usage reports, and cost calculations.

• Network Planning Management.
To prepare for capacity growth, contingency, and strategic planning.

• Security Management.
To handle authorization and authentication.

Network management of ATM networks  [5]  is divided  into  several  levels and  inter-
faces.  The  ATM  Forum  is  developing  a  five-layer  ATM  management  model  for
Operation, Administration,  and Maintenance  (OAM)  of ATM  networks.  The model
defines interfaces for managing hybrid networks that consist of both private and pub-
lic networks. OAM cells are being defined that automatically distribute management
information throughout the ATM network. The model also includes end-to-end man-
agement based on the Common Management Information Protocol (CMIP).
Loca l  ne tworks  (LAN)  connec ted  to  an  ATM  ne twork  can  use  the  ATM  Da ta
Exchange   In terface   (DXI)   for   exchang ing   da ta .   Ne twork   managemen t   in   pr i-
va te   ATM   ne tworks   has   been   de ﬁned   by   the   In ter im   Loca l  Managemen t   In ter-
face   (ILMI)   wh ich   is   based   on   the   S imp le   Ne twork   Managemen t   Pro toco l
(SNMP) .   SNMP   was   de ﬁned   by   the   In terne t   Eng ineer ing   T ask   Force   (IETF)
and   is   w ide ly   used   in   managemen t   of   compu ter   ne tworks .   SNMP   is   based   on

19

the   de ﬁn i t ion   of   Managemen t   Informa t ion   Bases   (MIBs)   wh ich   suppor t   read-
ing ,   wr i t ing ,   and   mon i tor ing   changes   to   da ta   re la ted   to   ne twork   e lemen ts .   The
IETF   has   produced   an   ATM   MIB   for   SNMP   and   the   ATM   Forum   has   de ﬁned
the   ATM   DXI   MIB   (as   an   ex tens ion   of   the   ISDN   MIB) .   A   remo te   mon i tor ing
AMON  MIB  (based  on  RMON ,  Remo te  MON i tor ing)  has  a lso  been  de ﬁned  for
suppor t   of   more   au toma t ic   ATM   ne twork   mon i tor ing .   MIBs   de ﬁne   ob jec ts   (or
var iab les)   wh ich   can   be   po l led   to   mon i tor   the   opera t ion   and   performance   of   a
managed  componen t .  Managed  componen ts  can  be  any  p iece  of  hardware  in  the
commun ica t ion  ne twork .  More  d iscuss ions  on  SNMP  and  MIBs  can  be  found  in
sec t ion  9 .5 .3 .
The  Cus tomer  Ne twork  Managemen t   (CNM)   in terface  makes   i t  poss ib le   for
cus tomers   of   an   ATM   serv ice   to   manage   cer ta in   aspec ts   of   the   serv ice   from
the ir   own   loca l   ne twork   managemen t   sys tem .   The   CNM   is   the   in terface
be tween   the   cus tomer   and   the   carr ier ’ s   pub l ic   ne twork   managemen t   sys tems
and   g ives   the   cus tomer   a   v iew   in to   the   carr ier ’ s   ne twork .   CNM   sys tems   a lso
re ly   on   MIBs   for   access ing   da ta .   The   goa l   of   the   in tegra t ion   of   cus tomer   and
carr ier ’ s   ne twork   managemen t   sys tems   is   tha t   cus tomers   w i l l   have   rea l- t ime
con tro l  over   the  serv ices   they  use .  The  carr ier  wan ts   to  prov ide   the  pr iva te  ne t-
work   managemen t   w i th   the   ab i l i ty   to   mon i tor   and   con tro l   the   qua l i ty   of   the
serv ices  rece ived ,  bu t  w i thou t  g iv ing  away  fu l l  con tro l  of   the  ne twork .
To   suppor t   managemen t   of   the   pub l ic   ne tworks   the   in terfaces   based   on   the
Ne twork  Managemen t  Leve l  (NML)  v iews  and   the  E lemen t  Managemen t  Leve l
(EML)   v iews   have   been   de ﬁned   [81] .   The  NML   prov ides   an   abs trac t ion   of   the
func t ions   prov ided   by   the   sys tems   tha t   manage   ne twork   e lemen ts   on   a   co l lec-
t ive   bas is   ( the   ne twork   managemen t   sys tems)   to   make   i t   poss ib le   to   mon i tor
and   con tro l   the   ne twork   end- to-end .   The   EML   prov ides   an   abs trac t ion   of   the
func t ions   prov ided   by   the   sys tems   wh ich   manage   each   ne twork   e lemen t   on   an
ind iv idua l  bas is  ( the  ne twork  con tro l  sys tems) .  The  bas ic   idea  beh ind   the   in ter-
faces   is   to  a l low   the  ne twork  managemen t   sys tem   to  work  on  an   in tegra ted  and
log ica l   v iew   of   larger   par ts   or   the   comp le te   pub l ic   ne twork .   More   on   log ica l
v iews  of   te lecommun ica t ion  ne tworks  can  be  found   la ter   in   th is  sec t ion .
S ince   there   w i l l   probab ly   be   severa l   carr ier   ne twork   prov iders ,   there   is   a
need   for   an   in terface   for   in tegra t ing   d ifferen t   carr iers ’   ne twork   managemen t
sys tems .  Th is  is  needed  to  prov ide  mon i tor ing  of  comp le te  connec t ions  through
the   who le   ne twork .   Informa t ion   such   as   forward ing   of   ne twork   usage ,   b i l l ing
informa t ion ,  and  a larms  w i l l  have  to  be  forwarded  us ing  s tandard  forma ts .  Th is
in terface  has  ye t   to  be  de ﬁned .
In   ﬁg .   2 .3   an   overv iew   of   the   d if feren t   ne twork  managemen t   in terfaces   can
be  seen  w i th   the   in terface  codes  exp la ined  be low.

• M1, M2 - Interim Local Management Interface (ILMI) based on the Simple Net-
work Management Protocol (SNMP)

• M3 - Customer Network Management (CNM) interface

• M4 - Interface providing Network Management Level (NML) views and Element
Management Level (EML) views of the public network

20

Background

Private
Network
Manager

Public
Network
Manager

Public
Network
Manager

M3

M5

M1

M2

M4

M4

ATM
Workgroup
F igure  2 .3: The  ATM  Forum  Managemen t  In terface  Reference  Arch i tec ture

Private
Network

Public
Network

Public
Network

• M5 - Interface between the public network management systems

In  telecommunication  network  management,  logical  views  are  usually  defined  in
terms of the physical network (fig. 2.4). Logical names of devices and users will have
to  be  translated  to  physical  addresses  by  a  name  server  function.  The  views  reflect

Logical Network

Logical views

Physical Network

F igure  2 .4: Mapp ing   the  phys ica l  ne twork   to  a   log ica l  ne twork   through   log ica l
v iews

21

area code regions and geographical regions more than how the network is physically
interconnected.  The  operators  of  network  management  centers  will  usually  find  it
more  convenient  to  access  the  different  parts  of  the  network  using  the  logical  view.
The physical network addresses will usually only be needed when devices and users
are added (removed) to (from) the network.
The   v iews   can   be   de ﬁned   on   severa l   leve ls   for   loca l   and   reg iona l   ne twork
managemen t   ( ﬁg .  2 .5) .   In   rea l i ty   (as   for  examp le   is  de ﬁned   in   the  Nor th  Amer-

Regional Network Management

Sectional/Primary Network Management

Network Traffic Control

F igure  2 .5: S tor ing  sub-ne tworks ,  ne twork  e lemen ts  and  connec t ion   tra i ls   in  da ta-
bases

ican   Te lephone   Sw i tch ing   Of ﬁce   H ierarchy)   the   te lecommun ica t ion   ne tworks
cons is t   of   severa l   leve ls   such   as   reg iona l   cen ters ,   sec t iona l   cen ters ,   pr imary
cen ters ,   to l l   cen ters   and   loca l   of ﬁces .   DBMSs   w i l l   be   needed   on   a l l   these   d if-
feren t   leve ls .   The   informa t ion   tha t   w i l l   be   s tored   in   the   da tabases   inc ludes
s ta t ic  da ta   such  as  ob jec ts   represen t ing   the  ne twork  e lemen ts ,   the  ne twork  con-
ﬁgura t ion ,   and  dynam ic  da ta   such   as   the   s ta tus  of   the  ne twork   e lemen ts ,   s ta t is-
t ics ,   se t   up   tra i l   connec t ions ,   ac tua l   ne twork   usage ,   and   b i l l ing   informa t ion .   In
te lecommun ica t ion  ne twork  managemen t  there  is  a  grea ter  need  for  da ta  mode l-
l ing   than   in   ne twork   traf ﬁc   con tro l .   The   ne twork   mode l l ing   is   l ike ly   to   be
de ﬁned   us ing   in terna t iona l   s tandards   based   on   the  Ob jec t-Or ien ted   (OO)   para-
d igm .

22

Background

The   Gu ide l ines   for   Deve lopmen t   of   Managed   Ob jec ts   (GDMO)   [74]   is   a
s tandard   for  mode l l ing   of   ne twork   e lemen ts   based   on  OO   techn iques .  Ne twork
prov iders   can   de ﬁne   how   the ir   ne tworks   are   log ica l ly   connec ted   us ing   GDMO
and   then   use   the   NML   and   EML   v iews   to   de ﬁne   how   the   log ica l   v iew   of   the
ne twork   is   mapped   to   the   phys ica l   v iew,   i .e .   the   re la t ionsh ip   be tween   how   the
e lemen ts   of   the   log ica l   ne twork   are   de ﬁned   to   be   in terconnec ted   and   how   the
phys ica l   ne twork   e lemen ts   are   phys ica l ly   in terconnec ted .   The   log ica l   v iew
makes   i t   eas ier   to   unders tand   how   the   ne twork   is   connec ted   and   eas ier   to  man-
age   by   ne twork   opera tors .   Opera t ions   such   as   mon i tor ing   can   be   done   on   the
log ica l  mode l  w i th  a l l   the   reques ts  and  da ta  be ing   trans la ted  be tween   the  phys-
ica l   and   the   log ica l   v iews .   Changes   to   the   phys ica l   and   the   log ica l   v iews   and
the  mapp ing   be tween   them  mus t   be   poss ib le   to   a l low   for   recon ﬁgura t ion  w i th-
ou t   tak ing   the  who le  ne twork  ou t  of  serv ice .
To   suppor t   the   ne twork   managemen t   the   log ica l   v iews   can   be   s tored   in   a
da tabase  w i th   d irec t   suppor t   for   the   ne twork  mode l l ing .  OODBMSs ,   for   exam-
p le ,   can   be   used   to   d irec t ly   s tore   GDMO   based   mode ls   of   the   ne tworks .   In ter-
connec t ions   be tween   DBMSs   a t   d ifferen t   leve ls   of   the   ne twork   h ierarchy   can
prov ide   the   mapp ings   be tween   the   d ifferen t   v iews .   Suppor t   for   de ﬁn ing   the
NML /EML  mapp ings  and  do ing  the  ac tua l  trans la t ions  w i l l  have  to  be  prov ided
as   par t   of   the   func t iona l i ty   of   the   ne twork  managemen t   sof tware   tha t   is   t igh t ly
in tegra ted  w i th   the  DBMS .
The   DBMSs   can   be   seen   as   be ing   par t   of   a   he terogeneous   sys tem   tha t   con-
nec ts   d ifferen t   da tabases   and   ne twork   e lemen ts   ( ﬁg .   2 .6) .   The   da ta   sen t
be tween   the  d ifferen t  da tabases  and   the  ne twork  e lemen ts  can  be :

• Alarms signalling different errors in the network. Failed network elements and
traffic congestion.

• Reconfiguration information, new added network elements, removed network
elements, and new interconnections between network elements.

• Information about set-up connections.

• Accounting information.

To  allow  databases  to  access  other  databases  they  have  to  be  designed  with  this  in
mind.  In he terogeneous   DBMSs access  to other databases  is  supported  and queries
spanning over several databases can be defined and optimized. In chapter 4 heteroge-
neous DBMSs are discussed further. To support access to other non-database sources
of  data  such  as  network  elements  the  DBMSs  must  support  this  as  well.  Standards
have  been  defined  such  as  different  MIBs  that  specify  how  the  different  objects
(data)  in  other  databases  and  network  elements  can  be  accessed  and  monitored.
DBMSs  integrated  in  network  management  have  to  be  designed  to  support  these
standards.  In  chapter  9 fore ign   da ta   sources   are  defined  and  discussed  that  allow
DBMSs  to  access  and  monitor  changes  to  data  that  is  not  stored  physically  in  the
database.
In  sec t ion  5 .6 .2  the  use  of  ADBMSs  in  te lecommun ica t ion  ne twork  manage-

23

Regional Network Management

Sectional/Primary Network Management

Network Traffic Control

F igure  2 .6: Connec t ing  DBMSs  and  ne twork  e lemen ts   in  d ifferen t   leve ls  as  for-
e ign  da ta  sources

men t   is  d iscussed .

2 .6 .3

Te lecommun icat ion  Network  App l icat ions

Current  Internet  applications  such  as  e-mail,  news,  and  WWW  (the  World  Wide
Web) will most likely be provided through future telecommunication networks [15].
This  can  be  achieved  by  just  extending  the  Internet  to  partly  run  on  top  of  the  tele-
communications networks through an IP (Internet Protocol) gateway in an ATM net-
work (see section 9.5.3). It can also be achieved by introducing these applications as
new  telecommunication  services  separate  from  equivalent  applications  on  the  Inter-
net.  Future  broad-band  telecommunication  networks  can  hopefully  provide  better
bandwidth,  reliability,  and  support  for billing of used  services which  cannot be pro-
vided by  the  Internet  today. Future applications such as multi-media e-mail,  interac-
tive TV (multi-media WWW), and video-on-demand can be provided directly  to  the
telecommunication network users or indirectly from the Internet through an IP/ATM
gateway.
Many  of  these  app l ica t ions  w i l l  need  DBMS  suppor t .  DBMSs  can  be  used  as
search   eng ines ,   e .g .   search ing   for   a   par t icu lar   serv ice ,   for   s tor ing   mu l t i-med ia

24

Background

da ta ,   and   for   on- l ine   b i l l ing   of   the   serv ices   prov ided .   These   app l ica t ions   w i l l
requ ire   more   suppor t   for   s tor ing   non- tabu lar   da ta ,   such   as   mu l t i-med ia   docu-
men ts   cons is t ing   of   bo th   aud io   and   v ideo   informa t ion .   BLOBs   (B inary   Large
Ob jec ts)   are   used   as   a   common   term   for   these   new   da ta   s truc tures .   Suppor t   for
ex tend ing   the   da tabases   w i th   these   da ta   s truc tures   is   no t   enough   in   i tse lf ;   sup-
por t   is   a lso   needed   for   access ing   these   ob jec ts   or   par ts   of   them   us ing   indexed
search   and   through   a   query   language .   The   DBMSs   mus t   suppor t   ex tens ions   of
the ir   type  sys tems  w i th  new  da ta   types  and  w i th  app l ica t ion-spec i ﬁc  opera t ions
on   them .  These   k inds   of   ex tens ib le   da tabase   sys tems   have   been   named Ob jec t-
Re la t iona l  Da tabase  Sys tems [118] .
In   fu ture   mob i le   te lecommun ica t ion   ne tworks   such   as   UMTS   where   users
w i l l  have  mob i le  term ina ls  there  are  spec ia l  cha l lenges  to  app l ica t ion  da ta  man-
agemen t   [71] .   To   suppor t   mob i le   app l ica t ions   DBMSs   for mob i le   compu t ing
[72] have   to   dea l   w i th   users   who   can   connec t   to   the   da tabase   for   br ief   per iods
and   then   d isconnec t  wh i le  mov ing   somewhere   e lse .  Da ta   can   be   s tored   bo th   in
ne twork  da tabases  and  loca l ly  in  the  mob i le  term ina l .  Here  a  separa t ion  is  made
be tween g loba l   and loca l   da ta   managemen t .   G loba l   da ta   managemen t   dea ls
w i th  ne twork  prob lems  such  as  loca t ing ,  address ing ,  rep l ica t ing ,  and  broadcas t-
ing   app l ica t ion   da ta   to   users .   Loca l   da ta   managemen t   refers   to   end-user   leve l
da ta   managemen t   in   the   mob i le   term ina l   and   inc ludes   energy-ef ﬁc ien t   da ta
access   w i th   cach ing   of   da ta ,   managemen t   of   d isconnec t ion   and   reconnec t ion ,
and   managemen t   of   query   process ing   for   ef ﬁc ien t   nav iga t ion   through   the   ne t-
work   to   ﬁnd   the   des ired   da ta .   There   are   many   new   poss ib le   app l ica t ions   for
mob i le  DBMSs .  One   in teres t ing   app l ica t ion   is   tha t   of   in tegra t ing veh ic le   nav i-
ga t ion   sys tems   and   mob i le   te lecommun ica t ion   sys tems .   In   veh ic le   nav iga t ion
sys tems   the  pos i t ions  of  veh ic les  are  mon i tored  us ing GPS   (G loba l  Pos i t ion ing
Sys tem) [112]  wh ich  is  based  on  us ing  sa te l l i tes  toge ther  w i th  the  reference  s ig-
na l   from   mob i le   te lecommun ica t ion   base   s ta t ions1.   Mob i le   term ina ls   can   be
used   for   send ing   and   rece iv ing   da ta   re la ted   to   the   pos i t ion   of   the   veh ic le .   Th is
app l ica t ion   w i l l   re ly   heav i ly   on   DBMS   suppor t   for   s tor ing   and   send ing   infor-
ma t ion   reques ted   by   the   user   such   as  maps   and  mu l t i-med ia   da ta   re la ted   to   the
veh ic le  pos i t ion .
In  sec t ion  5 .6 .3  the use of ADBMSs in telecommunication network applications
is discussed.

1 .  For  improved  accuracy  in  de term in ing  a  more  exac t  pos i t ion  compared  to  the  pos i t ion
prov ided  by  on ly  us ing  GPS .

25

3

Ac t ive  Da tabase
Managemen t  Sys tems

3 .1 An  Overv iew  of  Act ive  Database  Management  Systems
(ADBMSs)

In   Sys tem   R   [6]   a tr igger   mechan ism   was   de ﬁned   tha t   cou ld   execu te   a   pre-
spec i ﬁed   sequence   of   SQL   s ta temen ts   whenever   some   tr igger ing   even t
occurred .  The  tr igger ing  even ts  tha t  cou ld  be  spec i ﬁed  inc luded  re tr ieva l ,  inser-
t ion ,  de le t ion ,  and  upda te  of  a  par t icu lar  base  tab le  or  v iew.  Tr iggers  had  imme-
d ia te   seman t ics ,   i .e .   they   were   execu ted   immed ia te ly   when   the   even t   was
de tec ted .  In  Sys tem  R  i t  was  a lso  poss ib le  to  make asser t ions  tha t  spec i ﬁed  per-
m iss ib le   s ta tes   or   trans i t ions   in   the   da tabase   through in tegr i ty   cons tra in ts   tha t
a lways  had   to  be   true  af ter  each   transac t ion .  Spec i ﬁc  even ts  had   to  be  spec i ﬁed
for  when  asser t ions  were  to  be  checked  in  the  same  way  as  w i th  tr iggers .  Asser-
t ions   usua l ly   had   deferred   check ing   seman t ics ,   i .e .   they   were   checked   when
transac t ions   were   to   be   comm i t ted .   If   an   asser t ion   fa i led ,   then   the   transac t ion
was  abor ted .
The   term ac t ive   da tabases   was   co ined   in   [92]   as  mean ing   “a   parad igm   tha t
comb ines   aspec ts   of   bo th   da tabase   and   ar t i ﬁc ia l   in te l l igence   techno log ies ” .   In
[92]   a   mechan ism   for   cons tra in t   ma in tenance , Cons tra in t   Equa t ions ,   was   pre-
sen ted   as   a   dec lara t ive   represen ta t ion   for   a   se t   of   re la ted   Cond i t ion-Ac t ion
ru les .
In  H iPAC  [23][29][31][133]  a   thorough  spec i ﬁca t ion  was  made  of  wha t  d if-
feren t   mechan isms   are   des irab le   in   an Ac t ive   Da tabase   Managemen t   Sys tem
(ADBMS) .   Ac t ive   ru les   are   de ﬁned   as Even t-Cond i t ion-Ac t ion   (ECA)   ru les ,
where   the   Even t   spec i ﬁes   when   a   ru le   shou ld   be   tr iggered ,   the   Cond i t ion   is   a
query  tha t  is  eva lua ted  when  the  Even t  occurs ,  and  the  Ac t ion  is  execu ted  when
the   Even t   occurs   and   the   Cond i t ion   is   sa t is ﬁed .   Even ts   can   be   seen   as   s igna ls
tha t   inform   tha t  a  change   to  da ta   in   the  da tabase  has  occurred ,  e .g .  an  upda te  of
a  tab le .  In  H iPAC coup l ing  modes  ( ﬁg .  3 .1)  were  de ﬁned  wh ich  spec ify  how  the
eva lua t ion  of  ru le  cond i t ions  and  the  execu t ion  of  ru le  ac t ions  are  re la ted  to  the
de tec ted  even ts  and   the   transac t ion   in  wh ich   the  even ts  occur.
Immed ia te   ru le   process ing  means   tha t   the   ru le   cond i t ions   are   eva lua ted   and
the   ac t ions   are   execu ted   immed ia te ly   af ter   the   even t   occurred .   A   d is t inc t ion
was   a lso  made   be tween  whe ther   ru le   process ing   takes   p lace   before   or   af ter   the
change   has   taken   p lace   in   the   da tabase . De ferred   ru le   process ing   means   tha t
ru le   process ing   is   de layed   un t i l   the   transac t ion   is   to   be   comm i t ted . Casua l ly

26

Active Database Management Systems

Dependen t   Decoup led   ru le   process ing   means   tha t   any   tr iggered   ac t ion   execu-
t ion   is   execu ted   in   a   separa te   sub- transac t ion   tha t  wa i ts   un t i l   the  ma in   transac-
t ion   is   comm i t ted . Decoup led   ru le   process ing  means   tha t   the   sub- transac t ion   is
comp le te ly  decoup led   from   the  ma in   transac t ion  and  comm i ts   regard less  of   the
ou tcome  of   the  ma in   transac t ion .

Immediate
BOT

Event signal

EOT

Commit

Deferred

Triggered operation

BOT

Event signal

EOT

Commit

Causally-
Dependent
Decoupled

BOT

Decoupled

Triggered operation

Event signal

EOT

Commit

BOT

Triggered operation

Commit

BOT

Event signal

EOT

Commit

BOT
BOT : Beginning of transaction
EOT : End of transaction
F igure  3 .1: Ru le  process ing  coup l ing  modes   in  H iPAC

Triggered operation

Commit

In   POSTGRES   [116][133]   ru les   are   in troduced   as  ECA   ru les  where   even ts   can
be re tr ieve , rep lace , de le te , append , new   ( i .e   rep lace   or   append) ,   and o ld   ( i .e .
de le te  or   rep lace)  of   an  ob jec t   (a   re la t ion  name  or   a   re la t ion   co lumn) .  The   con-
d i t ion   can   be   any   POSTQUEL   query   and   the   ac t ion   can   be   any   sequence   of
POSTQUEL   commands .   Two   types   of   ru le   sys tems   ex is t ,   the Tup le   Leve l   Ru le
Sys tem   wh ich   is   ca l led   when   ind iv idua l   tup les   are   upda ted ,   and   the Query
Rewr i te  Sys tem wh ich   res ides   in   the  parser  and   the  query  op t im izer.  The  Query
Rewr i te   Sys tem   conver ts   a   user   command   to   an   a l terna t ive   form ,   i .e .   by  wrap-
p ing   ex tra   code   wh ich   checks   the   ru les   more   ef ﬁc ien t ly .   No   suppor t   ex is ts   for
hand l ing   tempora l ,  ex terna l  even ts ,  or  compos i te  even ts .
In   S tarburs t   [84][133]   ECA   ru les   are   suppor ted   wh ich   can   mon i tor   the
even ts   INSERT , DELETE ,   and UPDATE   of   a   tab le .   The   cond i t ion   can   be   any

27

SQL   query   and   the   ac t ion   any   sequence   of   da tabase   commands .   Ru les   tha t   are
de ﬁned   can   be   temporar i ly   deac t iva ted   and   then   be   re-ac t iva ted .  The   cond i t ion
and   ac t ion   par ts   may   refer   to trans i t ion   tab les   tha t   con ta in   the   changes   to   a
ru le ’ s   tab le   made   s ince   the   beg inn ing   of   the   transac t ion   or   the   las t   t ime   tha t   a
ru le   was   processed   (wh ichever   happened   mos t   recen t ly) .   The   trans i t ion   tab le
INSERTED /DELETED   con ta ins   records   inser ted /de le ted   in to /from   the   tr igger
tab le .   Trans i t ion   tab les   NEW_UPDATED   and   OLD_UPDATED   con ta in   new
and   o ld   va lues   of   upda ted   rows ,   respec t ive ly.   In   [132]   the se t-or ien ted   seman-
t ics   of   S tarburs t   ru les   are   presen ted .   In   se t-or ien ted   ru le   execu t ion   the   ac t ion
par t   of   a   ru le   is   execu ted   for   a l l   tup les   for   wh ich   the   cond i t ion   is   true   in   con-
tras t   to ins tance-or ien ted   ru le   execu t ion  where   i t   is   execu ted   for   one   tup le   a t   a
t ime .
In   Ar ie l   [63][133]   produc t ion   ru les   are   de ﬁned   on   top   of   POSTGRES .   In
Ar ie l   CA-ru les   are   a l lowed   wh ich   use   on ly   the   cond i t ion   to   spec ify log ica l
even ts   wh ich   tr igger   ru les .   Log ica l   even ts   can   be   expressed   by   a   query   or   a
re la t iona l   v iew   and   spec ify   the   log ica l   cond i t ions   tha t   are   the   resu l t   of   one   or
severa l phys ica l  even ts  (such  as  an  upda te  of  a   tab le) .
In  Ode   [55][133]   cons tra in ts   and   tr iggers   are   in troduced   in to   an  OODBMS .
The pr im i t ive   even ts   tha t   can   be   referenced   are   crea t ion ,   de le t ion ,   upda te ,   or
access   by   an   ob jec t  me thod .  Ode   a lso   suppor ts compos i te   even ts   through   even t
express ions   tha t   re la te   pr im i t ive   even ts .   The   even t   express ions   can   de ﬁne
sequence   order ings   be tween   even ts .   A   th ird   type   of   even t   has   been   de ﬁned ,
known   as   an   ex terna l   even t ,   wh ich   s igna ls   the   occurrence   of   an   even t   ou ts ide
the   da tabase   (e i ther   in   app l ica t ion   programs ,   in   the   opera t ing   sys tem ,   or   in
hardware) .  O ther   sys tems   based   on   ECA-ru les   and  wh ich   can   tr igger   on   ex ter-
na l   even ts   inc lude   REACH   [18]   and   SAMOS   [53] .   In   AMOS   ex terna l   even ts
are   in troduced   as   fore ign   even ts   toge ther  w i th   fore ign   da ta   sources   (se   chap ter
9) .

In  Ch imera  [133]  d ifferen t  mode ls  for  process ing  even ts , even t  consump t ion
modes ,   can   be   spec i ﬁed .   Ch imera   a lso   inc ludes   a debugg ing   mode where   the
s ta te  of  an  execu t ing  ru le  can  be  mon i tored   in terac t ive ly.
Cons iderab le   research   has   been   carr ied   ou t   in   the   area   of   ac t ive   da tabase
sys tems .  A  good   in troduc t ion   to   the   research  area  and  ac t ive  da tabase  arch i tec-
tures   can   be   found   in   [133]   wh ich   inc ludes   overv iews   of   mos t   of   the   research
sys tems   men t ioned   above   (an   add i t iona l   sys tem ,   A-RDL ,   is   d iscussed   in
sec t ion 6 .3   in   th is   thes is) .

3 .2 ADBMS  C lass i ﬁcat ions

In   the Ac t ive   Da tabase   Managemen t   Sys tem   Man i fes to [35]   requ ired   and
op t iona l   func t iona l i ty   for   an   ADBMS   are   presen ted .   Requ ired   func t iona l i ty
inc ludes   suppor t   for   crea t ing ,   mod ify ing ,   ac t iva t ing ,   and   deac t iva t ing   (ca l led
enab l ing   and   d isab l ing)   ECA-ru les .   The   ADBMS   mus t   suppor t   even t   mon i tor-
ing   and   s tor ing   even ts   in   an even t   h is tory   as   (<even t   type> ,   < t ime>)   where   the
<even t  type>  represen ts  any  pr im i t ive  even t  and  the  < t ime>  is  the  t ime  ( transac-
t ion   t ime)   when   the   even t   occurred .   The   ADBMS   mus t   have   c lear ly   de ﬁned

28

Active Database Management Systems

ru le   seman t ics   such   as   the even t   consump t ion   po l icy   ( i .e .   when   even ts   are   d is-
carded) ,  even t  de tec t ion   ( i .e .  when  even ts  are  de tec ted  and  s igna l led   to   the   ru le
manager) ,   and   ru le   seman t ics   such   as   coup l ing   modes   and   ins tance   or   se t-or i-
en ted  seman t ics .  Some  poss ib le  even t  consump t ion  po l ic ies  are : recen t , chron i-
c le ,  and cumu la t ive .   In   the   recen t  po l icy   the   la tes t   ins tance  of  a  pr im i t ive  even t
tha t   is  par t  of  a  comp lex  even t   is  consumed   if   the  comp lex  even t  occurs .   In   the
chron ic le   po l icy   the   even ts   are   consumed   in   t ime   order.   In   the   cumu la t ive   po l-
icy  a l l  ins tances  of  a  pr im i t ive  even t  are  consumed  if  the  comp lex  even t  occurs .
Two   new   coup l ing  modes   are   sugges ted   in   [35]   ( ﬁg .   3 .2) , Sequen t ia l   Caus-
a l ly   Dependen t   (some t imes   ca l led   De tached)   ru le   process ing ,   where   the   tr ig-
gered   transac t ion   s tar ts   af ter   the   tr igger ing   transac t ion   is   comm i t ted ,   and
Exc lus ive  Causa l ly  Dependen t   ru le   process ing ,  where   the   tr iggered   transac t ion
may   comm i t   on ly   if   the   tr igger ing   transac t ion   has   fa i led . Con ﬂ ic t   r eso lu t ion
po l ic ies  mus t   a lso  be  de ﬁned   for  manag ing   s imu l taneous ly   tr iggered   ru les ,   e .g .
by   a l low ing   the   user   to   spec ify   d ifferen t   pr ior i t ies   for   con ﬂ ic t ing   ru les .  Access
to   even ts   in   cond i t ion   and   ac t ion   par ts   of   ru les  m igh t   a lso   be   de ﬁned .  Op t iona l
func t iona l i ty   inc ludes   a   ru le   programm ing   env ironmen t  w i th   too ls   such   as   ru le
ed i tors ,   ru le   browsers ,   ru le   ana lyzers ,   ru le   debuggers ,   trace   fac i l i t ies ,   and   per-
formance   tun ing   too ls .   Some   examp les   of   too ls   in   a   suppor t   env ironmen t   for

Sequential
Causally
Dependent
BOT

Exclusive
Causally
Dependent
BOT

(Detached)

Event signal

EOT

Commit

BOT

Triggered operation

Commit

Event signal

EOT

Abort

BOT
BOT : Beginning of transaction
EOT : End of transaction

Triggered operation

Commit

F igure  3 .2: Two  new ly  sugges ted  ru le  process ing  coup l ing  modes

ac t ive  ru le  des ign  can  be  found   in  [8] .
Two   impor tan t   aspec ts   for   compar ing   d ifferen t   arch i tec tures   are   the   expres-
s iveness  of   the  ru le   language  and   the  execu t ion  seman t ics  of   the  ru les .
The   express iveness   of   the   ru les   can   be   d iv ided   in to   the   express iveness   of
ru le  even ts ,  cond i t ions  and  ac t ions .  The  express iveness  of  the  even t  par t  can  be

29

d iv ided  in to  compar ing  the  types  of  even ts  tha t  the  ru les  can  reference  and  how
the   even ts   can  be  mode l led   and   comb ined   in to   comp lex   even ts .  D ifferen t   types
of   even ts   inc lude   da tabase   upda tes ,   schema   changes ,   and   ex terna l   even ts   such
as   sensor   va lue   changes ,   spec i ﬁed   s ta te   changes   in   the   app l ica t ions ,   or   t ime .
Mode l l ing  even ts  can   inc lude  an  even t  spec i ﬁca t ion   language   tha t  can  comb ine
even ts   us ing   log ica l   compos i t ion ,   even t   order ing ,   sequen t ia l   and   tempora l
order ing ,  and  even t  per iod ic i ty  [24] .
The   express iveness   of   the   cond i t ion   par t   can   be   d iv ided   in to   whe ther   a   fu l l
query   language   is   ava i lab le   or   no t ,   whe ther   the   even ts   can   be   referenced   as
changed  da ta ,  and  whe ther  o ld  va lues  can  be  referenced  or  no t .
The   express iveness   of   the   ac t ion   par t   can   be   d iv ided   in to   whe ther   a   fu l l
query   language   is   ava i lab le   or   no t ,   i .e .   whe ther   quer ies   and   upda tes   can   be
in ter tw ined ,   and   whe ther   the   ac t ion   can   inc lude   schema   changes   and   ru le   ac t i-
va t ion /deac t iva t ion .
Execu t ion   seman t ics   of   ru les   inc ludes   ru le   process ing   coup l ing   modes
de ﬁned   in   sec t ion   3 .1 .   If   fu l l   query   language   express iveness   is   poss ib le   in   the
cond i t ion   par t ,   then   se t-or ien ted   ru le   seman t ics   are   a lso   poss ib le   [132] ,   where
the   ac t ion   par t   is   execu ted   over   a   se t   of   tup les   produced   by   the   cond i t ion .  Cas-
cad ing   ru le   execu t ion ,   i .e .  whe ther  one   ru le   can   tr igger   ano ther,   and   if   s imu l ta-
neous ly   tr iggered   ru les   are   sub jec ted   to   some   con ﬂ ic t   reso lu t ion   me thod   are
a lso  par t  of   the  c lass i ﬁca t ion  of  ru le  seman t ics .
In  [133]  d ifferen t  arch i tec tures  of  ADBMSs  are  de ﬁned  as
tures , bu i l t- in  arch i tec tures ,  and comp i led  arch i tec tures .

layered  arch i tec-

• In a layered architecture the rule system is loosely coupled with the DBMS by in-
tercepting  client-server  communication  and  by  calling  application  procedures  or
submitting  commands  to  the  DBMS.  Layered  architectures  are  usually  easier  to
implement, but can exhibit poor performance.

• In a built-in architecture the rule system is tightly coupled with the DBMS and rule
processing is integrated with query processing. Built-in architectures usually pro-
vide good performance, but are substantially more difficult to implement.

• In a compiled architecture the rule system is an extension of the application or da-
tabase query language where the rules are wrapped as procedural code around ex-
pressions  that generate events  that might affect  the rule. A compiled architecture
requires  that  the  compiler  can  detect  all  events  at  compile-time which  is  usually
not the case in general database interfaces where applications are allowed to per-
form ad-hoc modifications to the database.

In  [35]  ADBMSs  are  c lass i ﬁed  accord ing   to  how   they  are  used  by  app l ica t ions ,
i .e .   for   mon i tor ing   or   for   con tro l .   A   c lass i ﬁca t ion   is   a lso   made   accord ing   to
how   the   app l ica t ions   are   in tegra ted   w i th   the   ADBMS .   The   ADBMS   is   of ten
cons idered   as   a   s tand-a lone   sys tem  w i th   app l ica t ions   as   c l ien ts   tha t   connec t   to
the  ADBMS  server.  A l terna t ive ly,  the  ADBMS  can  be  in tegra ted  (embedded)  in
a   sys tem   as   a   componen t   tha t   can  be  used  by   app l ica t ions ,  bu t  where   the   app l i-
ca t ions  are  cons idered  as  prov id ing  the  ma in  func t iona l i ty  of  the  who le  sys tem .
The  AMOS  ADBMS   is   based   on   a   bu i l t- in   arch i tec ture  where   ru le   process-

30

Active Database Management Systems

ing   is   t igh t ly   in tegra ted   w i th   query   process ing .   Ac t ive   ru les   in   AMOS   are   pr i-
mar i ly   des igned   for   ef ﬁc ien t  mon i tor ing   of   changes   to   the   da tabase ,   bu t   can   be
used  for  con tro l  as  we l l .  AMOS  can  be  run  as  a  s tand-a lone  sys tem  or  be  t igh t ly
in tegra ted  w i th  app l ica t ions .

3 .3 AMOS

AMOS   [41]   (Ac t ive   Med ia tors   Ob jec t   Sys tem)   is   a   sys tem   tha t   can   mode l ,
loca te ,   search ,   comb ine ,   and   mon i tor   da ta   in   informa t ion   sys tems   w i th   many
works ta t ions   connec ted   us ing   fas t   commun ica t ion   ne tworks .   The   arch i tec ture
uses   the med ia tor   approach   [131]   tha t   in troduces   an   in termed ia te   leve l   of   sof t-
ware  be tween  da tabases   and   the ir  use   in   app l ica t ions   and  by  users .  We   ca l l  our
c lass   of   in termed ia te   modu les ac t ive   med ia tors ,   s ince   our   med ia tors   suppor t
ac t ive  da tabase   fac i l i t ies .  The  AMOS   arch i tec ture   is  bu i l t   around   a  ma in  mem-
ory-based   p la tform   for   in tercommun ica t ing   informa t ion   bases .   Each   AMOS
server  has  DBMS   fac i l i t ies ,   such   as   a   loca l  da tabase ,   a  da ta  d ic t ionary,   a  query
processor,   transac t ion   process ing ,   and   remo te   access   to   da tabases .   The   AMOS
mu l t i-DBMS  arch i tec ture   is  presen ted   in  Paper   III ,   [42] ,  and   [130] .  The AMOS
DBMS  is  an  extension  of  a  main-memory  version  of  Iris  [47],  called WS-Iris  [82],
where OSQL  queries  are  compiled  into  execution  plans  in  an OO  logical  language,
ObjectLog  [82].  The   query   language   of   AMOS ,   AMOSQL ,   is   a   der iva t ive   of
OSQL   [85] .   AMOSQL   ex tends   OSQL   w i th   ac t ive   ru les ,   a   r icher   type   sys tem ,
and  mu l t i-da tabase  func t iona l i ty.
In   ﬁg .  3 .3   the  AMOS  arch i tec ture   (exc lud ing   the  mu l t i-DBMS  par ts)  can  be
seen  where   the  d ifferen t   leve ls  and  modu les  are :

• The ex terna l   app l ica t ion   in ter face   level  can  handle  embedded  AMOSQL  by
sending  the expressions  to  the  level below for parsing and execution. An AMOS
fast-path  interface  that does not  require any parsing  is also available. Results are
returned  to  the  external  interface,  either  directly  or  through  interface  variables
and cursors.

• The AMOSQL   in terpre ter parses  AMOSQL  expressions  and  sends  requests  to
the  levels  below.  AMOSQL  supports  precompiled  functions  (views  and  stored
procedures) and most applications will only parse and optimize complicated que-
ries once and then call the functions directly.

• The schema  manager  handles all schema operations such as creating or deleting
types, i.e. object classes, and type instances including functions and rules.

• The ru le  processor  handles rule compilation, activation/deactivation, monitoring
of events, and execution of rules and is described in more detail in this chapter.

• The even t  manager  dispatches events received on the even t  bus  to the rule proc-
essor. Events can come from in terna l  even ts  intercepted by the transaction man-
ager such as schema updates or relational updates. Other possible events are for-
e ign   even ts   from  foreign  data  sources  and t ime   even ts   from  the  agenda.  The
event manager also supports storing events  in event histories represented as  time

31

series  that  can  be  accessed  through  event  functions.  The  event  functions  can  be
accessed by the rule processor through AMOSQL queries.

• The agenda  is a time management module that can schedule activities to be per-
formed at specific times. The agenda is more discussed in section 9.3.6.

• The fore ign   da ta   source   in ter face   supports  extension of AMOS with new data
structures  and  interfaces  to  other  non-local  data.  It  interacts  with  the  AMOSQL
optimizer since access of new data structures such as available indexes are crucial
for  query  optimization.  It  interfaces  with  the  ObjectLog  interpreter  since  com-
piled execution plans will need access  to foreign data. It  interfaces with  the  logi-

External Application Interface

Embedded AMOSQL

AMOS Fast-path Interface

Time Series

SNMP MIB

CORBA

Agenda

Time
Events
Event
Manager

Foreign
Events

l
a
s
t
n
n
r
e
e
v
t
n
E
I

Transaction
Manager

Recovery
Manager

AMOSQL Interpreter

Schema
Manager

Rule
Processor

Optimizer

ObjectLog Interpreter

Logical Object Manager

Physical Object Manager

Data Structures

e
c
a
f
r
e
t
n
I
 
e
c
r
u
o
S
 
a
t
a
D
 
n
g
i
e
r
o
F

Memory
Manager

Disk
Manager

F igure  3 .3: The  AMOS  arch i tec ture

32

Active Database Management Systems

cal object manager since many foreign data sources need to create special objects,
e.g. time series are used for storing the data of event functions and interfaces such
as CORBA and SNMP MIB (see section 9.5.3) would need to create interface ob-
jects and fore ign   func t ions  that are accessible through AMOSQL queries. Final-
ly it also needs to interface with the physical object manager since new data struc-
tures  such  as  time  series  have  to  be  defined  together  with  operations  for  alloca-
tion,  deallocation,  access,  and  updating.  Foreign  data  sources  in  general  are
discussed in chapter 9.

• The AMOSQL   op t imizer  is  responsible  for  transforming  ad  hoc  queries,  update
statements,  functions,  and  stored  procedures  into  efficient  execution  plans  using
query  optimization  and  compilation  techniques. This  process  involves  the  appli-
cation  of  transformation  rules  and  heuristic  cost-based  query  optimization  tech-
niques that produce executable and efficient query plans. By supporting the defi-
nition  of  execution  costs  for  foreign  functions  (default  costs  are  also  provided),
the  optimizer  can  optimize  expressions  that  include  foreign  functions  as  well.
Query optimization in AMOS and the management of foreign predicates are pre-
sented in [82] and [48].

• The Ob jec tLog   in terpre ter  [82] supports efficient execution of optimized query
plans. All  data  is  accessed  here  through  logical  predicates.  Stored  functions,  i.e.
tables,  are  represented  as  facts  and  derived  functions,  i.e.  views,  are  represented
as Horn Clauses. Foreign functions are represented as foreign predicates that can
access the foreign data through the foreign data source interface.

• The log ica l  ob jec t  manager  manages all operations to all objects in the database
schema  such as object creation, deletion, and updates of object attributes  includ-
ing  updating,  inserting,  and  deleting  data  in  stored  functions,  i.e.  base  relations.
This level also handles OIDs (Object Identifiers) of the logical objects. All opera-
tions on these objects are transactional and are thus logged. All operations gener-
ate events that are intercepted and sent to the event manager.

• The phys ica l   ob jec t   manager handles  all  basic  objects  (everything  in  the  data-
base is an object) such as atoms, strings, integers, real numbers, lists, arrays, hash
tables, tree structures, and time series.

• The transac t ion  manager  handles all database transactions by keeping an undo/
redo  log  of  all  database  operations.  It  also  intercepts  logged  operations  such  as
updates  and  schema  changes  and  passes  them  as  events  to  the  event  manager
through the event bus.

• The recovery   manager   ensures persistency by making periodical  snapshots  and
flushing the log to disk.

• The memory   manager  manages  all memory operations  such  as  allocation, deal-
location, and garbage collection.

• The d isk   manager   in  AMOS  is  more  primitive  in  comparison  to  disk-based
DBMSs.  It mainly  handles  flushing  of  database  images  and  logs  between main-
memory and disk for initiation, connection, or saving of databases.

33

The   even t   hand l ing   is   t igh t ly   in tegra ted   in to   the   sys tem   and   in terna l   changes
are   in tercep ted  where   they  occur   in   the   lower   leve ls   for  ef ﬁc iency   reasons .  The
ru le   processor   is   t igh t ly   in tegra ted  w i th   the   query   process ing   for   the   same   rea-
son .

3 .4 The  Ru le  Processor  and  the  Event  Manager

The   ac t ive   ru les   in   AMOS   are   of   Cond i t ion   Ac t ion   (CA) ,   Even t   Cond i t ion
Ac t ion   (ECA) ,   and   Even t   Ac t ion   (EA)   types .   The   AMOS   ru le   processor   han-
d les   ru le   crea t ion /de le t ion ,   ac t iva t ion /deac t iva t ion ,   mon i tor ing ,   and   execu t ion .
The  process ing  of  ru les   is  d iv ided   in to  four  phases :

1. Event Detection
2. Change monitoring
3. Conflict resolution1
4. Action execution

Even t   de tec t ion   cons is ts   of   de tec t ing   even ts   tha t   can   affec t   any   ac t iva ted   ru les
and   is   performed   con t inuous ly   dur ing   ongo ing   transac t ions .   Even ts   are   accu-
mu la ted   in   even t   h is tor ies   represen ted   by even t   func t ions .   Comp lex   even t
de tec t ion   ( in   ECA-ru les)   is   performed   by   execu t ing   log ica l   express ions   (bas i-
ca l ly  s imp le  quer ies)  over  severa l  even t  func t ions .  Change  mon i tor ing   inc ludes
us ing   the even t   da ta   from   the   even t   func t ions   to   de term ine  whe ther   any   cond i-
t ion   of   any   ac t iva ted   ru les   have   changed ,   i .e .   have   become   true .   Dur ing   ac t ion
execu t ion   fur ther   even ts   m igh t   be   genera ted   caus ing   a l l   the   phases   to   be
repea ted   un t i l   no   more   even ts   are   de tec ted .   D ifferen t   con ﬂ ic t   reso lu t ion   me th-
ods   are   ou ts ide   the   scope   of   the   thes is .   In   the   curren t   imp lemen ta t ion   a   s imp le
pr ior i ty  based  con ﬂ ic t  reso lu t ion   is  used .
The   ru le   execu t ion  mode l   in  AMOS   is   based   on   the Even t  Cond i t ion  Ac t ion
(ECA)   execu t ion   cyc le   ( ﬁg .   3 .4) .   A l l   even ts   are   sen t   on   an
even t   bus   tha t
queues   the  even ts  un t i l   they  are  processed .  The  execu t ion  cyc le   is  a lways   in i t i-
a ted   by   non-ru le- in i t ia ted   even ts   such   as   da tabase   upda tes ,   schema   changes ,
t ime  even ts ,  or  o ther  ex terna l  even ts .  In  AMOS  even ts  are  in tercep ted  in  a  s im-
i lar   manner   as   in   POSTGRES   [116]   and   S tarburs t   [84] .   However,   the   even ts
tha t   are   in tercep ted   in   AMOS   inc lude   a l l   opera t ions   of   log ica l   ob jec ts .   Th is
makes  i t  poss ib le  to  ex tend  ru les  to  tr igger  on  any  change  in  the  sys tem ,  inc lud-
ing   schema   upda tes .   A l l   even ts   are   d ispa tched   through   tab le-dr iven   execu t ion .
Even ts  are  accumu la ted  chrono log ica l ly  in  s tored  tempora l  even t  func t ions  rep-
resen ted  by  t ime  ser ies .  More  abou t  the  tempora l  aspec ts  of  even t  func t ions  can
be   found   in  chap ter  8 .  Even t   func t ions  are  used   in  AMOSQL even t  express ions
tha t  can  de ﬁne  comp lex  even ts .  The  even t  express ions  are  au toma t ica l ly  gener-
a ted  from  ana lyz ing  ru le  cond i t ions  for  CA-ru les  and  are  crea ted  from  the  even t
par t   of  ECA   and  EA-ru les .  The   even t   express ions   genera te   even t   da ta  wh ich   is

1 .  Con ﬂ ic t  reso lu t ion  is  the  process  of  choos ing  one  s ing le  ru le  when  more  than  one  ru le
is   tr iggered .

34

Active Database Management Systems

non-rule-
initiated
events

rule-
initiated
events

Action
 execution

action-set
tuples

Event
 detection

event
data

Event Bus

Condition
evaluation

F igure  3 .4: The  ECA  execu t ion  cyc le

used  for  eva lua t ing   the  ru le  cond i t ions .
Ru le   check ing   is   performed   in   a check   phase   usua l ly   a t   transac t ion   comm i t
(deferred   ru le   check ing) .   Ru le   check ing   can   a lso   be   invoked   by   ca l l ing   the
check  procedure  exp l ic i t ly.  Dur ing   ru le  check ing ,   ru le  cond i t ions  are  eva lua ted
if  there  is  any  even t  da ta ,  s ince  th is  s igna ls  tha t  the  ru le  has  been  tr iggered .  The
eva lua t ion   of   the   ru le   cond i t ions   produces ac t ion-se ts   tha t   con ta in   tup les   for
wh ich  the  ac t ions  are  to  be  execu ted .  If  an  ac t ion-se t  is  emp ty,  th is  s ign i ﬁes  tha t
the   ru le   cond i t ion  was   fa lse .  When   the   ac t ions   are   execu ted ,   new   even ts  m igh t
be   genera ted   and   the   execu t ion   cyc le   con t inues   un t i l   no   more   even ts   are
de tec ted  on   the  even t  bus .
The   ac t ive   ru les   in   AMOS   can   be   c lass i ﬁed   accord ing   to   the   fea tures   pre-
sen ted  in  sec t ion  3 .2 .  The  express iveness  of  even ts  is  based  on  log ica l  compos i-
t ion   (AND ,   OR) ,   even t   order ing   (BEFORE ,   AFTER) ,   and   s imp le   tempora l
even ts   (AT   < t ime   po in t> ,   WITHIN   < t ime   in terva l>) .   Even ts   can   be pr im i t ive ,
in terna l   (such   as   ADD ,   REMOVE ,   and   UPDATE   of   tab les   and   CREATE /
DELETE   of   ob jec ts)   and   ex terna l   (such   changes   to   a   sensor) .   Even ts   can   a lso
be comp lex   such   as   ADD ,   REMOVE ,   and   UPDATE   of   re la t iona l   v iews .   The
express iveness  of  cond i t ions  is  based  on  the  ava i lab i l i ty  of  comp le te  AMOSQL
quer ies   in   the   cond i t ion .   The   express iveness   of   ac t ions   is   based   on   fu l l
AMOSQL   procedura l   s ta temen ts ,   i .e .   quer ies   in ter tw ined   w i th   any   upda tes   of
the   schema ,   upda tes   of   func t ions ,   ru le   ac t iva t ion /deac t iva t ion ,   and   app l ica t ion
ca l l-backs .   The   ru les   in   AMOS   have   as   defau l t   a   deferred   coup l ing   mode ,   bu t
o ther   coup l ing   modes ,   such   as   immed ia te ,   sequen t ia l   causa l ly   dependen t   (or
de tached) ,  and  manua l  invoca t ion  of  ru le  check ing ,  can  be  used  by  us ing  d iffer-
en t  ru le  con tex ts  (see  Paper  IV  and  sec t ion 7 .8) .

35

3 .5 The  Ir is  Data  Mode l  and  OSQL

The  da ta  mode l  of  AMOS  and  AMOSQL  is  based  on  the  da ta  mode l  of  Ir is  [47]
and   OSQL   [85] .   The   Ir is   da ta   mode l   is   based   on   ob jec ts ,   types ,   and   func t ions
( ﬁg .   3 .5) .   Every th ing   in   the   da ta  mode l   is   an   ob jec t ,   inc lud ing   types   and   func-
t ions .   A l l   ob jec ts   are   c lass i ﬁed   by   be long ing   to   one   or   severa l   types ,   wh ich
equa l   ob jec t   c lasses .   Types   themse lves   are   of   the   type   ‘ type ’   and   func t ions   are
of   the   type   ‘func t ion ’ .

objects

participate
in

operate
on

classify

belong
to

functions

constrain
deﬁned with

types

F igure  3 .5: The  Ir is  da ta  mode l

The  da ta  mode l  in  Ir is  is  accessed  and  man ipu la ted  through  OSQL1.  (A l l  exam-
p les  of   ac tua l   schema  de ﬁn i t ions   and  da tabase  quer ies  w i l l  here  be  wr i t ten   in   a
cour ier  fon t .)  For  examp le ,   i t   is  poss ib le   to  de ﬁne  user   types  and  sub types :

create type person;
create type student subtype of person;
create type teacher subtype of person;
create type course;

S tored   func t ions   can   be   de ﬁned   on   types   tha t   equa l   a t tr ibu tes   in   Ob jec t-Or i-
en ted   da tabases   or   base   re la t ions   in   Re la t iona l   da tabases ;   hence   we   ca l l   th is
mode l Ob jec t  Re la t iona l [118] .  One   func t ion   in   the   Ir is  da ta  mode l   equa ls   sev-
era l   func t ions   in   a  ma thema t ica l   sense .   For   examp le ,   the   bu i l t- in sqr  func t ion
can  be  used  for  ca lcu la t ing  bo th  the  square  of  a  number  and  the  square  roo t .  By
ca l l ing sqr in  a  query  w i th  the  argumen t  unbound  and  the  resu l t  bound  to  some
number,  the  AMOSQL  comp i ler  w i l l  choose  an  in terna l  func t ion  tha t  ca lcu la tes
and  b inds   the  argumen t  of sqr  to   the  square  roo t  of   the  resu l t .
Le t   us   de ﬁne   a   func t ion   tha t   can   bo th   g ive   the   name   of   a   person   g iven   the
person  ob jec t  or  g ive  a l l   the  person  ob jec ts  assoc ia ted  w i th  a  name .

create function name(person) -> charstring as stored;

S tored  func t ions   is   the  defau l t  so   the   ‘ as stored’  par t  can  be  om i t ted :

1 .  Some  syn tax  here ,  espec ia l ly  for  s tored  procedures ,   is  ac tua l ly  AMOSQL .

36

Active Database Management Systems

create function studies(student) -> bag of course;
create function passed(course) -> bag of student;
create function gives(teacher) -> bag of course;

Bags   are   used   for   s tor ing mu l t i-va lued   func t ions .   Der ived   func t ions   equa l
me thods   or   re la t iona l   v iews   and   can   be   de ﬁned   in   terms   of   s tored   func t ions
(and  o ther  der ived  func t ions) .

create function teaches(teacher t) -> student s
as select s for each course c where
gives(t) = c and
c = studies(s);

No te   tha t   der ived   func t ions   such   as   the teaches  func t ion   imp l ic i t ly   re turn
bags ,   even   though   they   are   dec lared   as   re turn ing   a   s ing le   type ,   s ince   they   are
the   resu l t  of   a  query.  Quer ies   re turn   a   s tream  of  da ta   tha t   can   accessed  one   a t   a
t ime  or  be  co l lec ted   in to  a  bag .
Ins tance  ob jec ts  of  a   type  can  be  crea ted  and  s tored
func t ions  can  be  se t  for   these   ins tances :

create student instances :iris1, :amos;
set name(:iris) = “Iris”;
set name(:amos) = “AMOS”;
create course instances :active_DBMSs;

A l l  user-de ﬁned  ob jec ts  w i l l  be  g iven  an  Ob jec t  Iden t i ﬁer
(OID) .  S ing le  va lues  can  be  added   to  (and  removed
from)  mu l t ip le-va lued  func t ions .

Iris

add studies(:amos) = :active_DBMSs;
remove studies(:amos) = :active_DBMSs;

Func t ions   can   be   de ﬁned   w i th mu l t ip le   argumen ts   and   va lues ,   i .e .   w i th   tup le
resu l ts .

create function grade(student) ->
bag of <course, charstring>;

S tored  procedures  are  de ﬁned  as  func t ions   tha t  have  s ide-ef fec ts :

create function teach(teacher t, student s, course c)
-> boolean as
begin
if (s = passed(c))
/* the student has already passed the course */

1 .  These  are   in terface  var iab les  and  are  no t  par t  of   the  da tabase .

37

then result false
else
begin
/* if teacher t is not already teaching the
course c, mark t as teacher of course c */
if notany(select gives(t) = c)1
then add gives(t) = c;
/* if student s is not already taking the
course c, add s as student of course c */
if notany(select studies(s) = c)
then add studies(s) = c;
result true;
end;
end;

create function mark(student s, course c, charstring g)
-> boolean as
begin
if (c = studies(s))
/* the student is taking the course */
then
begin
add grade(s) = <c, g>;
if g != “Failed” then add passed(c) = s;
remove studies(s) = c;
result true;
end
else
/* the student is not taking the course */
result false;
end;

As   can   be   seen   in   the   examp les   above ,   s tored   procedures   can   access   func t ions
and   perform   ad   hoc   quer ies .   S tored   procedures   are ,   however,   no t   a l lowed   in
quer ies   (and   der ived   func t ions)   s ince   a   ser ies   of   quer ies   shou ld   a lways   re turn
the   same   resu l t   regard less   of   in   wha t   order   the   quer ies   are   execu ted2,   i .e .   they
canno t  con ta in  s ide-effec ts .
Mu l t ip le   inher i tance ,   i .e .  mu l t ip le   super types ,   is  poss ib le  by   crea t ing   a   type
w i th   two  super types :

create type student_teacher subtype of student, teacher;

1 .  Bags  can  be  crea ted  a t  run- t ime  by  sub-se lec t  express ions ,  and notany   is  an  aggre-
ga te  func t ion   tha t  re turns   true   if   i t   is  ca l led  w i th  an  emp ty  bag .
2 .  Th is  is  cruc ia l  for  query  op t im iza t ion  s ince  the  query  op t im izer  w i l l  reorder  quer ies  to
genera te  an  ef ﬁc ien t  execu t ion  p lan .

38

Active Database Management Systems

New   types1 can  be  added   to  an   ins tances :
add type student_teacher to :amos;

Procedures  are  ca l led  by :

call teach(:amos, :iris, :active_DBMSs);
TRUE

Func t ions   are mu l t i-d irec t iona l   wh ich   means   tha t   they   can   be   accessed   in
inverse   quer ies   where   the   resu l t   va lue   is   known   and   the   argumen t(s)   is(are)
requ ired .

select name(t)
for each teacher t
where teaches(t) = :iris;

“AMOS”

In   the  prev ious   examp le   the   las t  query   re turns   a   s ing le   tup le .  Quer ies ,   and   sub-
sequen t ly   func t ions ,   can   re turn   severa l   tup les .   Dup l ica te   tup les   are   removed
from   s tored   func t ions   if   they   are   no t   exp l ic i t ly   de ﬁned   to   re turn   a   bag .  W e   say
tha t  we   have se t-or ien ted   seman t ics . Bag-or ien ted   seman t ics   is   ava i lab le   as   an
op t ion   and   can   be   spec i ﬁed   a long  w i th   the   re turn   type   of   a   func t ion   as   de ﬁned
for   the studies func t ion .
Func t ions   can   be   over loaded   on   the   types   of   the ir   argumen ts ,   i .e .   we   can
de ﬁne   the   same   func t ion   in   severa l   ways   depend ing   on   the   types   of   the   ar gu-
men ts .   The   sys tem   w i l l   in   mos t   cases   choose   the   correc t   func t ion   a t   comp i le
t ime ,   th is   is   known   as ear ly   b ind ing .   In   some   cases   the   sys tem   canno t   de ter-
m ine   wha t   func t ion   to   choose   a t   comp i le   t ime   and   the   execu t ion   p lan   mus t
check  some  types  a t  run  t ime ,  th is  is  known  as la te  b ind ing .  Le t  us  de ﬁne  a  new
func t ion name  tha t  over loads  on   the   ﬁrs t  ar gumen t :

create function name(course) -> charstring;

The  AMOSQL   comp i ler  w i l l   choose   the   correc t   vers ions   of   the name  func t ion
by   look ing   a t   the   type   of   the   argumen ts   (ear ly   b ind ing) .   If ,   however,   the   exac t
type  of  the  argumen t  is  unknown ,  e .g .  the  type  is  on ly  spec i ﬁed  as object ( the

1 .  Ins tances  be long   to  a  se t  of   types  (usua l ly   the   immed ia te  super type  w i th   i ts  super-
types)  and  a  new  added   type  mus t  be  a  sub type  of  one  of   the  curren t   types  of   the
ins tance .

39

mos t   genera l   type)   a t   comp i le- t ime ,   bu t   is   known   a t   run- t ime ,   then   the   cho ice
w i l l  be  made  a t  run- t ime  ( la te  b ind ing) .  If  for  some  reason   the  exac t   type   is  no t
known  a t  run- t ime  e i ther,   i t   is  poss ib le   to  he lp   the  AMOSQL  comp i ler  by  spec-
ify ing   the   fu l l   names   of   the   func t ions .  Fu l l   names   of   func t ions   are   spec i ﬁed   by
the   comp le te   func t ion   s igna ture :   <arg1  type>.  . . .<argm  type>.<func t ion
name>-><res1  type>.  . . .<resn  type> ,   e .g . person.name->charstring  and
course.name->charstring.
In terface   var iab les   are   un typed   if   they   are   no t   dec lared1  so   the   fo l low ing
express ion  mus t  be  manua l ly   type  reso lved :

set course.name->charstring(:active_DBMSs) =
“Active Database Management Systems”;

On   the   top- leve l select and call can  be   lef t  ou t :

course.name->charstring(:active_DBMSs);
“Active Database Management Systems”
mark(:iris, :active_DBMSs, “Excellent”);
TRUE

AMOS   a lso   a l lows   the   in troduc t ion   of   func t ions   wr i t ten   in   some   o ther   pro-
gramm ing   language  such  as  C  and   these  are  known  as fore ign   func t ions :

create function print(charstring) -> boolean as
2;
foreign “Cprintfn”
create function print_grades(course c) -> boolean as
begin /* prints course grades on a console or printer */
print(name(c));
for each student s, charstring g
where grade(s) = <c, g>
print(name(s) + ”: “ + g);

3

end;

print_grades(:active_DBMSs);
Active Database Management Systems
Iris: Excellent

D ifferen t   access   pa t terns   and   cos t   informa t ion   can   be   spec i ﬁed   for   fore ign
func t ions   to   suppor t   inverse   quer ies   and   query   op t im iza t ion .   See   [82]   for  more
de ta i ls .

1 .  Var iab les  can  be  dec lared  by : declare course :active_DBMSs;
2 .  B ind ings   to  fore ign  func t ions  are  reso lved  dur ing   l ink ing  and  a t  sys tem   in i t ia l iza t ion .
3 .  The   ‘ + ’  opera tor   is  over loaded  on charstring  w i th  a  fore ign  func t ion  for  s tr ing
conca tena t ion .

40

Active Database Management Systems

A   transac t ion  can  be  comp le ted  and  made  permanen t  by :

commit;

A   transac t ion   is  abor ted  and  ro l led  back  by :

rollback;

More   informa t ion   abou t   the  AMOSQL   comp i ler   and   op t im izer   can   be   found   in
[48][82] .   S ince   types   and   func t ions   are   ob jec ts   as  we l l ,   of   the   types   ‘ type ’   and
‘func t ion ’ ,   i t   is   poss ib le   to   de ﬁne   gener ic   func t ions ,   i .e .   func t ions   tha t   take
types   as   argumen ts ,   and   h igher   order   func t ions ,   i .e .   func t ions   tha t   take   o ther
func t ions  as  argumen t .

3 .6 About  Paper  II

Th is   paper   was   the   ﬁrs t   pub l ica t ion   on   add ing   ru les   to   AMOS .   The   ru les   pre-
sen ted   in   th is   paper   have   la ter   been   imp lemen ted .   No te   tha t   the   ru le   syn tax   in
Paper   II   d iffers   s l igh t ly   from   the   syn tax   in   th is   chap ter   wh ich   is   based   on   the
ac tua l   imp lemen ta t ion .   To   d is t ingu ish   th is   new   ex tended   query   language   from
tha t  of  Ir is  we  dec ided   to  change   the  name   to  AMOSQL .

3 .7 The  AMOS  Data  Mode l  and  AMOSQL

The  AMOS  da ta  mode l  ex tends  tha t  of  Ir is  by  in troduc ing  ru les  ( ﬁg .  3 .6) .  Ru les
are   a lso   ob jec ts   [30]   and   of   the   type   ‘ru le ’ .   AMOS   is   a lso   based   on   the
func-
t iona l  da ta  mode l  of  Dap lex  [108]  and  the  ac t ive  ru les  of  AMOS  are  based  on  a
func t iona l  mode l .  Ru les  mon i tor  changes   to   func t ions  and  changes   to   func t ions
can   tr igger   ru les .   A l l   the   even ts   tha t   the   ru les   can   tr igger   on   are   mode l led   as
changes  to  va lues  of  func t ions .  Th is  g ives  us  the  power  of  AMOSQL  func t iona l
express ions  as  our  even t  mode l l ing  language .  Func t ions  are  seen  as  hav ing  pas-
s ive   (synchronous)   or   ac t ive   (asynchronous)   behav iour   depend ing   on   whe ther
they   are   used   in   a   query   or   in   a   ru le   cond i t ion .   Pass ive   func t ions   d isp lay   syn-
chronous  po l l ing  behav iour,   i .e .  query   answer ing  behav iour,  wh i le   ac t ive   func-
t ions  d isp lay  asynchronous   in terrup t  behav iour,   i .e .  even t   s igna l l ing  behav iour.
Th is   is   s im i lar   to   the   idea   of ﬂuen ts
[104]   as   func t ions   for   mode l l ing   dynam ic
behav iour.   Pure ly   pass ive   func t ions   are   func t ions   tha t   never   change   the ir
ex ten t ,   such   as   bu i l t- in   ar i thme t ic   func t ions ,   e .g . +, -, *, and /,   boo lean   func-
t ions ,   e .g . = , <  and >,   and   aggrega te   func t ions   such   as sum  and count.   Func-
t ions  tha t  are  de ﬁned  in  terms  of  these  func t ions  can  have  the ir  va lues  changed ,
bu t  never  the  pure ly  pass ive  func t ions  themse lves .1Fore ign  func t ions  wr i t ten  in
some   procedura l   language   were   in i t ia l ly   a lso   cons idered   to   be   pure ly   pass ive
func t ions ,   bu t   th is   was   la ter   changed   w i th   the   in troduc t ion   of fore ign   da ta

1 .  I t  wou ld  be  s trange   to  mon i tor  changes   to plus ,  e .g .   if 1+1  were   to  become 3 .

41

rules

operate
on

participate
in

deﬁned
with

objects

constrain

trigger

monitor

participate
operate
in
on

classify

belong
to

functions

constrain
deﬁned with

types

F igure  3 .6: The  AMOS  da ta  mode l

sources  (see  chap ter  9) .
The   ﬁrs t  vers ion  of  the  ru le  sys tem  (us ing  CA-ru les)  d id  no t  have  any  pure ly
ac t ive   func t ions ,   bu t   these  wou ld   have   been even t   func t ions ,   i .e .   func t ions   tha t
represen t   in terna l   or   fore ign   even ts .   In   some   cases   i t   is   des irab le   to   d irec t ly
refer   to   spec i ﬁc   even ts   such   as   added   or   removed ;   these   can   be   mode l led   as
spec i ﬁc  even t   func t ions   tha t  change   if   tup les  are  added /removed   to /from  a   spe-
c i ﬁc   func t ion .   Th is   was   la ter   imp lemen ted   in   a   ru le   sys tem   suppor t ing   ECA-
ru les   (as   we l l   as   CA   and   EA-ru les)   where   changes   to   s tored   func t ions   are
de ﬁned   through   three   even t   func t ions   for   added ,   removed ,   and   upda ted   tup les .
Even t   func t ions   tha t   represen t   ex terna l   changes   are   ac t ive   fore ign   func t ions   or
fore ign   da ta   sources   and   can   be   func t ions   represen t ing   sensors   in   a  CIM   app l i-
ca t ion  or   the  s ta tus  of  ne twork  e lemen ts   in  an  ATM  ne twork  (see  chap ter  9) .
The   CA-ru les   presen ted   here   have   cond i t ions   tha t   reference   s tored   and
der ived  func t ions  on ly.  The  even ts  tha t  tr igger  these  cond i t ions  are  the  func t ion
upda te   even ts ,   or   even ts   from   add ing   or   remov ing   tup les   to /from   func t ions .
S tored  and  der ived  func t ions  can  be  seen  as  hav ing  ac t ive  behav iour   if   they  are
referenced   in   even t   express ions   in   ECA   and   EA-ru les ,   or   in   even t   express ions
der ived   from   CA-ru les .   Func t ions   can   be   seen   as   hav ing   pass ive   behav iour   if
referenced   ins ide   quer ies .   On ly   func t ions   w i thou t   s ide-effec ts ,   i .e .   no   s tored
procedures ,  are  a l lowed   in  ru le  cond i t ions .
The   ru le  processor   ca lcu la tes   a l l   the   even ts   tha t   can   affec t   a  CA-ru le   cond i-
t ion .   Th is   is   the   defau l t   for   ru le   cond i t ion   spec i ﬁca t ions   and   can   be   seen   as   a
sa fe   way   to   avo id   users   forge t t ing   to   spec ify   re levan t   even ts ,   as   can   happen
w i th   trad i t iona l   ECA-ru les .   ECA-ru les   are   some t imes   needed   if   the   user,   for

42

Active Database Management Systems

some   reason ,   wan ts   the   ru le   to   d isregard   some   even ts   tha t   wou ld   be   au toma t i-
ca l ly   mon i tored   by   a   CA-ru le   (such   as   upda tes   tha t   are   a l lowed   to   v io la te   the
cond i t ion   of   an   in tegr i ty   ru le)   or   if   the   user   wan ts   to   mon i tor   some   even t   tha t
wou ld  be   ignored  by  a  CA-ru le  (such  as  spec i ﬁc   tempora l  order ing  of  even ts) .
By   mode l l ing   ru les   as   ob jec ts   i t   is   poss ib le   to   make   quer ies   over   ru les .
Over loaded  and  gener ic   ru les  are  a lso  a l lowed ,   i .e .   ru les   tha t  are  parame ter ized
and   can   be   ac t iva ted   for   d ifferen t   types .   However,   unknown   type   informa t ion
dur ing   ru le   comp i la t ion   w i l l   cause   la te   b ind ing ,   i .e .   run- t ime   type   check ing ,
and  w i l l  degrade  ru le  process ing  performance .
In   AMOSQL ,   OSQL   is   ex tended   w i th   ru les   hav ing   a   syn tax   conform ing   to
tha t  of  OSQL   func t ions .  AMOSQL   suppor ts   ru les  of  CA   type  where   the   cond i-
t ion   is   an   AMOSQL   query,   and   the   ac t ion   is   any   AMOSQL   procedure   s ta te-
men t ,   excep t commit .   Da ta   can   be   passed   from   the   cond i t ion   to   the   ac t ion   of
each   ru le   by   us ing   shared   query   var iab les ,   i .e .   se t-or ien ted   ac t ion   execu t ion
[132]   is  suppor ted .
The syntax for creating and deleting CA-rules is as follows1:

create rule rule-name parameter-specification as
[ for-each-c lause]
when pred ica te-express ion
do procedure-express ion
where
for-each-clause ::=
for  each var iab le-dec lara t ion-comma l is t

delete rule rule-name

The predicate-expression can contain any boolean expression, including conjunction,
disjunction, and negation. Rules are activated and deactivated by:

activate rule rule-name ([parameter-value-commalist]) [priority 0|1|2|3|4|5]
deactivate rule rule-name ([parameter-value-commalist])

Ru les   can  be   ac t iva ted /deac t iva ted   for  d ifferen t   argumen t  pa t terns .  The   seman-
t ics   of   a   ru le   is   as   fo l lows :   If   an   even t   in   the   da tabase   changes   the   tru th   va lue
for   some   ins tance   of   the   cond i t ion   to true ,   the   ru le   is   marked   as tr iggered   for
tha t   ru le   ac t iva t ion .   If   some th ing   happens   la ter   in   the   transac t ion  wh ich   causes
the   cond i t ion   to   become   fa lse   aga in ,   the   ru le   is   no   longer   tr iggered .   Th is
ensures   tha t   we   on ly   reac t   to log ica l   even ts .   The   tru th   va lue   of   a   cond i t ion   is
here   represen ted  by true   for  a  non-emp ty   resu l t  of   the  query   tha t   represen ts   the
cond i t ion  and fa lse  for  an  emp ty  answer.
When  the  cond i t ion  of  a  tr iggered  ru le  ac t iva t ion  is  eva lua ted ,  i t  is  execu ted
separa te ly   w i th   i ts   ac tua l   parame ter   va lues .   Af ter   the   eva lua t ion   of   the   cond i-
t ion   the   va lues   of   any   shared   var iab les   be tween   the   cond i t ion   and   ac t ion   are

1 .  No te   tha t   the  syn tax  d iffers  s l igh t ly  from   tha t   in   the  pub l ished  papers .

43

saved   in  an ac t ion-se t  for  each  ru le  ac t iva t ion .
In   the  curren t   imp lemen ta t ion  a  s imp le con ﬂ ic t-r eso lu t ion  me thod ,  based  on
pr ior i t ies ,   is   used   to   spec ify   the   order   of   ac t ion   execu t ion   of   ru le   ac t iva t ions
tha t   are   s imu l taneous ly   tr iggered .   Ru le   ac t iva t ions   w i th   correspond ing   ac t ion-
se ts   are   s tored   as schedu led   ru le   ac t iva t ions   in   a   pr ior i ty   queue   based   on   the
pr ior i ty   of   the   ru le   ac t iva t ion .   The   schedu led   ru le   ac t iva t ions   are   then   fe tched
in   pr ior i ty   order   and   each   ac t ion   is   eva lua ted   us ing   the   correspond ing   ac t ion-
se t .   Any   dup l ica tes   are   removed   from   the   ac t ion-se t   to   g ive   true   se t-or ien ted
ru le  execu t ion .
Some  examp les  of  AMOSQL  ru les  are  g iven  be low.

A   c lass ic   examp le   for   ac t ive   da tabases   is   tha t   of   mon i tor ing   the   quan t i ty   of
i tems   in   an   inven tory.   When   the   quan t i ty   of   an   i tem   drops   be low   a   cer ta in
thresho ld ,  new   i tems  are   to  be  au toma t ica l ly  ordered .

create type item;
create type supplier;
create function quantity(item) -> integer;
create function max_stock(item) -> integer;
create function min_stock(item) -> integer;
create function consume_frequency(item) -> integer;
create function supplies(supplier) -> item;
create function delivery_time(item, supplier)
-> integer;
create function threshold(item i) -> integer as
select consume_frequency(i) * delivery_time(i, s)
+ min_stock(i)
for each supplier s where supplies(s) = i;

create rule monitor_item(item i) as
when quantity(i) < threshold(i)
do order(i, max_stock(i) - quantity(i));1
Th is   ru le  mon i tors   the   quan t i ty   of   an   i tem   in   s tock   and   orders   new   i tems  when
the  quan t i ty  drops  be low  the  thresho ld  ( ﬁg .  3 .7)  wh ich  cons iders  the  t ime  to  ge t
new   i tems   de l ivered   (where order  is   some   procedure   tha t   does   the   ac tua l
order ing) .   The   consume-frequency   de ﬁnes   how   many   ins tances   of   a   spec i ﬁc
i tem  are  consumed  on  average  per  day.
For   examp le ,   the   fo l low ing  de ﬁn i t ions   ensure   tha t   the  quan t i ty  of   shoe laces
in  the  inven tory  is  a lways  kep t  be tween  100  and  10  000  ( if  the  supp l ier  de l ivers
on   t ime)  and  w i l l   tr igger   the  ru le   if   the  quan t i ty  drops  be low  140 .

create item instances :shoelaces;
set max_stock(:shoelaces) = 10000;
set min_stock(:shoelaces) = 100;

1 .  In  AMOSQL select  and call  are  syn tac t ic  sugar  and  are  op t iona l  on  the  top- leve l .

44

Active Database Management Systems

quantity

max_stock

threshold

min_stock

F igure  3 .7: Mon i tor ing   i tems   in  an   inven tory

set consume_frequency(:shoelaces) = 20;
create supplier instances :shoestring_inc;
set supplies(:shoestring_inc) = :shoelaces;
set delivery_time(:shoelaces, :shoestring_inc) = 2;
activate rule monitor_item(:shoelaces);

A  ru le   tha t  mon i tors  a l l   i tems  can  be  de ﬁned  as :

create rule monitor_items() as
for each item i
when quantity(i) < threshold(i)
do order(i, max_stock(i) - quantity(i));

In  real  life  there  will  probably  be  several  suppliers  for  one  item  and  with  different
prices.  In  this  case  the  rules  should  really  consider  the  minimum  threshold,  i.e.  the
supplier who can deliver the fastest and at an acceptable cost.
Ano ther   examp le   of   ru les   in   ac t ive   da tabases   is   tha t   of cons tra in ts .   If   we
wan t   to   ensure   tha t   the quantity   of   an   i tem   can   never   exceed   the
max_stock  of   tha t   i tem ,  we  can  express   th is   in   the  fo l low ing  ru le :

create rule check_quantity() as
for each item i
when quantity(i) > max_stock(i)
do rollback;

If  this  rule  is  triggered by  too many  items being ordered,  it  is not enough  to  just  roll
back  the  transaction.  Sometimes compensa t ing   transac t ions   are  needed  that  undo
some  external  operation  such  as  undoing  an  order  for  too  many  items  by  returning
excess  items  to  the supplier. See section 5.5 for further discussion about compensat-
ing transactions.
The   prev ious   ru les   d id   no t   rea l ly   use   any   of   the   OO   capab i l i t ies   of
AMOSQL ,   i .e .   there  was   on ly   a   ﬂa t   se t   of   user -de ﬁned   types .   T o   i l lus tra te  OO
capab i l i t ies ,   take   as   an   examp le   a   ru le   tha t   ensures   tha t   no   one   a t   a   spec i ﬁc

            

45

depar tmen t  has   a  h igher   sa lary   than  h is /her  manager.  Emp loyees   are  de ﬁned   as
hav ing   a   name ,   an   income ,   and   a   depar tmen t .   The   ne t   income   is   de ﬁned   based
on   25%   tax   for   bo th   emp loyees   and   managers ,   bu t   w i th   a   bonus   of   100   before
tax   for   managers .   Depar tmen ts   are   de ﬁned   as   hav ing   a   name   and   a   manager .
The   manager   of   an   emp loyee   is   der ived   by   ﬁnd ing   the   manager   of   the   depar t-
men t   to  wh ich   the   emp loyee   is   assoc ia ted .  The   ru le no_high   is   de ﬁned   to   se t
the  income  of  an  emp loyee  to  tha t  of  h is /her  manager  if  he /she  has  a  ne t  income
grea ter   than  h is /her  manager.  The  AMOSQL  schema   is  de ﬁned  by :

create type department properties (name1 charstring);
create type employee properties
(name charstring, income number, dept department);
create type manager subtype of employee;
create function grossincome(employee e) -> number as
select income(e);
create function grossincome(manager m) -> number as
select income(m) + 100;
create function netincome(employee e) -> number as
select employee.grossincome->number(e) * 0.75;
create function netincome(manager m) -> number as
select grossincome(m) * 0.75;
create function mgr(department) -> manager;
create function mgr(employee e) -> manager as
select mgr(dept(e));

create rule no_high(department d) as
for each employee e
when dept(e) = d and
employee.netincome->number(e) >
netincome(mgr(e))
do set employee.grossincome->number(e) =
grossincome(mgr(e));

Note  that  the  functions grossincome, netincome,  and mgr  are  overloaded  on
the types employee, manager, and department, employee. For the function
calls grossincome(m), grossincome(mgr(e)), netincome(mgr(e)),
mgr(dept(e)),  and mgr(e)  this  is  resolved  at  compile  time; we  call  this ear ly
b ind ing . This is possible since the actual parameters in the calls are of distinct types.
In  cases  when  the  compiler  cannot  deduce  what  function  to  choose,  the  complete
function  signature,  e.g. employee.netincome>number(e),  can  be  specified
to aid  the compiler  to choose  the correct function at compile  time. In  the rule condi-
tion, employee.netincome->number  can be  called  for  all  employees,  includ-
ing managers, since managers are employees as well. If e is a manager, the rule will
check if the manager makes more than his/her manager; if there is no manager above
him/her, the condition will be considered false since the answer to the query mgr(e)

1 .  Th is   is  shor thand  for  de ﬁn ing  a  s tored  func t ion , name ,  on  depar tmen ts .

46

Active Database Management Systems

will be empty.
In   cases   when   the   comp i ler   canno t   deduce   wha t   func t ion   to   choose ,   i t   w i l l
produce   a   query   p lan   tha t   does   run- t ime   type   check ing   to   choose   the   correc t
func t ion ;   we   ca l l   th is la te   b ind ing .   Look   a t   the   fo l low ing   rede ﬁn i t ion   of   the
no_high ru le :

create rule no_high(department d) as
for each employee e
when dept(e) = d and
netincome(e) > netincome(mgr(e))
do set employee.grossincome->number(e) =
grossincome(mgr(e));

D ifferen t netincome  func t ions  w i l l  here  be   chosen  depend ing  on  whe ther   the
argumen t   i t   is   ca l led   w i th   is   jus t   an   emp loyee ,   or   a   manager   as   we l l .   The   ru le
cond i t ion   is   d ifferen t   than   tha t   of   the   prev ious   ru le   s ince ,   if   the employee  e
is  a  manager,  the  ne t  income  w i l l  be  ca lcu la ted  d ifferen t ly. This is because man-
ager.netincome->number would,  in  this  case,  be  chosen  in  both  instances  in
the condition. This rule is more elegant, but in order not to complicate the generated
code  and  the  discussion  of  change-monitoring  techniques  in  the  following  chapters,
the first version of no_high will be used in the continuation of the example.
No te   tha t   the employee.grossincome->number   func t ion   is   upda ta-
b le   s ince   i t   is   d irec t ly   mapped   to   the   s tored   func t ion employee.income-
>number.   The   func t ion manager.grossincome->number   is ,   however,
no t   d irec t ly   upda tab le   s ince   i t   canno t   be   d irec t ly   mapped   to   a   s tored   func t ion .
Th is   is  descr ibed   in  more  de ta i l   in  [82] .
The no_high   ru le   w i l l   be   ac t iva ted   for   a   spec i ﬁc   depar tmen t   and   w i l l
serve  as  an  examp le   in   the  res t  of   the  sec t ion .

Le t  us  de ﬁne  a   toys  depar tmen t  w i th  a  manager  and   ﬁve  emp loyees :

create department(name) instances
:toys_department("Toys")1;
create manager(name, dept, income) instances
:boss("boss", :toys_department, 10400);
set mgr(:toys_department) = :boss;
create employee(name,dept,income) instances
:e1("employee1",:toys_department,10100),
:e2("employee2",:toys_department,10200),
:e3("employee3",:toys_department,10300),
:e4("employee4",:toys_department,10400),
:e5("employee5",:toys_department,10500);

The  emp loyees  w i th   the ir   incomes  and  ne t incomes  can  be  seen   in   ﬁg .  3 .8 .
Now,   if   we   ac t iva te   the   ru le   for   the   toys   depar tmen t   and   try   to   comm i t   the
transac t ion ,   a   check   is   made   as   to   whe ther   any   of   the   emp loyees   have   a   ne t

1 .  Th is   is  a  shor t-hand  for  se t t ing   the  func t ion name ,  for  a  depar tmen t   ins tance .

income  h igher  than  the ir  manager.  No  such  emp loyees  ex is t  and  thus  the  ru le  is
no t   tr iggered .

.

47

name

income

netincome

boss

employee1

employee2

employee3

employee4

employee5

10400

10100

10200

10300

10400

10500

7875

7575

7650

7725

7800

7875

F igure  3 .8: In i t ia l  emp loyee  sa lar ies

activate rule no_high(:toys_department);
commit; /* check and commit */

Now   if  we  change   the   income  of  emp loyee2  and  emp loyee4 :

set income(:e2) = 10600;
set income(:e4) = 10600;

we   can   see   in   ﬁg .  3 .9   tha t   the  ne t incomes  of   emp loyee2   and   emp loyee4   exceed
tha t  of   the ir  manager.

name

income

netincome

boss

employee1

employee2

employee3

employee4

employee5

10400

10100

10600

10300

10600

10500

7875

7575

7950

7725

7950

7875

F igure  3 .9: Emp loyee  sa lar ies  before  comm i t

48

Active Database Management Systems

If   we   try   to   comm i t   th is   transac t ion ,   the no_high   ru le   w i l l   be   tr iggered   and
the   sa lar ies   of   emp loyee2   and   emp loyee4   w i l l   be   se t   to   tha t   of   the ir   manager.
Th is  can  be  seen   in   ﬁg .  3 .10 .

commit; /* check and commit */

name

income

netincome

boss

employee1

employee2

employee3

employee4

employee5

10400

10100

10500

10300

10500

10500

7875

7575

7875

7725

7875

7875

F igure  3 .10: Emp loyee  sa lar ies  af ter  comm i t

In this example, the rule condition monitoring consists of determining changes to the
condition  of  the no_high  rule.  Changes  to  several  stored  functions  (i.e. dept,
income, and mgr) can affect  the  rule condition.  In  the example, only  two updates
are made  to  the income  function.  The  rule-condition monitoring must  be  efficient
even if the number of employees is very large. However, evaluating the condition of
no_high naively (i.e. evaluating the whole query of the rule condition) would result
in checking the income of all employees for the department. Efficient techniques for
evaluating rule conditions based on changes that result from small updates, such as in
these previous examples, are discussed in chapter 6.
No te  tha t  the  ru les  can  a lso  be  invoked  exp l ic i t ly  a t  any  t ime  dur ing  a  trans-
ac t ion  by  ca l l ing   the  check  procedure :

check();

Ru les   can   a lso   be   grouped   in to   ru le   con tex ts   tha t   can   be   passed   as   argumen t   to
the  check  procedure  (see  Paper  IV  and  sec t ion 7 .8) .

3 .8 ECA-ru les

CA-ru les   do   no t   a lways   prov ide   a l l   the   con tro l   over   the   ru les   and   the ir   behav-

49

iour   tha t   is   some t imes   needed .   A   CA-ru le   can   be   trans la ted   to   an   ECA-ru le
where   the   even t   par t   is   a   d is junc t ion   of   a l l   the   even ts   tha t   can   affec t   the   cond i-
t ion .   In   some   s i tua t ions   i t   is   des irab le   to   separa te   th is   ru le   in to   severa l   ECA-
ru les   tha t   perform   d ifferen t   ac t ions   depend ing   on   wh ich   even t   tr iggered   the
ru les .   An   ECA-ru le   can   be   wr i t ten   to   d isregard   even ts   tha t   a   CA-ru le   wou ld
mon i tor  and   to  mon i tor  even ts   tha t  a  CA-ru le  wou ld   ignore .

3 .9 ECA-ru les   in  AMOS

The   imp lemen ta t ion   of   the   ru le   sys tem   in  AMOS   has   con t inued  w i th   the   in tro-
duc t ion  of  exp l ic i t  even ts  and  ECA-ru les  [86] .  The  syn tax  for  the  ru les  has  now
changed   to :

create  ru le ru le-name  parame ter-spec i ﬁca t ion
[ for-each-c lause]
[on even t- type-spec i ﬁca t ion ]
[when pred ica te-express ion]
do procedure-express ion
de lete  ru le ru le-name

where

for-each-c lause   : :=
for each var iab le-dec lara t ion-comma l is t

Th is   a l lows   for   wr i t ing   ECA-ru les ,   CA-ru les ,   and   EA-ru les .   The   ma in   d iffer-
ence   from   the  CA-ru le   syn tax   is   the   exp l ic i t   even t   spec i ﬁca t ion .  The   even t ,   the
cond i t ion ,   and   the   ac t ion   par t   can   a l l   share   the   same   var iab les   to   a l low   da ta   to
be   passed   be tween   the   par ts   of   the   ru le   dur ing   ru le   execu t ion .   The   even ts   tha t
can  be  spec i ﬁed   inc lude :

even t- type-spec i ﬁca t ion   : :=
added( func t ion-ca l l)   |
removed( func t ion-ca l l)   |
updated( func t ion-ca l l)   |
created(var iab le-name)   |
de leted(var iab le-name)1  |
fore ign-even t-name   |
even t- type-spec i ﬁca t ion and even t- type-spec i ﬁca t ion   |
even t- type-spec i ﬁca t ion or even t- type-spec i ﬁca t ion |
even t- type-spec i ﬁca t ion before  even t- type-spec i ﬁca t ion |
even t- type-spec i ﬁca t ion after even t- type-spec i ﬁca t ion

1 .  Ac tua l ly  no t  ye t   imp lemen ted  due   to   techn ica l  prob lems   in  AMOS  on  how   to  refer-
ence  ob jec ts   tha t  have  been  marked  as  de le ted .  Here   the  mark ing  of  de le ted  ob jec ts
can  be  de layed  or  an  immed ia te  coup l ing  mode  w i th  check ing  before  opera t ions  take
effec t   is  needed .

50

Active Database Management Systems

The   added ,   removed ,   and   upda ted   even t   types   mon i tor   changes   to   s tored   and
der ived  func t ions .  The  crea ted  and  de le ted  even t  types  mon i tor  the  crea t ion  and
de le t ion  of  ob jec t   ins tances  of  some  cer ta in  ob jec t   type .
The  seman t ics  for  ECA  and  EA-ru les  is :  If  enough  even ts  occur  to  make  the
even t  spec i ﬁca t ion  of  an  ac t iva ted  ru le  true ,  then  the  ru le  is  marked  as  tr iggered
for   th is  ru le  ac t iva t ion .  Any  even t  da ta ,   i .e .  shared  var iab les  be tween  even t  and
cond i t ion ,  ac t ion  par ts ,   is  saved .   If   the   ru le  has  a  cond i t ion ,   i t   is  eva lua ted  w i th
the   even t   da ta .   The   da ta   shared   be tween   the   ac t ion   and   bo th   the   even t   and   the
cond i t ion   is   then   saved   as   the   ac t ion-se t   for   each   ru le   ac t iva t ion .   Any   dup l i-
ca tes  in  even t  da ta  are  removed  to  avo id  mu l t ip le  tr igger ing  on  the  same  even ts .
Any   dup l ica tes   are   removed   from   the   ac t ion-se t   to   g ive   true   se t-or ien ted   ru le
execu t ion .  Ac t ion  execu t ion   is   then  schedu led  as  was  de ﬁned  for  CA-ru les .

Take   the  ru le :

create rule eca_no_high(department d) as
for each employee e, manager m
on updated(income(e)) or updated(income(m)) or
updated(dept(e)) or updated(mgr(e))
when dept(e) = d and
m = mgr(e) and
employee.netincome->number(e) > netincome(m)
do set employee.grossincome->number(e) =
grossincome(m);

Th is  ru le  has  iden t ica l  behav iour  to  the  CA-ru le no_high.  I t  is ,  however,  more
cumbersome  to  wr i te .  When  a  CA-ru le  is  comp i led ,  the  ru le  comp i ler  w i l l  au to-
ma t ica l ly   deduce   a l l   invo lved   even ts   and   assume   an   imp l ic i t   d is junc t ion
be tween   them .   If   we   wan ted   to   de ﬁne   a   ru le   tha t   on ly   tr iggers   when   an
emp loyee  ge ts  a  sa lary  ra ise  and  ignore  a l l  o ther  even ts  (such  as  if  an  emp loyee
changes  depar tmen t  or  manager) ,  we  can  wr i te :

create rule no_raise(department d) as
for each employee e, manager m
on updated(income(e))
when dept(e) = d and
m = mgr(e) and
employee.netincome->number(e) > netincome(m)
do set employee.grossincome->number(e) =
grossincome(m);

Th is   ru le   is   imposs ib le   to   wr i te   as   a   CA-ru le   and   shows   the   need   for   hav ing
ECA-ru les   as   we l l .   Mos t   ADBMSs   w i th   ECA-ru les   on ly   suppor t   spec ify ing
even ts   re la t ing   to   tab les   (s tored   func t ions   in  AMOSQL)  and  no t  even ts   re la t ing
to   v iews   (der ived   func t ions   in   AMOSQL) .   In   AMOS   i t   is   poss ib le   to   spec ify
even ts   re la t ing   to   der ived   func t ions   as  we l l   [86] .  The no_raise  ru le   cou ld   be
wr i t ten  as :

51

create rule no_raise(department d) as
for each employee e, manager m
on updated(employee.netincome->number(e))
when dept(e) = d and
m = mgr(e) and
employee.netincome->number(e) > netincome(m)
do set employee.grossincome->number(e) =
grossincome(m);

Th is   makes   the   ECA-ru les   more   conven ien t   to   wr i te   s ince   we   do   no t   have   to
know  wha t  s tored   func t ions  affec t  a  der ived   func t ion .  ECA-ru les   in  AMOS  can
a lso  spec ify  con junc t ive  even ts  such  as   in   the  ru le :

create rule check_new(department d) as
for each employee e, manager m
on updated(dept(e)) and
updated(employee.netincome->number(e))
when dept(e) = d and
m = mgr(e) and
employee.netincome->number(e) > netincome(m)
do rollback;

Th is   ru le   spec i ﬁes   tha t   new   emp loyees   a t   a   cer ta in   depar tmen t   are   no t   a l lowed
to   be   g iven   an   immed ia te   income   tha t   is   h igher   than   the  manager ;   if   th is   is   the
case ,   then   the   transac t ion   is  cons idered  fau l ty  and   is  ro l led  back .
I t   is  poss ib le   to  spec ify   the  even t  of  crea t ing  an  ob jec t  as  we l l :

create rule check_new(department d) as
for each employee e, manager m
on created(e) and
updated(employee.netincome->number(e))
when dept(e) = d and
m = mgr(e) and
employee.netincome->number(e) > netincome(m)
do rollback;

Th is   ru le   spec i ﬁes   tha t  new   emp loyees   a t   the   company ,   i .e .   emp loyees  who  d id
no t  prev ious ly  ex is t  in  the  company  da tabase ,  are  no t  a l lowed  to  be  g iven  a  sa l-
ary  h igher   than   the ir  manager.
Examp les  of  AMOSQL  ru les  for  the  app l ica t ions  s tud ied  in  chap ter  2  can  be
found   in   chap ter   5 .  Ef ﬁc iency   issues   of   ac t ive   ru les   are   d iscussed   in   chap ter   6 .
Imp lemen ta t ion  de ta i ls  on   the  ac t ive  ru les  are  d iscussed   in  chap ter  7 .

52

Active Database Management Systems

53

4

He terogeneous  Da ta
Managemen t

4 .1 DBMSs   in  Networks

In   bo th   CIM   and   te lecommun ica t ion   ne tworks   (as   presen ted   in   chap ter   2)   the
DBMSs  w i l l  be  connec ted  in  ne tworks .  The  ne tworks  w i l l  mos t  l ike ly  be he ter-
ogeneous ,   i .e .   the  nodes   in   the  ne tworks  w i l l  perform  d ifferen t   func t ions   in   the
sys tem   and   w i l l   probab ly   con ta in   d ifferen t   p ieces   of   sof tware   and   some t imes
have   d ifferen t   hardware .   The   da tabases   in   the   ne twork   w i l l   re ﬂec t   th is   he tero-
gene i ty   by   s tor ing   d ifferen t   da ta   in   d ifferen t   nodes ,   e .g .   da ta   tha t   is   needed
loca l ly   by   the   func t ions   prov ided   by   a   par t icu lar   node .   Some t imes   the   nodes
w i l l  con ta in  d ifferen t  DBMS  produc ts  w i th  d ifferen t  s torage  s truc tures .  To  sup-
por t   access   of   severa l   nodes   in   the   same   quer ies   there   is   a   need   for   a   he teroge-
neous  da tabase   layer   tha t  can   in terac t  w i th   the  d ifferen t  he terogeneous  nodes .

4 .2 D istr ibuted  v.s .  Mu lt idatabases  Database  Systems

In d is tr ibu ted  da tabase   sys tems [94]   the  goa l   is   to   show   a  g loba l   schema   to   the
user   to   g ive   the   i l lus ion   of   a   s ing le   da tabase   sys tem .   Th is   causes   much   over-
head   dur ing   da tabase   opera t ions   to   keep   a l l   the   da tabases   in   cons is ten t   s ta tes .
Quer ies  tha t  reference  d is tr ibu ted  da ta  need  to  be  op t im ized  to  m in im ize  a  to ta l
cos t  wh ich   inc ludes  access ing  remo te  da ta  over  a  ne twork .
In mu l t ida tabase  sys tems [19][69]   the  goa l  of  prov id ing  a  g loba l  d is tr ibu ted
v iew  has  been  re laxed  and   the  user   is  a l lowed   to  reference   the   ind iv idua l  nodes
in   the   sys tem   d irec t ly.   Th is   s imp l i ﬁes   the   imp lemen ta t ion   and   prov ides   more
au tonomy   to   each   node   wh i le   a t   the   same   t ime   forc ing   the   user   to   make   sure
tha t   the   nodes   are   kep t   cons is ten t .   Mu l t ida tabases   are   of ten   used   as   p la tforms
for   connec t ing   he terogeneous   da tabases   (wh ich   cou ld   be   e i ther   s ing le   node   or
d is tr ibu ted   da tabases) .   In   some   cases   a   g loba l   schema   can   be   sp l i t   in to   severa l
sub-schemas   tha t   each   represen ts   da ta   tha t   is   s tored   on   a   subse t   of   the   nodes .
Then   the  mu l t ida tabase  can  suppor t  ma in tenance  of  each  sub-schema .  The  sub-
schemas   can   some t imes   over lap ,   i .e .   nodes   can   have   d ifferen t   da ta   in   d ifferen t
sub-schemas .   Mu l t ida tabases   usua l ly   prov ide   op t im iza t ion   of   mu l t ida tabase
quer ies   wh ich   may   invo lve   trans la t ing   da ta   from   d ifferen t   forma ts   in to   some
s tandard   forma t  prov ided  by   the  mu l t ida tabase   (as  we l l  as  cons ider ing  commu-
n ica t ion  cos ts) .  Of ten  he terogeneous  ne tworks  are  h ierarch ica l   (such  as   in   te le-

54

Heterogeneous Data Management

commun ica t ion  ne tworks) .  The   sub-schemas   can   then   re ﬂec t  d if feren t   leve ls   in
the  ne twork  h ierarchy.
In   a med ia tor   arch i tec ture   [131]   such   as  AMOS   a  mu l t ida tabase   is   used   for
in tegra t ing   var ious   da ta   sources   w i th   non-conform ing   da ta   forma ts   wh ich   are
in tegra ted  for  access   through   the  mu l t ida tabase .

4 .3 About  Paper  III

Paper  III  presen ts  an  overv iew  of  the  AMOS  mu l t ida tabase  arch i tec ture .  Th is  is
an   ear ly   paper   tha t   in troduces   the   AMOS   med ia tor   arch i tec ture .   More   work
done   on   the   AMOS   med ia tor   and   mu l t ida tabase   func t iona l i ty   is   descr ibed   in
[42][130] .

4 .4 Act ive  Mu lt idatabase  Systems

Ac t ive   DBMSs   in   ne tworks   is   no th ing   new,   bu t   mos t   such   sys tems   (such   as
AMOS)  do  no t  suppor t  ac t ive  ru les  tha t  span  over  severa l  da tabases .  One  ma jor
prob lem   tha t  has   to  be   reso lved   is  how   to  genera te  and  mon i tor  even ts  be tween
severa l   da tabases .   A   ma jor   prob lem   is   how   to   compare   even ts   or ig ina t ing   in
d ifferen t  nodes  (such  as  wh ich  even t  occurred  before  ano ther)  and  how  to  com-
b ine  these  even ts  in to  comp lex  even ts .  Some  research  on  th is  top ic  is  presen ted
in  [106] .
Ano ther   prob lem   in   ac t ive   mu l t ida tabase   (or   d is tr ibu ted)   sys tems   is   tha t   i t
can   be   expens ive   to   sh ip   even ts   over   the   ne twork   when   the   ru les   tha t   mon i tor
the   even ts   are   no t   execu ted   by   the   same   DBMS   as   where   the   even ts   or ig ina te .
One   techn ique   tha t   can  be  used   is   to  have   the   ru le   comp i ler   sp l i t  mu l t ida tabase
ru les  ( i .e .  ru les  tha t  have  even t  express ions  or  cond i t ions  tha t  reference  changes
to   da ta   s tored   in   o ther   da tabases)   in to   severa l   ru les   tha t   are   sh ipped   and
inser ted   in to   the   da tabases   where   the   d ifferen t   even ts   or ig ina te .   The   or ig ina l
ru le  mus t   then   be   de ﬁned   to   co l lec t   the   resu l ts   from   a l l   the   d is tr ibu ted   ru les   to
ﬁna l ly   de term ine   if   the  mu l t ida tabase-ru le   has   been   tr iggered   and   if   the   cond i-
t ion   is   true .
Ac t ive   mu l t ida tabases   can   be   used   for   add ing   cons tra in ts   to   da ta   s tored   in
severa l   he terogeneous   da tabase   sys tems .   In   [27]   a   too lk i t   for   cons tra in t   man-
agemen t   in   a  he terogeneous   informa t ion   sys tem   is  presen ted . In [119] a descrip-
tion of some work can be found on the specification of a language for achieving rule-
based interoperabillity among heterogeneous systems. In [137] work can be found on
maintaining  consistency  of  an  integrated  view  of  information  from  various  distrib-
uted data sources.

4 .5 Heterogeneous  Databases   in  CIM

In  CIM  app l ica t ions   there  are  many  sources  of   informa t ion   tha t  are  no t  d irec t ly
invo lved   in   the   manufac tur ing   process ,   bu t   wh ich   are   s t i l l   des irab le   to   be   ab le

55

to   access   from   the   CIM   sys tem .   Th is   can   be   informa t ion   such   as   produc t   da ta
(e .g .  wha t   sub-par ts   a  manufac tured   i tem   cons is ts  of) ,   inven tory  da ta   (e .g .  how
many   sub-par ts   are   ava i lab le   in   s tock) ,   econom ic   da ta   (e .g .   pro ﬁ t   mar g ins   in
terms   of   how   much   each   produced   i tem   shou ld   cos t   based   on   the   sum   of   the
cos ts   of   the   sub-par ts   and   the   cos t   of  manufac tur ing) ,   and   sa les   da ta   (e .g .   how
many   i tems  shou ld  be  produced) .
For   a   CIM   sys tem   to   be   ab le   to   access   he terogeneous   da ta   a   med ia t ing
DBMS  such  as  AMOS  can  prov ide  un iform  access  to  a l l  da ta  ( ﬁg .  4 .1) .  A  med i-
a t ing  ADBMS  can  a lso  suppor t  mon i tor ing  changes   to  he terogeneous  da ta  such
as   mon i tor ing   the   number   of   par ts   in   s tore   and   to   order   more   when   the   s tock
runs   low.

Product
Information
System
Database

Inventory
Information
System

Database

CIM System
(Process Control)

Mediating
ADBMS

Economic
Information
System

Database

Sales
Information
System

Database

F igure  4 .1: A  med ia t ing  ADBMS   in  CIM  for  access ing  he terogeneous  da ta

Mon i tor ing   of   he terogeneous   da tabases   usua l ly   requ ires   some   mon i tor ing   sup-
por t   from   each   invo lved   DBMS .   If   ECA-ru les   or   tr iggers   are   suppor ted ,   these
can   be   genera ted   by   the  med ia t ing  ADBMS   and   be   comp i led   in to   the   invo lved
da tabases  (see  sec t ion  9 .5 .8) .

4 .6 Heterogeneous  Databases   in  Te lecommun icat ion  Net-
works

In  te lecommun ica t ion  ne tworks  there  w i l l  be  a  need  to  in tegra te  d ifferen t  he ter-
ogeneous   da tabases   such   as  DBMSs   be long ing   to   severa l   par ts   of   the   ne twork ,

56

Heterogeneous Data Management

e .g .  DBMSs  in  loca l  ne tworks  and  in  pub l ic  ne tworks  opera ted  by  d ifferen t  ne t-
work  prov iders .
D ifferen t  k inds  of  he terogene i ty  can  be  de ﬁned  on   the  bas is  of   loca t ion ,   i .e .
where   the   informa t ion   is   s tored   geograph ica l ly,   and   on   the   bas is   of   func t iona l-
i ty,   i .e .   wha t   func t ions   in   the   ne twork   h ierarchy   are   us ing   the   da ta   ( ﬁg .   4 .2) .
The   h igher   up   in   the   h ierarch ica l   d is tr ibu t ion ,   the  more   the   access   s ideways   in
the   geograph ic   d is tr ibu t ion   is   u t i l ized .   In   ne twork   traf ﬁc   con tro l   there   is   l i t t le
exchange  of  da ta  be tween  da tabases ,  usua l ly  on ly  the  da ta  needed  for  se t t ing  up
connec t ions .  In  sec t iona l  and  reg iona l  ne twork  managemen t  there  can  be  a  con-
s iderab le   exchange   of   da ta ,   e .g .   pass ing   of   b i l l ing   da ta   be tween   d ifferen t   par ts
of   the  ne twork  or  ne twork  prov iders .
The   DBMSs   used   in   ne twork   con tro l   m igh t   be   d is tr ibu ted   to   ach ieve   h igh-
performance   transac t ion   process ing   and   to   prov ide   re l iab i l i ty   a t   hardware   fa i l-
ures   [122] .   The   ne twork   managemen t   w i l l   co l lec t   da ta   from   the   ne twork   con-
tro l ,  such  as  bas ic  b i l l ing  da ta  based  on  used  resources .  The  da ta  w i l l  be  passed
upwards   in   the   h ierarchy   to   off- l ine   DBMSs   for   process ing   and ,   even tua l ly,
send ing   b i l ls   to   subscr ibers .   On- l ine   b i l l ing   m igh t   a lso   be   performed   where

Regional Network Management

Sectional/Primary Network Management

Network Traffic Control

Hierarchical

(Functional)

Heterogeneous

Distribution

Geographical (Locational) Heterogeneous Distribution

F igure  4 .2: He terogeneous  d imens ions   in  a  ne twork  h ierarchy

subscr ibers  are  no t i ﬁed  of   the  cos t  wh i le   they  are  u t i l iz ing  spec i ﬁc  serv ices .
No te   tha t   th is   is   on ly   a   d iscuss ion   of   da ta   passed   be tween   DBMSs   in   the
ne twork .   Traf ﬁc   da ta   (e .g .   speech   da ta)   in   the   phys ica l   ne twork   can   be   cons id-
erab le ,   bu t   th is   da ta   usua l ly   or ig ina tes   from   one   user   and   is   d irec t ly   passed   to
ano ther  user.  In  cases  where  the  da tabases  con tr ibu te  d irec t ly  to  the  traf ﬁc  da ta ,

57

such   as   da tabases   for   ne twork   app l ica t ions   tha t   send   mu l t i-med ia   da ta   to   the
ne twork   users ,   the   he terogeneous   d is tr ibu t ion   mode l   has   to   be   ex tended   to
inc lude  ne twork  app l ica t ions .
By   cons ider ing   da tabases   for   ne twork   app l ica t ions   as   we l l ,   we   can   de ﬁne
the   gener ic   term ne twork  DBMS   as   a  DBMS   tha t   can  manage   the   da tabases   for
ne twork   traf ﬁc   con tro l ,   ne twork   managemen t ,   and   ne twork   app l ica t ions   ( ﬁg .
4 .3) .   D ifferen t   ne twork   DBMSs   can   be   used   separa te ly   for   each   k ind   of   da ta-
base   or   some t imes   for   a l l   k inds   of   da tabases   a t   once .   The  mos t   l ike ly  mode l   is
tha t  severa l  ne twork  DBMSs  makes  up  a  he terogeneous  (mu l t ida tabase)  DBMS
arch i tec ture .   The   ind iv idua l   ne twork   DBMSs   are   mos t   l ike ly   (homogeneous)
d is tr ibu ted   c lus ter   DBMSs   to   prov ide   the   performance   and   h igh   re l iab i l i ty
requ ired  by   the  d ifferen t  da tabase  app l ica t ions .
The  con ﬁgura t ion  of  the  he terogeneous  ne twork  DBMS  depends  on  the  geo-
graph ica l   and   h ierarch ica l   d is tr ibu t ion   of   the   ne twork .   The   con ﬁgura t ion   of
each   ne twork   DBMS   server   (such   as   d is tr ibu t ion   topo logy,   fragmen ta t ion   and
dup l ica t ion  of  da ta)  depends  on  the  requ iremen ts  of  the  spec i ﬁc  da tabase  app l i-
ca t ions  us ing  a  spec i ﬁc  server .

Network Applications

Applications Database

Network Management

Network Management Database

Network Trafﬁc Control

Network Control Database

Network
DBMS

Distributed Servers

Hierarchical

(Functional)

Heterogeneous

Distribution

F igure  4 .3: A  ne twork  DBMS  for  manag ing  da tabases  of  ne twork  con-
tro l ,  ne twork  managemen t ,  and  ne twork  app l ica t ions

Commun ica t ion  be tween  he terogeneous  DBMSs  w i l l  be  based  on  ne twork   spe-
c i ﬁc  pro toco ls  wh i le  commun ica t ion  be tween  nodes   in   ind iv idua l  c lus ter  nodes
in   each   DBMS   server   can   be   any   h igh-speed   pro toco l   (see   sec t ion   9 .5 .3   for
more  d iscuss ion  abou t  pro toco ls) .  The  he terogeneous  ne twork  DBMS  w i l l  mos t
l ike ly   have   to   med ia te   be tween   var ious   da ta   sources ,   e .g .   when   mapp ing   da ta
from   the   phys ica l   leve l   to   a   log ica l   leve l   in   the   ne twork   h ierarchy,   in tegra t ing
da tabases   managed   by   d ifferen t   ne twork prov iders ,   or   access ing   da tabases
be long ing   to  spec i ﬁc  ne twork  app l ica t ions .

58

Heterogeneous Data Management

59

5

App ly ing  Ac t ive  Da tabase
Sys tems

5 .1 App l icat ions  and  Act ive  Database  Systems

In   the  deve lopmen t  of  new   fea tures   in  an  ac t ive  da tabase  sys tem   i t   is   impor tan t
to   have   some   po ten t ia l   app l ica t ions   tha t   requ ire   these   fea tures .   In   chap ter   2
app l ica t ion   s tud ies   of  Compu ter   In tegra ted  Manufac tur ing   (CIM)   and   te lecom-
mun ica t ions   ne tworks   were   presen ted .   These   s tud ies   were   made   to   mo t iva te
some  of   the  ac t ive  func t iona l i ty   in  AMOS .  Th is  chap ter  presen ts  some  poss ib le
scenar ios  of   in tegra t ion  be tween   the  app l ica t ions  and  ADBMS   techno logy.

5 .2 Scenar ios  for  an  ADBMSs   in  CIM  Systems

Cons ider  a  CIM  sys tem  for  process  con tro l  in  a  manufac tur ing  p lan t .  The  ac tua l
con tro l   of   the   p lan t   is   carr ied   ou t   by   a   rea l- t ime   process   con tro l   sys tem   ( ﬁg .
5 .1) .

Pressure: 301
Temp: 127

ADBMS

Process Control
System

F igure  5 .1: The  Ac t ive  DBMS  for   in tegra t ion  of  a  Process  Con tro l  Sys tem

An   ADBMS   is   used   for   s tor ing   da ta   abou t   p lan t   layou t   (equ ipmen t   such   as
manufac tur ing   mach ines   w i th   ac tua tors   and   sensors   and   the ir   con ﬁgura t ion) ,

60

Applying Active Database Systems

equ ipmen t   da ta   (mach ine   s ta tus ,   sensor   read ings) ,   par ts   da ta   (da ta   abou t   the
par ts   be ing   produced   such   as   s ize ,   we igh t ,   co lour,   pos i t ion ,   sub-par ts ,   com-
p le teness   s ta tus) ,   and   sys tem   con ﬁgura t ion   (con ﬁgura t ion   of   the   who le   CIM
sys tem) .   The   da ta   from   sensors   is   made   ava i lab le   from   the   rea l- t ime   process
con tro l  sys tem  by  e i ther  s tor ing  the  da ta  d irec t ly  in  the  ADBMS  or  by  a l low ing
the  ADBMS  access   the  da ta  as  fore ign  da ta  sources .
The   ADBMS   can   mon i tor   changes   to   sensor   da ta   through   ac t ive   ru les   by
mon i tor ing  changes  to  sensor  da ta  s tored  in  the  da tabase ,  or  by  le t t ing  the  proc-
ess   con tro l   sys tem   send   fore ign   even ts  when   a   sensor   has   changed   (every   t ime
or   when   there   is   a   s ign i ﬁcan t   change) .   The   ac t ive   ru les   can ,   for   examp le ,   be
used   for   manag ing   au toma t ic   red isp lay   func t ions   in   user   in terface   too ls   [97]
tha t   d isp lay   the   s ta tus   of   the   con tro l led   p lan t   or   for   de tec t ing   abnorma l   s i tua-
t ions  tha t  the  process  con tro l  sys tem  canno t  de tec t  (such  as  s i tua t ions  invo lv ing
severa l   loca l  con tro l   loops) .

A Scenario for Automatic Redisplay of User Interface T

ools

Let us take a scenario where an ADBMS should monitor the change of the state
of  a  control  process  to  automatically  refresh  interface  tools  that  monitor  the
process.  In  the schema below  the process state  is deﬁned as a  foreign  function
that is exported by the process control system. The process control system also
signals an update event when the state of the process changes. Note that it is up
to  the  process  control  system  to  determine  how  often  it  should  inform  the
ADBMS. It is very likely that the process state seen in the database might have
a coarser granularity than the state used in controlling the process.
Interface  tools  are deﬁned  to have  several  interfaces  that  can be  associated
with  a  certain  process  that  is  being  displayed.  The  interface management  sys-
tem  provides  the  ADBMS  with  a  function  that  can  directly  refresh  a  certain
interface.
One  active  rule  is  deﬁned  that  monitors  updates  to  the  state  of  a  certain
process and refreshes the corresponding interfaces of a given tool if the change
exceeds  some  given  threshold.  If  the  interfaces  are  refreshed,  then  the  rule
caches  the  process  state  so  that  it  can  determine  the  change  the  next  time  the
process  state  changes.  The  rule  also  automatically  refreshes  new  interfaces
associated with the monitored process and the given tool.

create type process;
create function process_state(process) -> real
as foreign;
create function cached_state(process) -> real;
create type tool;
create type interface;
create function tool_interface(tool, process) ->
bag of interface;
create function refresh(interface, real) -> boolean
as foreign;

61

create rule monitor_process(process p, real threshold,
tool t) as

for each real s
on update(process_state(p)) or added(tool_interface(t,p))
when abs(cached_state(p) - s) > threshold
and s = process_state(p)
do begin
set cached_state(p) = s;
for each interface i where i = tool_interface(t, p)
refresh(i, s);

end;

A  Scenar io  for  Mon i tor ing  In terac t ion  Be tween  Con tro l led  Processes

Ano ther   use   of   an   ADBMS   in   process   con tro l   app l ica t ions   is   for   mon i tor ing
severa l   processes   a t   once .   The   con tro l   process   sys tem   usua l ly   on ly   mon i tors
and  con tro ls  each  de ﬁned  process  separa te ly .  I t  usua l ly  has  no  way  of  de term in-
ing   in terac t ions   be tween   the   d ifferen t   processes .   A l l   such   in terac t ions   were
de ﬁned   when   the   d if feren t   processes   were   de ﬁned .   An   ADBMS   can   suppor t
add ing  new  mon i tor ing  func t iona l i ty   tha t  de tec ts   in terac t ion  be tween  processes
in   the   con tro l   sys tem .   Take   an   examp le   of   two   robo ts   tha t   can   in   rare   c ircum-
s tances   in terac t   by   en ter ing   each   o ther ’ s  work ing   areas .   Th is  wou ld   usua l ly   be
avo ided   by   the   con tro l   sys tem ,   bu t   in   case   of   sof tware   errors   i t   can   s t i l l   occur.
Two   func t ions   are   used ,   one   for   de tec t ing   wha t   is   an   i l lega l   in terac t ion   and   a
procedure  tha t  ca l ls  the  con tro l  sys tem  to  reso lve  the  con ﬂ ic t .  The  reso lve  func-
t ion  cou ld  dec ide  to  move  one  of  the  robo ts  ou t  of  the  way  or  to  emergency  s top
bo th  robo ts .

create type robot;
create function position(robot)
-> <real x, real y, real z>;
/* The current 3D-position of the robot */
create function working_area(robot)
-> <real origin, real radius>;
/* The working area of a robot defined as a sphere */
create function within(real x, real y, real z,
real origin, real radius)
-> boolean as foreign;
/* Foreign function that checks if a point is inside
a sphere */
create function illegal_interaction(robot r1,
robot r2)

-> boolean as
select within(x1, y1, z1, or2, ra2) or
within(x2, y2, z2, or1, ra1)
for each real x1,real y1,real z1,real or1,real ra1,

62

Applying Active Database Systems

real x2,real y2,real z2,real or2,real ra2
where <x1,y1,z1> = postion(r1) and
<or1, ra1> = working_area(r1) and
<x2,y2,z2> = postion(r2) and
<or2, ra2> = working_area(r2);
create function resolve_interaction(robot r1,
robot 2)
-> boolean as ...; /* Application dependent code */

create rule monitor_interaction(robot r1, robot r2) as
on update(position(r1)) or
update(position(r2))
when illegal_interaction(r1, r2)
do resolve_interaction(r1, r2);

Th is  ru le  cou ld  a lso  be  wr i t ten  more  dec lara t ive ly  as  a  CA-ru le  where   the  ru le
comp i ler  w i l l  deduce  wha t  even ts  to  mon i tor  from  the  cond i t ion .  The  fo l low ing
ru le  wou ld  mon i tor  changes  to  robo t  pos i t ions  as  we l l  as  changes  to  the  work ing
areas .

create rule monitor_interaction(robot r1, robot r2) as
when illegal_interaction(r1, r2)
do resolve_interaction(r1, r2);

Au toma t ic  Genera t ion  of  Ac t ive  Ru les

In  a  rea l  CIM  scenar io  i t  is  no t  l ike ly  tha t  the  opera tors  or  eng ineers  tha t  se t-up
the  app l ica t ions  are  fam i l iar  w i th  DBMSs  or  have  the  know ledge  to  use  a  query
language   or   even   less   l ike ly,   ac t ive   ru les   in   an   ADBMS .   I t   is   more   l ike ly   tha t
the  CIM   sys tem  w i l l   have   a   ded ica ted   app l ica t ion   task   language   for   spec ify ing
the   tasks  of   the  con tro l  app l ica t ions .  The  sys tem  can   then  comp i le   the   task  pro-
grams   in to   the   schema   de ﬁn i t ions ,   quer ies ,   and   ac t ive   ru les   tha t   are   needed   by
the  ADBMS .
An   ex tens ion   of   the   above   scenar ios   above   cou ld   be   an   arch i tec ture   s im i lar
to  ARAMIS   (see  Paper   I)  where  a  h igh- leve l   task   language   is  used   for  de ﬁn ing
the   manufac tur ing   tasks   wh ich   are   then   execu ted   on   top   of   the   ADBMS   w i th
suppor t   of   au toma t ica l ly   genera ted   ac t ive   ru les   tha t   in terac t   w i th   the   rea l- t ime
process   con tro l   sys tem   ( ﬁg .   5 .2) .   In   th is   arch i tec ture   the   env ironmen t   w i th   the
con tro l led  equ ipmen t  is  d irec t ly  mode l led  in  a  Wor ld  Mode l  (WM)  s tored  in  the
da tabase .   The   WM   (as   de ﬁned   in   Paper   I)   wou ld   cons is t   of   two   par ts ,   a   h igh-
leve l   con tro l   par t   managed   by   the   ADBMS   and   a   low- leve l   con tro l   par t   wh ich
managed  by   the  rea l- t ime  process  con tro l  sys tem .

63

Compilation of
application
task language

Task Level

Pressure: 301
Temp: 127

Tools

Active Database Level

Executable task programs
Transaction management
Stored relations and views
Active rules

Logical Level

Actuator data

Sensor data

l
e
d
o
M
 
d
l
r
o
W
 
e
h
T

Real-time
Process Control System

Physical Level

Control
programs

Actuators

Sensors

F igure  5 .2: Comp i l ing  a   task   language   in to  ac t ive  ru les

Here   the  phys ica l  con tro l   is   s t i l l  be ing  performed  by   the   rea l- t ime  process  con-
tro l  sys tem ,  bu t  the  effec ts  on  the  da ta  in  the  WM  from  con tro l  loops  are  known
by   the   ADBMS .   If   an   ac tua tor   is   ordered   to   change   i ts   phys ica l   s ta te ,   then   the
ADBMS   w i l l   know   wha t   the   ou tcome   in   terms   of   sensor   va lues   w i l l   be   ( if   the
con tro l   was   successfu l) .   Th is   a l lows   for   de ﬁn ing   cons tra in t   ru les   over   a l lowa-
b le  ac tua tor  se t t ings   in   terms  a l lowed  sensor  va lues .
The   ac t ive   ru les   can   be   invo lved   in   more   coarse-gra ined   con tro l   loops   tha t
mon i tor  and  affec t  severa l   ﬁne-gra ined  con tro l  loops  in  the  process  con tro l  sys-
tem .   These  may   be   ru les   tha t  mon i tor   the   progress   of   the  who le  manufac tur ing
process  no t   jus t  one  opera t ion .

5 .3 About  Paper  IV

The  ARAMIS   sys tem  was   taken  as  an  app l ica t ion   to   s tudy   the  use  of   the  ac t ive
ru les  in  AMOS .  The  in i t ia l  ideas  of  how  th is  cou ld  be  ach ieved  are  presen ted  in
Paper   IV .   An   imp lemen ta t ion   was   made   tha t   jo ined   toge ther   the   ideas   in   the
ARAMIS  arch i tec ture  w i th  AMOS .  The   resu l ts   from   th is  work  are  presen ted   in
[43][44] .

64

Applying Active Database Systems

The   ru les   presen ted   in   th is   paper   seem   to   be   invo lved   in   fa ir ly   low   leve l
con tro l ,   bu t   the   rea l- t ime   con tro l   loops   are   in   prac t ice   jus t   in i t ia ted   by   the
ac t ions  of  these  ru les .  The  procedures  ca l led  in  the  ac t ions  w i l l  genera te  ca l ls  to
the   under ly ing   process   con tro l   sys tem   wh ich   w i l l   schedu le   the   ac t iv i t ies   to
mee t  any  rea l- t ime  requ iremen ts .

5 .4 About  Paper  V

In   a   manufac tur ing   app l ica t ion   there   are   usua l ly   d ifferen t   phases   in   the   manu-
fac tur ing   process .   D ifferen t   opera t ions   are   usua l ly   app l icab le   in   d ifferen t
phases   and   thus   d ifferen t   ac t ive   ru les   are   a lso   app l icab le .   One   resu l t   from   the
AMOS-ARAMIS   s tudy   was   the   need   for   group ing   ru les .   To   suppor t   th is   the
concep t  of ru le  con tex ts  was  deve loped  and   is  presen ted   in  Paper  V .
Ru le   con tex ts   suppor t   group ing   of   ru les   to   enab le   ef ﬁc ien t   ac t iva t ion   and
deac t iva t ion   of   severa l   ru les   s imu l taneous ly.   The   ru le   con tex ts   have   been
imp lemen ted   in   AMOS   and   fur ther   imp lemen ta t ion   de ta i ls   can   be   found   in
chap ter  7 .

5 .5 Mon itor ing  Long-runn ing  Transact ions

Ac t ive   ru les   and   tr iggers   have   been   used   for   organ iz ing   long-runn ing   transac-
t ions   [32] .   In work ﬂow  managemen t   sys tems   [57]  bus iness  or  con tro l  processes
are  mode l led  us ing  work ﬂow  languages  tha t  spec ify  sequences  and  in terac t ions
of  opera t ions   in   the  processes .  Work ﬂow  managemen t  sys tems  can  use   transac-
t ions   and   ac t ive   ru les   in   ADBMSs   for   organ iz ing   and   synchron iz ing   processes
as   long-runn ing   transac t ions .   In   AMOS   suppor t   for   long-runn ing   transac t ions
have   been   imp lemen ted   as sagas [51] .   Sagas   spec ify   sequences   of   comm i t ted
transac t ions   tha t   are   cha ined   toge ther   w i th   compensa t ing   transac t ions   tha t   are
execu ted  when  a  saga  is  abor ted .  The  ru le  con tex ts  presen ted  in  Paper  V  can  be
a t tached   to   a   saga   to   be   au toma t ica l ly   ac t iva ted   for   transac t ions   in   tha t   saga .
When   the   saga   is   ex i ted ,   i .e .   when   a   transac t ion   in   tha t   saga   is   comm i t ted ,   the
a t tached   ru le   con tex ts   can   be   au toma t ica l ly   checked   and   then   be   deac t iva ted .
A l terna t ive ly,   the   a t tached   con tex ts   can   be   checked   when   the   comp le te   saga   is
comm i t ted .  When   the  saga   is  en tered  aga in ,   the  a t tached  ru le  con tex ts  are  au to-
ma t ica l ly   reac t iva ted .  When   (or   if)   a   saga   is   ro l led   back ,   the   same   or   d ifferen t
ru le   con tex ts   can   be   de ﬁned   to   be   au toma t ica l ly   ac t iva ted   and   checked .   See
sec t ion 14 .1  for  syn tax  descr ip t ions  of  sagas   in  AMOS .

5 .6 Scenar ios  for  ADBMSs   in  Te lecommun icat ion  Networks

Fu ture   te lecommun ica t ion   ne tworks   w i l l   have   very   comp l ica ted   mon i tor ing
tasks  tha t  need  to  be  suppor ted .  In tegra t ion  of  DBMSs  in  the  ne tworks  prov ides
a   dynam ic   proper ty   to   da ta   managemen t   tha t   is   needed   for   long- term   ne twork
managemen t   and   w i l l   suppor t   fu ture   grow th   and   ne twork   recon ﬁgura t ions .   In

65

the   deve lopmen t   of   these   ne tworks   there   are  many   cha l lenges   such   as  mee t ing
performance   requ iremen ts   and   suppor t ing   new   func t iona l i ty.   In tegra t ing
ADBMSs   w i th   these   ne tworks   is   perhaps   a   so lu t ion   tha t   mee ts   some   of   the
cha l lenges .  Us ing   an  ADBMS   to   s tore  ne twork  da ta  makes   i t  poss ib le   to  mon i-
tor  changes   to   the  ne twork  da ta   through   the  da tabase .
The   in tegra t ion   of   ADBMSs   mus t ,   however,   be   p lanned   ear ly   in   the   deve l-
opmen t   phases   of   the   ne tworks   s ince   i t   can   rad ica l ly   change   how   the   d ifferen t
func t iona l i ty   is   imp lemen ted   and  where   d ifferen t   da ta   is   genera ted ,   s tored ,   and
can   be   accessed .   The   use   of   ADBMSs   can   be   d iv ided   in to   d ifferen t   scenar ios
for  ne twork   traf ﬁc  con tro l ,  ne twork  managemen t ,  and  ne twork  app l ica t ions .

5 .6 .1

ADBMSs   in  Te lecommun icat ions  Network  Traf ﬁc
Contro l
Today ’ s   large   te lecommun ica t ion   exchanges   usua l ly   cons is t   of   a   large   number
of   sof tware   func t ions   in tegra ted   w i th   ded ica ted   DBMSs   for   pass ive   da ta   man-
agemen t .   The   argumen t   for   us ing   ac t ive   DBMS   techno logy   in   ne twork   traf ﬁc
con tro l  is  perhaps  no t  as  s trong  as  for  ne twork  managemen t ,  bu t  there  are  some
poss ib le  uses  here  as  we l l .
These   sys tems   have   some   func t ions   for   mon i tor ing   the   s ta te   of   the   sw i tch
hardware  and  sof tware .  By  s tor ing  s ta te   informa t ion   in  an  ADBMS  ac t ive  ru les
can   be   used   for  mon i tor ing   the   s ta tus   of   the   sys tem   and   to   inform   opera tors   of
poss ib le  prob lems  and  fa i lures .
Some   subscr iber   serv ices   in   loca l   exchanges   cou ld   a lso  be   suppor ted  by   the
use  of  ac t ive  ru les ,  such  as :

• wake-up  call, where  a  temporal  event  triggers  a wake-up  call  to  a  sleeping  sub-
scriber

• call diversion, where active rules trigger on an attempted call-setup to a busy sub-
scriber and re-routes the call somewhere else

• call waiting, where  active  rules  trigger on  an  attempted  call-setup  to  a busy  sub-
scriber and notifies the called subscriber with an intrusion signal

• malicious call tracing, where a called subscriber triggers an active rule by pressing
a button and that traces where the call comes from

• call cost information, where the termination of a call triggers a rule that causes call
cost information to be sent to the calling (paying) subscriber

Subscr iber   serv ices   are   qu i te   in tr ica te   and   w i l l   requ ire   many   d ifferen t   tr igger-
ing   po in ts ,   i .e .   d ifferen t   even ts ,   to   be   de ﬁned   dur ing   ca l l-se tup ,   dur ing   a   ca l l ,
and  a t  ca l l   term ina t ion .
One   ma in   prob lem   in   these   sys tems   is   tha t   of   hand l ing fea ture   in terac t ions
[60] ,  i .e .  how  to  hand le  the  ac t iva t ion  of  severa l  in terac t ing  subscr iber  serv ices .
Curren t ly   each  manufac turer   hand les   these   in   d ifferen t  ways .   In   he terogeneous
te lecommun ica t ion  ne twork  produc ts  from  many  manufac turers   th is  can  be  d if-
ﬁcu l t  w i thou t  some  coopera t ion  based  on  s tandards .

66

Applying Active Database Systems

One   (among  many)   so lu t ions   of   how   to   spec ify   and   perhaps   reso lve   fea ture
in terac t ion  is  to  spec ify  log ica l  ru les  tha t  de term ine  wha t  shou ld  happen  in  spe-
c i ﬁc   in terac t ion   scenar ios .   These   ru les   are   then   used   dur ing   imp lemen ta t ion   of
the   fea tures .   Curren t ly   the   fea tures   are   of ten   hard-coded   in to   the   sys tems ,
wh ich  makes   i t   d if ﬁcu l t   if   the   in terac t ion   be tween   the   fea tures   is   changed   or   if
new   fea tures   are   added .  A  more   ﬂex ib le   so lu t ion   is   to   suppor t   d irec t   execu t ion
of   the   ru les   in   a   ru le-based   sys tem   tha t   is   in tegra ted   in to   the   sys tems .  Ru les   in
an  ADBMS  are  poss ib le  cand ida tes   for  ach iev ing   th is .  Be low   fo l lows  a   s imp l i-
ﬁed   scenar io   to   g ive   the   reader   some   idea   of   how   some   func t iona l i ty   for   te le-
commun ica t ion  ne twork   traf ﬁc  con tro l  can  be  prov ided  by  an  ADBMS .

A Scenario for using Active Rules in Subscriber Services

In this scenario an ADBMS is directly involved in the call set-up phase and can
monitor the actions of the subscribers which are deﬁned as instances of the type
‘subscriber
’. A call is, somewhat simpliﬁed, de ﬁned as an instance of the ‘call’
type  and  can  be  in  the  states:  ringing,  busy
,  connecting,  connected,  or  discon-
necting. A call has one subscriber who controls the call and one or several par-
ticipants  (ﬁg. 5.3). The  call  controller  is usually  the one who  initiated  the  call
and is usually the one who is billed. In conference calls a participant can some-
times take over the role of controller
, e.g. if the original controller hangs up. If
a call participant has some special service, e.g. call diversion, then he is usually
billed for the transferred call, not the caller
.

controller

call

participant(s)

subscriberA

subscriberB

subscriberC

F igure  5 .3: A  s imp l i ﬁed  ca l l  mode l

subscriber
services
MCT
CTB
CW

Three rules are deﬁned in this scenario:

 • One  rule  that  supports  the  malicious  call  tracing  (MCT)  where  a  sub-
scriber  can  press  the  R(ﬂash)-button  when  he/she  receives  an  unwanted
call. The  rule will  ﬁnd who made  the  call  and  inform  the  operator  of  the
malicious call.
 • One  rule  that  supports  the  call  transfer  (call  diversion)  on  busy  (CTB).
The rule automatically transfers the caller to another number if the called
subscriber is busy .
 • One  rule  that  supports  the  call  waiting  (CW)  service  where  a  subscriber
who  is  engaged  in  a  call  will  receive  notiﬁcation  about  incoming  calls.
The subscriber can choose to talk to the new calling subscriber (switching

67

back  and  for th)  or  engage  in  a  three-par ty  ca l l .  The  CW  serv ice  has  prece-
dence  over  CTB  so  the  CW  ru le  is  ac t iva ted  w i th  a  h igher  pr ior i ty  than  the
CTB  ru le .

create type subscriber;
create function key_press(subscriber) -> integer;
/* 0 - 9, 10(*), 11(#) 12(R) */
create type subscriber_service;
create function provided_service(subscriber)
-> bag of subcriber_service;

create type call;
create function call_controller(call) -> subscriber;
create function call_participant(call)
-> bag of subscriber;
create function call_state(call) -> charstring;
/* ringing, busy, connecting, connected, disconnecting */

create type charging_record;
create function tariff(call) -> charging_record as ...
/* Procedure for calculating cost of a call */
create function tariff(subscriber_service)
-> charging_record as ...
/* Procedure for calculating flat rate cost of a service */
create function tariff(subscriber_service, call)
-> charging_record as ...
/* Procedure for calculating usage cost of a service in a
call */
create function bill(subscriber s, charging_record cr)
-> boolean as ...
/* Procedure that bills or prepares billing of subscriber
depending on the state of the call in the charging
record */

/* ****************************** */
/* Malicious Call Tracing Service */
/* ****************************** */

create subcriber_service instances :MCT;
create function malicious_call(subscriber sa,
subscriber sb)

-> boolean as ...
/* Procedure that informs operator about the MCT */

create rule MCT(subscriber sb) as
for each call c, subscriber sa

68

Applying Active Database Systems

on added(key_press(sb))
when key_press(sb) = 12 and /* Flash (R) */
sb = call_participant(c)
state(c) = “connected” and
sa = call_controller(c) and
do malicious_call(sa, sb); /* Inform operator */

create function setup_MCT(subscriber s) -> boolean as
begin

add provided_service(s) = :MCT;
activate rule MCT(s);
bill(s, tariff(:MCT)); /* Bill subscriber */

end;

/* ********************* */
/* Call Transfer on Busy */
/* ********************* */

create subscriber_service instances :CTB;
create function ctb_redirect(subscriber sb)
-> subscriber sc;
create function reconnect(call c, subscriber s)
-> boolean as ...
/* Procedure redirects a call attempt, will set
call_state(c) = “connected” if successful */

create rule CTB(subscriber sb) as
for each call c
on updated(call_state(c))
when call_state(c) = “busy” and
call_participant(c) = sb
do begin
reconnect(c, ctb_redirect(sb));
bill(sb, tariff(:CTB, c));
end;

create function setup_CTB(subscriber sb,
subscriber sc) -> boolean

begin

end;

add provided_service(sb) = :CTB;
set ctb_redirect(sb) = sc;
activate rule CTB(sb) priority 3;
bill(sb, tariff(:CTB)); /* Flat rate */

69

/* ************ */
/* Call Waiting */
/* ************ */

create subscriber_service instances :CW;
create function cw_inform(subscriber) -> boolean as ...
/* Procedure that sends intrusion signal to busy
subscriber */

create rule CW(subscriber sb) as
for each call c
on updated(call_state(c))
when call_state(c) = “busy” and
call_participant(c) = sb
do begin
cw_inform(sb);
bill(sb, tariff(:CW, c));
end;

create function setup_CW(subscriber s) -> boolean
begin

add provided_service(s) = :CW;
activate rule CW(s) priority 4;
bill(s, tariff(:SW)); /* Flat rate */

end;

No te   tha t   in   th is   scenar io   the  prob lem  of   fea ture   in terac t ion   is  hand led   through
d ifferen t   ru le   pr ior i t ies   on   the   ru le   ac t iva t ions   where   the   ca l l   wa i t ing   ru le   is
g iven   a   h igher   pr ior i ty   than   the   ca l l   transfer   on   busy   ru le .   Th is   is   a  ma jor   s im-
p l i ﬁca t ion   of   the   fea ture   in terac t ion   prob lem   in   genera l .   In   a   rea l   scenar io   the
in terac t ion   can   be   more   comp lex   where   comb ina t ions   of   fea tures   can   prov ide
new   func t iona l i ty   (e .g .   such   as   in i t ia t ing   a   three-par ty   ca l l   or   conference   ca l l
when   accep t ing   new   par t ic ipan ts   in   ca l l   wa i t ing)   tha t   has   to   be   de ﬁned   proce-
dura l ly  or  w i th  o ther  ru les .

5 .6 .2
Te lecommun icat ion  Network  Management
Managemen t   of   fu ture   broad-band   te lecommun ica t ion   ne tworks   such   as   ATM-
ne tworks   is   a  more   l ike ly   app l ica t ion   for   the   use  ADBMSs   than   in   te lecommu-
n ica t ion   ne twork   con tro l .   The   ne twork   can   be   mode l led   in   the   ADBMS   us ing
in terna t iona l   s tandards   for   ne twork   spec i ﬁca t ion .   An   ADBMS   w i th   OO   capa-
b i l i ty  w i l l  d irec t ly  be  ab le  to  s tore  OO  spec i ﬁca t ions  based  on  s tandards  such  as
GDMO  [74] .  The  ADBMSs  w i l l  have  to  suppor t  the  d ifferen t  in terfaces  for  ne t-
work   managemen t   as   spec i ﬁed   in   sec t ion 2 .6 .2   and   suppor t   the   mapp ings
be tween   the   log ica l   v iew   and   the   phys ica l   v iews   of   the   ne twork .   The   ADBMS
mus t   a lso   have   a   fore ign   da ta   source   in terface   suppor t ing   pro toco ls   such   as

70

Applying Active Database Systems

SNMP  MIB   (see   sec t ion 9 .5 .3)   for   d irec t ly   access ing   da ta   in   d ifferen t   ne twork
e lemen ts .   The  mon i tor ing   func t iona l i ty   in   SNMP  MIB  w i l l   have   to   be   adap ted
to   presen t   changes   to   ne twork   e lemen ts   as   fore ign   even ts   tha t   the   ac t ive   ru les
can  mon i tor.

A Scenario for Monitoring Failures in an A TM-network

In an A TM-network a connection is considered full-duplex (two data streams in
two  directions).  If  a  failure  occurs  we  have  to  de ﬁne  where  it  is  detected  and
what  has  been  af fected  by  the  failure.  In  the
ATM-network  failur e  model   we
distinguish between network elements upstream or downstream  from  the point
of  failure  (ﬁg.  5.4).  A  detected  failure  is  not  always  detected  at  the  point  of
failure,  i.e.  faulty  equipment  might  be  detected  through  lost  packages  down-
stream from the equipment. If failures are detected in both streams in a connec-
tion, but at dif ferent points, then the point of failure can sometimes be deduced
by meeting half-way and upstream from the detected failures.

Upstream
from A

Downstream
from A

Source
ATM
end-station

ATM
switch

Failure-A

Failure-B

ATM
switch

Destination
ATM
end-station

Downstream
from B

Upstream
from B

F igure  5 .4: The  ATM-ne twork  fa i lure  mode l

To explain how connections in an A TM-network can be monitored we also have
to  deﬁne  an ATM-network  connection model
. A  network  connection  is  deﬁned
by a trail  connection through the dif
ferent subnetworks that make up the A TM-
network  (ﬁg.  5.5).  Connections  between  subnetworks  are  grouped  into
links
  (mapped  to  VCIs)  in  each  end  of  the  sub-
with connection  termination  points
network.  The  trail  is  an  allocated  sequence  of  connections with
trail  termina-
tion points  in both ends of the network.
The  following database  schema  is  an  example of how  the model  above  can
be implemented in an ADBMS. It should be regarded as a somewhat simpliﬁed
scenario 1 to show the complexity of the application and not as a full implemen-

1 .  The  mode l l ing   is  based  on  de ﬁn i t ions  from   the  A TM-Forum  [3][81]  and   in  GDMO
[74] .

71

Network

Trail termination point

Link

Subnetwork

T r a i

l

Subnetwork

Trail

Connections between subnetworks
Connection termination point

F igure  5 .5: An  ATM-ne twork  connec t ion  mode l

ta t ion .  Two  ru les  are  de ﬁned :  one  ru le  tha t  mon i tors  the qua l i ty  o f  serv ice  (qos)
in  a   spec i ﬁc   tra i l  connec t ion  and  one   tha t  mon i tors  a larms   tha t  af fec t  a   spec i ﬁc
l ink .   No te   tha t   mos t   func t ions   in   th is   scenar io   wou ld   be   fore ign   func t ions   tha t
access  and  mon i tor  the  ne twork  s ta tus  ex terna l ly  from  the  da tabase .  Mon i tor ing
fore ign  func t ions   is  d iscussed  fur ther   in  chap ter  9 .

create type network;
create type subnetwork subtype of network;
create type link;
create function bandwidthUpstream(link) -> real;
create function bandwidthDownstream(link) -> real;
/* Quality of service */
create function qosUpstream(link)
-> <real error_ratio,
real loss_ratio,
real average_delay,
real variance_delay,
real misinsertion_rate>;
create function qosDownstream(link)
-> <real error_ratio,
real loss_ratio,
real average_delay,
real variance_delay,
real misinsertion_rate>;
create function unacceptableQos(
real error_ratio,
real loss_ratio,
real average_delay,

72

Applying Active Database Systems

real variance_delay,
real misinsertion_rate)
-> boolean as ...
/* Function that checks if qos is too low */
create type connection;
/* Traffic data */
create function receiveData(connection)
-> <real bandwidth,
real average_information_rate,
real peak_information_rate,
real burstiness>;
create function transmitData(connection)
-> <real bandwidth,
real average_information_rate,
real peak_information_rate,
real burstiness>;

create type TP; /* Termination Point */
create type linkTP subtype of TP;
create type connectionTP subtype of TP;
create type trailTP subtype of TP;
create type managedElement;
create type equipment subtype of managedElement;
create type software subtype of managedElement;

create function networkLink(subnetwork, subnetwork)
-> link;
create function linkConnections(link)
-> bag of connection;
create function connectionEnds(connection)
-> <connectionTP, connectionTP>;
create function direction(TP)
-> chartstring; /* Uni- or bi-directional */
create function trailConnections(trail)
-> bag of connection;
create function networkElement(network)
-> bag of managedElement;
create function alarm(TP) -> bag of charstring;
create function alarm(managedElement)
-> bag of charstring;
create function raiseTrailAlarm(trail, charstring)
-> boolean as ...
/* Procedure that signals trail alarm */
create function raiseLinkAlarm(link, charstring)
-> boolean as ...
/* Procedure that signals link alarm */

73

create rule monitorQos(trail t) as
for each connection c, link l,
real er, /* error_ratio */
real lr, /* loss_ratio */
real ad, /* average_delay */
real vd, /* variance_delay */
real mr /*misinsertion_rate */
on update(qosUpstream(l)) or
update(qosDownstream(l))
when c = trailConnections(t) and
c = linkConnections(l) and
(<er, lr, ad, vd, mr> = qosUpstream(l) or
<er, lr, ad, vd, mr> = qosDownstream(l)) and
unacceptableThroughput(er, lr, ad, vd, mr)
do begin
raiseLinkAlarm(l, “Unacceptable QOS”);
raiseTrailAlarm(t, “Unacceptable QOS”);
end;

create rule monitorLink(link l) as
for each connectionTP ctp, connectionTP ctp1,
managedElement me, connection c,
subnetwork sn, subnetwork sn1
on added(alarm(ctp)) or added(alarm(me))
when c = linkConnections(l) and
(<ctp, ctp1> = connectionEnds(c) or
<ctp1, ctp> = connectionEnds(c)) and
(networkLink(sn, sn1) = l or
networkLink(sn1, sn) = l) and
me = networkElement(sn)
do for each charstring ad
where (ad = alarm(ctp) or ad = alarm(me))
raiseLinkAlarm(l, ad);

5 .6 .3

Te lecommun icat ion  Network  App l icat ions

In  network  applications  the  use  of  a  DBMS  in  general  is  fairly  obvious  (see
section 2.6.3),  while  the  use  of  an  ADBMS,  however,  is  perhaps  not  as  obvious.
Some  uses  of  active  database  functionality  in  telecommunication  network  applica-
tions could be services such as:

• subscribing to newsgroups that are of particular interest to the user, e.g. subscrib-
ing to news relating to the user’s professional interests or hobbies

• integration of vehicle navigation systems and mobile telecommunication networks

74

Applying Active Database Systems

where an ADBMS monitors the position of vehicles (e.g. using GPS) and informs
drivers of the routes to destinations or changes to the traffic situation (e.g. by mes-
sages to a mobile terminal)

• on-line monitoring  of  access  to  certain  services,  e.g.  can  be  used  by  the  users  to
keep track on misuse of their account and for the service providers to monitor user
access profiles (of different users, at different hours)

• on-line billing by monitoring the use and total cost of the services used so far, e.g.
to help the user monitor how much his or her family has spent so far and perhaps
to lock certain services in order to avoid receiving unexpectedly high bills

A  Scenar io  for  On- l ine  B i l l ing  of  Ne twork  App l ica t ions

Th is   scenar io   re la tes   to   the   ne twork   con tro l   scenar io   where   charg ing   records
are  produced   from   the  use  of  var ious   serv ices .  Here   charg ing   records   are  be ing
rece ived  (mon i tored)   tha t  are   the  resu l t  of   the  use  of  some  ne twork  app l ica t ion .
Here  an  ADBMS   is   in tended   to  perform  on- l ine  b i l l ing  by   incremen ta l ly  ca lcu-
la t ing  the  b i l l  so  far  and  send ing  i t  to  the  user  (perhaps  show ing  up  in  a  coun ter
or  as  a  me ter  on  the  d isp lay  on  h is  ce l lu lar  phone)  wh i le  he  is  us ing  the  serv ice .
When   the   user   ﬁn ishes   the   ca l l   or   the   app l ica t ion   sess ion ,   the   b i l l   is   ﬁna l ized
and   sen t   to   the   user   as   an   invo ice .   A l terna t ive ly,   the   incremen ta l   b i l l   can
d irec t ly   be   used   to   decrease   some   v ir tua l   resources   (e .g .   Ne tCash   [89])   of   the
user  wh i le  he   is  us ing   the  app l ica t ion .

create function charging_records(subscriber)
-> bag of charging_record;
create type bill;
create function subscriber_bill(subscriber) -> bill;
create function calculate_bill
(subscriber, bill, charging_record) -> bill;
/* Procedure that incrementally calculates the
subscriber’s
bill */
create function notify_subscriber(subscriber, bill)
-> boolean as ...
/* Procedure that informs subscriber of current bill
amount */

create rule online_billing(subscriber s) as
on added(charging_records(s))
do /* EA-rule */
begin
set subscriber_bill(s) =
calculate_bill(s, added(charging_records(s)),
subscriber_bill(s));
notify_subscriber(s, subscriber_bill(s));
end;

No te  tha t  in  th is  ru le  the  added  charg ing  record  da ta  is  accessed  in  the  ac t ion  of
the   ru le   to   incremen ta l ly   ca lcu la te   the   new   b i l l .   Th is   is   an   access   of   an   even t
func t ion  ou ts ide  the  even t  par t  of  a  ru le  ( in  the  cond i t ion  or  the  ac t ion)  wh ich  is
d iscussed   in  sec t ion 7 .4 .

75

76

Applying Active Database Systems

77

6

Ef ﬁc ien t  Ru le  Execu t ion
Us ing  Par t ia l  D ifferenc ing

6 .1 Ef ﬁc iency  Pr ob lems   in  ADBMSs

One major requirement that was concluded from the case studies in chapter 2 was the
need  for  efficient  execution  of  rules  with  complex  conditions.  When  introducing
rules  into  a  database  it  is  crucial  that  the  overall  performance  of  the  DBMS  is  not
impaired  significantly. Rule monitoring  is  the  activity  of monitoring  changes  to  the
state of  rule conditions. A naive method of detecting changes  is  to execute  the com-
plete condition when an event that triggers the rule has occurred. This, however, can
be  very  costly,  since  a  rule  condition  can  span  over  large  portions  of  the  database.
One  ma jor  reason  for  in troduc ing  ru les  in to  da tabases  is  tha t  i t  is  more  ef ﬁc ien t
to  de tec t   changes   to   the  da ta   ins ide   the  da tabase   than   to  have   app l ica t ions  pose
quer ies   tha t   de tec t   the   changes .   When   ru les   are   in troduced ,   they   w i l l   impose
some   overhead   on   transac t ions   tha t   are   perform ing   upda tes   to   da ta   referenced
in   even t   spec i ﬁca t ions   or   cond i t ions   of   ac t ive   ru les .   S ince   these   transac t ions
m igh t   be long   to   an   app l ica t ion   unaware   of   the   ru les   i t   affec ts ,   i t   is   impor tan t
tha t   the  ru les  are  processed  ef ﬁc ien t ly .

6 .2 Part ia l  D ifferenc ing  of  Ru le  Cond it ions

Th is   chap ter   presen ts   a   techn ique   for   ef ﬁc ien t   eva lua t ion   of   ru le   cond i t ions .
The  techn ique  is  based  on  incremen ta l  eva lua t ion  techn iques  and  is  named par-
t ia l   d i f ferenc ing .   I t   is   used   for   ef ﬁc ien t   mon i tor ing   of   ac t ive   ru les   in   AMOS .
The  techn ique  is  espec ia l ly  des igned  for de ferred  ru les ,  i .e .  ru les  where  the  ru le
execu t ion   is  deferred  un t i l   a   check  phase   tha t  usua l ly  occurs  when   transac t ions
are   comm i t ted .   The   techn ique   can   a lso   be   used   for   immed ia te   ru le   process ing
[31] .
Par t ia l   d ifferenc ing   is   presen ted   here   based   on   a   conference   paper   [110]
(Paper   VI)   a long   w i th   some   con t inued   work .   A d i f ference   ca lcu lus   is   de ﬁned
for   compu ta t ions   of   the   changes   to   the   resu l t   of   da tabase   quer ies   and   v iews .
Quer ies   and   re la t iona l   v iews   are   regarded   as   func t ions   over   se ts   of   tup les   and
the   ca lcu lus   for  mon i tor ing   changes   is   regarded   as   an   ex tens ion   of   se t   a lgebra .
Le t   P   be   a   func t ion   dependen t   on   the   func t ions   Q   and   R ,   deno ted   the in ﬂuen ts
of   the a f fec ted   func t ion  P.  The  prob lem  of ﬁn i te  d i f fer enc ing [80][96]   is  how   to
ca lcu la te  the  changes  to  P, DP,  in  terms  of  the  changes  to  i ts  in ﬂuen ts .  W i th par-

78

Efficient Rule Execution Using Partial Differencing

t ia l  d i f ferenc ing ,  changes   to  P  are  de ﬁned  as   the  comb ina t ion  of   the  changes   to
P   or ig ina t ing   in   the   changes   to   each   of   i ts   in ﬂuen ts .   Thus , DP   is   de ﬁned   in
terms   of   the par t ia l   d i f feren t ia l func t ions DP /DQ   and DP /DR .   We   w i l l   de ﬁne
how   to   au toma t ica l ly   der ive   the   par t ia l   d ifferen t ia ls DP /DQ   and DP /DR ,   and
how  to  ca lcu la te DP  from  them .  The  ca lcu lus  is  mapped  to  re la t iona l  a lgebra  by
de ﬁn ing  par t ia l  d if feren t ia ls  for  the  bas ic  re la t iona l  opera tors .  Par t ia l  d ifferenc-
ing  has   the  fo l low ing  proper t ies  compared   to  o ther  approaches :

• We assume that the number of updates in a transaction is usually small and often
very few (or only one) tables are updated. Therefore, very few partial differentials
are  affected  in  each  transaction.  Each  partial  differential  generated  by  the  rule
compiler  is  a  relatively  simple  database  query  which  is  optimized  using  tradi-
tional  query  optimization  techniques  [107].  The  optimizer  assumes  few  changes
to a single influent.
• We  separately define positive  and negative partial differentials, denoted DP/D+Q
and DP/D-Q, respectively, since monitored conditions are often only dependent on
insertions  in  influents (not on deletions), as will be shown. Furthermore,  the par-
tial differentials for handling insertions and deletions do not have the same struc-
ture. Conditions that depend on deletions are actually historical queries that must
be executed in the database state when the deleted data were present. This makes
negative differentials different and not easily mixable with positive ones.

• The  calculus  allows  us  to  optimize  both  space  and  time.  Space  optimization  is
achieved since the calculus and the algorithm does not presuppose materialization
of  monitored  conditions  to  find  their  previous  state. Ins tead   i t   g ives   a   cho ice
be tween  ma ter ia l iza t ion   and   compu ta t ion  of   the  o ld   s ta te   from   the  new  one ,
g iven   a l l   the   s ta te   changes . Time optimization is achieved through incremental
evaluation techniques.

• Based  on  the  calculus,  an  algorithm  has  been  developed  for  efficient  rule  condi-
tion  monitoring  by  propagation  of incremen ta l   changes  through  a propagation
network. For correct handling of deletions  in  the absence of materializations and
for  efficient  execution,  a breadth-first,  bottom-up  propagation  is  made  through
the  network  of  both  insertions  and  (only  when  applicable)  deletions.  The  algo-
rithm  reduces  memory  utilization  by  only  temporarily  saving  the  intermediate
changes occurring during the propagation.

• For  explainability,  one  can  easily  determine  which  influents  actually  caused  a
rule  to  trigger  and  whether  it  was  triggered  by  an  insertion  or  a  deletion.  It  is
straightforward to determine this by remembering which partial differentials were
actually executed in the triggering.

Par t ia l  d ifferenc ing  has  been  imp lemen ted  for  CA-ru les  in  AMOS  and  perform-
ance  measuremen ts  have  been  made .  We  have   imp lemen ted  bo th  our   incremen-
ta l  a lgor i thm  and  a   ‘na ive ’  cond i t ion  mon i tor ing  a lgor i thm   tha t   recompu tes   the
who le   ru le   cond i t ion   every   t ime   an   upda te   has   been  made   to   an   in ﬂuen t   af fec t-

79

ing   a   cond i t ion .   The   performance   eva lua t ion   shows   tha t   for   transac t ions   w i th
few  upda tes  our   incremen ta l  a lgor i thm  sca les  be t ter  over   the  da tabase  s ize   than
the   na ive   me thod .   For   transac t ions   w i th   many   upda tes   to   severa l   in ﬂuen ts   the
me thod   is   no t   as   ef ﬁc ien t   as   the   na ive   eva lua t ion ,   bu t   on ly   by   a   fac tor   tha t   is
cons tan t  over   the  s ize  of   the  da tabase .
The method supports ECA-rules as well; the event part just further restricts when
the condition  is  tested. Partial differencing also allows  for  specifying events  such as
added, removed, and updated over views by propagating physical changes to the event
parts  of  ECA  and  EA-rules  (while  propagating  logical  changes  to  conditions  of CA
and  ECA-rules).  Partial  differencing  for  ECA-rules  is  discussed  in  section 6.15,
section 6.16, and section 6.17.

6 .3 Re lated  Work

In   [96] ﬁn i te   d i f fer enc ing   was   presen ted   as   a   techn ique   for   improv ing   the   ef ﬁ-
c iency   of   the   se t-or ien ted   programm ing   language   SETL .   I t   was   based   on   pro-
gram   transforma t ions   us ing   d ifferen t ia t ion   opera tors   de ﬁned   for   the   bas ic   se t-
func t ions  in  SETL .  F in i te  d ifferenc ing  for  ma in ta in ing  der ived  da ta  in  ma ter ia l-
ized   v iews   in   a   func t iona l   da ta  mode l  was   de ﬁned   in   [80] .   In   [13]   ﬁn i te   d if
fer-
enc ing   was   used   for   ma in ta in ing   ma ter ia l ized   v iews   in   the   re la t iona l   da ta
mode l  de ﬁned   in   terms  of  Se lec t-Pro jec t-Jo in  (SPJ)  v iews .
The   techn ique   was   adop ted   for   ru le   cond i t ion   mon i tor ing   in   H iPAC
[31][103] ,  Ar ie l  [63] ,  PARADISER  [33] ,  and  in  A-RDL  [40][133].  Recen t  work
on  
incremen ta l   ma in tenance   of   ma ter ia l ized   v iews   can   be   found  
in
[61][62][75][77][100] .  Re la ted  work  on  incremen ta l  eva lua t ion  of  Da ta log  pro-
grams   can   be   found   in   [36]   and   on   change   compu ta t ion   in   deduc t ive   da tabases
in  [126] .
In   [103]   incremen ta l   eva lua t ion   of   SPJ-v iews   was   presen ted   for   ef ﬁc ien t
eva lua t ion  of  ECA-ru les  w i th  comp lex   ru le  cond i t ions .  The  work  was  based  on
de ﬁn ing   an   a lgebra   for   compu ta t ions   over   da tabase   changes , D-re la t ions .   Each
re la t ion   had   an   assoc ia ted D-re la t ion   where   the   tup les   tha t   go t   added   and
de le ted   dur ing   da tabase   upda tes   were   s tored .   Each   SPJ-v iew   a lso   had D-re la-
t ions  wh ich  were  compu ted   through  a cha in-ru le  for  SPJ  quer ies .
Our  work  differs  from  the  above  in  that  we  deal  with  the  problem  of par t ia l
d i f ferenc ing  of database queries, i.e. automatic generation of several separate partial
differentials from a given rule condition rather than one large incremental expression.
Furthermore, we also deal with deletions and incremental evaluation of deferred rule
conditions.
In  [99]  the  relational algebra  is extended with  incremental expressions.  In  [9] a
method  is  presented  that  derives  two  optimized  conditions, Previously  True  and
Previously  False,  based  on  a materialization  of  a  simple  truth  value  of  a  condition.
Since our rules are set-oriented, we need to consider sets of truth values.
A  classical  algorithm  for  incremental  evaluation  of  rule  conditions  in AI  is  the
Rete  algorithm  [49].  It  is  used  to  incrementally  evaluate  rule  conditions  (called
patterns) in the OPS5 [17] expert system shell. OPS5 is a forward-chaining production
rule  system where  all  patterns  are  checked  using Rete.  Thus,  in  difference  to  active

80

Efficient Rule Execution Using Partial Differencing

database  systems,  all  the  instantiations  of  all  patterns  in  an  OPS5  program  are
incrementally maintained. Regular demand-driven database queries are not supported.
In  Rete  the  system  records  each  incremental  change  (insertions  or  deletions,  called
tokens)  to  the  stored  data.  For  patterns  that  reference  other  patterns  (i.e  derived
patterns) a propaga t ion  ne twork  is built that incrementally maintains the instances of
the  derived  patterns.  The  propagation  network  may  contain  both  selections
(represented as a lpha  nodes) and joins (represented as be ta  nodes). The alpha nodes
(selections) are always propagated before the beta nodes (joins).
The main problem with using Rete  for  rule matching  in active databases  is  that
Rete  is  very  space  inefficient  for  large  databases  since  Rete  saves  all  intermediate
results for all rule conditions. Rete furthermore does not do join optimizations which
may result in a combinatorical explosion of the size of the working memory [91]. To
improve the performance of Rete the TREAT [91] algorithm was developed. TREAT
avoids  the  combinatorical  explosion  by  using  relational  database  optimization
techniques  and  has  been  shown  to  be  more  efficient  for  large  databases  than  Rete
[129].
Ariel  [63]  uses  an  extension  of  TREAT,  A-TREAT,  that  further  reduces  the
memory usage by avoiding to materialize some intermediate results by defining some
selection  nodes  in  the  propagation  network  as  simple  relational  expressions  (named
v ir tua l   a lpha   nodes). A  related approach  is proposed  in  [40] where an algorithm  is
presented that can take a set of rules and return a set of relational expressions that are
the most profitable to materialize to support efficient execution of the rules. These are
examples of how to trade query execution time for space in rule condition checking.
In  contrast  to  the  work  above  we  use  a  propagation  algorithm  based  on  our
calculus for partial differencing. The nodes in the propagation network do not reflect
hard-coded primitive operations such as alpha or beta nodes, but represent temporary
storage  of  data  propagated  from  the  nodes  below.  The  arcs  represent  differential
relational expressions that calculate the changes from an input node below that should
be  propagated  to  the  output  node  above.  By  using breadth-first,  bottom-up
propagation to correctly and efficiently propagate both positive and negative changes
without  retaining  space  consuming  materializations  of  intermediate  views  our
algorithm  differs  from  the  PF-algorithm  [65].  The  materialized  views  can  be  very
large  and  can  even  be  considerably  larger  than  the  original  database,  e.g.  where
cartesian  products  or  unions  are  used.  This  may  exhaust  memory  or  buffers  when
many conditions are monitored and the database is large.
In A-RDL [40][133] incremental evaluation and a ﬁxpo in t  technique are used for
determining  whether  a  rule  has  been  triggered  and  whether  a  set  of  rules  will
terminate,  i.e.  if  they  have  some  fixpoint.  This  technique  is  used  in  a  rule  system
outside  a  DBMS  where  the  client-server  communication  is  intercepted  to  detect
events. This  is  different  from  the  approach  in  this  thesis  in which  the  rule  condition
monitoring  is  integrated  into  an  ADBMS  and  where  incremental  expressions  are
generated that are executed by the query processor (i.e. by the ObjectLog interpreter).
The fixpoint technique could be used as an extension to partial differencing, but this
would  require  an  analysis  of  the  rule  actions  to  determine  what  events  will  be
generated, which is not discussed in this thesis.
In [75] a differential technique is presented for supporting efficient execution of

81

historical  queries  based  on  transaction  time.  The  technique  is  based  on  efficient
calculation of cached queries by using d i f feren t ia l   ﬁ les  that contain transaction time-
ordered  insert,  delete,  and  update  data.  The  differential  files  can  be  used  for  both
incremen ta l  ca lcu la t ion  (moving to a future state in the database) and decremen ta l
ca lcu la t ion   (moving  to  a  past  state  in  the  database).  The  technique  is  supported  by
differential  versions  of  the  relational  operators  (select,  project,  and  join)  which  are
used in full differential expressions similarly as in finite differencing. The differential
expressions  are  optimized  using  a  state  transition  network,  dynamic  programming
techniques, and a number of optimization rules. The optimization technique is related
to  that  in  AMOS  which  is  discussed  further  in  section 6.10.  The  technique  for
supporting transaction time is related to an extension of partial differencing to support
propagation of temporal information such as the time of updates. It is based on event
histories  ordered  by  transaction  time  for  an  integration  of  partial  differencing  and
event propagation for ECA-rules. This makes it possible to use the same propagation
network  to  calculate  complex  event  specifications  and  to  incrementally  calculate
complex rule conditions. This is more discussed further in sections 6.16 and 6.17.
In  [22][117] ECA-rules  are  used  to  incrementally maintain materialized  views.
In [22] a technique is presented how the rules can be semi-automatically derived given
the views to be materialized. The generated ECA-rules are parameterized to allow for
a  simple  form  of  incremental  evaluation.  In  [117]  ECA-rules  are  used  to  manually
maintain materialized views.
Heraclitus  [50]  is  a  dedicated  database  programming  language  which  directly
supports  incremental  evaluation by  supporting de l tas ,  i.e. objects  containing update
information. The deltas can be explicitly constructed, combined, and accessed through
the  programming  language.  The  Heraclitus  paradigm  can  be  used  to  implement
different execution models for active rules in an ADBMS.
In   [93]   a   performance   tes t   is   presen ted   for   incremen ta l   upda tes   in   two   d if-
feren t   ru le-based   programs .   The   ﬁrs t   is   the   game   of   LIFE   where   incremen ta l
upda tes   of   a  ma tr ix   of   vary ing   s ize   are  mon i tored .   The   second   is   a   comb ina to-
r ia l   op t im iza t ion   prob lem   for   a l loca t ing   mor tgage-backed   secur i t ies .   The
resu l ts   favour   incremen ta l   upda te   for   the   second   program ,   bu t   no t   for   the   ﬁrs t
one .  No  rea l  in-dep th  ana lys is  is  prov ided  as  to  why  th is  is  so ,  on ly  tha t  upda tes
in   the   ﬁrs t   program   produce   ma jor   changes   in   the   cha in   of   inference   wh ich   is
unsu i tab le  for  incremen ta l  eva lua t ion .  In  sec t ion 6 .9  par t ia l  d ifferenc ing  is  ana-
lyzed   through  a  performance  measuremen t  cons is t ing  of  seven  d ifferen t  bench-
marks .
In   sec t ion 6 .16   the   propaga t ion   techn ique   used   for   par t ia l   d ifferenc ing   is
ex tended   for   propaga t ing   even ts   of   ECA-ru les .   ECA-ru les   in   AMOS   a l low
spec ify ing   the   even ts   added ,   removed ,   and   upda ted   on   bo th   s tored   func t ions
( tab les)   and   der ived   func t ions   (v iews) .   Th is   is   re la ted   to   work   on   spec ify ing
compos i te   even ts   in   Sen t ine l   [25] ,   SAMOS   [54] ,   and   Ode   [56]   wh ich   are
de ﬁned   in   terms   of   pr im i t ive   even ts .   The   propaga t ion   techn iques   for   ca lcu la t-
ing   the  occurrence  of  compos i te  even ts   from  pr im i t ive  even ts  are   re la ted   to   the
propaga t ion   techn ique   presen ted   in   th is   thes is .   The   propaga t ion   techn iques   for
compos i te   even t   de tec t ion   is   usua l ly   based   on   techn iques   and   da ta   s truc tures
spec ia l ized  for  even t  de tec t ion  and  no t  for  change  propaga t ion .  In  [25]  an even t

82

Efficient Rule Execution Using Partial Differencing

tree   is  used   for  propaga t ing   even ts ,   [54]  uses   a mod i ﬁed   co lor ed  Pe tr i  Ne t ,   and
[56]   uses   a s ta te   au toma ta .   The   work   in   th is   thes is   focuses   on   de tec t ing
changes   to   re la t iona l   v iews ,   i .e .   imp l ic i t   compos i te   even t   spec i ﬁca t ions   of   the
even ts  added ,  removed ,  and  upda ted .  The  techn ique  cou ld  be  ex tended  to  a l low
exp l ic i t   compos i te   even t   spec i ﬁca t ions   and   of   o ther   even ts   as   we l l ,   bu t   th is   is
ou ts ide   the  scope  of   th is   thes is .

6 .4 An  Examp le  Ru le  w ith  Ef ﬁc iency  Pr ob lems

Le t  us  look  a t  the  inven tory  ru le  examp le from  chap ter  3  aga in .  When  the  quan-
t i ty   of   an   i tem   drops   be low   a   cer ta in   thresho ld ,   new   i tems   are   to   be   au toma t i-
ca l ly  ordered . Here   is   the monitor_items ru le  aga in :

create type item;
create type supplier;
create function quantity(item) -> integer;
create function max_stock(item) -> integer;
create function min_stock(item) -> integer;
create function consume_frequency(item)
-> integer;
create function supplies(supplier) -> item;
create function delivery_time(item,supplier)
-> integer;
create function threshold(item i) -> integer
as
select consume_frequency(i) *
delivery_time(i, s) + min_stock(i)
for each supplier s where supplies(s) = i;

create rule monitor_items() as
when for each item i
where quantity(i) < threshold(i)
do order(i,max_stock(i) - quantity(i));

Execu t ing  th is  ru le  can  be  very  inef ﬁc ien t  if  the  da tabase  con ta ins  thousands  of
i tems .   If   we   eva lua te   the   cond i t ion   as   i t   s tands   we   w i l l   scan   the   quan t i ty   and
ca lcu la te   the   thresho ld   for   a l l   i tems   every   t ime   there   is   a   change   to   some   i tem .
The   user   cou ld   de ﬁne   a   CA-ru le   tha t   is   parame ter ized   w i th   spec i ﬁc   i tems
(monitor_item) ,   bu t   if   we   wan t   to  mon i tor   a l l   i tems   we   wou ld   have   to   ac t i-
va te   th is   ru le   for   every   i tem .   A l terna t ive ly,   an   ECA-ru le   cou ld   be   de ﬁned   tha t
cap tures  the  re levan t  even ts  for  a  spec i ﬁc  i tem  and  passes  the  i tem  to  the  cond i-
t ion   through   a   shared   var iab le .   Th is   requ ires   tha t   the   user   knows   wha t   even ts
can  affec t   the  cond i t ion .  The   ru le  above   is  more  e legan t  s ince   the  user  does  no t
need  to  know  wha t  even ts  the  ru le  shou ld  mon i tor,  thus  we  wan t  the  ADBMS  to
ef ﬁc ien t ly  mon i tor   these  k ind  of  CA-ru les  as  we l l .

Database Management for Life Sciences Research 

H. V. Jagadish 
University of Michigan 
jag@umich.edu 

Frank Olken 
Lawrence Berkeley National Laboratory 
olken@lbl.gov 

The  life  sciences  provide  a  rich  application 
domain for  data  management  research,  with  a  broad 
diversity  of  problems  that  can  make  a  signifcant 
difference  to progress  in  life  sciences  research.  This 
article  is  an  extract  from  the  Report  of  the  NSF 
Workshop  on  Data  Management  for  Molecular  and 
Cell  Biology,  edited  by  H.  V.  Jagadish  and  Frank 
Olken  The workshop was held at the National Library 
of Medicine, Bethesda, MD, Feb. 2-3,2003. 

The Crisis in Data Management for Biological 
Sciences 
Over  the  past  15  years  we  have  witnessed  a 
dramatic  transformation  in  the  practice  of  molecular 
biology.  What was  once a  cottage  industry marked  by 
scarce,  expensive  data  obtained  largely  by  the  manual 
efforts of  small  groups  of  graduate  students, post-docs, 
and  a  few  technicians  has  become 
industrialized 
(routinely and  robustly  high  throughput) and  data-rich, 
marked by  factory scale sequencing organizations (such 
as  the  Joint  Genome  Institute, Whitehead  Institute,  the 
Institute  for  Genomic  Research).  Such  sequencing 
factories  rely  on  extensive  automation  of  both 
sequencing  and  sample preparation.  Commencing with 
sequencing,  such  industrialization is  being  extended  to 
high throughput proteomics, metabolomics, etc. 
While this industrialization of biological research is 
partly  the  result  of  technological  improvements  in 
sequencing  instrumentation  and  automated  sample 
preparation  it  is  also  driven  by  massive  increases  in 
public  and  private  investment  and  dramatic  changes  in 
the  social  organization of  molecular  biology  (e.g.,  the 
creation of highly specialized, factory scale organizations 
for  mass  genomic  sequencing).  Such  industrialization 
and  the  accompanying growth  in molecular biology data 
availability demand similar scale up and specialization in 
the  data  management  systems  that  support  and  exploit 
this  data  gathering. 
To  date,  the  bioinformatics 
community has largely made do with custom handcrafted 
data management  software or with  conventional DBMS 
(database management system) technology developed for 
accounting applications. 
The industrialization of molecular biology has been 
largely  the  province  of  pharmacological,  government, 
and,  to  a  lesser  extent,  academic  molecular  biology 
research.  However,  it  is  clear  that  we  stand  at  the 
threshold  of  clinical  application  of  many  of  these 

technologies, e.g.,  as clinical laboratory tests for medical 
applications.  Such  clinical applications will  entail great 
increases  in  the  laboratory  and  data  management 
activities to handle tens or hundreds of millions of assays 
annually in  the U.S.  Similarly, the  approaches and data 
generation  output  from  ever  higher  levels  of  biological 
complexity will  be  increasingly data  intensive and  high 
throughput. 
Instruments,  data,  and  data  management  systems 
are complementary goods, i.e.,  their joint  consumption is 
much more useful than consuming a single commodity at 
a time.  It  is trivial to  see that data management systems 
are much more useful if they contain data.  Consider also 
what  how  limited  the  utility  of  genomic  sequence data 
would  be  if  we  could  only  publish  it  in  books,  and 
manually  compare 
it. 
The  availability  of  data 
management software that permits the rapid  searching of 
large genomic sequence databases for similar sequences 
greatly enhances the utility of such sequence data.  Quick 
sequence comparisons are  not  sufficient by  themselves; 
the  fact that many  (most)  of  these  sequences have been 
collected  into  a  few  databases  (e.g.,  GenBank)  greatly 
simplifies the comparison task. 
In  a  similar  vein,  we  note  that  many  instruments 
used  in  molecular  biology  and  chemistry  produce 
spectra,  or 
spectra-like 
results, 
e.g., 
infrared 
spectrographs, gas  andlor  liquid  chromatography,  mass 
spectrometers.  Such instruments must be  complemented 
with  large  community  databases  of  spectra,  and  data 
management  systems  that  can  store and quickly retrieve 
matching  spectra,  to  provide  greatest  value  to  biology, 
biochemistry, forensics, and medicine. 
We expect that this explosive growth in  the volume 
and  diversity  of  biological  and  biochemical  data  will 
continue  into  the  21"  century.  Success  in  the  life 
sciences  will  hinge  critically  on  the  availability  of 
computational  and  data  management  tools  to  analyze, 
interpret,  compare,  and manage  this  abundance of  data. 
Increasingly,  much  of  biology 
is  viewed  as  an 
information  science,  concerned  with  how  cells, 
organisms,  and  ecological  systems encode  and  process 
information  in  genetics,  cellular  control,  organism 
development, environmental response, and evolution. 
For  small  data  sets  that  are  analyzed  by  a  single 
user, 
it 
is  often  possible 
to  side-step  database 
management systems altogether. 
Indeed,  simple home- 
grown  programs,  and  Per1  scripts  in  particular,  have 

SIGMOD Record, Vol. 33, No.  2, June 2004 

adequately  served  the  needs  of  many  a  scientist. 
However, as the size of the data grows, the complexity of 
the  analysis  grows,  and  the  diversity  of  the  sources 
grows,  these  home-grown  solutions do  not  scale  easily. 
The  value  of  developing  cross-cutting  technology  for 
data management becomes more apparent. 

Requirements of Biological Data Management 
Database  management  systems  researchers  and 
vendors  have  often  advertised  that  their  products  have 
universal  applicability. 
In  fact,  data  management 
technology  development  has  been  shaped  by  different 
applications  over  the  past  30  years.  Commercial 
(banking,  payroll,  and  inventory) applications drove the 
development of relational DBMS, CAD (computer aided 
design)  applications  drove  the  development  of  object- 
oriented  databases,  management  information  systems 
have  driven  data  warehousing  and  OLAP  (Online 
Analytical Processing) data management technology, and 
web  content  and  e-commerce  technology  have  driven 
XML data management systems.  Biological applications 
have  their  own  requirements  that  will  require  further 
advances  in  data  management  technology. 
These 
include: 
1. 
sequences, 
A  great  diversity  of  data  types: 
graphs, three dimensional structures, images, etc. 
Unconventional  types  of  queries: 
similarity 
2. 
queries,  e.g.,  sequence  similarity,  pattern  matching 
queries, pattern finding queries, etc. 
3. 
Ubiquitous  uncertainty  (and  sometimes  even 
inconsistency) in  the data 
4. 
Extensive  requirements  for  data  curation  (data 
cleaning and annotation) 
5 .  
A need to support detailed data provenance 
A  need  for 
large  scale  data 
integration 
6. 
(hundreds of databases) 
7. 
Extensive 
requirements 
management 
8 .  
Support for rapid schema evolution 
9 .  
A need to support temporal data 
10. 
A  need  to  provide  model  management  for  a 
variety  of  mathematical  and  statistical  models  of 
organisms and biological systems 

terminology 

for 

These topics are discussed more  extensively in  the 
full  technical  report  [I].  Here  we  briefly  elaborate on 
only a few of these points. 

Diversity of Data Types and Queries 
A  striking  feature  of  biological  data  is  the  great 
diversity of data types: sequences, graphs, 3D structures, 
scalar  and  vector  field  data,  etc.  The  queries  posed 
against  these  data  types  are  also  diverse,  and  different 
from 
common 
commercial 
queries.  Whereas 
conventional  databases  are  dominated  by  exact  match 
(equality)  and  range  (inequality)  queries,  biological 
applications  involve  the  pervasive  use  of  similarity 

queries, e.g.,  classic sequence similarity queries, but also 
including  subgraph  isomorphism, 
pattern  matching 
queries  (e.g., 
regular  expressions,  Hidden  ~ a r k o i  
models) and pattern identification queries. 
Sequences: The availability of sequence data, e.g., 
DNA,  RNA,  and  amino-acid  sequences  (proteins),  has 
grown  explosively  over  the  past  decade  with  the 
development  of  automated  sequencing  machines  and 
large  scale  sequencing projects  such  as  the  human  and 
mouse  genome  sequencing  projects.  Sequences  are 
presently  often  stored  as 
text  strings,  but 
this 
representation  is  awkward  when  we  want  to  annotate 
sequences, since text strings typically lack addressability 
at  the  level  of  individual  letters  (nucleotides, or  amino 
acids).  Often  DNA  sequences  include  not  only 
individual  nucleotides,  but  also  gaps,  usually  with  a 
length (or bounds on length) specification of the gap. 
Graphs: Many  types of graphs occur in  biological 
data, including a directed (or undirected) labeled graph, a 
nested  graph,  and  a  hyper-graph.  Examples  include 
various  biopathways  (metabolic  pathways,  signaling 
pathways,  and  gene  regulatory networks),  genetic maps 
(partial  order  graphs  (i.e.,  directed  acyclic  graphs), 
taxonomies  (either  trees  or  DAGs),  chemical  structure 
graphs,  contact  graphs  (for  3D  protein  structure),  etc. 
Graphs  are  easily  stored  in  existing  DBMSs,  e.g., 
relational DBMSs.  However, many graph  queries, e.g., 
subgraph  isomorphism,  subgraph  homomorphism,  and 
subgraph homeomorphism are difficult (or impossible) to 
pose  and  answer  efficiently  in  existing  relational 
DBMSs, which know nothing of graphs. 
High-Dimensional  Data:  It  is  not  unusual  for 
micro-array  experiments  of  gene  expression  to  involve 
thousands (or  tens of  thousands) of genes and  hundreds 
(or  thousands)  of  experimental conditions and  samples. 
Generated datasets are arrays of spot intensities over the 
Cartesian  product  of  genes  and  samples 
(e.g., 
experimental  conditions).  Often 
researchers  are 
interested  identifying  clusters  of  genes  which  exhibit 
similar  (or  opposite)  patterns  of  gene  regulation. 
Specialized data structures and clustering algorithms are 
needed to support nearest neighbor, range searching, and 
clustering queries in high-dimensional spaces. 
Shapes:  Three-dimensional  molecular  (protein, 
ligand, complex)  structure data  is  another common  data 
type.  Such data  includes both  shape  information  (e.g., 
ball  and  stick models for protein backbones) and  (more 
generally)  scalar  and  vector  field  data  of  charge, 
hydrophobicity, and  other  chemical  properties  specified 
as functions over the  volume  (or surface) of  a molecule 
or complex. 
Temporal Data: Temporal data must frequently be 
managed  when  studying  the  dynamics  of  biological 
systems. 
Examples  include  cellular  response 
to 
environmental changes, pathway regulation, dynamics of 

SIGMOD Record, Vol. 3 3 ,  No.  2, J u n e  2004 

gene  expression  levels,  protein  structure  dynamics, 
developmental biology, and evolutionary biology. 
Temporal data  in  biological  settings can  either be 
absolute or relative.  Absolute time-stamping  is common 
in  administrative or  long  term  ecological  observational 
databases  --  time  is  recorded  relative  to  an  absolute 
global  temporal  coordinates  such  as  UTC  date-time. 
Relative  time-stamping  records  time  relative  to  some 
event --  e.g.,  cell division,  organism birth,  oncogenesis, 
diagnosis,  cold  shock,  etc.  Most  implementations  of 
time  in  the  database  cornmunitv  have  focused  on 
absolute  time,  whereas  relative  time  is  much  more 
commonly  used  in  most  biological  experiments. 
In 
complex settings such as disease progression,  there may 
be  multiple  important  events  against  which  time  is 
reckoned: 
Scalar and Vector Fields:  Scalar and  vector  field 
data  is  normally  thought  of  primarily  in  the  context  of 
spatio-temporal applications such as computational fluid 
dynamics,  weather, 
climate,  oceanography  and 
combustion  modeling.  However,  a  number  of 
participants  of  the  workshop  argued  that  such  data  is 
quite 
important  for  molecular  and  cell  biology 
applications.  Examples  include modeling  reactant  and 
charge distribution across the  volume  of  a  cell,  calcium 
fluxes across the cell  surface or cell volume, reactant or 
protein  fluxes  across  cell  membranes,  transport  across 
cellular  compartments,  clinical  response  to  drugs. 
the  visualization,  computational  fluid 
Efforts 
in 
dynamics, 
and  geographic 
information 
systems 
communities to  deal  with  vector  and  scalar  field  data 
have  focused  on  the  development  of  fiber  bundle  or 
vector bundle data models. 
Mathematical Models: Much of modern biological 
data  analysis  is  concerned  with  the  specification, 
development,  parameter 
estimation,  and 
testing 
(statistical  or  simulation)  of  various  mathematical  and 
statistical  models  of  biological  systems  and  datasets. 
Thus  far  the  database  community  has  largely  been 
concerned  with  storing  and  querying  input  data  sets, 
estimated  parameters  sets,  and  simulation  output 
datasets.  Relatively  little  attention  has  been  paid  to 
systematic  methods  of  representing,  storing,  and 
querying  the  mathematical  and  statistical models  being 
used.  One would like to have declarative specification of 
mathematical  and  statistical models,  means of  recording 
bindings  of  model  variables  to  database  contents,  and 
some way  of recording the statistical analysis method (or 
simulation method) used. 
Constraints:  Historically,  DBMSs  have  provided 
mechanisms  to  specify  and  enforce  a  variety  of  logical 
constraints on  the  contents  or  allowable updates  of  the 
database, 
e.g., 
referential 
integrity 
constraints. 
Biological  databases  require  a  variety  of  constraint 
specifications,  both  logical  rules,  and  mathematical 
constraints (e.g.,  equations or  inequalities) as  first  class 
data types in a biological  data management system, with 

SIGMOD Record, Vol. 33, No.  2, J u n e  2004 

the  ability to  store, enforce, and  query  such  constraints. 
In  particular,  traditional  DBMSs  typically  have  no 
mechanism to enforce non-local constraints. 
Examples  of  mathematical  constraints  include 
various  conservation  constraints  such  as  mass, 
momentum  and  energy  conservation.  Thus  individual 
chemical  reactions  in  a  bio-pathway  database  must 
satisfy mass balance for each element.  Such constraints 
In  contrast,  cycles  of  reactions 
are 
in 
local. 
thermodynamic 
database  must 
satisfy 
energy 
conservation constraints.  These  are  non-local  (global) 
constraints.  Another  example  of  non-local  constraints 
are  the  prohibition of  cycles  in  overlap graphs of  DNA 
sequence  reads  for  linear  chromosomes,  or  in  the 
directed graphs of conceptual or biological taxonomies 
Patterns: On the many data types described above, 
one would  naturally expect similarity queries.  These are 
clearly important.  In addition, much effort has gone into 
specifying,  characterizing,  and  finding  patterns  (a.k.a. 
motifs),  e.g.  in  DNA,  RNA,  and  protein  sequences. 
These  patterns  are  often  represented  as  regular 
expressions or Hidden Markov Models (HMMs) or other 
types  of  grammars.  Biologists  are  interested  in 
collecting, storing, and querying these patterns.  Patterns 
thus need  to be  considered as first class data types, with 
support for storage and querying. 
A  second  class  of  queries  consists  of  pattern 
matching  queries,  i.e.,  queries  which  find  instances  of 
sequences,  etc.  which  match  a  specific  pattern.  On 
strings these  queries  involve pattern  specifications such 
as regular expressions, Hidden Markov Models,  or chart 
grammars.  Graph pattern queries might  involve patterns 
specified by  graph  grammars,  subgraph homomorphism 
queries, etc. 
One will  also want  to be  able  query  collections of 
patterns (motifs).  One such query would involve finding 
all  patterns which match  a  sequence (the  inverse of  the 
customary  query).  Alternatively,  one  might  ask  for 
patterns which are similar to a specified pattern.  Pattern 
similarity might  be  defined  either  structurally  (akin  to 
sequence  similarity)  or  in  terms  of  the  overlap  in  the 
sequences matched by  the  two patterns from a  specified 
database. 

This diversity of  data  and  query  types has  two 
implications for data management  technology.  First,  we 
need 
to  develop  specialized  indexing  and  query 
processing techniques to deal with these specialized data 
and  query  types.  Second,  we  need  to  develop  more 
extensible data  management  systems.  Current  DBMSs 
have  object-relational 
facilities 
that  offer  some 
extensibility features, which  have been  used  to  support 
geographic  information  systems and  chemo-informatics 
systems. Most of the workshop  participants believe that 
limited  and 
too 
current  extension  facilities  are 

cumbersome to fully cope with the diversity of biological 
data and queries. 

Data Provenance 
Questions  of  data  release  policies  for  biological 
data are properly questions of public policy, not technical 
discussion.  However,  it has  become  increasingly clear 
that  good  data management  infrastructure for  recording 
and  querying  data  provenance  -  the  origin  and 
processing  history  of  data  - is  vital  if  we  are  to 
effectively  encourage  the  sharing  of  biological  and 
biomedical  data.  Data  provenance  issues  have  been 
largely  neglected  by  the  database  research  community 
except  for  a  few  researchers  in  statistical  data 
management  and  data  warehousing.  This  area  clearly 
needs  further  work  to  support  bioinformatics  data 
sharing.  The  topic  is  also  of  increasing interest  to  the 
regulatory  community  (e.g., 
the  Food  and  Drug 
Administration). 
The  classic  approach to  sharing knowledge  in  the 
biology community has been  to publish journal  articles. 
Authors receive public  acclaim and acknowledgement in 
exchange for publication of their knowledge.  Individual 
articles and  authors are  acknowledged via  bibliographic 
citations (or sometimes co-authorship), and systems have 
been  developed to  record the number of citations papers 
received.  We  believe  that  similar  mechanisms  are 
needed  to  acknowledge  "publication"  of  datasets  in 
shared  databases,  so  as  to  encourage  rapid,  effective 
sharing  of  data.  Data  management  support  for  tracking 
data  provenance  (origins)  can  provide  the  analog  of 
citations.  Usage  tracking  software  can  potentially 
provide analogs to bibliographic citation counts.  Support 
for automatic tracking and  querying of data  provenance 
is fairly undeveloped in current DBMSs. 
There are other important motivations for recording 
and querying data provenance.  Knowledge of the source 
and  processing  history  of  data  items  permits  users  to 
place  the  data  in  context  and  helps  to  assess  its 
reliability.  Data  provenance  histories  also  facilitate 
revision of  derived data when  the  base  data  (or  analysis 
codes) change.  DBMS support is needed to facilitate the 
automated  update  of  provenance  information  as  the 
database  is  updated  and  the  automatic  propagation  of 
provenance information wit query results.  Experience in 
other  settings,  e.g.,  geographic  information  systems, 
indicates that  unless metadata  (e.g.,  data provenance)  is 
automatically  updated,  it  is  likely  to  quickly  become 
outdated. 

Uncertainty 
Biological  data  has  a  great  deal  of  inherent 
uncertainty.  Often, when  a scientist says "A  is a B  they 
mean "A  is probably a B, because there is some (possibly 
substantial) evidence  suggesting that  such  is  the  case". 
For  example:  A  protein  sequence may  be  erroneously 
recorded  in GenBank, because  only a partial protein was 

reported; this error  is propagated when  another scientist 
runs  a  Blast  search  against  sequences  in  GenBank  and 
reports matches against such an erroneous sequence. 
For all of these reasons, it is important to recognize 
uncertainty (and possible  inconsistency) of data recorded 
in  biological  databases.  Standard  database  technology 
provides  no  support  for  uncertainty,  since  business- 
oriented commercial databases typically contain data that 
is  certain. 
investigators  often  resolve 
Individual 
uncertainties  and  inconsistencies by  manual  inspection 
and  editing  of  datasets  - a  process  known  as  manual 
curation. 
In  large  scale  database  setting,  explicit 
representation  of  uncertainty  and  automated  tools  for 
curation  are  needed.  Difficulties  in  scaling  up  curation 
activities have  been  the bane  of major public biological 
databases. 

Workflow Management 
Large  scale  molecular  biology  experiments  and 
data  analyses  need  workflow  management  systems  to 
assist in  orchestrating the work  and recording the  details 
of what was  done  to  each  sample andlor dataset.  Both 
laboratory  WFMS  (known  as  LIMS  -  laboratory 
information  management  systems)  and  computational 
workflow  management  systems  (sometimes  called 
scientific workflow  management)  are  needed  for  large 
projects.  Explicit  representation  and  recording  of 
laboratory  and  computational  protocols  is  useful  in 
driving automated data analyses and subsequent retrieval 
of  experiments  on  the  basis  of  protocol  features. 
Detailed  records  on  experiments  are  useful  for  process 
yield analyses and  process  failure diagnosis.  Biological 
workflows  differ  from  conventional workflows  in  that 
pooling and splitting of samples is commonplace. 

Data Integration 
Many,  if  not  most,  applications  of  biological  and 
biomedical  databases require  the  ability  to  access  data 
from many different databases (and datasets).  There has 
been  a  veritable  explosion  in  specialized  biological 
databases.  Many  researchers  regard  these  specialized 
databases as extremely valuable, in part  due  to the  very 
detailed and carefil curation of the  data by  specialists in 
particular domains.  However,  no  matter how  good  the 
data management technology for data  integration, we  do 
not  foresee that it will be practical for data integration to 
succeed  in  a world  of  hundreds  of  biological databases 
unless 
the  database  providers  provide  extensive 
assistance  in  the  form  of  publicly  accessible,  machine 
processable  documentation  concerning  the  database 
schemas,  contents,  query  interfaces,  query  languages, 
etc.  Adoption  of  such  current  technology by  database 
providers was seen as a pressing issue. 
The  current  practice  of  only  providing  access  to 
most  specialized  biological  databases  via  web-based 
forms is not  sufficient: query APIs  and  query languages 
are needed to facilitate data integration.  The provision 

SIGMOD Record, Vol. 33, No.  2, J u n e  2004 

of  suitable data documentation and adoption of standard 
data  exchange  formats  and  query  languages  and  APIs 
will  have  to  be  seen  as  a  social  obligation  of 
investigators 
similar 
to 
careful  description  of 
experimental methods  in  publication.  The  efforts  of  the 
Micro-array Gene  Expression Data  Society, to  develop 
standard  schemas  for  micro-array  data,  represent  an 
instance where  significant steps have  been  taken  in  this 
direction. 
We  note  that  the  structural biology  and  genomics 
communities  have  also  resorted  to  various  social 
sanctions to encourage data sharing, e.g., requirements of 
depositing data  in  PDB  or GenBank prior  to  acceptance 
of  papers  for  publication,  and  requirements  for  data 
deposition as a condition of grant renewal and a criterion 
for  funding  of  new  grants.  We  anticipate  that  similar 
activism  by  federal  research  program  managers  and 
journal  editors will  continue to be required, both  for data 
deposition  and  to  assure  adoption  of  best  practices  to 
facilitate data  sharing, such as complete documentation, 
data  exchange  encoding,  and  support  for  query  APIs 
(e.g.,  Web  Services  Description  Language)  and  query 
languages (SQL, OQL, XQuery, et al.) 
In  addition  to  the  short-term  needs  of  machine- 
readable descriptions, and the constructions of wrappers, 
there are deeper questions to be  addressed with regard to 
model  management.  Mapping  between  different  data 
models  or data representations is an integral part of any 
biological  database  application.  For  example,  there  is 
often  external  information  or archival data  that must  be 
imported 
to  augment 
local  computationally  or 
experimentally  derived  data.  Even  within  a  single 
project,  there  can  be  the  need  for  multiple  models  or 
representations  for  the  same  kind  of  information,  as  it 
moves  through  various  stages,  e.g.,  data  entry,  data 
query,  data  interchange,  and  data  archiving.  With 
Affymetrix gene expression data, for example, data entry 
may  be  what Affyrnetrix produces,  data query may  be  a 
relational  database  with  some 
local  model,  data 
interchange  may  use  MAGE-ML,  and  data  archive  is 
what some consortium requires. 
Data  sources evolve as knowledge  changes and  as 
new  experimental  techniques  produce  more  data  and 
different characterizations of the  data.  As  a result,  both 
the schemas that describe the data as well as applications 
and  queries written specific to the original version of the 
schema must be updated.  This is difficult to accomplish, 
particularly  when  the  data  types  and  structures  are 
complex  and  when  the  analysis  involves  complex 
transformations  or  aggregations.  Keeping  up  with 
evolution becomes  significantly more  difficult if  there  is 
a  fundamental  change  in  our  understanding  of  the 
meaning or the characterization of the data. 

Interdisciplinary Research 
the  rise  of 
The  past  decade  has  seen 
bioinformaticists (a.k.a.  bioinformaticians), a new group 

SIGMOD Record, Vol. 33, No.  2, June 2004 

of researchers operating across the disciplines of biology, 
statistics,  computer  science,  and  mathematics.  Their 
interdisciplinary  activities  now  have 
their  own 
professional society, conferences, and journals. 
Orchestrating  fruitful  interdisciplinary  research 
across biology,  bioinformatics,  and  data management is 
not  easy.  Even within  the  workshop, there was  heated 
debate about  the  best  strategy to  accomplish this.  Lack 
of 
sufficient 
interaction 
among 
biologists, 
bioinformaticists, and  data management  researchers  can 
easily  lead  to  attempts  to  reinvent  well-known  data 
management technologies by bioinformaticists, or  sterile 
pursuits  of  insignificant or  misunderstood problems  by 
data management  researchers.  Also,  the  time  scales  of 
data  management  research  and  development  are  often 
incompatible  with 
the  production  requirements  of 
ongoing  biological  laboratories  or  public  databases. 
Despite early plans  and efforts (e.g.,  by DOE)  the major 
human  genome  sequencing  centers  have  generally  not 
been  major  sources  of  innovative  data  management 
technology.  The  most  intellectually  fruitful  endeavors 
have  often  come  from  data  management  or  computer 
science research  groups with  looser  collaborations with 
biologists.  The  time  required  to  develop new  database 
technologies  often  exceeds  the  time  demands  of  most 
biologists  or  bioinformaticists,  who  must  produce 
biologically relevant data to sustain funding. 

Recommendations 
A  sustained program  supported  across the  federal 
agencies  at  the  frontier  between  biology  and  data 
management  technology  will  allow  us  to  share  the 
database  expertise  of  the  IT  (information  technology) 
professionals  with  bioinformaticists  and  biological 
experimentalists supported  across  the  federal  agencies. 
There  are  needs  for  both 
research 
in  database 
management  technologies  and  innovative application of 
existing  database  technology  to  biological  problems. 
Funding  agencies  will  have  to  set  up  appropriately 
staffed  review  panels  charged  with  suitable  review 
criteria for supporting such interdisciplinary work. 
It is also valuable to define challenge problems that 
push  the  boundaries  of  data  management  technology, 
which,  if  successful, would  enable  major  advances  in 
biomedical  science.  Well-specified  challenges  can  help 
direct  data  management  researchers  toward  important 
bioinformatics problems.  Creation  of  test  data  sets and 
benchmarks  are  also  worthy  endeavors  in  themselves, 
and  should  be  supported  as  appropriate  and  possible. 
Much  of  this work must be  done by  life scientists.  The 
availability of  such test data  sets and  query benchmarks 
facilitates  the  comparison  of  new  approaches  to  older 
ones. 
We  expect,  in  the  foreseeable  future,  that  it  will 
become  important  to  have  physicians  and  experimental 
biologists  trained  in  computational  methods,  just  as 
training  in  genetics  has  now  become  routine  for 

The  full  report  was  the  work  of  the  writing 
committee comprised of Russ Altman  (Stanford), Susan 
Davidson  (U.  Penn.),  Barbara  Eckman  (IBM),  Michael 
Gribskov  (SDSC),  H.V.  Jagadish  (U.  Michigan),  Toni 
Kazic  (U.  Missouri),  David  Maier  (Oregon  Health 
Sciences  University),  Frank  Olken  (LBNL),  Z.  Meral 
Ozsoyoglu  (Case  Western  Reserve  Univ.),  Louiqa 
Raschid (U. of Maryland), and John C.  Wooley (UC San 
Diego). 
The  many  attendees  of  the  workshop  contributed 
white papers and discussions that formed the basis of the 
report  and  this  summary.  Many  also  contributed 
comments to the report. 

References 
[ I ]   Workshop on Data Management for  Molecular and 
Cell Biology, web site. 
h~://www.lbl.gov/-olken/wdmbio/ 
[2]  Data Management for Integrative Biology, Special 
Issue of the OMICS Journal, vol. 7, no.  1, Jul. 2003. 

physicians.  Biology  is  often  an  exercise  in  induction 
(generalization from many  instances), whereas computer 
science  is  more  often  a  deductive  enterprise,  because 
computer  algorithrns/systems are  usually  designed,  not 
evolved, artifacts.  Solution to  a  specific biological  data 
management  problem  is  of  less  interest  to  a  computer 
scientist than the generalization of this problem to a class 
of  data  management  problems,  all  of  which  can  be 
solved  in  one  fell  swoop  through  an  appropriate 
computational  advance.  And  rightly  so,  since  this 
paradigm  is  significantly  more  cost-effective  in  the 
domains  to  which  it  is  applicable.  We  note  that 
experimental  design  and  algorithmic  design  are  often 
similar endeavors. 

Conclusions 
The  development  of  high  throughput methods 
and  the  establishment of  commercial  sources  for  even 
highly  specialized biochemical  reagents  for  research  in 
molecular and cell biology over the past fifteen years has 
brought  a  huge  increase  in  the  volume  and  diversity of 
biological  and  biomedical  data.  Clinical  use  of  these 
technologies  has  already  begun  and  extensive,  even 
routine,  application  is 
Full,  efficient 
imminent. 
exploitation  of  these  expensive  investments  in  data 
collection  will  require  complementary  investments  in 
data management technology. 
To date most efforts to manage this data have relied 
either on commercial off-the-shelf DBMSs developed for 
business data, or on homegrown systems that are neither 
flexible  nor  scalable. 
Better  data  management 
technology  is needed  to effectively address specific data 
management  needs  of  the  life  sciences.  Such  needs 
include  support  for  diverse  data  types  (such  as 
sequences, graphs,  3D structures, etc.) and  queries (e.g., 
similarity based retrieval), data provenance tracking,  and 
integration of numerous autonomous databases. 

Full Report 
This  article  is  an  extract  from  the  full  report, 
which  is  available  online  from  the  workshop  web  site 
[I].  This  site  also  contains  the  position  papers,  the 
original workshop  proposal,  attendee lists, etc.  Position 
papers  from  several attendees, and  an  interim  summary 
report  were  published  in  the  OMICS Journal[2];  these 
materials are also accessible via the workshop web site. 

Acknowledgements 
This  document  is  the  product  of  a  workshop 
funded  primarily  by  the  National  Science  Foundation, 
Computer  and  Information  Science  and  Engineering 
Directorate  under  grant  EIA-0239993.  The  National 
Library of Medicine at NIH  provided us with conference 
facilities and support in kind.  The Department of Energy 
provided  support  to  one  of  the  organizers,  via  the 
Genomes to Life Program, as part of the Virtual  Institute 
of Microbial Stress and Survival Project. 

SIGMOD Record, Vol. 33, No.  2, June 2004 

Transaction  Management  in the  R* 
Distributed  Database  Management  System 

C.  MOHAN,  B.  LINDSAY,  and  R.  OBERMARCK 
IBM  Almaden  Research  Center 

database  system. 
the  transaction  management  aspects  of  the  R*  distributed 
It 
This  paper  deals  with 
of  the  R*  commit  protocols,  Presumed  Abort 
primarily 
concentrates 
(PA)  and 
on  the  description 
two-phase 
(PC).  PA  and  PC  are  extensions 
Presumed  Commit 
of  the  well-known, 
(2P)  commit 
protocol.  PA  is  optimized 
for  read-only 
transactions 
and  a  class  of  multisite  update 
transactions, 
and 
transactions.  The  optimizations 
PC  is  optimized 
in  reduced 
result 
for  other  classes  of  multisite 
intersite  message  traffic  and  log  writes,  and,  consequently, 
a  better 
response 
time.  The  paper  also 
discusses  R*‘s  approach 
toward  distributed 
deadlock  detection  and  resolution. 

Distributed 
Networks]: 
[Computer-Communication 
Categories  and  Subject  Descriptors:  C.2.4 
Process  Management-concurrency; 
[Operating 
datahes; 
Systems-distributed 
Systems]: 
D.4.1 
Systems]:  Organization 
deadlocks,  syndvonization; 
D.4.7  [Operating 
and  Design-distributed 
[Database  Management]: 
tolerance;  H.2.0 
tems;  D.4.5 [Operating Systems]:  Reliability--fault 
and 
Management]: 
[Database 
General-concurrency 
control;  H.2.2 
‘Physical  Design-recouery 
restart;  H.2.4  [Database  Management]: 
Systems-ditributed 
systems;  transactionprocessing; 
H.2.7 
and  recouery 
Database  Administration-logging 
[Database  Management]: 

sys- 

General  Terms:  Algorithms,  Design,  Reliability 

Additional  Key  Words  and  Phrases:  Commit  protocols,  deadlock  victim  selection 

1.  INTRODUCTION 
R*  is  an  experimental,  distributed  database  management  system 
developed  and  operational  at  the  IBM  San  Jose  Research  Laboratory 
(now 
renamed  the  IBM  Almaden  Research  Center)  118, 201. In  a distributed  database 
system,  the  actions  of  a transaction  (an  atomic  unit  of  consistency  and  recovery 
[13])  may  occur  at  more  than  one  site.  Our  model  of  a  transaction,  unlike  that 
of  some  other  researchers’  [25,  281, permits  multiple  data  manipulation  and 
definition  statements  to  constitute  a  single  transaction.  When  a  transaction 
execution  starts,  its  actions  and  operands  are  not  constrained.  Conditional 
execution  and  ad  hoc  SQL  statements  are  available  to  the  application  program. 
The  whole  transaction  need not  be fully  specified  and made known  to  the  system 
in  advance.  A  distributed 
transaction  commit  protocol  is  required  in  order  to 
ensure  either  that  all  the  effects  of  the  transaction  persist  or  that  none  of  the 

Authors’  address:  IBM  Almaden  Research  Center,  K55/801,650  Harry  Road,  San  Jose,  CA  95120. 
fee  all  or  part  of  this  material 
to  copy  without 
Permission 
is  granted  provided 
that 
the  copies  are  not 
the  ACM  copyright  notice  and  the  title  of  the 
for  direct  commercial  advantage, 
made  or  distributed 
is  by  permission  of  the  Association 
that  copying 
is  given 
and  its  date  appear,  and  notice 
publication 
for  Computing  Machinery. 
To  copy  otherwise, 
or 
to 
republish, 
requires  a  fee  and/or 
specific 
permission. 
0  1986  ACM  0362-5915/86/1200-0378 

$00.75 

ACM  Transactions 

on  Database  Systems,  Vol.  11,  No.  4,  December  1966,  Pages  373-396. 

Transaction  Management  in  the  R’  Distributed  Database  Management  System 

’ 

379 

effects persist,  despite  intermittent  site  or  communication 
link  failures.  In  other 
words,  a  commit  protocol  is  needed  to  guarantee  the  uniform  commitment  of 
distributed 
transaction  executions. 
requires  that  certain  facilities  exist  in  the  distributed 
Guaranteeing  uniformity 
database  system.  We  assume  that  each  process  of  a  transaction 
is  able  to 
provisionally  perform  the  actions  of  the  transaction 
in  such  a way  that  they  can 
be undone  if  the  transaction  is  or  needs to  be aborted.  Also,  each database of  the 
distributed  database system  has a log that  is  used to  recoverably  record  the  state 
changes of  the  transaction  during  the  execution  of  the  commit  protocol  and  the 
transaction’s  changes  to  the  database  (the  UNDO/REDO 
log  114, 151).  The 
log  records  are  carefully  written  sequentially 
in  a  file  that  is  kept  in  atoMe 
(nonvolatile)  storage  [17]. 
When  a  log  record  is  written, 
the  write  can  be  done  synchronously  or  asyn- 
chronously.  In  the  former  case, called  forcing  a  log  record,  the  forced  log  record 
and  all  preceding  ones are  immediately  moved  from  the  virtual  memory  buffers 
to stable  storage. The  transaction  writing  the  log record  is not  allowed  to continue 
execution  until  this  operation  is  completed.  This  means  that,  if  the  site  crashes 
(assuming  that  a crash  results  in  the  loss of  the  contents  of  the  virtual  memory) 
after  the  force-write  has completed,  then  the  forced  record and  the  ones preceding 
it  will  have  survived  the  crash  and  will  be  available,  from  the  stable  storage, 
when  the  site  recovers.  It  is  important 
to  be able  to  “batch”  force-writes  for  high 
performance  [ 111. R*  does rudimentary  batching  of  force-writes. 
On  the  other  hand,  in  the  asynchronous  case, the  record  gets written  to  virtual 
memory  buffer  storage  and  is  allowed  to  migrate  to  the  stable  storage  later  on 
(due  to  a  subsequent  force  or  when  a  log  page buffer  fills  up).  The  transaction 
writing 
the  record  is  allowed  to  continue  execution  before  the  migration 
takes 
place.  This  means  that,  if  the  site  crashes  after  the  log  write,  then  the  record 
may  not  be  available  for  reading  when  the  site  recovers.  An  important  point  to 
note  is  that  a  synchronous  write 
the  response  time  of  the  transaction 
compared  to  an  asynchronous  write.  Hereafter,  we refer  to  the  latter  as simply  a 
write  and  the  former  as a force-write. 
Several  commit  protocols  have been proposed  in  the  literature,  and  some have 
been  implemented 
[8,  16,  17,  19,  23,  26,  271. These  are  variations  of  what  has 
come to  be known  as the  two-phase  (2P)  commit  protocol.  These protocols  differ 
in  the  number  of messages sent, the  time  for  completion  of the  commit  processing, 
the  level  of  parallelism  permitted  during  the  commit  processing,  the  number  of 
state  transitions 
that  the  protocols  go  through,  the  time  required  for  recovery 
once a site  becomes operational  after  a failure,  the  number  of  log  records written, 
and  the  number  of  those  log  records  that  are  force-written 
to  stable  storage.  In 
general,  these  numbers  are  expressed  as  a  function  of  the  number  of  sites  or 
processes involved  in  the  execution  of  the  distributed  transaction. 
Some of  the  desirable  characteristics  in  a commit  protocol  are  (1)  guaranteed 
transaction  atomicity  always,  (2) ability  to  “forget”  outcome of commit  processing 
after  a  short  amount  of  time,  (3)  minimal  overhead  in  terms  of  log  writes  and 
message traffic,  (4) optimized  performance  in  the  no-failure  case, (5) exploitation 
of completely  or  partially  read-only  transactions,  and  (6)  maximizing  the  ability 
to  perform  unilateral  aborts. 

ACM  Transactions  on Database  Systems, Vol.  11, No.  4, December  1986. 

380 

l 

C. Mohan  et  al. 

This  paper  concentrates  on  the  performance  aspects  of  commit  protocols, 
especially  the  logging  and  communication  performance  during  no-failure  situa- 
tions.  We  have  been careful  in  describing  when  and  what  type  of  log  records  are 
written.  The  discussions  of  commit  protocols  in  the  literature  are  very  vague,  if 
there  is  any  mention  at  all,  about  this  crucial  (for  correctness  and  performance) 
aspect  of  the  protocols.  We  also  exploit  the  read-only  property  of  the  complete 
transaction  or  some of  its  processes, In  such  instances,  one can 
from  the 
fact  that  for  such  processes of  the  transaction 
it  does not  matter  whether  the 
transaction  commits  or  aborts,  and  hence  they  can  be excluded  from  the  second 
phase of  the  commit  protocol.  This  also means  that  the  (read)  locks  acquired  by 
such  processes can  be  released  during  the  first  phase.  No  a priori  assumptions 
are made about  the  read-only  nature  of  transactions.  Such  information 
is discov- 
ered only  during  the  first  phase of  the  commit  protocol. 
Here,  we  suggest  that  complicated  protocols  developed  for  dealing  with  rare 
kinds  of  failures  during  commit  coordination  are  not  worth  the  costs  that  they 
impose  on  the  processing  of  distributed 
transactions  during  normal  times  (i.e., 
when  no  failures  occur).  Multilevel  hierarchical  commit  protocols  are  also  sug- 
gested to  be more  natural  than  the  conventional 
two-level  (one  coordinator  and 
a  set  of  subordinates)  protocols.  This  stems  from  the  fact  that  the  distributed 
query  processing  algorithms  are  efficiently 
implemented  as a tree  of  cooperating 
processes. 
With  these  goals  in  mind,  we  extended  the  conventional  2P  commit  protocol 
to  support  a tree  of processes [18]  and  defined  the  Presumed  Abort  (PA)  and  the 
Presumed  Commit  (PC)  protocols  to  improve  the  performance  of  distributed 
transaction  commit. 
R*,  which  is  an  evolution  of  the  centralized  DBMS  System  R  [5],  like  its 
predecessor, supports  transaction  serializability  and  uses the  two-phase  locking 
(2PL)  protocol 
[lo]  as  the  concurrency  control  mechanism.  The  use  of  2PL 
introduces 
the  possibility  of  deadlocks.  R*,  instead  of  preventing  deadlocks, 
allows  them  (even  distributed  ones)  to  occur  and  then  resolves them  by  deadlock 
detection  and  victim  transaction  abort. 
Some  of  the  desirable  characteristics 
in  a  distributed  deadlock  detection 
protocol  are  (1)  all  deadlocks  are  resolved  in  spite  of  site  and  link 
failures, 
(2)  each  deadlock  is  detected  only  once,  (3)  overhead  in  terms  of  messages 
exchanged  is small,  and  (4) once a distributed  deadlock  is detected the  time  taken 
to  resolve  it  (by  choosing  a victim  and  aborting  it)  is  small. 
The  general  features  of  the  global  deadlock  detection  algorithm  used in  R*  are 
described  in  [24].  Here  we  concentrate  on  the  specific  implementation  of  that 
distributed  algorithm 
in  R*  and  the  solution  adopted  for  the  global  deadlock 
victim  selection  problem.  In  general,  as  far  as  global  deadlock  management  is 
concerned,  we  suggest  that  if  distributed  detection  of  global  deadlocks  is  to  be 
performed  then,  in  the  event  of  a  global  deadlock,  it  makes  sense to  choose as 
that  is  local to 
the  victim  a transaction 
the  site  of  detection  of  that  deadlock  (in 
preference  to,  say,  the  “youngest” 
transaction  which  may  be  a  nonlocal  trans- 
action),  assuming  that  such  a local  transaction  exists. 
The  rest  of  this  paper  is  organized  as follows.  First,  we give  a careful  presen- 
tation  of 2P. Next,  we derive  from  2P in  a stepwise  fashion  the  two  new protocols, 
namely,  PA  and  PC.  We  then  present  performance  comparisons,  optimizations, 
on  Database  Systems,  Vol.  11,  No.  4,  December  1986. 
ACM  Transactions 

Transaction  Management  in  the  R* Distributed  Database  Management  System 

l 

381 

and  extensions  of  PA  and  PC.  Next,  we  present  the  R*  approach  to  global 
deadlock  detection  and  resolution.  We  then  conclude  by  outlining 
the  current 
status  of  R*. 

2.  THE  TWO-PHASE  COMMIT  PROTOCOL 
In  2P,  the  model  of  a distributed 
transaction  execution  is  such  that  there  is  one 
process, called  the  coordinator, 
that  is  connected  to  the  user  application  and  a 
set of other  processes, called  the  subordinates.  During  the  execution  of the  commit 
protocol  the  subordinates  communicate  only  with  the  coordinator,  not  among 
themselves.  Transactions  are  assumed  to  have  globally  unique  names.  The 
processes are  assumed  to  have  globally  unique  names  (which  also  indicate  the 
locations  of  the  corresponding processes; 
the  processes do  not  migrate  from  site 
the  processes  together  accomplish  the  actions  of  a  distributed 

to  site).’  All 
transaction. 

2.1  2P Under Normal Operation 
First,  we describe the protocol  without  considering  failures.  When  the  user decides 
the  coordinator,  which  receives  a  commit-transaction 
to  commit  a  transaction, 
command  from  the  user,  initiates 
the  first  phase  of  the  commit  protocol  by 
sending 
PREPARE  messages, in  parallel, 
to  the  subordinates 
to  determine 
to  commit  the  transaction.2  Each  subordinate  that  is 
whether  they  are  willing 
willing  to  let  the  transaction  be committed  first 
force-writes  a prepare 
log  record 
and  then  sends a  YES  VOTE  to  the  coordinator  and  waits  for  the  final  decision 
(commit/abort) 
from  the  coordinator.  The  process  is  then  said  to  be  in  the 
state,  and  it  cannot  unilaterally  commit  or  abort  the  transaction.  Each 
prepared 
subordinate  that  wants  to  have  the  transaction  aborted  force-writes  an  abort 
record  and  sends a NO  VOTE  to  the  coordinator.  Since  a NO  VOTE  acts  like  a 
veto,  the  subordinate  knows  that  the  transaction  will  definitely  be  aborted  by 
the  coordinator.  Hence  the  subordinate  does not  need  to  wait  for  a  coordinator 
the  local  effects  of  the  transaction.  Therefore, 
response  before  aborting 
the 
subordinate  aborts  the  transaction, 
releases  its  locks,  and  “forgets” 
it  (i.e.,  no 
information  about  this  transaction 
is  retained  in  virtual  storage). 
After  the  coordinator  receives  the  votes  from  all  its  subordinates,  it  initiates 
the  second phase  of  the  protocol.  If  all  the  votes  were  YES  VOTES,  then  the 
coordinator  moves  to  the  committing 
state  by  force-writing  a  commit  record 
and  sending  COMMIT  messages to  all  the  subordinates.  The  completion  of  the 
force-write  takes  the  transaction  to  its  commit  point.  Once this  point  is  passed 
the  user  can  be told  that  the  transaction  has been committed.  If  the  coordinator 
then  it  moves to  the  aborting 
had  received  even  one NO  VOTE, 
state  by  force- 
writing  an  abort  record  and  sends ABORTS 
to  [only)  all  the  subordinates  that 
are  in  the  prepared 
state  or  have  not  responded  to  the  PREPARE.  Each 
subordinate,  after  receiving  a  COMMIT,  moves  to  the  committing 
state, 

has  only 
’  For  ease  of  exposition,  we  assume  that  each  site  participating 
transaction 
in  a  distributed 
transaction.  However, 
one  process  of  that 
the  protocols  presented  here  have  been  implemented 
in 
R*,  where 
this  assumption 
is  relaxed 
to  permit  more  than  one  such  process  per  site. 
latter  sends  an 
to  abort 
wants 
21n  cases  where 
the 
transaction, 
the 
the  user  or  the  coordinator 
ABORT  message  to  each  of  the  subordinates. 
is  resubmitted  after  being  aborted, 
If  a  transaction 
it  is 
given  a  new  name. 

ACM  Transactions  on Database  Systems, Vol.  11, No.  4, December  1986. 

382 

l 

C.  Mohan  et  al. 

force-writes  a  commit  record,  sends an  acknowledgment  (ACK)  message to  the 
coordinator,  and then  commits  the  transaction  and  “forgets”  it.  Each subordinate, 
after  receiving  an  ABORT,  moves  to  the  aborting 
state,  force-writes  an  abort 
record,  sends  an  ACK  to  the  coordinator,  and  then  aborts  the  transaction  and 
“forgets”  it.  The  coordinator,  after  receiving  the  ACKs  from  all  the  subordinates 
that  were  sent  a message in  the  second phase  (remember  that  subordinates  who 
voted  NO  do not  get any  ABORTS  in  the  second phase), writes  an  end record  and 
“forgets”  the  transaction. 
By  requiring  the  subordinates  to  send AC%,  the  coordinator  ensures that  all 
the  subordinates  are  aware  of  the  final  outcome.  By  forcing  their  commit/abort 
records before  sending  the ACKs,  the  subordinates  make sure that  they  will  never 
be  required  (while  recoveripg  from  a  processor  failure) 
to  ask  the  coordinator 
about  the  final  outcome  after  having  acknowledged  a  COMMIT/ABORT. 
The 
general  principle  on  which  the  protocols  described  in  this  paper  are based is  that 
if  a  subordinate  acknowledges  the  receipt  of  any  particular  message,  then  it 
should  make  sure  (by  forcing  a  log  record  with  the  information 
in  that  message 
before sending  the  ACK)  that  it  will  never  ask  the  coordinator  about  that  piece 
of  information. 
If  this  principle 
is  not  adhered  to,  transaction  atomicity  may  not 
be guaranteed. 
The  log  records  at  each site  contain  the  type  (prepare,  end, etc.)  of  the  record, 
the  identity  of  the  process  that  writes  the  record,  the  name  of  the  transaction, 
the  identity  of  the  coordinator, 
the  names  of  the  exclusive  locks  held  by  the 
writer  in  the  case of  prepare  records,  and  the  identities  of  the  subordinates  in 
the  case of  the  commit/abort  records written  by  the  coordinator. 
To  summarize,  for  a  committing 
the  execution  of  the 
transaction,  during 
protocol,  each subordinate  writes  two  records  (prepare  and  commit,  both  of which 
are  forced)  and  sends  two  messages (YES  VOTE  and  ACK).  The  coordinator 
sends two  messages (PREPARE  and  COMMIT) 
to  each  subordinate  and  writes 
two  records  (commit,  which  is  forced,  and  end, which  is  not). Figure 1  shows  the  message flows  and  log  writes  for  an  example  transaction 
following  2P. 

2.2  2P  and  Failures 
Let  us  now  consider  site  and  communication 
failures.  We  assume that  at 
link 
each active  site  a  recovery process exists  and  that  it  processes all  messages from 
recovery  processes  at  other  sites  and  handles  all  the  transactions 
that  were 
executing  the  commit  protocol  at  the  time  of  the  last  failure  of  the  site.  We 
assume  that,  as  part  of  recovery  from  a  crash,  the  recovery  process  at  the 
recovering  site  reads the  log  on  stable  storage and  accumulates  in  virtual  storage 
information 
relating  to  transactions  that  were executing  the  commit  protocol  at 
the  time  of  the  crash.3  It  is  this  information 
in  virtual  storage  that  is  used  to 
answer  queries  from  other  sites  about  transactions 
that  had  their  coordinators 
to  other  sites  that  had  subordi- 
at  this  site  and  to  send  unsolicited 
information 
nates  for  transactions 
that  had  their  coordinators  at  this  site.  Having 
the 

3 The  extent  of  the  log  that  has  to  be  read  on  restart  can  be  controlled 
normal  operation 
[14,  151.  The 
log  is  scanned 
forward 
starting 
from 
crash  until 
the  end  of  the  log. 

by  taking  checkpoints  during 
the  last  checkpoint 
before 
the 

ACM  Transactions  on Database  Systems, Vol.  11,  No.  4,  December  1986. 

Transaction  Management  in  the  R’  Distributed  Database  Management  System 

l 

383 

2P  Example 

in 
in  2P.  The  names 
flows  and  log  writes 
Fig.  1.  Message 
the  types  of  log  records  written.  An  *  next 
indicate 
italics 
to 
the  record 
to  stable 
type  means 
that 
the  record 
is  forced 
storage. 

information 
in  virtual  storage allows  remote site 
inquiries  to be answered quickly. 
There  will  be no  need to  consult  the  log  to  answer  the  queries. 
When  the  recovery  process finds  that  it  is in  the 
state  for  a particular 
prepared 
transaction, 
tries  to  contact  the  coordinator  site  to  find  out  how 
it  periodically 
the  transaction  should  be  resolved.  When  the  coordinator  site  resolves  a  trans- 
action  and  lets  this  site  know  the  ‘final  outcome,  the  recovery  process takes  the 
steps outlined  before  for  a  subordinate  when  it  receives  an  ABORT/COMMIT. 
If  the  recovery  process finds  that  a  transaction  was executing  at  the  time  of  the 
crash and  that  no  commit  protocol  log  record  had been written,  then  the  recovery 
process neither  knows  nor  cares whether  it  is  dealing  with  a  subordinate  or  the 
coordinator  of the  transaction.  It  aborts  that  transaction  by  “undoing”  its  actions, 
if  any,  using  the  UNDO  log  records, writing  an  abort  record,  and  “forgetting” 
it.4 
If  the  recovery  process  finds  a  transaction 
in  the  committing 
(respectively, 
to  all  the 
tries  to  send  the  COMMIT 
state,  it  periodically 
aborting) 
(ABORT) 
subordinates  that  have  not  acknowledged  and  awaits  their  ACKs.  Once  all  the 

first  and  then  write  a prepare 
cannot  send  a  YES  VOTE 
4 It  should  be  clear  now  why  a  subordinate 
the  commit  record. 
first  and  then  write 
cannot  send  a  COMMIT 
record,  and  why  a  coordinator 
If 
such  actions  were  permitted, 
the  log  write  may 
the  message  sending  but  before 
then  a  failure  after 
result 
in  the  wrong  action  being  taken  at  restart;  some  sites  might  have  committed  and  others  may 
abort. 

ACM  Transactions  on Database  Systems, Vol.  11, No.  4, December  1986. 

Coordinator 

Subordinate 

PREPARE 

384 

9 

C. Mohan  et  al. 

ACKs  are  received,  the  recovery  process writes  the  end  record  and  “forgets”  the 
transaction. 
In  addition  to  the  workload  that  the  recovery  process accumulates  by  reading 
the  log  during  restart,  it  may  be  handed  over  some transactions  during  normal 
operation  by  local  coordinator  and  subordinate  processes that  notice  some link 
or  remote  site  failures  during 
the  commit  protocol  (see  [I$%] for  information 
relating 
to  how  such  failures  are  noticed).  We  assume  that  all  failed  sites 
ultimately 
recover. 
If  the  coordinator  process notices  the  failure  of a subordinate  while  waiting  for 
the  latter  to  send  its  vote,  then  the  former  aborts  the  transaction  by  taking  the 
previously  outlined  steps. If  the  failure  occurs when  the  coordinator  is waiting  to 
get  an  ACK, 
then  the  coordinator  hands  the  transaction  over  to  the  recovery 
process. 
If  a subordinate  notices  the  failure  of  the  coordinator  before  the  former  sent  a 
YES  VOTE  and  moved  into  the  prepared 
state,  then  it  aborts  the  transaction 
(this  is called  the  unilateral  abort  feature).  On  the  other  hand,  if  the  failure  occurs 
after  the  subordinate  has moved  into  the  prepared 
state,  then  the  subordinate 
hands  the  transaction  over  to  the  recovery  process. 
When  a  recovery  process  receives  an  inquiry  message  from  a  prepared 
subordinate  site,  it  looks  at  its  information 
in  virtual  storage. If  it  has information 
that  says the  transaction 
state,  then  it  sends 
or  committing 
is  in  the  aborting 
the  appropriate  response. The  natural  question  that  arises  is what  action  should 
be  taken  if  no  information 
is  found  in  virtual  storage  about  the  transaction. 
Let  us see when  such a situation  could  arise.  Since both  COMMITS  and ABORTS 
is  being  made means  that  the 
are  being  acknowledged,  the  fact  that  the  inquiry 
inquirer  had  not  received  and  processed a COMMIT/ABORT 
before  the  inquiree 
the  transaction.  Such  a  situation  comes  about  when  (1)  the  inquiree 
“forgot” 
sends out  PREPARES, 
(2)  it  crashes before  receiving  all  the  votes  and  deciding 
to  commit/abort,  and  (3) on  restart,  it  aborts  the  transaction  and  does not  inform 
any  of  the  subordinates.  As  mentioned  before,  on  restart,  the  recipient  of  an 
inquiry  cannot  tell  whether 
it  is  a  coordinator  or  subordinate, 
if  no  commit 
protocol  log  records exist  for  the  transaction.  Given  this  fact,  the  correct  response 
to  an  inquiry 
in  the  no  information 
case is  an ABORT. 

2.3  Hierarchical  2P 
2P  as  described  above  is  inadequate  for  use  in  systems  where  the  transaction 
execution  model  is  such  that  multilevel 
(>2)  trees  of processes are possible,  as in 
R*  and  ENCOMPASS 
[8].  Each  process  communicates  directly  with  only  its 
immediate  neighbors  in  the  tree,  that  is,  parent  and  children.  In  fact,  a process 
would  not  even  know  about  the  existence  of  its  nonneighbor  processes. There  is 
a  simple  extension  of  2P  that  would  work  in  this  scenario.  In  the  hierarchical 
version  of 2P, the  root  process that  is 
to  the  user/application  acts only 
as a  coordinator, 
the  leaf  processes act  only  as  subordinates,  and  the  nonleaf, 
nonroot  processes act  as both  coordinators  (for  their  child  processes)  and  sub- 
ordinates  (for  their  parent  processes). The  root  process  and  the  leaf  processes 
act  as  in  nonhierarchical  2P.  A  nonroot,  nonleaf  process  after  receiving  a 
PREPARE  propagates  it  to  its  subordinates  and  only  after  receiving  their  votes 
ACM  Transactions  on  Database  Systems, Vol.  11, No.  4, December  19%. 

Transaction  Management  in  the  R”  Distributed  Database  Management  System 

l 

385 

does it  send  its  combined  (i.e.,  subtree)  vote  to  its  coordinator.  The  type  of  the 
subtree  vote  is  determined  by  the  types  of  the  votes  of  the  subordinates  and  the 
type  of  the  vote  of  the  subtree’s  root  process.  If  any  vote  is  a NO  VOTE,  then 
the  subtree  vote  is  a NO  VOTE  also  (in  this  case, the  subtree  root  process, after 
sending  the  subtree  vote  to  its  coordinator,  sends ABORTS  to  all  those  subordi- 
nates that  voted  YES).  If  none  of the  votes  is a NO  VOTE,  then  the  subtree  vote 
is  a  YES  VOTE.  A  nonroot,  nonleaf  process in  the  prepared  state,  on  receiving 
an  ABORT  or  a  COMMIT,  propagates  it  to  its  subordinates  after  force-writing 
its  commit  record  and  sending  the  ACK  to  its  coordinator. 

THE  PRESUMED  ABORT  PROTOCOL 
In  Section  2.2  we  noticed  that, 
in  the  absence  of  any  information  about  a 
transaction, 
the  recovery  process  orders  an  inquiring  subordinate  to  abort.  A 
careful  examination  of this  scenario  reveals the  fact  that  it  is safe for  a coordinator 
to  “forget”  a transaction  immediately  after  it  makes the  decision  to  abort  it  (e.g., 
by  receiving  a NO  VOTE)  and  to  write  an  abort  record.’  This  means  that  the 
abort  record  need  not  be  forced  (both  by  the  coordinator  and  each  of  the 
subordinates),  and  no  ACKs  need to  be sent  (by  the  subordinates)  for  ABORTS. 
Furthermore, 
the  coordinator  need not  record  the  names of  the  subordinates  in 
the  abort  record  or  write  an  end  record  after  an  abort  record.  Also,  if  the 
coordinator  notices  the  failure  of  a  subordinate  while  attempting 
to  send  an 
ABORT  to  it,  the  coordinator  does not  need  to  hand  the  transaction  over  to  the 
recovery  process.  It  will  let  the  subordinate  find  out  about  the  abort  when  the 
recovery  process  of  the  subordinate’s  site  sends an  inquiry  message. Note  that 
the  changes  that  we  have  made  so far  to  the  2P  protocol  have  not  changed  the 
performance  (in  terms  of  log  writes  and  message sending)  of  the  protocol  with 
respect  to  committing 
transactions. 
Let  us now  consider  completely  or partially  read-only  transactions  and see how 
of  the  transaction  do  not  perform  any  updates  to  the  database while 
if  some processes 
read-only 
is  partially 
we  can  take  advantage  of  them.  A  transaction 
the  others  do.  A  transaction 
is  (completely) 
read-only 
if  no  process  of  the 
transaction  performs  any  updates. We do not  need to  know  before the  transaction 
starts  whether  it  is  read-only  or  not.6 If  a leaf  process receives a PREPARE  and 
it  finds  that  it  has not  done any  updates  (i.e., no UNDO/REDO 
log  records  have 
been written), 
then  it  sends a READ  VOTE,  releases its  locks,  and  “forgets”  the 
transaction.  The  subordinate  writes  no  log  records.  As  far  as it  is  concerned,  it 
does not  matter  whether  the  transaction  ultimately  gets aborted  or  committed. 
So the  subordinate,  who  is  now  known  to  the  coordinator  to  be  read-only,  does 
not  need to  be sent  a COMMIT/ABORT  by  the  coordinator.  A  nonroot,  nonleaf 
sends a READ  VOTE  only  if  its  own  vote  and  those  of  its  subordinates’  are also 
READ  VOTES. Otherwise,  as long  as none  of  the  latter  is  a NO  VOTE,  it  sends 
a  YES  VOTE. 

’  Remember 
(during  normal  execution) 
in  2P  the  coordinator 
that 
sure  that  all  the  subordinates  are  aware  of  the  abort  decision. 
6 If  the  program  contains  conditional 
the  same  program  during  different  executions  may 
statements, 
be  either 
read-only  or  update  depending  on  the  input  parameters  and  the  database  state. 

an  abort  only  after 

“forgets” 

it  is 

ACM  Transactions  on Database  Systems, Vol.  11, No.  4, December  1986. 

386 

l 

C.  Mohan  et  al. 

Root  Process 

Leaf  Process 

(read-only1 

cmmil* 

- 

end 

COMMITTING 

L 

Non-Root, 

Non-Leaf 

Process 

abort 

ccmamif  x 
___I) 

COMMITTING 

end 

I 

State  Changes  and  Log  Writes 
for  Presumed  Abort 

indicate 
the  types  of  log 
diagrams 
Fig.  2.  The  names  in  italics  on  the  arcs  of  the  state-transition 
to  stable  storage.  No  log 
is  forced 
type  means  that  the  record 
records  written.  An  *  next 
to  the  record 
In  such  cases,  information 
records  are  written  during  some  transitions. 
in  parentheses 
indicates  under 
what  circumstances 
such  transitions 
take  place.  IDLE 
is  the  initial  and  final  state  for  each  process. 

There  will  not  be  a  second  phase  of  the  protocol  if  the  root  process  is  read- 
only  and  it  gets  only  READ  VOTES.  In  this  case the  root  process, just  like  the 
other  processes, writes  no  log  records  for  the  transaction.  On  the  other  hand,  if 
the  root  process or  one of  its  subordinates  votes  YES  and  none  of  the  others  vote 
NO,  then  the  root  process behaves  as in  2P.  But  note  that  it  is  sufficient 
for  a 
nonleaf  process  to  include  in  the  commit  record  only  the  identities  of  those 
subordinates 
(if  any)  that  voted  YES  (only 
those  processes  will  be  in  the 
prepared  state, and  hence only  they  will  need to be sent COMMITS).  If  a nonleaf 
process or  one of its  subordinates  votes NO,  then  the  former  behaves as described 
earlier  in  this  section. 
To  summarize,  for  a  (completely)  read-only  transaction,  none  of  the  processes 
write  any  log  records,  but  each  one  of  the  nonleaf  processes sends one  message 
(PREPARE) 
to  each  subordinate  and  each  one  of  the  nonroot  processes sends 
one message (READ  VOTE). 
the  root  process sends  two 
read-only  transaction, 
For  a committing  partially 
messages (PREPARE  and  COMMIT) 
to  each update  subordinate  and  one  mes- 
sage (PREPARE)  to  each of the  read-only  subordinates.  Each  one of the  nonleaf, 
ACM  Transactions  on  Database  Systems,  Vol.  11,  No.  4,  December  1986. 

Transaction  Management  in  the  R*  Distributed  Database  Management  System 

l 

387 

Presumed 

Commit 

Example 

Presumed 

Abort  Example 

in  PA  and  PC.  A  (update/read-only) 
Fig.  3.  Message  flows  and  log  writes 
is  the  root  of  the  process 
is  the  leaf  of  the  tree  and  the  child  of  B. 
tree  with  B  (update)  as  its  child.  C  (read-only) 

is  the  root  of  an  update  subtree  sends  two  messages 
nonroot  processes  that 
(PREPARE  and  COMMIT) 
to  each  update  subordinate,  one  message (PRE- 
PARE)  to  each  of  the  other  subordinates,  and  two  messages (YES  VOTE  and 
ACK)  to  its  coordinator.  Each  one  of  the  nonleaf,  nonroot  processes that  is  the 
root  of  a  read-only  subtree  behaves  just  like  the  corresponding  processes in  a 
completely  read-only  transaction  following  PA.  Each  one of the  nonleaf  processes 
writes  three  records  (prepare  and  commit,  which  are  forced,  and  end,  which  is 
not)  if  there  is  at  least  one  update  subordinate,  and  only  two  records  (prepare 
and  commit,  which  are  forced)  if  the  nonleaf  process itself  is  an  update  one  and 
it  does not  have  any  update  subordinates.  A  read-only  leaf  process behaves just 
following  PA,  and  an  update 
like  the  one  in  a completely  read-only  transaction 
leaf process behaves like  a subordinate  of  a committing 
transaction 
in  2P. 
By  making  the  above  changes  to  hierarchical  2P,  we  have  generated  the  PA 
protocol.  The  name  arises  from  the  fact  that  in  the  no  information 
case  the 
transaction 
is  presumed  to  have  aborted,  and  hence  the  recovery  process’s 
response to  an  inquiry  is an ABORT.  Figure  2 shows the  state  transitions  and  log 
writes  performed  by  the  different  processes following  PA.  Figure  3  shows  the 
following  PA. 
message flows  and  log writes  for  an  example  transaction 

4.  THE  PRESUMED  COMMIT  PROTOCOL 
Since  most  transactions  are  expected  to  commit,  it  is  only  natural  to  wonder  if, 
by  requiring  ACKs  for  ABORTS,  commits  could  be made cheaper  by  eliminating 
the  ACKs  for  COMMITS.  A  simplistic  idea that  comes to  mind  is  to  require  that 
ABORTS  be  acknowledged,  while  COMMITS  need  not  be,  and  also  that  abort 
records  be  forced  while  commit  records  need  not  be  by  the  subordinates.  The 
consequences are that,  in  the  no  information 
case, the  recovery process responds 
with  a  COMMIT  when  a  subordinate 
inquiries.  There  is, however, a  problem 
with  this  approach. 
Consider  the  situation  when  a  root  process  has  sent  the  PREPARES,  one 
subordinate  has  gone  into  the 
state,  and  before  the  root  process  is 
prepared 
able  to  collect  all  the  votes  and  make  a decision,  the  root  process crashes. Note 
ACM  Transactions  on Database  Systems, Vol.  11, No.  4, December  1986. 

388 

l 

C. Mohan  et  al. 

that  so  far  the  root  process  would  not  have  written  any  commit  protocol  log 
records.  When  the  crashed  root  process’s site  recovers,  its  recovery  process will 
abort  this 
transaction  and  “forget” 
it  without 
informing  anyone,  since  no 
information 
is  available  about  the  subordinates.  When  the  recovery  process  of 
the  prepared  subordinate’s  site  then  inquires  the  root  process’s site,  the  latter’s 
recovery  process  would  respond  with  a  COMMIT,7 
causing  an  unacceptable 
inconsistency. 
The  way  out  of  this  problem  is  for  each  coordinator  (i.e.,  nonleaf  process)  to 
record  the  names of  its  subordinates  safely  before  any  of  the  latter  could  get into 
the  prepared  state.  Then,  when  the  coordinator  site  aborts  on  recovery  from  a 
crash  that  occurred  after  the  sending  of  the  PREPARES 
(but  before  the  coordi- 
nator  moved  into  the  prepared  state,  in  the  case of  the  nonroot  coordinators), 
the  restart  process  will  know  who  to  inform  (and  get  ACKs)  about  the  abort. 
These  modifications  give  us  the  PC protocol.  The  name  arises  from  the  fact  that 
in  the  no  information 
case the  transaction 
is presumed  to  have  committed  and 
hence the  response to  an  inquiry 
is  a COMMIT. 
In  PC,  a  nonleaf  process behaves  as in  PA  except  (1)  at  the  start  of  the  first 
phase  (i.e.,  before  sending  the  PREPARES) 
it  force-writes  a  collecting 
record, 
which  contains  the  names of  all  the  subordinates,  and  moves into  the  collecting 
state;  (2)  it  force-writes  only  abort  records  (except  in  the  case of  the  root  process, 
which  force-writes  commit  records  also);  (3)  it  requires  ACKs  only  for  ABORTS 
(4)  it  writes  an  end  record  only  after  an  abort  record  (if 
and  not  for  COMMITS; 
record  is  written)  and  not  after  a  commit 
the  abort  is  done  after  a  collecting 
record;  (5)  only  when  in  the  aborting 
state  will  it,  on  noticing  a  subordinate’s 
to  the  restart  process; and  (6)  in  the  case of  a 
failure,  hand  over  the  transaction 
(completely)  read-only  transaction, 
it  would  not  write  any  records  at  the  end  of 
the  first  phase  in  PA,  but  in  PC  it  would  write  a commit  record  and  then  “forget” 
the  transaction. 
The  subordinates  behave  as in  PA  except  that  now  they force-write only 
abort 
records and not  commit  records, and they  ACK  only  ABORTS  and not  COMMITS. 
On  restart,  if  the  recovery  process finds,  for  a particular 
transaction,  a collecting 
record  and  no  other  records  following 
it,  then  it  force-writes  an  abort  record, 
informs  all  the  subordinates,  gets ACKs 
from  them,  writes  the  end  record,  and 
“forgets” 
case,  the  recovery  process 
In  the  no  information 
the  transaction. 
responds  to  an  inquiry  with  a COMMIT. 

(collecting,  which  is  forced,  and  commit,  which  is 
not)  and  sends one message (PREPARE) 
to  each subordinate.  Furthermore,  each 
one  of  the  nonleaf,  nonroot  processes sends  one  more  message (READ  VOTE). 
The  leaf  processes write  no  log  records,  but  each one of  them  sends one message 
to  its  coordinator. 
(READ  VOTE) 

is  the  same  as  when  a  root 
is 
this  situation 
that,  as  far  as  the  recovery  process 
‘Note 
the  names  of  the  subordi- 
(which  now  will  not  contain 
a  commit 
force-writing 
process,  after 
record 
“forgets” 
nates), 
it  has  crashed,  and 
subordinate, 
tries 
to  inform 
a  prepared 
finds 
therefore 
the 
transaction 
(i.e.,  does  not  hand  it  to  the  recovery  process).  Later  on,  when 
the  subordinate 
inquires, 
respond  with  a  COMMIT. 
and  hence  would 
find  no  information 
the  recovery  process  would 

ACM  Transactions 

on  Database  Systems,  Vol.  11,  No.  4,  December  1986. 

To  summarize,  for  a (completely)  read-only  transaction,  each one of the  nonleaf 
processes writes  two  records 

Transaction  Management  in  the  R’  Distributed  Database  Management  System 
CmIwrvMO 
Root  Process 
abo+( 
m 
COLLECTING- 
IDLE- 
ABORTING 

Leaf  Process 

l 

389 

Non-Root, 

Non-Leaf 

Process 

IDLE  - 

cornmU 

prCpZr*. 
COLLECTING- 

abort+ 
PREPARED- 

ABORTING 

abort 

and 

State  Changes and  Log Writes 
for  Presumed Comnit 

Figure  4 

the  root  process writes  two 
For  a  committing  partially 
read-only  transaction, 
records  (collecting  and  commit,  both  of which  are forced) 
sends two  messages 
(PREPARE  and  COMMIT) 
to  each subordinate  that  sent  a  YES  VOTE  and  one 
to  each  one  of  the  other  subordinates.  Each  one  of  the 
message (PREPARE) 
is  the  root  of  an  update  subtree  sends  two 
nonleaf,  nonroot  processes  that 
messages (PREPARE  and  COMMIT) 
to  each  subordinate 
that  sent  a  YES 
VOTE,  one message (PREPARE)  to  each one of  the  other  subordinates,  and  one 
message (YES  VOTE)  to  its  coordinator,  and  it  writes  three  records  (collecting 
and  prepared,  which  are  forced,  and  commit,  which 
is  not).< Read-only 
leaf 
processes, and processes that  are roots  of  read-only  subtrees, behave just  like  the 
corresponding  processes in  a  completely  read-only  transaction.  An  update  leaf 
process sends one message (YES  VOTE)  and writes  two  records  (prepare,  which 
is  forced,  and  commit,  which  is  not). 
Figure  4 shows the  state  transitions  and  log  writes  performed  by  the  different 
processes following  PC.  Figure  3 shows  the  message flows  and  log  writes  for  an 
example  transaction  following  PC. 
ACM  Transactions  on Database  Systems, Vol.  11, No.  4, December  1986. 

390 

l 

C. Mohan et  al. 

U 

-  Update 

Transaction 

R 

-  Read-Only 

Transaction 

RS 

-  Read-Only 

Subordinate 

US 

-  Update 

Subordihate 

mrnroIp 

-  m  Records 

Written, 

n  of 

Them 

Forced 

o  For 

a  Coordinator: 

I  of  Messages 

a  Subordinate: 

I  of  Messages 

Each  RS 

Sent 

Sent 

to 

to 

P  #  of  Messages 

Sent 

to 

Each 

US 

Coordinator 

Fig.  5.  Comparison  of  log  I/O  and  messages  for  committing 
tions  with  2P,  PA,  and  PC. 

two-level  process  tree  transac- 

5.  DISCUSSION 
In  the  table  of  Figure  5 we summarize  the  performance  of  2P,  PA,  andSC  with 
respect  to  committing  update  and  read-only 
transactions 
that  have  two-level 
process trees.  Note  that  as far  as 2P  is  concerned  all  transactions  appear  to  be 
completely  update  transactions  and  that  under  all  circumstances  PA  is  better 
than  2P. It  is obvious  that  PA  performs  better  than  PC in  the  case of  (completely) 
read-only  transactions  (saving  the  coordinator  two  log  writes,  including  a  force) 
read-only  transactions  in  which  only  the  coordinator 
and  in  the  case of partially 
does any  updates  (saving  the  coordinator  a  force-write). 
In  both  cases, PA  and 
PC  require  the  same number  of  messages to  be sent.  In  the  case of  a transaction 
with  only  one  update  subordinate,  PA  and  PC  are  equal  in  terms  of  log  writes, 
but  PA  requires  an  extra  message (ACK  sent  by  the  update  subordinate).  For  a 
transaction  with  n  >  1 update  subordinates,  both  PA  and  PC  require  the  same 
number  of  records  to  be written,  but  PA  will  force  n  -  1 times  when  PC will  not. 
These  correspond  to  the  forcing  of  the  commit  records  by  the  subordinates.  In 
addition,  PA  will  send n  extra  messages (AC!%). 
on  Database  Systems,  Vol.  11,  No.  4,  December  1986. 
ACM  Transactions 

Transaction  Management  in  the  R* Distributed  Database  Management  System 

l 

391 

Depending  on the  transaction  mix  that  is expected to be run  against  a particular 
distributed  database, the  choice  between  PA  and  PC  can be made. It  should  also 
be  noted  that  the  choice  could  be  made  on  a  transaction-by-transaction 
basis 
(instead  of  on  a systemwide  basis)  at  the  time  of  the  start  of  the  first  phase by 
the  root  process.’  At  the  time  of  starting  a  transaction, 
the  user  could  give  a 
hint(not  a guarantee)  that  it  is  likely  to  be read-only,  in  which  case PA  could  be 
chosen; otherwise  PC could  be chosen. 
It  should  be pointed  out  that  our  commit  protocols  are  blocking  [26]  in  that 
they  require  a prepared  process  that  has  noticed  the  failure  of  its  coordinator 
to  wait  until 
it  can  reestablish  communication  with 
its  coordinator’s  site  to 
determine  the  final  outcome  (commit  or  abort)  of  the  commit  processing  for  that 
transaction.  We  have  extended,  but  not  implemented,  PA  and  PC  to  reduce  the 
probability  of  blocking  by  allowing  a  prepared  process  that  encounters  a 
coordinator  failure  to ask its  peers about  the  transaction  outcome. The  extensions 
require  an  additional  phase  in  the  protocols  and  result  in  more  messages and/or 
synchronous  log  writes  even  during  normal  times.  In  [23]  we  have  proposed  an 
approach  to  dealing  with 
the  blocking  problem  in  the  context  of  the  Highly 
Available  Systems project  in  our  laboratory.  This  approach  makes use of  Byzan- 
tine  Agreement  protocols.  To  some extent  the  results  of  [9]  support  our  conclu- 
sion  that  blocking  commit  protocols  are not  undesirable. 
To  handle  the  rare  situation 
in  which  a  blocked  process  holds  up  too  many 
other  transactions 
from  gaining  access to  its  locked  data,  we  have  provided  an 
interface  that  allows  the  operator  to  find  out  the  identities  of  the  prepared 
processes and  to  forcibly  commit  or  abort  them.  Of  course,  the  misuse  of  this 
facility  could  lead  to  inconsistencies  caused  by  parts  of  a  transaction  being 
committed  while  the  rest  of  the  transaction 
is  aborted.  In  cases where  a  link 
failure  is  the  cause of  blocking,  the  operator  at  the  blocked  site  could  use  the 
telephone  to  find  out  the  coordinator  site’s  decision  and  force  the  same decision 
at  his  or  her  site. 
Given  that  we  have  our  efficient  commit  protocols  PA  and  PC,  and  the  fact 
that  remote  updates  are  expected  or  postulated  to  be  infrequent,  the  time  spent 
executing  the  commit  protocol  is  going  to  be  small  compared  to  the  total  time 
spent  executing  the  whole  transaction.  Furthermore,  site  and  link  failures  cannot 
be frequent  or  long-duration  events  in  a well-designed  and  well-managed  distrib- 
uted  system.  So the  probability  of  the  failure  of  a coordinator  happening  after  it 
sent  PREPARES,  thereby  blocking 
the  subordinates 
that  vote  YES  in  the 
prepared  state  until  its  recovery,  is  going  to  be very  low. 
In  R*,  each site  has one  transaction  manager  (TM)  and  one  or  more  database 
managers  (DBMS).  Each  DBM 
is  very  much  like  System  R  [5]  and  performs 
similar  functions.  TM  is  a new  (to  R*)  component  and  its  function  is  to  manage 
the  commit  protocol,  perform  local  and  global  deadlock  detection,  and  assign 
transaction 
IDS  to  new  transactions  originating  at  that  site.  So  far  we  have 
pretended  that  there  is  only  one  log  file  at  each  site.  In  fact,  the  TM  and  the 

include 
the 
the  nonleaf  processes  should 
‘If 
then 
(as  we  have  done  in  R*), 
is  taken 
this  approach 
name  of  the  protocol  chosen  in  the  PREPARE  message,  and  all  processes  should 
this  name 
include 
in  the 
that  each  one  writes.  The  name  should  also  be  included 
in  the  first  commit  protocol 
log  record 
inquiry  messages  sent  by  restart  processes,  and  this 
information 
is  used  by  a  recovery  process 
in 
in  the  no  information  case. 
responding 
to  an  inquiry 

ACM  Transactions  on Database  Systems, Vol.  11, No.  4, December  1986. 

392 

l 

C. Mohan  et  al. 

DBMS  each have their  own  log  files.  A  transaction  process executes both  the  TM 
code and  one DBM’s  code (for  each DBM  accessed by  a transaction,  one process 
is  created).  The  DBM 
incarnation  of  the  process  should  be  thought  of  as  the 
child  of  the  (local)  TM 
incarnation  of  the  same  process.  When  the  process 
executes  the  TM  code, it  behaves  like  a nonleaf  node  in  the  process tree,  and  it 
writes  only  commit-protocol-related 
records  in  the  TM  log.  When  the  process 
executes  the  DBM  code,  it  behaves  like  a  leaf  node  in  the  process  tree,  and  it 
writes  both  UNDO/REDO 
records.  When 
records  and  commit-protocol-related 
different  processes communicate  with  each  other  during  the  execution  of  the 
commit  protocol,  it  is  actually  the  TM  incarnations  of  those  processes, not  the 
DBM incarnations, 
that  communicate.  The  leaf  nodes of  the  process tree  in  this 
scenario  are  always  DBM  incarnations  of  the  processes, and  the  nonleaf  nodes 
are always  TM  incarnations  of  the  processes. 
In  cases where  the  TM  and  the  DBMS  at  a  given  site  make  use  of  the  same 
file  for  inserting  log information  of all  the  transactions  at that  site  (i.e., a common 
log),  we wanted  to  benefit  from  the  fact  that  the  log  records  inserted  during  the 
execution  of the  commit  protocol  by  the  TM  and  the  DBMS  would  be in  a certain 
order,  thereby  avoiding 
some  synchronous  log writes  (currently,  in  R*,  the  commit 
protocols  have been designed and  implemented  to  take  advantage  of the  situation 
when  the  DBMS  and  the  TM  use the  same log).  For  example,  a DBM  need  not 
force-write  itsprepare  record  since the  subsequent  force-write  of the  TM’sprepare 
record  into  the  same log  will  force  the  former  to  disk.  Another  example  is  in  the 
case of  PC,  when  a process and  all 
subordinates  are  at  the  same site.  In  this 
case, the  former  does not  have  to  force-write  its  collecting  record  since  the  force 
of  the  collecting/prepared  record  by  a subordinate  will  force  it  out. 
With  a common  log,  in  addition  to  explicitly  avoiding  some of  the  synchronous 
writes,  one  can  also  benefit  from  the  batching  effect  of  more  log  records  being 
written  into  a single  file.  Whenever  a log page in  the  virtual  memory  buffers  fills 
up,  we write  it  out  immediately  to  stable  storage. 
If  we  assume  that  processes  of  a  transaction  communicate  with  each  other 
using  virtual  circuits  (as in  R*  [20]),  and  that  new  subordinate  processes may  be 
created  even  at  the  time  of  receipt  of  a PREPARE  message by  a process  (e.g., to 
install  updates  at  the  sites  of  replicated  copies),  then  it  seems reasonable  to  use 
the  tree  structure  to  send  the  commit-protocol-related  messages also  (i.e.,  not 
tree  into  a two-level  tree just  for  the  purposes of the  commit 
flatten  the  multilevel 
protocol).  This 
avoids  the  need  to  set  up  any  new  communication 
channels  just  for  use by  the  commit  protocol.  Furthermore, 
there  is  no  need  to 
make one process in  each site  become responsible  for  dealing  with  commit-related 
[8]). 
messages for  different  transactions  (as in  ENCOMPASS 
Just  as  the  R*  DBMS  take  checkpoints  periodically 
to  bound  DBM  restart 
recovery  time 
[14],  the  R*  TM  also  takes  its  own  checkpoints.  The  TM’s 
checkpoint  records contain  the  list  of active  processes that  are currently  executing 
the  commit  protocol  and  those  processes that  are  in  recovery  (i.e.,  processes in 
the  prepared/collecting 
state  and  processes  waiting 
to  receive  AC& 
from 
subordinates).  Note  that  we do  not  have  to  include  those  transactions  that  have 
not  yet  started  executing  the  commit  protocol.  TM  checkpoints  are taken  without 
completely  stopping  all  TM  activity  (this  is  in  contrast  with  what  happens  in  the 
R*  DBMS).  During  site  restart  recovery,  the  last  TM  checkpoint  record  is  read 
on  Database  Systems,  Vol.  11,  No.  4,  December  1986. 
ACM  Transactions 

Transaction  Management  in  the  R’  Distributed  Database  Management  System 

l 

393 

by  a  recovery  process,  and  a  transaction 
table  is  initialized  with  its  contents. 
Then  the  TM  log  is  scanned  forward  and,  as necessary, new  entries  are added to 
the  transaction  table  or  existing  entries  are modified/deleted.  Unlike  in  the  case 
of  the  DBM  log  (see  [14]),  there  is  no  need  to  examine  the  portion  of  the  TM 
log  before  the  last  checkpoint.  The  time  of  the  next  TM  checkpoint  depends on 
the  number  of  transactions  initiated  since  the  last  checkpoint,  the  amount  of  log 
consumed  since  the  last  checkpoint,  and  the  amount  of  space still  available  in 
the  circular  log  file  on  disk. 

6.  DEADLOCK  MANAGEMENT 
IN  R* 
The  distributed  2PL  concurrency  control  protocol  is used in  R*.  Data  are  locked 
where  they  are  stored.  There  is  no  separate  lock  manager  process. All  locking- 
related  information 
is  maintained 
in  shared  storage where  it  is  accessible to  the 
processes of  transactions.  The  processes themselves  execute  the  locking-related 
code and  synchronize  one  another.  Since  many  processes of  a transaction  might 
be concurrently  active  in  one or  more  sites, more  than  one  lock  request  might  be 
made  concurrently  by  a  transaction. 
It  is  still  the  case that  each  process  of  a 
transaction  will  be  requesting  only  one  lock  at  a time.  A  process might  wait  for 
one of two  reasons: (1) to  obtain  a lock  and  (2)  to  receive a message from  a cohort 
process of  the  same transaction? 
In  this  scenario,  deadlocks,  including  distrib- 
uted/global  ones, are  a  real  possibility.  Once we  chose to  do  deadlock  detection 
instead  of  deadlock  avoidance/prevention, 
it  was  only  natural, 
for  reliability 
reasons, to  use a distributed  algorithm  for  global  deadlock  detecti0n.i’ 
In  R*,  there  is  one  deadlock  detector  (DD)  at  each site.  The  DDs  at  different 
sites operate  asynchronously.  The  frequencies  at which  local  and  global  deadlock 
detection  searches are  initiated  can  vary  from  site  to  site.  Each  DD  wakes  up 
periodically  and  looks  for  deadlocks  after  gathering 
the  wait-for 
information 
from  the  local  DBMS  and  the  communication  manager.  If  the  DD  is  looking  for 
multisite  deadlocks  during  a detection  phase, then  any  information  about  Poten- 
tial  Global  (i.e., multisite)  Deadlock  Cycles  (PGDCs)  received  earlier  from  other 
sites  is combined  with  the  local  information.  No  information  gathered/generated 
during  a  deadlock  detection  phase  is  retained 
for  use  during  a  subsequent 
detection  phase  of  the  same  DD.  Information 
received  from  a  remote  DD  is 
consumed  by  the  recipient,  at  the  most,  during  one  deadlock  detection  phase. 
This  is  necessary  in  order  to  make  sure  that  false  information  sent  by  a  remote 
DD,  which  during  many  subsequent  deadlock  detection  phases  may  not  have 
anything  to  send,  is  not  consumed  repeatedly  by  a DD,  resulting  in  the  repeated 
detection  of, possibly,  false  deadlocks.  If,  due  to  the  different  deadlock  detection 
frequencies  of  the  different  DDs,  information 
is  received  from  multiple  phases of 
a  particular 
remote  DD  before  it  is  consumed  by  the  recipient,  then  only  that 
remote  DD’s  last  phase’s  information 
is  retained  for  consumption  by  the  recipi- 
ent.  This  is because the  latest  information 
is  the  best  information. 
The  result  of analyzing  the  wait-for  information  could  be the  discovery  of some 
local/global  deadlocks  and  some  PGDCs.  Each  PGDC  is  a  list  of  transactions 

9 All  other 
I0 We  refer 
approaches 

types  of  waits  are  not  dealt  with  by  the  deadlock  detector. 
the  reader 
to  other  papers 
for  discussions  concerning 
[3,  4,  241. 

deadlock  detection 

versus  other 

ACM  Transactions  on Database  Systems, Vol.  11, No.  4, December  1986. 

394 

l 

C. Mohan  et  al. 

(not  processes) in  which  each  transaction,  except  the  last  one,  is  on  a  lock  wait 
on  the  next  transaction 
in  the  list.  In  addition,  the  first  transaction’s  one  local 
process  is  known  to  be expected  to  send  response  data  to  its  cohort  at  another 
site,  and  the last 
transaction’s  one local  process is  known  to  be waiting  to  receive 
response data  from  its  cohort  at  another  site.  This  PGDC  is  sent  to  the  site  on 
which  the  last  transaction’s  local  process is waiting  if  the  first  transaction’s  name 
is  lexicographically 
less than  the  last  transaction’s  name;  otherwise,  the  PGDC 
is  discarded.  Thus  wait-for 
in  the  direction  of  the 
travels  only 
information 
real/potential  deadlock  cycle,  and  on  the  average, only  half  the  sites  involved  in 
a global  deadlock  send information  around 
cycle.  In  general,  in  this  algorithm 
only  one  site  will  detect  a given  global  deadlock. 
Once a global  deadlock  is  detected,  the  interesting  question  is  how  to  choose a 
victim.  While  one  could  use detailed  cost  measures  for  transactions  and  choose 
as the  victim  the  transaction  with  the  least  cost  (see [4]  for  some performance 
comparisons),  the  problem  is  that  such  a  transaction  might  not  be  in  execution 
at  the  site  where  the  global  deadlock  is  detected.  Then,  the  problem  would  be  in 
identifying 
the  site  that  has  to  be  informed  about  the  victim  so  that  the  latter 
could  be  aborted.  Even  if  information  about  the  locations  of  execution  of  every 
transaction  in  the  wait-for  graph  were to  be sent  around  with  the  latter,  or  if  we 
pass along  the  cycle  the  identity  of  the  victim,  there  would  still  be  a  delay  and 
cost  involved  in  informing 
remote  sites  about  the  nonlocal  victim  choice.  This 
delay  would  cause an  increase  in  the  response  times  of  the  other  transactions 
that  are  part  of  the  deadlock  cycle.  Hence,  in  order  to  expedite  the  breaking  of 
the  cycle,  one  can  choose  as  the  victim  a  transaction 
that  is  executing  locally, 
transmission  protocol  guarantees  the 
assuming  that  the  wait-for 
information 
existence  of  such  a  local  transaction.  The  latter 
is  the  characteristic  of  the 
deadlock  detection  protocol  of  R*  [6,  241, and  hence we choose a  local  victim.  If 
more than  one local  transaction  could  be chosen as the  victim,  then  an appropriate 
cost  measure  (e.g.,  elapsed  time  since  transaction  began  execution) 
is  used  to 
in  more  than  one 
make  the  choice.  If  one  or  more  transactions  are  involved 
deadlock,  no  effort  is  made  to  choose as  the  victim  a  transaction 
that  resolves 
the  maximum  possible  number  of  deadlocks. 
Depending  on whether  or  not  (1) the  wait-for  information 
transmission  among 
different  sites  is  synchronized  and  (2)  the  nodes  of  the  wait-for  graph  are 
transactions  or  individual  processes of  a  transaction, 
false  deadlocks  might  be 
detected.  In  R*  transmissions  are  not  synchronized  and  the  nodes  of  the  graph 
are  transactions.  Since  we do  not  expect  false  deadlocks  to  occur  frequently,  we 
treat  every  detected  deadlock  as a true  deadlock. 
Even  though  the  general  impression  might  be that  our  database 
systems  release 
all  locks  of  a  transaction  only  at  the  end  of  the  transaction, 
in  fact,  some locks 
(e.g., short  duration  page-level  locks  when  data  are  being  locked  at  the  tuple- 
level  and  locks  on  nonleaf  nodes  of  the  indices)  are  released before  all  the  locks 
are  acquired.  This  means  that  when  a  transaction 
is  aborting 
it  will  have  to 
reacquire  those  locks  to  perform  its  undo  actions.  Since  a  transaction  could  get 
into  a  deadlock  any  time  it  is  requesting  locks,  if  we  are  not  careful  we  could 
have a situation  in  which  we have a deadlock  involving  only  aborting  transactions. 
It  would  be  quite  messy to  resolve  such  a deadlock.  To  avoid  this  situation,  we 
on  Database  Systems,  Vol.  11,  No.  4,  December  1986. 
ACM  Transactions 

Transaction  Management  in  the  R*  Distributed  Database  Management  System 

l 

395 

permit,  at  any  time,  only  one  aborting 
to  be  actively  reacquiring 
transaction 
locks  in  a given  DBM.  While  the  above-mentioned  potential  problem  had  to  be 
dealt  with  even  in  System  R,  it  is  somewhat  complicated  in  R*.  We  have  to 
ensure  that  in  a global  deadlock  cycle  there  is at  least  one  local  transaction  that 
is  not  already  aborting  and  that  could  be chosen  as the  victim. 
This  reliable,  distributed  algorithm  for  detecting  global  deadlocks is operational 
now  in  R*. 

7.  CURRENT  STATUS 
The  R*  implementation  has  reached  a  mature  state,  providing  support 
for 
snapshots  [ 1,  21,  distributed  views  [7],  migration  of  tables,  global  deadlock 
detection,  distributed  query  compilation  and  processing  [20],  and  crash  recovery. 
Currently 
there  is  no  support  for  replicated  or  fragmented  data.  The  prototype 
is undergoing  experimental  evaluations  [ 211. 

REFERENCES 
1.  ADIBA,  M.  Derived  relations:  A  unified  mechanism  for  views,  snapshots  and  distributed  data. 
Res. Rep.  RJ2881,  IBM,  San Jose, Calif.,  July  1980. 
2.  ADIBA,  M.,  AND  LINDSAY,  B.  Database  snapshots.  In  Proceedings  of  the  6th 
International 
Conference  on  Very  Large  Data  Bases  (Montreal,  Oct.  1980).  IEEE  Press,  New York, 1980, 
86-91. 
3.  AGRAWAL, R., AND CAREY, M.  The  performance  of concurrency  control  and recovery  algorithms 
for  transaction-oriented  database  systems. 
Database  Eng.  8,  2 (June  1985), 58-67. 
4.  AGRAWAL, R., CAREY, M.,  AND MCVOY, L.  The  performance  of alternative  strategies  for dealing 
with  deadlocks  in  database  management  systems.  Tech.  Rep.  590, Dept.  of  Computer  Sciences, 
Univ.  of Wisconsin,  Madison,  Mar.  1985. 
5.  ASTRAHAN, M.,  BLASGEN, M.,  CHAMBERLIN, D.,  GRAY, J.,  KING,  F.,  LINDSAY, B.,  LORIE, 
MEHL,  J.,  PRICE, T.,  PUTZOLU, F.,  SCHKOLNICK, M.,  SELINGER, P.,  SLUT&  D.,  STRONG, R., 
TIBERIO, P.,  TRAIGER, I.,  WADE, B.,  AND YOST, R.  System  R: A  relational  data  base manage- 
ment  system. Computer  12,5  (May  1979), 43-48. 
6.  BEERI, C., AND OBERMARCK, R.  A  resource  class-independent  deadlock  detection  algorithm.  In 
Conference  on  Very  Large  Data  Bases  (Cannes, Sept.  1981). 
Proceedings  of  the  7th  International 
IEEE  Press, New  York,  1981, 166-178. 
L.,  AND LINDSAY, B.  View  management  in  distributed  data  base systems. 
7.  BERTINO, E., 
In  Proceedings  of  the  9th  International 
Conference  on  Very  Large  Data  Bases  (Florence,  Oct. 
1983) VLDB  Endowment,  1983, 376-378.  Also  available  as Res.  Rep.  RJ3851,  IBM,  San  Jose, 
Calif.,  Apr.  1983. 
in  ENCOMPASS:  Reliable  distributed  transaction  process- 
8.  BORR, A.  Transaction  monitoring 
ing.  In  Proceedings  of  the  7th  International 
Conference  on  Very  Large  Data  Bases  (Cannes, Sept. 
1981). IEEE  Press, New  York,  1981,155-165. 
9.  COOPER, E.  Analysis  of  distributed  commit  protocols.  In  Proceedings  of  the  ACM  SZGMOD 
of  Data  (Orlando,  Fla.,  June  1982). ACM,  New  York, 
International 
Conference  on  Management 
1982,175-183. 
10.  ESWARAN, K.  P.,  GRAY, J.  N.,  LORIE, R.,  A.,  AND TRAIGER, I.  L.  The  notions  of  consistency 
and  predicate  locks  in  a database  system.  Commun.  ACM  19,ll 
(Nov.  1976), 624-633. 
11.  GAWLICK, D., AND KINKADE, D.  Varieties  of concurrency  control  in  IMS/VS  fast path.  Database 
Eng.  8,2  (June  1985), 3-10. 
12.  GRAY, J.  Notes  on  data  base  operating  systems.  In  Operating  Systems-An 
Advanced  Course. 
Lecture  Notes  in  Computer  Science, vol.  60. Springer-Verlag,  New  York,  1978. 
13. GRAY, J.  The  transaction  concept:  Virtues  and  limitations. 
In  Proceedings  of  the  7th  Znternu- 
tied  Conference  on  Very  Large  Data  Bases  (Cannes,  Oct.  1981). IEEE  Press, New  York,  1981, 
144-154. 

ACM Transactions on  Database  Systems,  Vol.  11,  No.  4,  December  1986. 

396 

l 

C. Mohan  et  al. 

tax- 

14.  GRAY, J.,  MCJONES, P.,  BLASGEN, M.,  LINDSAY, B.,  LORIE, R.,  PRICE, T.,  PIJTZOLU, F.,  AND 
TRAIGER, I.  The  recovery  manager  of  the  system  R  database manager.  ACM  Comput.  Surv.  13, 
2 (June  1981), 223-242. 
15.  HAERDER, T.,  AND REUTER, A.  Principles  of  transaction  oriented  database  recovery-A 
onomy.  ACM  Comput.  Surv.  15,4  (Dec.  1983), 287-317. 
16.  HAMMER, M.,  AND SHIPMAN, D.  Reliability  mechanisms  for  SDD-1:  A  system  for  distributed 
databases. ACM  Trans.  Database  Syst.  5,4  (Dec.  1980), 431-466. 
17.  LAMPSON, B.  Atomic  transactions.  In  Distributed  Systems-Architecture 
and  Implementation. 
Lecture  Notes  in  Computer  Science, vol.  100, B.  Lampson,  Ed.  Springer-Verlag,  New  York,  1980, 
246-265. 
18.  LINDSAY, B.  G.,  HAAS, L.  M.,  MOHAN, C.,  WILMS,  P.  F.,  AND YOST, R.  A.  Computation  and 
communication 
in  R*:  A  distributed  database  manager.  ACM  Trans.  Comput.  Syst.  2,  1  (Feb. 
19&L), 24-38.  Also  Res. Rep.  RJ3740,  IBM,  San  Jose, Calif.,  Jan.  1983. 
19.  LINDSAY, B.,  SELINGER, P.,  GALTIERI, C.,  GRAY, J.,  LORIE, R.,  PUTZOLU, F.,  TRAIGER, I.,  AND 
WADE, B.  Single  and multi-site  recovery  facilities.  In  Distributed  Data  Bases, I. W. Draffan and 
F. Poole, Eds. Cambridge  University  Press, New York,  1980. Also  available  as Notes  on distributed 
databases. Res. Rep.  RJ2571,  IBM,  San Jose, Calif.,  July  1979. 
20.  LOHMAN,  G.,  MOHAN,  C.,  HAAS,  L.,  DANIELS,  D.,  LINDSAY, B.,  SELINGER, P.,  AND WILMS, 
P.  Query  processing  in  R*.  In 
in  Database  Systems,  W.  Kim,  D.  Reiner,  and 
Query  Processing 
D.  Batory,  Eds. Springer-Verlag,  New  York,  1984. Also  Res. Rep.  RJ4272,  IBM,  Apr. 1984. 
21.  MACKERT, L.,  AND LOHMAN, G. 
Index  scans using  a  finite  LRU  buffer:  A  validated  I/O  model. 
Res. Rep.  RJ4836,  IBM,  San Jose, Calif.,  Sept.  1985. 
22.  MOHAN,  C.  Tutorial: 
in  Distributed  Data  Bose  Management.  IEEE  catalog 
Recent  Advances 
number  EH0218-8,  IEEE  Press, New  York,  1984. 
23.  MOHAN, C., STRONG, R., AND FINKELSTEIN, S.  Method  for  distributed  transaction  commit  and 
recovery  using  Byzantine  agreement  within  clusters  of processors. In  Proceedings  of  the  2nd  ACM 
SZGACT/SZGOPS  Symposium  on  Principles  of  Distributed  Computing 
(Montreal,  Aug.  1983). 
ACM,  New  York,  1983, 89-103.  Reprinted  in  ACM/SIGOPS  Operating  Systems  Review,  July 
1985. Also  Res. Rep. RJ3882,  IBM,  San Jose, Calif.,  June  1983. 
24.  OBERMARCK, R.  Distributed  deadlock  detection  algorithm.  ACM  Trans.  Database  Syst.  7,  2 
(June  1982), 187-208. 
25.  ROTHNIE, J.  B.,  JR., BERNSTEIN, P.  A.,  Fox,  S., GOODMAN, N.,  HAMMER, M.,  LANDERS, T.  A., 
Introduction 
to  a system  for  distributed  databases 
REEVE, C.,  SHIPMAN,  D.  W.,  AND  WONG,  E. 
(SDD-1).  ACM  Trans.  Database  Syst.  5,  1 (Mar.  1980), 1-17. 
26.  SKEEN, D.  Nonblocking  commit  protocols.  In  Proceedings  of  the  ACM/SZGMOD 
International 
(Ann  Arbor,  Mich.,  May  1981).  ACM,  New  York,  1981, 
Conference  on  Management 
of  Data 
133-142. 
27.  SKEEN, D.  A  quorum-based  commit  protocol.  In  Proceedings  of  the  6th  Berkeley  Workshop  on 
(May  1982). Lawrence  Berkeley  Labora- 
Distributed  Data  Management  and  Computer  Networks 
tories,  1982, 69-90. 
28.  STONEBRAKER, M.  Concurrency  control  and consistency  of multiple  copies of data  in  distributed 
INGRES.  IEEE  Trans.  Softw.  Eng.  5,3  (May  1979), 235-258. 

Received  September  1985; revised  July  1986; accepted July  1986 

ACM  Transactions 

on  Database  Systems,  Vol.  11,  No.  4,  December  1986. 

DBMS RESEARCH
AT A CROSSROADS: THE VIENNA UPDATE
Michael Stonebraker
Rakesh Agrawal
Umeshwar Dayal
Erich J. Neuhold
Andreas Reuler
Abstract - On April 23, 1993 a panel discussion was
held at the IEEE International Conference on Data Engi-
neering in Vienna, Austria, at which five members of the
data base research community discussed future research
topics in the DBMS area. This paper summarizes the dis-
cussion which took place. The panel followed a similar
format to that used at Laguna Beach four years earlier, and
four of the five panelists attended the earlier conference.
As such, we contrast the recommendations of the Laguna
Beach participants with those obtained four years later by a
similar group.
1. INTRODUCTION
In February 1989, an informal workshop was held in
Laguna Beach, California, attended by 7 senior DBMS
researchers from Germany and 9 from the USA. This
workshop was organized by Erich Neuhold of GMD and
Michael Stonebraker of Berkeley, and sponsored by the
International Computer Science Institute (ICSI). The pur-
pose of that workshop was to discuss what DBMS topics
deserve research attention in the future. During the first
day, each participant presented four topics that he was not
working on that he thought were important and that he
would like to investigate. In addition, each participant was
asked to present two topics that others were working on,
which he thought were unlikely to yield significant
research progress. All participants then cast five votes in
support of research topics proposed by others. They were
also given two votes to indicate agreement with overrated
topics. The workshop report [4] summarized the discus-
sion which took place, but did not indicate the actual
scorn from the exercise.
On April 23, 1993, a similar exercise was held in a
panel discussion at the IEEE Data Engineering Confcrcncc
among five participants, four of whom had attcndcd the
Laguna Beach workshop. Each panelist was asked to pre-
sent 4 problems he would like to see solved that he was not
working on. Further, he was asked to present 4 problems
that he would be happy never to see another paper on.
Subsequently, each panelist was given two votes hc could
cast to support important topics proposed by others and
two votes to agree with overrated topics.
The exercise in Vienna was slightly diffcrcnt from
Laguna Beach, in that it ensured that “positive” topics
could not have “ncgativc” votes and ncgativc topics could
not have positive votes. Also, Vienna had a much smaller
tGun of panelists, who did not bcncfit from an opportunity
to discuss the various topics before voting. Even so, the
authors believe that contrasting the two sets of scores will
provide guidance to the research community in sclccting
what problems to address.
As such, in Section 2 we briefly review the Laguna
Beach scores, followed in Section 3 by the Vienna scores.
We close in Section 4 with some comments and views,
shared by all five authors.
2. A REVIEW OF LACUNA
BEACH
There were thereby a total 144 “positive” votes and 64
“negative” votes cast at Laguna Beach, and the raw results
arc summarized in Table 1. Notice that it is possible for
some researchers to consider a topic to have much promise
and others to consider it having littlc promise. Hence, the
number of positive and negative votes for each topic arc
prescntcd.
The thing that amazed the participants was that 10 top-
ics collected 101 of 144 positive votes and six topics
received 42 out of 64 possible ncgativc votes.
Essentially all participants wanted to see more re.scan*h
on end-user interfaces to data base systems and active data
bases, i.e. rule systems supporting triggers and alcrtcrs.
Considcrablc support was also present for parallel query
Research sponsored by the National Science Foundation Grant
w-91 -07455.
Permission IO copy witho~ fee all or part of fhir material k grant-
ed provided what the copies are not made or distributed for direct com-
merical advantage, the VLDB copyrighl notice and the title of the publi-
cation and its dale appear, and notice is given thaw copying is by permk-
sion of the Very Large Data Base Endowment. To copy otherwire. or 10
republirh, requires a fee andlor special permiwion from the Endowment.
Proceedings of the 19th VLDB Conference Dublin,
Ireland, 1993.
688Topic
End User Interfaces
Active Data Bases
Parallelism
New Transaction Models
CIM. Image, IR Appl.
CASE Applications
Security & High Availability
Large Dist. Data Bases
DB/OS Interaction
Transaction Design Tools
Large Syslem Admin.
Real lime DBMS
DBMS Impl. Blkbd Paradigm
IMS-style Joins
Automatic DB Design
Tool-kit DBMS Systems
Data Translation
CICDB
Dcpendcncy Theory
Interface Btwn DBMS & Prolog
New Data Model
Common 00 Data Model
Tradit ConcurrConaol
Hardware DB machines
General Recursion Queries
Positive
votes
14
15
11
10
10
9
9
9
7
7
5
3
3
3
4
5
2
7
0
0
0
2
0
0
0
Negative
votes
0
1
0
0
0
0
0
1
0
1
1
0
0
0
2
3
1
6
3
5
5
7
7
8
10
Laguna Beach Results
Table I
processing on multiprocessor systems, new transaction
models, c.g. Sagas [31 and Contracts [5), and finding rele-
vant rcscarch problems by studying new application arcas
such as Computer Integrated Manufacturing (CIM), image
data bases, Information Retrieval (IR) applications, and
Computer Assisted Softwarc Engineering (CASE). Con-
sidcration of high availability, security, scaling problems in
very large distributed data bases, interface issues between
the DBMS and the operating system and tools to assist
users in designing transactions rounded out the list of pop-
ular topics.
The six unpopular topics were general recursion, hard-
wart data base machines, exploration of concurrency con-
tml schcmcs supporting serializability on a single machine
a common object-oriented data model. new data models of
any kind, and interfaces between a DBMS and Prolog.
Gcncral recursion was unpopular because none of the
participants had ever seen an application that needed this
capability. The participants thought that advocates of gen-
eral recursion research should either find a credible appli-
cation for the technology or move on to other more rele-
vant topics. Hardware data base machines were unpopular
because the participants felt that software-only data base
machines, i.e. conventional multiprocessors running paral-
lel software offered much more promise. Concurrency
control was unpopular because of the appearance of a large
number of papers on the topic in the mid 1980’s, all differ-
ing in seemingly minor ways. The participants thought
that little progress would be made by continuing to publish
minor variations on a set of common themes. Data models
(object-oriented or otherwise) were not in favor, because
the participants had seen a large number of them, differing
in small ways, and they did not want to see any more.
Lastly, interfaces to Prolog were not considered the best
way to build expert data base systems. Rather rules sys-
tems integrated with the DBMS should be the focus of
research activity.
It is an understatement to say that the report was imme-
diately controversial. Perhaps the biggest problem with
the report was that the composition of the participants was
primarily from the systems area. For example, there was
nobody from the theory .community, and the representative
from the deductive DBMS community was forced to can-
cel at the last minute. Hence, the participants did not rep-
resent a broad cross section of DBMS researchers. As
such. their collective judgement may be biased in assorted
ways.
3. THE VIENNA
UPDATE
In this section we present the scores captured during the
Vienna panel discussion. Although opinions were hastily
conceived and from a narrower collection of researchers;
nevertheless some of the conclusions that can be drawn are
very interesting. There were a total of 30 positive votes
and 30 negative votes cast by the panelists, and we summa-
rize the results in Table. 2.
There was near-universality of interest in five topics.
The panelists were enthusiastic about new user interfaces,
such as workflow languages and collaboration tools. They
lamented that progress in this area continues to be done by
industry, and the research community has very little impact
on this important topic.
In addition, there was interest in studying problems of
scaling DBMSs to very big (multi-terabyte) data bases and
very big (thousands of clients) systems. Scaling to ter-
abyte data bases entails coping with memory management
in a multilevel hierarchy and performing very intelligentTopic
Positive
votes
End User Interfaces
Big Systems
Legacy Applications
Multimedia Applications
Data Mining
Mobile Data Bases
Method Optimization
Embedded DBMS
Object Repositories
00 Data Base Design
Constraints
Relational Extensions
Synchronization theory
Simplistic Data Integration
Less than ACID Transactions
Persistent C++
Multi-data base Transactions
New 00 Data Models
Replication Algorithms
Bizarre Performance Studies
Traditional Engines
General recursion
4.5
4.5
4
4
4
2
2
2
1
1
1
0
0
0
0
0
0
0
0
0
0
0
Problems associated with storing large multi-media
objects in data bases also stood out. These include how to
build indexes on the content of such objects and how to
provide services such as guaranteed delivery.
Negative
votes
0
0
0
0
0
0
0
0
0
0
0
1
1
1
2
2
3
3
4
4
4
5
Lastly, “data mining” was a very popular topic. It is
motivated by the decision support problem faced by most
large retail chains. They record every item that is pur-
chased in cvcry store by capturing this data at the point of
sale. Buyers and merchandise arrangers use this data base
to rotate stock and make purchasing decisions. The query
to such a data base is “tell me something interesting”.
Specifically, users want a system that would “mine” the
data for useful information.
Three other topics received lesser support. The first
concerned problems in mobile data bases. There will hc
applications where clients have hand-held dcviccs, which
may only be intermittently connected to a DBMS server.
As such, system designers must cope with issues such as
operating the system in disconnected mode and then per-
forming downstream version merging. Furthermore, opti-
mizing queries to minimize power consumption is a worth-
while cxcrcisc.
Second, extendible and object-oriented data base sys-
tems allow user to add user-defined functions to the
DBMS. Such functions can be written in the query lan-
guage, or they can bc written in a gcncml purpose pro-
gramming language such as C with intermixed SQL
queries intcmal to the function. In this latter cast, the
function is “opaque” and its cost of cxccution cannot bc
idcntilicd. How to make a query optimizer intclligcntly
deal with queries containing such funclions was thought
important by some panelists.
Vienna Results
Table 2
caching. Also, a DBMS must cope with millions (and pcr-
haps billions) of objects. Scaling to a large number of
clients requires solving such matters as installing a new
copy of an application program without taking the system
down and keeping track of an application in which certain
clients am running different versions of the same applica-
tion.
Furthermore, essentially all large companies are run-
ning their business on large application systems that are at
least ten years old. Such systems are typically poorly
structured and often use obsolete DBMS technology or
even no DBMS at all. Managers in these companies want
to retire this “legacy” code to move to modem DBMS and
client-server technology, and they can proceed by a global
rewrite or incremental migration. Since total rewrites are
perilous and failure prone, users need help in generating
feasible incremental migration strategies for legacy appli-
cations. Participants were enthusiastic about reverse engi-
neering techniques as well as architectural suggestions
such as [l].
ti!)o
The final topic was one of embcddcd DBMSs. Hcrc,
the focus was on applications such as telephone switches
where the hardware and software arc a “closed world”
which is constructed at the factory and not changul in the
field. There is no requirement to run arbitrary user pro-
grams or for protecting the DBMS from application pro-
grams. Instead other issues arise such as a very high avail-
ability requirement, which requires that new versions of
the software be installable without taking down the device,
and extremely high performance requirements.
The panelists were uniformly hostile to gcncral recur-
sion. Ever increasing numbers of papers are being written
to define yet another declarative semantics of stratelicd
aggregation/negation or provide a twist on magic set opti-
mization techniques. It has been four years since Laguna
Beach, and there is still no known user of this technology.
The segment of the DBMS research community that writcs
papers on this topic should really be charged with finding
applications that can use their results.The optimization of traditional single site DBMSs for
business data processing applications was also poorly
received. The scn.sc of the panelists was that this topic is
well understood and that WC should d&arc it a solved
problem. Future research will bc incrcmcntal in this arca,
and researchers are “polishing a round ball”. In fact, one
panelist observed that in 1995 it will be possible to buy
1000 transactions per second for $100,000, and that there
arc only two known applications which require higher
transaction rates. More typical applications require 100
transactions per second and will need only a small portion
of a chwp machine. They will increasingly be able to get
by with “brute force” solutions to their DBMS problems,
rcndcring further research in this area of questionable
value. In a sense Laguna Beach declared traditional con-
currency control a dead topic; Vienna extended this death
warranl to single site DBMSs.
request to this site can be piggy-backed onto the query.
Similarly, all copies must be updated and a lock request
again can be piggy-backed. As such, it is difficult to beat a
scheme that reads and locks any copy and writes and locks
all copies that are currently operational, as explained in
[2]. Any author writing a replication paper must keep in
mind this simple fact.
Another hostilely received topic was any additional
object-oriented data models. The feeling was that lots of
models have been invented, and lots more will presumably
be discovered, all differing in minor ways. The feeling of
the panelists was that no more papers should be written in
this area. This reinforces the same feeling from the
Laguna Beach participants.
Another topic with 3 negative votes was transactions
spanning multiple data bases. Specifically, the panelists
were negative on algorithms supporting two-phase commit
in a heterogeneous distributed data base environment in
which the various local DBMSs do not support a prepare
message. This requires sophisticated and expensive algo-
rithms to simulate this capability outside the DBMS. The
feeling of the panelists was that XA would force all vcn-
dors of data managers to support a common distributed
transaction capability, and render this problem irrelevant.
In this scenario, a prepare message would only be missing
from legacy “home brew” systems, and it is unlikely that
the sophistication to implement simulations of two-phase
commit would be present in such application shops.
Hence, this problem is not relevant to any real world situa-
tion.
Two final topics deserve comment. First, the panelists
felt that there is a limited commercial market for persistent
C++ data base systems. Compared to the SQL DBMS mar-
ket, persistent C++ is perhaps l-2%, and that it is not likely
to “take off” in the near future. As such, researchers
should focus their energy on problem areas with a higher
possibility of product penetration.
The third topic received with disfavor was performance
studies of artificial environments. Two examples were
heavily cited. Fist, studies of “toy” disk-based data bases
of a few megabytes or less which were fronted by even
smaller main memory caches were scorned. Current work-
stations routinely come with 32 Mbytes of memory, and
performance studies that assume a cache size considerably
smaller than this number seemed unreal to the panelists. In
cffcct any study with a small number of Mbytes of data
that did not assume full main memory caching seemed
silly. Hcncc, performance studies should use technology
pWilmCtCrS rcflccting current reality, not some past reality.
Second, Jim Gray once formulated to following law:
In a well-designed data base, the probability
of waiting as a result of a lock
rcqucst is less than 0.01
Specifically, in a real data base, transactions nrely wait.
The reason is that an application cannot afford to have
humans sitting idle waiting for lock releases. A data base
administrator faced with this situation will redesign his
data base to make the probability of waiting very rare.
The last topic was the study of concurrency control and
crash recovery systems that supported less than ACID
properties. The feeling was that such schemes are not gen-
eral purpose enough to ever find much favor in real
DBMSs. Hence, there is limited applicability for such
research.
There have been a large number of papers recently pub-
lished in which the probability of waiting is more than one
order of magnitude higher than that in Jim Gray’s law.
Such authors should realize they are optimizing a DBMS
for a load that will never be experienced in the real world.
Another unappealing arca was algorithms for updating
multiple topics of objects in distributed data bases. There
have been a large number of papers exploring new tech-
niyucs in this arca, and the panelists felt that a large num-
bcr of additional papers could be written. Moreover, most
entail setting read locks at more than one site and write
locks at less than all sites. Quorum and majority consen-
sus algorithms have this property. However, a read com-
mand need be sent to only one site, and a single lock
4. COMMENTS
ON THE EXERCISE
One striking feature of these two exercises is that most
of the important Laguna Beach topics have been exten-
sively addressed in the intervening four years, and have
dropped off the list of things requiring attention. Only user
interfaces remains on the 1993 list. In addition, work on
the negative topics has largely ceased. With the exception
691of general recursion, most of the negative topics have dis-
appeared from the 1993 list. As a result, it appears that the
DBMS community has largely addressed the opinions
voiced in the Laguna Beach report PI
However, we must now ponder the Vienna results in
Table 2. One member of the Vienna audience pointed out
that the 1993 Data Engineering conference had a large
number of papers in the areas considered negative by the
panel and almost no papers in areas considered important.
Assuming that this conference is typical of DBMS
research, it appears that our community is largely working
on the wrong problems. 121
Put more strongly, we are at a crossroads, in that the
traditional topics we have studied such as buffer manage-
ment, concurrency control and query optimization should
be declared “solved”. However,.as a community we con-
tinue to “plow” the familiar ground and we appear to be
increasingly “polishing a round ball”. On the other hand,
the problems identified by the panel as important have the
property that they are both very hard (e.g. data mining is
almost certainly “AI complete”) and also away from the
center of previous DBMS activity. Hence, our community
is at a crossroads where we can either continue along the
traditional road or take a path exploring largely unknown
terrain.
It is, of course, safer to take the traditional path. Pro-
gram committees react favorably to “more of the same”,
and often react badly to papers in new areas, especially if
they do not contain well thought out formal results. As a
community, we should consciously break out of this mold.
Another way of considering the 1993 table is that
DBMS research in the 1990’s should have an application
focus rather than a technology focus. The old wisdom was
to find a technical problem and then solve it, while the new
adage appears to be “find a customer” and then solve the
problem that he explains to you. The important problems
from the 1993 table appear to have largely come from
applying this advice.
A last lament echoed in the halls of the conference hut
not directly by the data in Table 2 is that there are simply
too many papers being published. The number of
researchers needing to gain tenure as well as the number of
conferences has increased dramatically. It is now nearly
impossible to keep up with the DBMS literature across
more than a very narrow slice of the research terrain.
Moreover, most researchers seem to dissect their ideas into
“least publishable units”, so as to maximize the length of
their vitae, contributing further to the paper explosion. A
way to lower the number of words published is clearly
needed.
REFERENCES
r31
r41
PI
Brodie, M. and Stonebmlcer, M., “Incrcmcntal
Migration of Legacy Data Base Applications,”
GTE Laboratories, Waltham, Mass., Technical
Report 93-12, January 1993.
El Abbadi. A. et. al., “An Efficient Fault-
tolerant Protocol for Rcplicatcd Data Managc-
ment,” hoc. 1985 SIGACTSIGMOD Sympo-
sium on Principles of Data Base Systems,
1985.
Garcia-Molina, H. and Sakm. K., “SAGAS.”
Pm. 1987 ACM-SIGMOD
Conference on
Management of Data, San Francisco, Ca.,
May 1987.
Stonebrakcr, M. and N&old,
E., “The
Laguna Beach Report,” International Institute
of Computer Science Technical Report #I,
Berkeley, Ca., June 1989.
Wachter, H. and Reuter, A., “The ConTract
Model,” in “Transaction Models for Advanced
Database Applications,” Morgan-Kaufman
Publishers, Redwood City, Ca., 1992.
 

 

C-Store: A Column-oriented DBMS 
 
Mike Stonebraker*, Daniel J. Abadi*, Adam Batkin+, Xuedong Chen† , Mitch Cherniack+,  
Miguel Ferreira*, Edmond Lau*, Amerson Lin*, Sam Madden*, Elizabeth O’Neil † ,  
Pat O’Neil † , Alex Rasin‡ , Nga Tran+, Stan Zdonik‡  
+Brandeis University 
Waltham, MA 

‡ Brown University 
Providence, RI 

*MIT CSAIL 
Cambridge, MA 

† UMass Boston 
Boston, MA 

Abstract 
This  paper  presents  the  design  of  a  read-optimized 
relational  DBMS  that  contrasts  sharply  with  most 
current 
systems,  which  are  write-optimized.  
Among  the  many  differences  in  its  design  are: 
storage  of  data  by  column  rather  than  by  row, 
careful  coding  and  packing  of  objects  into  storage 
including  main  memory  during  query  processing, 
storing  an  overlapping  collection  of  column-
oriented  projections,  rather  than  the  current  fare  of 
tables 
and 
indexes, 
a 
non-traditional 
implementation of transactions which includes high 
availability  and  snapshot  isolation  for  read-only 
transactions,  and  the  extensive  use  of  bitmap 
indexes to complement B-tree structures. 
We  present  preliminary  performance  data  on  a 
subset  of  TPC-H  and  show  that  the  system  we  are 
building,  C-Store, 
is  substantially  faster 
than 
popular  commercial  products. 
the 
  Hence, 
architecture looks very encouraging. 
1.  Introduction 
Most major DBMS vendors implement record-oriented 
storage  systems, where  the attributes of a  record  (or  tuple) 
are  placed  contiguously  in  storage.    With  this  row  store 
architecture,  a  single  disk  write  suffices  to  push  all  of  the 
fields  of  a  single  record  out  to  disk.    Hence,  high 
performance  writes  are  achieved,  and  we  call  a  DBMS 
with  a  row  store  architecture  a  write-optimized  system.  
These are especially effective on OLTP-style applications. 
In  contrast,  systems  oriented  toward  ad-hoc  querying 
of  large  amounts  of  data  should  be  read-optimized.    Data 
warehouses  represent  one  class  of  read-optimized  system, 

Permission  to  copy  without  fee  all  or  part  of  this  material  is  granted 
provided  that  the  copies  are  not  made  or  distributed  for  direct 
commercial  advantage,  the  VLDB  copyright  notice  and  the  title  of  the 
publication  and  its  date  appear,  and  notice  is  given  that  copying  is  by 
permission of the Very Large Data Base Endowment.  To copy otherwise, 
or  to  republish,  requires  a  fee  and/or  special  permission  from  the 
Endowment 
Proceedings of the 31st VLDB Conference, 
Trondheim, Norway, 2005 

 

in  which  periodically  a  bulk  load  of  new  data  is 
performed,  followed  by  a  relatively  long  period  of  ad-hoc 
queries.  Other  read-mostly  applications  include  customer 
relationship  management  (CRM)  systems,  electronic 
library card catalogs, and other ad-hoc inquiry systems.  In 
such  environments,  a  column  store  architecture,  in  which 
the  values  for  each  single  column  (or  attribute)  are  stored 
contiguously,  should  be  more  efficient.    This  efficiency 
has  been  demonstrated  in  the  warehouse  marketplace  by 
products like Sybase IQ [FREN95, SYBA04], Addamark  
[ADDA04],  and KDB  [KDB04].  In  this  paper, we  discuss 
the design of a column store called C-Store that includes a 
number of novel features relative to existing systems. 
With  a  column  store  architecture,  a  DBMS  need  only 
read the values of columns required for processing a given 
query,  and  can  avoid  bringing  into  memory  irrelevant 
attributes.    In  warehouse  environments  where  typical 
queries  involve  aggregates  performed  over  large  numbers 
of  data  items,  a  column  store  has  a  sizeable  performance 
advantage.    However,  there  are  several  other  major 
distinctions that can be drawn between an architecture that 
is read-optimized and one that is write-optimized. 
Current  relational  DBMSs  were  designed  to  pad 
attributes to byte or word boundaries and to store values in 
their  native  data  format.    It  was  thought  that  it  was  too 
expensive 
to  shift  data  values  onto  byte  or  word 
boundaries  in  main  memory  for  processing.    However, 
CPUs  are  getting  faster  at  a  much  greater  rate  than  disk 
bandwidth  is  increasing.    Hence,  it  makes  sense  to  trade 
CPU  cycles,  which  are  abundant,  for  disk  bandwidth, 
which is not.  This tradeoff appears especially profitable in 
a read-mostly environment.   
There are two ways a column store can use CPU cycles 
to  save  disk  bandwidth.    First,  it  can  code  data  elements 
into  a more  compact  form.    For  example,  if  one  is  storing 
an attribute that is a customer ’s state of residenc e, then US 
states  can  be  coded  into  six  bits,  whereas  the  two-
character  abbreviation  requires  16  bits  and  a  variable 
length  character  string  for  the  name  of  the  state  requires 
many  more.    Second,  one  should  densepack  values  in 
storage. 
  For  example, 
in  a  column  store 
it 
is 
straightforward  to pack N  values, each K bits  long,  into N 
* K  bits.   The  coding  and  compressibility  advantages  of  a 

column  store  over  a  row  store  have  been  previously 
pointed out in [FREN95].  Of course, it is also desirable to 
have the DBMS query executor operate on the compressed 
representation  whenever  possible  to  avoid  the  cost  of 
decompression,  at  least  until  values  need  to  be  presented 
to an application. 
Commercial  relational  DBMSs  store  complete  tuples 
of  tabular  data  along  with  auxiliary  B-tree  indexes  on 
attributes  in  the  table.    Such  indexes  can  be  primary, 
whereby  the  rows  of  the  table  are  stored  in  as  close  to 
sorted  order  on  the  specified  attribute  as  possible,  or 
secondary,  in  which  case  no  attempt  is  made  to  keep  the 
underlying records in order on the indexed attribute.   Such 
indexes  are  effective 
in  an  OLTP  write-optimized 
environment  but  do  not  perform  well  in  a  read-optimized 
world.    In  the  latter  case,  other  data  structures  are 
advantageous,  including  bit  map  indexes  [ONEI97],  cross 
table 
indexes 
[ORAC04],  and  materialized  views 
[CERI91].    In  a  read-optimized  DBMS  one  can  explore 
storing  data  using  only  these  read-optimized  structures, 
and not support write-optimized ones at all. 
Hence,  C-Store  physically  stores  a  collection  of 
columns,  each  sorted  on  some  attribute(s).    Groups  of 
columns  sorted  on  the  same  attribute  are  referred  to  as 
“projections”;  the  same  column  may  exist  in  multipl e 
projections, possibly sorted on a different attribute in each.  
We  expect  that  our  aggressive  compression  techniques 
will  allow  us  to  support many  column  sort-orders  without 
an  explosion  in  space.    The  existence  of  multiple  sort-
orders opens opportunities for optimization. 
Clearly,  collections  of  off-the-shelf  “blade ”  or  “g
rid ” 
computers  will  be  the  cheapest  hardware  architecture  for 
computing  and  storage  intensive  applications  such  as 
DBMSs  [DEWI92].  Hence,  any  new  DBMS  architecture 
should  assume  a  grid  environment  in  which  there  are  G 
nodes  (computers),  each  with  private  disk  and  private 
memory. We  propose  to  horizontally  partition  data  across 
the  disks  of  the  various  nodes  in  a  “shared  nothing ” 
architecture  [STON86].  Grid  computers  in  the  near  future 
may  have  tens  to  hundreds  of  nodes,  and  any  new  system 
should be architected  for grids of  this  size.   Of course,  the 
nodes  of  a  grid  computer may  be  physically  co-located  or 
divided  into  clusters  of  co-located  nodes.    Since  database 
administrators  are  hard  pressed  to  optimize  a  grid 
environment,  it  is  essential  to  allocate  data  structures  to 
grid  nodes  automatically. 
  In  addition, 
intra-query 
parallelism  is  facilitated  by  horizontal  partitioning  of 
stored  data  structures,  and  we  follow  the  lead  of  Gamma 
[DEWI90] in implementing this construct. 
Many  warehouse  systems  (e.g.  Walmart  [WEST00]) 
maintain  two  copies  of  their  data  because  the  cost  of 
recovery  via  DBMS  log  processing  on  a  very  large 
(terabyte)  data  set  is  prohibitive.    This  option  is  rendered 
increasingly  attractive  by  the  declining  cost  per  byte  of 
disks.    A  grid  environment  allows  one  to  store  such 
replicas  on  different  processing  nodes,  thereby  supporting 
a  Tandem-style  highly-available  system  [TAND89].  

However,  there  is  no  requirement  that  one  store  multiple 
copies  in  the  exact  same  way.    C-Store  allows  redundant 
objects  to  be  stored  in  different  sort  orders  providing 
higher 
to  high 
in  addition 
retrieval  performance 
availability.    In  general,  storing  overlapping  projections 
further  improves  performance,  as  long  as  redundancy  is 
crafted  so  that  all  data  can  be  accessed  even  if  one  of  the 
G  sites  fails.   We call a  system  that  tolerates K  failures K-
safe.    C-Store  will  be  configurable  to  support  a  range  of 
values of K. 
It  is  clearly  essential  to  perform  transactional  updates, 
even  in  a  read-mostly  environment.    Warehouses  have  a 
need to perform on-line updates to correct errors.  As well, 
there  is  an  increasing  push  toward  real-time  warehouses, 
where the delay to data visibility shrinks toward zero.  The 
ultimate  desire  is  on-line  update  to  data  warehouses.  
Obviously,  in  read-mostly  worlds  like CRM,  one  needs  to 
perform general on-line updates.   
There  is  a  tension  between  providing  updates  and 
optimizing  data  structures  for  reading.    For  example,  in 
KDB  and  Addamark,  columns  of  data  are  maintained  in 
entry  sequence  order.  This  allows  efficient  insertion  of 
new  data  items,  either  in  batch  or  transactionally,  at  the 
end  of  the  column.    However,  the  cost  is  a  less-than-
optimal  retrieval  structure,  because most  query  workloads 
will  run  faster  with  the  data  in  some  other  order.  
However,  storing  columns  in  non-entry  sequence  will 
make insertions very difficult and expensive. 
C-Store  approaches 
this  dilemma  from  a  fresh 
perspective.  Specifically,  we  combine  in  a  single  piece  of 
system  software,  both  a  read-optimized  column  store  and 
an  update/insert-oriented  writeable  store,  connected  by  a 
tuple mover,  as  noted  in Figure  1.     At  the  top  level,  there 
is  a  small  Writeable  Store  (WS)  component,  which  is 
architected  to  support  high  performance  inserts  and 
updates.  There is also a much larger component called the 
Read-optimized  Store 
(RS),  which 
is  capable  of 
supporting  very  large  amounts  of  information.    RS,  as  the 
name  implies,  is  optimized  for  read  and  supports  only  a 
very  restricted  form of  insert, namely  the batch movement 
of  records  from WS  to RS, a  task  that  is performed by  the 
tuple mover of Figure 1. 
 

  

 

 

 

 

 

Writeable Store (WS) 

Tuple Mover 

Read-optimized Store (RS) 

Figure 1. Architecture of C-Store 

Of  course,  queries  must  access  data  in  both  storage 
systems.    Inserts  are  sent  to  WS,  while  deletes  must  be 

marked  in  RS  for  later  purging  by  the  tuple  mover.  
Updates  are  implemented  as  an  insert  and  a  delete.    In 
order  to  support  a  high-speed  tuple  mover,  we  use  a 
variant  of 
the  LSM-tree  concept  [ONEI96],  which 
supports  a  merge  out  process  that  moves  tuples  from WS 
to  RS  in  bulk  by  an  efficient  method  of  merging  ordered 
WS  data  objects  with  large  RS  blocks,  resulting  in  a  new 
copy of RS that is installed when the operation completes. 
The  architecture  of  Figure  1  must  support  transactions 
in  an  environment  of  many  large  ad-hoc  queries,  smaller 
update 
transactions,  and  perhaps  continuous 
inserts.  
Obviously,  blindly  supporting  dynamic  locking will  result 
in  substantial 
read-write  conflict  and  performance 
degradation due to blocking and deadlocks.   
Instead,  we  expect  read-only  queries  to  be  run  in 
historical  mode.    In  this  mode,  the  query  selects  a 
timestamp,  T,  less  than  the  one  of  the  most  recently 
committed  transactions,  and  the  query  is  semantically 
guaranteed  to  produce  the  correct  answer  as  of  that  point 
in  history.    Providing  such  snapshot  isolation  [BERE95] 
requires  C-Store  to  timestamp  data  elements  as  they  are 
inserted  and  to  have  careful  programming  of  the  runtime 
system to ignore elements with timestamps later than T. 
Lastly,  most  commercial  optimizers  and  executors  are 
row-oriented,  obviously  built  for  the  prevalent  row  stores 
in  the  marketplace.    Since  both  RS  and  WS  are  column-
oriented,  it  makes  sense  to  build  a  column-oriented 
optimizer  and  executor.    As  will  be  seen,  this  software 
looks nothing like the traditional designs prevalent today. 
In  this  paper,  we  sketch  the  design  of  our  updatable 
column  store,  C-Store,  that  can  simultaneously  achieve 
very  high  performance  on  warehouse-style  queries  and 
achieve  reasonable  speed  on  OLTP-style  transactions.    C-
Store  is  a  column-oriented  DBMS  that  is  architected  to 
reduce  the  number  of  disk  accesses  per  query.    The 
innovative features of C-Store include: 
1.  A  hybrid architecture with a WS component optimized 
for  frequent  insert  and  update  and  an  RS  component 
optimized for query performance.  
2.  Redundant  storage  of  elements  of  a  table  in  several 
overlapping  projections  in  different  orders,  so  that  a 
query  can  be  solved  using  the  most  advantageous 
projection.  
3.  Heavily  compressed  columns  using  one  of  several 
coding schemes.  
4.  A  column-oriented  optimizer  and  executor,  with 
different primitives than in a row-oriented system. 
5.  High  availability  and  improved  performance  through 
K-safety  using  a  sufficient  number  of  overlapping 
projections. 
6.  The use of snapshot isolation to avoid 2PC and locking 
for queries. 
It  should  be  emphasized  that  while  many  of  these  topics 
have  parallels  with  things  that  have  been  studied  in 
isolation  in  the  past,  it  is  their  combination  in  a  real 
system that make C-Store interesting and unique. 

 The  rest  of  this  paper  is  organized  as  follows.    In 
Section  2  we  present  the  data  model  implemented  by  C-
Store.    We  explore  in  Section  3  the  design  of  the  RS 
portion  of  C-Store,  followed  in  Section  4  by  the  WS 
component.    In Section  5 we  consider  the  allocation  of C-
Store  data  structures  to  nodes  in  a  grid,  followed  by  a 
presentation  of  C-Store  updates  and  transactions  in 
Section  6.  Section  7  treats  the  tuple  mover  component  of 
C-Store,  and  Section  8  presents  the  query  optimizer  and 
executor.    In  Section  9  we  present  a  comparison  of  C-
Store  performance  to  that  achieved  by  both  a  popular 
commercial  row  store  and  a  popular  commercial  column 
store.    On  TPC-H  style  queries,  C-Store  is  significantly 
faster  than  either  alternate  system.  However,  it  must  be 
noted  that  the  performance  comparison  is  not  fully 
completed;  we  have  not  fully  integrated  the WS  and  tuple 
mover,  whose  overhead  may  be  significant.    Finally, 
Sections  10  and  11  discuss  related  previous  work  and  our 
conclusions. 
2.  Data Model 
C-Store  supports  the  standard  relational  logical  data 
model, where  a  database  consists  of  a  collection  of  named 
tables,  each  with  a  named  collection  of  attributes 
(columns).  As  in  most  relational  systems,  attributes  (or 
collections  of  attributes)  in  C-Store  tables  can  form  a 
unique  primary  key  or  be  a  foreign  key  that  references  a 
primary key in another table.   The C-Store query language 
is assumed to be SQL, with standard SQL semantics. Data 
in  C-Store  is  not  physically  stored  using  this  logical  data 
model.    Whereas  most  row  stores  implement  physical 
tables  directly  and  then  add  various  indexes  to  speed 
access, 
C-Store 
implements 
only 
projections.  
Specifically,  a  C-Store  projection  is  anchored  on  a  given 
logical  table,  T,  and  contains  one  or  more  attributes  from 
this  table.    In  addition,  a  projection  can  contain  any 
number  of  other  attributes  from  other  tables,  as  long  as 
there  is  a  sequence  of  n:1  (i.e.,  foreign  key)  relationships 
from the anchor table to the table containing an attribute. 
To  form  a  projection,  we  project  the  attributes  of 
interest  from T,  retaining any  duplicate  rows, and perform 
the  appropriate  sequence  of  value-based  foreign-key  joins 
to  obtain  the  attributes  from  the  non-anchor  table(s).  
Hence,  a  projection  has  the  same  number  of  rows  as  its 
anchor  table.   Of  course, much more  elaborate  projections 
could  be  allowed,  but  we  believe  this  simple  scheme  will 
meet  our  needs  while  ensuring  high  performance.    We 
note  that  we  use  the  term  projection  slightly  differently 
than  is  common  practice,  as  we  do  not  store  the  base 
table(s) from which the projection is derived. 

Name 

Age 

Dept 

Salary 

Bob 
Bill 
Jill 

25 
27 
24 

Math 
EECS 
Biology 

10K 
50K 
80K 

 

Table 1: Sample EMP data 

We denote the ith projection over table t as ti, followed 
by  the  names  of  the  fields  in  the  projection.    Attributes 
from  other  tables  are  prepended  with  the  name  of  the 
logical  table  they come  from.    In  this  section, we consider 
an example  for  the  standard EMP(name, age,  salary, dept) 
and  DEPT(dname,  floor)  relations.  Sample  EMP  data  is 
shown in Table 1. One possible set of projections for these 
tables could be as shown in Example 1. 
EMP1 (name, age) 
EMP2 (dept, age, DEPT.floor) 
EMP3 (name, salary)  
DEPT1(dname, floor) 

Example 1: Possible projections for EMP and DEPT 

Tuples  in  a  projection  are  stored  column-wise.  Hence, 
if  there  are  K  attributes  in  a  projection,  there  will  be  K 
data  structures,  each  storing  a  single  column,  each  of 
which  is  sorted on  the  same  sort key.   The  sort  key can be 
any  column  or  columns  in  the  projection.  Tuples  in  a 
projection are sorted on the key(s) in left to right order. 
We indicate the sort order of a projection by appending 
the sort key to the projection separated by a vertical bar. A 
possible ordering for the above projections would be: 
 

EMP1(name, age| age) 
EMP2(dept, age, DEPT.floor| DEPT.floor) 
EMP3(name, salary| salary) 
DEPT1(dname, floor| floor) 

Example 2:  Projections in Example 1 with sort orders 

Lastly, every projection  is horizontally partitioned  into 
1  or more  segments, which  are  given  a  segment  identifier, 
Sid,  where  Sid    >  0.    C-Store  supports  only  value-based 
partitioning  on  the  sort  key  of  a  projection.    Hence,  each 
segment  of  a  given  projection  is  associated  with  a  key 
range of the sort key  for the projection.   Moreover, the set 
of all key ranges partitions the key space.  
Clearly,  to  answer  any  SQL  query  in  C-Store,  there 
must be a covering set of projections  for every table in the 
database such that every column  in every table is stored in 
at  least  one  projection.    However,  C-Store  must  also  be 
able  to  reconstruct  complete  rows  of  tables  from  the 
collection  of  stored  segments.    To  do  this,  it  will  need  to 
join  segments  from  different  projections,  which  we 
accomplish using storage keys and join indexes.  
Storage  Keys.  Each  segment  associates  every  data 
value  of  every  column  with  a  storage  key,  SK.    Values 
from  different  columns 
in 
the  same  segment  with 
matching  storage  keys  belong  to  the  same  logical  row.  
We  refer  to  a  row  of  a  segment  using  the  term  record  or 
tuple.  Storage keys are numbered 1, 2, 3,  … in RS and are 
not  physically  stored,  but  are  inferred  from  a  tuple ’s 
physical  position  in  the  column  (see  Section   3  below.)  
Storage  keys  are  physically  present  in  WS  and  are 
represented  as  integers,  larger  than  the  largest  integer 
storage key for any segment in RS. 
Join  Indices.  To  reconstruct  all  of  the  records  in  a 
table  T  from  its  various  projections,  C-Store  uses  join 

indexes.    If  T1  and  T2  are  two  projections  that  cover  a 
table  T,  a  join  index  from  the M  segments  in  T1  to  the  N 
segments  in  T2  is  logically  a  collection  of  M  tables,  one 
per segment, S, of T1  consisting of rows of the form: 

(s: SID in T2, k: Storage Key in Segment s) 

Here,  an  entry  in  the  join  index  for  a  given  tuple  in  a 
segment of T1 contains the segment ID and storage key of 
the  corresponding  (joining)  tuple  in  T2.  Since  all  join 
indexes  are  between  projections  anchored  at  the  same 
table, this is always a one-to-one mapping.   An alternative 
view  of  a  join  index  is  that  it  takes  T1,  sorted  in  some 
order O, and logically resorts it into the order, O' of T2. 
In  order  to  reconstruct  T  from  the  segments  of  T1,  …, 
Tk  it  must  be  possible  to  find  a  path  through  a  set  of  join 
indices  that  maps  each  attribute  of  T  into  some  sort  order 
O*.   A path  is a collection of  join  indexes originating with 
a  sort  order  specified  by  some  projection,  Ti  ,  that  passes 
through  zero  or  more  intermediate  join  indices  and  ends 
with  a  projection  sorted  in  order  O*.    For  example,  to  be 
able  to  reconstruct  the  EMP  table  from  projections  in 
Example  2,  we  need  at  least  two  join  indices.    If  we 
choose  age  as  a  common  sort  order,  we  could  build  two 
indices  that  map  EMP2  and  EMP3  to  the  ordering  of 
EMP1.  Alternatively,  we  could  create  a  join  index  that 
maps EMP2  to EMP3  and one  that maps EMP3  to EMP1. 
Figure 2 shows a simple example of a join index that maps 
EMP3  to  EMP1,  assuming  a  single  segment  (SID  =  1)  for 
each  projection.    For  example,  the  first  entry  of  EMP3, 
(Bob, 10K),  corresponds  to  the  second  entry  of  EMP1,  and 
thus the first entry of the join index has storage key 2. 

 
Figure 2: A join index from EMP3 to EMP1. 
In  practice,  we  expect  to  store  each  column  in  several 
projections, thereby allowing us to maintain relatively  few 
join  indices.    This  is  because  join  indexes  are  very 
expensive to store and maintain in the presence of updates, 
since each modification  to a projection  requires every  join 
index that points into or out of it to be updated as well. 
The segments of the projections  in a database and their 
connecting  join  indexes  must  be  allocated  to  the  various 
nodes  in  a  C-Store  system.  The C-Store  administrator  can 
optionally  specify  that  the  tables  in  a  database must  be K-
safe.    In  this  case,  the  loss  of K  nodes  in  the  grid will  still 
allow  all  tables  in  a  database  to  be  reconstructed  (i.e., 
despite the K failed sites, there must exist a covering set of 
projections  and  a  set  of  join  indices  that  map  to  some 
common  sort  order.)    When  a  failure  occurs,  C-Store 
simply  continues  with  K-1  safety  until  the  failure  is 

repaired and the node is brought back up to speed.  We are 
currently working on fast algorithms to accomplish this. 
Thus, the C-Store physical DBMS design problem is to 
determine  the  collection  of  projections,  segments,  sort 
keys, and join indices to create for the collection of logical 
tables  in  a  database.  This  physical  schema  must  give  K-
safety  as  well  as  the  best  overall  performance  for  a  given 
training workload,  provided  by  the  C-Store  administrator, 
subject to requiring no more than a given space budget, B.  
Additionally, C-Store can be instructed to keep a log of all 
queries  to  be  used  periodically  as  the  training  workload.  
Because  there  are  not  enough  skilled DBAs  to  go  around, 
we  are  writing  an  automatic  schema  design  tool.    Similar 
issues are addressed in [PAPA04] 
We  now  turn  to  the  representation  of  projections, 
segments, storage keys, and join indexes in C-Store. 
3.  RS 
RS  is  a  read-optimized  column  store.    Hence  any 
segment  of  any  projection  is  broken  into  its  constituent 
columns,  and  each  column  is  stored  in  order  of  the  sort 
key  for  the  projection.    The  storage  key  for  each  tuple  in 
RS  is  the  ordinal  number  of  the  record  in  the  segment.  
This storage key is not stored but calculated as needed. 
3.1 Encoding Schemes 
Columns  in  the  RS  are  compressed  using  one  of  4 
encodings.  The encoding chosen for a column depends on 
its  ordering  (i.e.,  is  the  column  ordered  by  values  in  that 
column  (self-order)  or  by  corresponding  values  of  some 
other  column  in  the  same  projection  (foreign-order),  and 
the  proportion  of  distinct  values  it  contains.   We  describe 
these encodings below. 
 
Type  1:    Self-order,  few  distinct  values:    A  column 
encoded  using  Type  1  encoding  is  represented  by  a 
sequence of  triples,  (v,  f, n)  such  that v  is a value  stored  in 
the  column,  f  is  the  position  in  the  column  where  v  first 
appears,  and  n  is  the  number  of  times  v  appears  in  the 
column.    For  example,  if  a  group  of  4 ’s  appears  in 
positions  12-18,  this  is  captured  by  the  entry,  (4,  12,  7).  
For  columns  that  are  self-ordered,  this  requires  one  triple 
for  each  distinct  value  in  the  column.    To  support  search 
queries  over  values  in  such  columns,  Type  1-encoded 
columns  have  clustered  B-tree  indexes  over  their  value 
fields.    Since  there  are  no  online  updates  to  RS,  we  can 
densepack  the  index  leaving  no  empty  space.    Further, 
with  large  disk  blocks  (e.g.,  64-128K),  the  height  of  this 
index can be kept small (e.g., 2 or less).  
Type  2:  Foreign-order,  few  distinct  values:    A  column 
encoded  using  Type  2  encoding  is  represented  by  a 
sequence  of  tuples,  (v,  b)  such  that  v  is  a  value  stored  in 
the  column  and  b  is  a  bitmap  indicating  the  positions  in 
which the value is stored.  For example, given a column of 
integers  0,0,1,1,2,1,0,2,1,  we  can  Type  2-encode  this  as 
(1,  001101001),  and 
(0,  110000100), 
three  pairs: 

(2,000010010).  Since  each  bitmap  is  sparse,  it  is  run 
length  encoded  to  save  space.    To  efficiently  find  the  i-th 
value  of  a  type  2-encoded  column,    we  include  “offs et 
indexes”:    B-trees  that  map  positions  in  a  column  t o  the 
values contained in that column. 
Type  3:    Self-order,  many  distinct  values:    The  idea  for 
this  scheme  is  to  represent  every  value  in  the  column  as  a 
delta  from  the  previous  value  in  the  column.    Thus,  for 
example, a column consisting of values 1,4,7,7,8,12 would 
be  represented  by  the  sequence:  1,3,3,0,1,4,  such  that  the 
first  entry  in  the  sequence  is  the  first  value  in  the  column, 
and  every  subsequent  entry  is  a  delta  from  the  previous 
value.    Type-3  encoding  is  a  block-oriented  form  of  this 
compression  scheme,  such  that  the  first  entry  of  every 
block  is  a  value  in  the  column  and  its  associated  storage 
key,  and  every  subsequent  value  is  a  delta  from  the 
previous  value.    This  scheme  is  reminiscent  of  the  way 
VSAM  codes  B-tree  index  keys  [VSAM04].  Again,  a 
densepack  B-tree  tree  at  the  block-level  can  be  used  to 
index these coded objects. 
Type 4: Foreign-order, many distinct values:  If there are a 
large  number  of  values,  then  it  probably  makes  sense  to 
leave  the  values  unencoded.    However,  we  are  still 
investigating  possible  compression  techniques  for  this 
situation.  A  densepack  B-tree  can  still  be  used  for  the 
indexing.   
3.2 Join Indexes 
Join  indexes  must  be  used  to  connect  the  various 
projections anchored at the same table.   As noted earlier, a 
join index is a collection of (sid, storage_key) pairs.   Each 
of these two fields can be stored as normal columns. 
There  are  physical  database  design 
implications 
concerning  where  to  store  join  indexes,  and  we  address 
these  in  the  next  section.    In  addition,  join  indexes  must 
integrate RS  and WS;  hence, we  revisit  their  design  in  the 
next section as well.  
4.  WS 
In  order  to  avoid  writing  two  optimizers, WS  is  also  a 
column  store  and  implements  the  identical  physical 
DBMS  design  as  RS.    Hence,  the  same  projections  and 
join  indexes  are  present  in  WS.    However,  the  storage 
representation  is  drastically  different  because WS must  be 
efficiently updatable transactionally.  
The  storage  key,  SK,  for  each  record  is  explicitly 
stored in each WS segment.  A unique SK is given to each 
insert of a logical tuple in a table T.  The execution engine 
must  ensure  that  this  SK  is  recorded  in  each  projection 
that stores data for the logical  tuple. This SK is an integer, 
larger than the number of records in the largest segment in 
the database.   
For  simplicity  and  scalability,  WS  is  horizontally 
partitioned  in  the  same  way  as  RS.    Hence,  there  is  a  1:1 
mapping between RS segments and WS segments.   A (sid, 

storage_key)  pair  identifies  a  record  in  either  of  these 
containers. 
Since  we  assume  that  WS  is  trivial  in  size  relative  to 
RS, we make no effort to compress data values; instead we 
represent all data directly.   Therefore, each projection uses 
B-tree indexing to maintain a logical sort-key order. 
Every  column  in  a  WS  projection  is  represented  as  a 
collection  of  pairs,  (v,  sk),  such  that  v  is  a  value  in  the 
column and  sk  is  its corresponding  storage  key.   Each pair 
is represented in a conventional B-tree on the second field.  
The  sort  key(s)  of  each  projection 
is  additionally 
represented  by  pairs  (s,  sk)  such  that  s  is  a  sort  key  value 
and  sk  is  the  storage  key  describing  where  s  first  appears.  
Again,  this  structure  is  represented  as  a  conventional  B-
tree  on  the  sort  key  field(s).    To  perform  searches  using 
the  sort  key,  one  uses  the  latter  B-tree  to  find  the  storage 
keys  of  interest,  and  then  uses  the  former  collection  of B-
trees to find the other fields in the record.   
Join  indexes  can  now  be  fully  described.    Every 
projection  is  represented  as  a  collection  of  pairs  of 
segments,  one  in  WS  and  one  in  RS.    For  each  record  in 
the  “sender, ”  we  must  store  the  sid  and  storage  key   of  a 
corresponding record in the  “receiver. ”  It will be
 useful to 
horizontally partition the join index in the same way as the 
“sending”  projection  and  then  to  co-locate  join  ind ex 
partitions  with  the  sending  segment  they  are  associated 
with.    In  effect,  each  (sid,  storage  key)  pair  is  a  pointer  to 
a record which can be in either the RS or WS. 
5.   Storage Management 
The  storage  management  issue  is  the  allocation  of 
segments  to  nodes  in  a  grid  system;  C-Store  will  perform 
this operation automatically using a  storage allocator.       It 
seems  clear  that  all  columns  in  a  single  segment  of  a 
projection  should  be  co-located.    As  noted  above,  join 
indexes  should  be  co-located  with 
their 
“sender ” 
segments.  Also, each WS segment will be co-located with 
the RS segments that contain the same key range.   
Using  these  constraints,  we  are  working  on  an 
allocator.    This  system  will  perform  initial  allocation,  as 
well  as  reallocation  when  load  becomes  unbalanced.    The 
details of this software are beyond the scope of this paper. 
Since  everything  is  a  column,  storage  is  simply  the 
persistence  of  a  collection  of  columns.    Our  analysis 
shows  that  a  raw  device  offers  little  benefit  relative  to 
today’s  file  systems.   Hence, big columns (megabyte s) are 
stored  in  individual  files  in  the  underlying  operating 
system. 
6.  Updates and Transactions 
An  insert  is  represented  as  a  collection  of  new  objects 
in  WS,  one  per  column  per  projection,  plus  the  sort  key 
data  structure.    All  inserts  corresponding  to  a  single 
logical  record  have  the  same  storage  key.        The  storage 
key  is  allocated  at  the  site  where  the  update  is  received.  
To  prevent  C-Store  nodes  from  needing  to  synchronize 

with  each  other  to  assign  storage  keys,  each  node 
maintains  a  locally  unique  counter  to  which  it  appends  its 
local  site  id  to  generate  a  globally  unique  storage  key.  
Keys  in  the  WS  will  be  consistent  with  RS  storage  keys 
because  we  set  the  initial  value  of  this  counter  to  be  one 
larger than the largest key in RS. 
We are building WS on  top of BerkeleyDB  [SLEE04]; 
we use the B-tree structures  in that package to  support our 
data  structures.   Hence, every  insert  to a projection  results 
in  a  collection  of  physical  inserts  on  different  disk  pages, 
one  per  column  per  projection. 
  To  avoid  poor 
performance, we plan  to utilize a very  large main memory 
buffer  pool,  made  affordable  by  the  plummeting  cost  per 
byte  of  primary  storage.    As  such,  we  expect  “hot”  WS 
data structures to be largely main memory resident.  
C-Store ’s  processing  of  deletes  is  influenced  by  ou r 
locking  strategy.  Specifically,  C-Store  expects 
large 
numbers  of  ad-hoc  queries  with 
large 
read  sets 
interspersed  with  a  smaller  number  of  OLTP  transactions 
covering  few  records.  If  C-Store  used  conventional 
locking,  then  substantial  lock  contention  would  likely  be 
observed, leading to very poor performance.   
Instead,  in  C-Store,  we  isolate  read-only  transactions 
using  snapshot  isolation.    Snapshot  isolation  works  by 
allowing  read-only  transactions  to  access  the  database  as 
of  some  time  in  the  recent  past,  before  which  we  can 
guarantee  that  there are no uncommitted  transactions.   For 
this reason, when using snapshot isolation, we do not need 
to  set  any  locks.   We  call  the most  recent  time  in  the  past 
at  which  snapshot  isolation  can  run  the  high  water  mark 
(HWM)  and  introduce  a  low-overhead  mechanism  for 
keeping track of its value in our multi-site environment.  If 
we  let  read-only  transactions  set  their  effective  time 
arbitrarily,  then  we  would  have  to  support  general  time 
travel, an onerously expensive task.   Hence, there is also a 
low  water  mark  (LWM)  which  is  the  earliest  effective 
time  at  which  a  read-only  transaction  can  run.  Update 
transactions  continue  to  set  read  and write  locks  and  obey 
strict two-phase locking, as described in Section  6.2. 
6.1 Providing Snapshot Isolation 
The  key  problem  in  snapshot  isolation  is  determining 
which  of  the  records  in WS  and RS  should  be  visible  to  a 
read-only  transaction  running  at  effective  time  ET.    To 
provide  snapshot  isolation,  we  cannot  perform  updates  in 
place.    Instead,  an  update  is  turned  into  an  insert  and  a 
delete.   Hence,  a  record  is  visible  if  it  was  inserted  before 
ET  and  deleted  after  ET.  To  make  this  determination 
without  requiring  a  large  space  budget,  we  use  coarse 
granularity  “epochs, ”  to  be  described  in  Section  6. 1.1,  as 
the  unit  for  timestamps.    Hence,  we  maintain  an  insertion 
vector  (IV)  for  each  projection  segment  in  WS,  which 
contains for each record the epoch in which the record was 
inserted.    We  program  the  tuple  mover    (described  in 
Section  7)  to  ensure  that  no  records  in  RS  were  inserted 
after the LWM.   Hence, RS need not maintain an insertion 

vector.    In  addition,  we  maintain  a  deleted  record  vector 
(DRV)  for  each  projection,  which  has  one  entry  per 
projection  record,  containing  a  0  if  the  tuple  has  not  been 
deleted;  otherwise,  the  entry  contains  the  epoch  in  which 
the  tuple  was  deleted.    Since  the  DRV  is  very  sparse 
(mostly zeros), it can be compactly coded using the type 2 
algorithm  described  earlier.      We  store  the  DRV  in  the 
WS,  since  it  must  be  updatable.    The  runtime  system  can 
now consult IV and DRV  to make the visibility calculation 
for each query on a record-by-record basis. 
6.1.1  Maintaining the High Water Mark 
To  maintain  the  HWM,  we  designate  one  site  the 
timestamp  authority  (TA)  with  the  responsibility  of 
allocating  timestamps  to  other  sites.   The  idea  is  to  divide 
time into a number of epochs; we define the epoch number 
to  be  the  number  of  epochs  that  have  elapsed  since  the 
beginning  of  time.     We  anticipate  epochs  being  relatively 
long  –  e.g.,  many  seconds  each,  but  the  exact  durat ion 
may  vary  from deployment  to deployment.   We define  the 
initial  HWM  to  be  epoch  0  and  start  current  epoch  at  1.  
Periodically,  the  TA  decides  to  move  the  system  to  the 
next  epoch;  it  sends  a  end  of  epoch  message  to  each  site, 
each  of  which  increments  current  epoch  from  e  to  e+1, 
thus  causing  new  transactions  that  arrive  to  be  run  with  a 
timestamp  e+1.      Each  site  waits  for  all  the  transactions 
that began in epoch e (or an earlier epoch) to complete and 
then  sends  an  epoch  complete  message  to  the  TA.  Once 
the  TA  has  received  epoch  complete  messages  from  all 
sites  for  epoch  e,  it  sets  the  HWM  to  be  e,  and  sends  this 
value to each site.   Figure 3 illustrates this process. 
After  the  TA  has  broadcast  the  new  HWM  with  value 
e,  read-only  transactions  can  begin  reading  data  from 
epoch  e  or  earlier  and  be  assured  that  this  data  has  been 
committed.      To  allow  users  to  refer  to  a  particular  real-
world  time  when  their  query  should  start,  we  maintain  a 
table mapping epoch numbers to times, and start the query 
as of the epoch nearest to the user-specified time. 
To  avoid  epoch  numbers  from  growing  without  bound 
and  consuming  extra  space,  we  plan  to  “reclaim”  epo chs 
that are no  longer  needed.   We will do  this by  “wra pping” 
timestamps,  allowing  us  to  reuse  old  epoch  numbers  as  in 
other  protocols,  e.g.,  TCP. 
In  most  warehouse 
 
applications,  records  are  kept  for  a  specific  amount  of 
time,  say  2  years.    Hence,  we  merely  keep  track  of  the 

oldest  epoch  in  any  DRV,  and  ensure  that  wrapping 
epochs through zero does not overrun.    
To  deal  with  environments  for  which  epochs  cannot 
effectively  wrap,  we  have  little  choice  but  to  enlarge  the 
 
“wrap length” of epochs or the size of an epoch.   
6.2 Locking-based Concurrency Control 
Read-write  transactions  use  strict  two-phase  locking 
for  concurrency  control  [GRAY92].    Each  site  sets  locks 
on  data  objects  that  the  runtime  system  reads  or  writes, 
thereby  implementing  a  distributed  lock  table  as  in  most 
distributed  databases.    Standard  write-ahead  logging  is 
employed  for  recovery  purposes;  we  use  a  NO-FORCE, 
STEAL  policy  [GRAY92]  but  differ  from  the  traditional 
implementation of logging and locking in that we only log 
UNDO records, performing REDO as described in Section 
 6.3,  and  we  do  not  use  strict  two-phase  commit,  avoiding 
the PREPARE phase as described in Section  6.2.1 below.   
Locking can, of course, result  in deadlock.   We resolve 
deadlock  via  timeouts  through  the  standard  technique  of 
aborting one of the deadlocked transactions. 
6.2.1  Distributed COMMIT Processing 
In  C-Store,  each  transaction  has  a  master  that  is 
responsible  for assigning units of work corresponding  to a 
transaction  to  the  appropriate  sites  and  determining  the 
ultimate  commit  state  of  each  transaction.    The  protocol 
differs  from 
two-phase  commit  (2PC) 
in 
that  no 
PREPARE messages are  sent. When  the master  receives a 
COMMIT  statement  for  the  transaction,  it  waits  until  all 
workers  have  completed  all  outstanding  actions  and  then 
issues  a  commit  (or  abort)  message  to  each  site.    Once  a 
site has received a commit message, it can release all locks 
related  to  the  transaction and  delete  the UNDO  log  for  the 
transaction.    This  protocol  differs  from  2PC  because  the 
master  does  not  PREPARE  the  worker  sites.    This  means 
it  is  possible  for  a  site  the  master  has  told  to  commit  to 
crash before writing any updates or log records related to a 
transaction  to  stable  storage.    In  such  cases,  the  failed  site 
will  recover  its  state,  which  will  reflect  updates  from  the 
committed  transaction,  from  other  projections  on  other 
sites in the system during recovery.   
6.2.2  Transaction Rollback 
When  a  transaction  is  aborted  by  the  user  or  the  C-

Site 
1 

T1 

T2 

T3 

T4 

Site 
2 

T6 

T7 

T5 

Site 
3 

T8 
 

TA 

time 

Start  
epoch 
e+1 

End of epoch 
(e) (e) 
Epoch complete 
Epoch complete 
Epoch complete 
New HWM(e) 

Figure 3. Illustration showing how the HWM selection algorithm works.  Gray arrows indicate messages from the TA 
to the sites or vice versa.  We can begin reading tuples with timestamp e when all transactions from epoch e have 
committed.  Note that although T4 is still executing when the HWM is incremented, read-only transactions will not 
see its updates because it is running in epoch e+1. 

Store  system,  it  is  undone  by  scanning  backwards  in  the 
UNDO  log,  which  contains  one  entry  for  each  logical 
update to a segment.  We use logical logging (as in ARIES 
[MOHA92]),  since  physical  logging would  result  in many 
log records, due to the nature of the data structures in WS. 
6.3 Recovery 
As  mentioned  above,  a  crashed  site  recovers  by 
running  a  query  (copying  state)  from  other  projections.  
Recall  that  C-Store  maintains  K-safety;  i.e.  sufficient 
projections and join indexes are maintained, so that K sites 
can  fail  within  t,  the  time  to  recover,  and  the  system  will 
be  able  to  maintain  transactional  consistency.  There  are 
three  cases  to  consider.    If  the  failed  site  suffered  no  data 
loss,  then  we  can  bring  it  up  to  date  by  executing  updates 
that will be queued  for  it elsewhere  in  the network.   Since 
we  anticipate  read-mostly  environments,  this  roll  forward 
operation  should  not  be  onerous.    Hence,  recovery  from 
the  most  common  type  of  crash  is  straightforward.  The 
second  case  to  consider  is  a  catastrophic  failure  which 
destroys  both  the  RS  and  WS.    In  this  case,  we  have  no 
choice  but  to  reconstruct  both  segments  from  other 
projections  and  join  indexes  in  the  system.    The  only 
needed functionality is the ability to retrieve auxiliary data 
structures  (IV, DRV)  from  remote  sites.  After  restoration, 
the  queued  updates must  be  run  as  above.     The  third  case 
occurs  if  WS  is  damaged  but  RS  is  intact.    Since  RS  is 
written only by the tuple mover, we expect it will typically 
escape  damage.    Hence,  we  discuss  this  common  case  in 
detail below.   
6.3.1  Efficiently Recovering the WS 
Consider a WS  segment, Sr, of a projection with a  sort 
key K and a  key  range R on a  recovering  site  r along with 
a  collection  C  of  other  projections,  M1,  …,  Mb   which 
contain  the  sort  key  of  Sr.    The  tuple  mover  guarantees 
that  each  WS  segment,  S,  contains  all  tuples  with  an 
insertion  timestamp  later  than  some  time  tlastmove(S), which 
represents  the  most  recent  insertion  time  of  any  record  in 
S ’ s corresponding RS segment.  
To  recover,  the  recovering  site  first  inspects  every 
projection  in C  for  a  collection  of  columns  that  covers  the 
key  range  K  with  each  segment  having  tlastmove(S)  ≤ 
tlastmove(Sr).  If it succeeds, it can run a collection of queries 
of the form: 

SELECT desired_fields,  
       insertion_epoch, 
       deletion_epoch 
FROM recovery_segment 
WHERE insertion_epoch > tlastmove(Sr)  
      AND insertion_epoch <= HWM 
      AND deletion_epoch = 0  
          OR deletion_epoch >= LWM 
      AND sort_key in K 
 

 
As  long  as  the  above  queries  return  a  storage  key,  other 
fields 
in 
the  segment  can  be  found  by  following 

appropriate  join  indexes.    As  long  as  there  is  a  collection 
of  segments  that  cover  the  key  range  of  Sr,  this  technique 
will  restore  Sr  to  the  current  HWM.    Executing  queued 
updates will then complete the task. 
On  the other hand,  if  there  is  no cover with  the desired 
property,  then  some  of  the  tuples  in  Sr  have  already  been 
moved  to  RS  on  the  remote  site.  Although  we  can  still 
query  the  remote  site,  it  is  challenging  to  identify  the 
desired  tuples  without  retrieving  everything  in  RS  and 
differencing  against  the  local  RS  segment,  which  is 
obviously an expensive operation. 
To  efficiently  handle  this  case,  if  it  becomes  common, 
we  can  force  the  tuple  mover  to  log,  for  each  tuple  it 
moves,  the  storage  key  in  RS  that  corresponds  to  the 
storage  key  and  epoch  number  of  the  tuple  before  it  was 
moved  from  WS.    This  log  can  be  truncated  to  the 
timestamp  of  the  oldest  tuple  still  in  the  WS  on  any  site, 
since  no  tuples  before  that will  ever  need  to  be  recovered.  
In  this  case,  the  recovering  site  can  use  a  remote  WS 
segment,  S,  plus  the  tuple  mover  log  to  solve  the  query 
above, even though tlastmove(S) comes after tlastmove(Sr). 
At  r,  we  must  also  reconstruct  the  WS  portion  of  any 
join  indexes  that  are  stored  locally,  i.e.  for  which  Sr  is  a 
“sender. ” 
  This  merely  entails  querying 
remote 
“receivers, ” which can then compute the join index 
as they 
generate  tuples,  transferring  the  WS  partition  of  the  join 
index along with the recovered columns. 
7.  Tuple Mover 
The  job  of  the  tuple mover  is  to move  blocks  of  tuples 
in  a  WS  segment  to  the  corresponding  RS  segment, 
updating  any  join  indexes  in  the  process.    It  operates  as  a 
background  task  looking  for  worthy  segment  pairs. When 
it finds one, it performs a merge-out process, MOP on this 
(RS, WS) segment pair.   
MOP  will  find  all  records  in  the  chosen  WS  segment 
with  an  insertion  time  at  or  before  the  LWM,  and  then 
divides them into two groups: 
•  Ones  deleted  at  or  before  LWM.    These  are  discarded, 
because the user cannot run queries as of a time when 
they existed. 
•  Ones  that  were  not  deleted,  or  deleted  after  LWM.  
These are moved to RS. 
MOP  will  create  a  new  RS  segment  that  we  name  RS'. 
Then,  it  reads  in  blocks  from  columns  of  the RS  segment, 
deletes any RS  items with a value  in  the DRV  less  than or 
equal  to  the  LWM,  and  merges  in  column  values  from 
WS.  The  merged  data  is  then  written  out  to  the  new  RS' 
segment,  which  grows  as  the  merge  progresses.  The  most 
recent  insertion  time  of  a  record  in  RS ’  becomes  th e 
segment’s  new  tlastmove  and  is  always  less  than  or  equal  to 
the  LWM.  This  old-master/new-master  approach  will  be 
more  efficient  than  an  update-in-place  strategy,  since 
essentially  all  data  objects  will  move.  Also,  notice  that 
records  receive new  storage  keys  in RS',  thereby  requiring 
join  index  maintenance.    Since  RS  items  may  also  be 

deleted, maintenance of  the DRV  is also mandatory. Once 
RS' contains all the WS data and join indexes are modified 
on  RS',  the  system  cuts  over  from  RS  to  RS'.  The  disk 
space used by the old RS can now be freed. 
Periodically  the  timestamp  authority  sends  out  to  each 
site  a  new  LWM  epoch  number.    Hence,  LWM  “chases” 
HWM,  and  the  delta  between  them  is  chosen  to  mediate 
between the needs of users who want historical access and 
the WS space constraints.  
8.  C-Store Query Execution 
The  query  optimizer  will  accept  a  SQL  query  and 
construct a query plan of execution nodes.   In this  section, 
we  describe  the  nodes  that  can  appear  in  a  plan  and  then 
the architecture of the optimizer itself.   
8.1 Query Operators and Plan Format 
There  are  10  node  types  and  each  accepts  operands  or 
produces  results  of  type  projection  (Proj),  column 
(Col), or bitstring (Bits).  A projection is simply a set of 
columns  with  the  same  cardinality  and  ordering.    A 
bitstring  is  a  list  of  zeros  and  ones  indicating  whether  the 
associated  values  are  present  in  the  record  subset  being 
described.      In  addition,  C-Store  query  operators  accept 
predicates  (Pred),  join  indexes  (JI),  attribute  names 
(Att), and expressions (Exp) as arguments. 
Join  indexes  and  bitstrings  are  simply  special  types  of 
columns.    Thus,  they  also  can  be  included  in  projections 
and used as inputs to operators where appropriate. 
We briefly summarize each operator below. 
1.  Decompress  converts  a  compressed  column  to  an 
uncompressed (Type 4) representation.   
2.  Select  is  equivalent  to  the  selection  operator  of 
the  relational  algebra  (s),  but  rather  than  producing  a 
restriction  of  its  input,  instead  produces  a  bitstring 
representation of the result.   
3.  Mask accepts a bitstring B and projection Cs, and 
restricts  Cs  by  emitting  only 
those  values  whose 
corresponding bits in B are 1.  
4.  Project  equivalent  to  the  projection  operator  of 
the relational algebra (p). 
5.  Sort  sorts  all  columns  in  a  projection  by  some 
subset of those columns (the sort columns).  
6.  Aggregation  Operators    compute  SQL-like 
aggregates  over  a  named  column,  and  for  each  group 
identified by the values in a projection. 
7. Concat combines one or more projections sorted in 
the same order into a single projection 
8.  Permute  permutes  a  projection  according  to  the 
ordering defined by a join index.  
9. Join  joins  two  projections  according  to  a  predicate 
that correlates them.  
10.  Bitstring  Operators  BAnd  produces  the 
bitwise  AND  of  two  bitstrings.    BOr  produces  a  bitwise 
OR.  BNot produces the complement of a bitstring.   

A C-Store query plan consists of a tree of the operators 
listed  above,  with  access  methods  at  the  leaves  and 
iterators serving as the interface between connected nodes.  
Each  non-leaf  plan  node  consumes  the  data  produced  by 
its  children  via  a modified  version  of  the  standard  iterator 
interface  [GRAE93]  via  calls  of  “get_next. ”    To  red uce 
communication  overhead  (i.e.,  number  of  calls  of 
“get_next”)  between  plan  nodes,    C-Store  iterators 
return 
64K blocks from a single column. This approach preserves 
the  benefit  of  using  iterators  (coupling  data  flow  with 
control  flow),  while  changing  the  granularity  of  data  flow 
to better match the column-based model. 
8.2 Query Optimization 
We  plan  to  use  a  Selinger-style  [SELI79]  optimizer 
that  uses  cost-based  estimation  for  plan  construction.   We 
anticipate using a two-phase optimizer [HONG92] to limit 
the  complexity  of  the  plan  search  space.  Note  that  query 
optimization  in  this  setting  differs  from  traditional  query 
optimization  in  at  least  two  respects:  the  need  to  consider 
compressed  representations  of  data  and  the  decisions 
about when to mask a projection using a bitstring. 
C-Store  operators  have  the  capability  to  operate  on 
both  compressed  and  uncompressed  input.  As  will  be 
shown in Section 9, the ability to process compressed data 
is  the  key  to  the  performance  benefits  of  C-Store.    An 
operator ’s  execution  cost  (both  in  terms  of  I/O  and  
memory  buffer  requirements) 
is  dependent  on 
the 
compression  type  of  the  input.  For  example,  a  Select 
over  Type  2  data  (foreign  order/few  values,  stored  as  a 
delta-encoded  bitmaps,  with  one  bitmap  per  value)  can  be 
performed by reading only those bitmaps from disk whose 
values  match  the  predicate  (despite  the  column  itself  not 
being  sorted). However, operators that take Type 2 data as 
input  require much  larger memory  buffer  space  (one  page 
of  memory  for  each  possible  value  in  the  column)  than 
any of the other three types of compression. Thus, the cost 
model must be sensitive to the representations of input and 
output columns. 
The  major  optimizer  decision 
is  which  set  of 
projections  to use  for a given  query.   Obviously,  it will be 
time  consuming  to  construct  a  plan  for  each  possibility, 
and  then  select  the  best  one. Our  focus will  be  on  pruning  
this  search  space.    In  addition,  the  optimizer  must  decide 
where  in  the  plan  to  mask  a  projection  according  to  a 
bitstring.    For  example,  in  some  cases  it  is  desirable  to 
push the Mask early in the plan (e.g, to avoid producing a 
bitstring  while  performing  selection  over  Type  2 
compressed  data)  while  in  other  cases  it  is  best  to  delay 
masking  until  a  point  where  it  is  possible  to  feed  a 
bitstring to the next operator in the plan (e.g., COUNT) that 
can produce results solely by processing the bitstring.  
9.  Performance Comparison 
At  the  present  time,  we  have  a  storage  engine  and  the 
executor 
for  RS 
running. 
  We  have  an  early 

implementation of  the WS and  tuple mover; however  they 
are  not  at  the  point  where  we  can  run  experiments  on 
them.   Hence, our performance analysis  is  limited  to  read-
only  queries,  and  we  are  not  yet  in  a  position  to  report  on 
updates.   Moreover,  RS  does  not  yet  support  segments  or 
multiple  grid  nodes.    As  such,  we  report  single-site 
numbers.    A  more  comprehensive  performance  study  will 
be  done  once  the  other  pieces  of  the  system  have  been 
built. 
Our  benchmarking  system  is  a  3.0  Ghz  Pentium, 
running RedHat Linux, with 2 Gbytes of memory and 750 
Gbytes of disk.   
In  the  decision  support  (warehouse)  market  TPC-H  is 
the  gold  standard,  and  we  use  a  simplified  version  of  this 
benchmark,  which  our  current  engine  is  capable  of 
running.    Specifically,  we  implement  the  lineitem,  order, 
and customer tables as follows: 
 

CREATE TABLE LINEITEM ( 
L_ORDERKEY  INTEGER NOT NULL, 
L_PARTKEY  INTEGER NOT NULL, 
L_SUPPKEY  INTEGER NOT NULL, 
L_LINENUMBER 
INTEGER NOT NULL, 
L_QUANTITY  INTEGER NOT NULL, 
INTEGER NOT NULL, 
L_EXTENDEDPRICE 
L_RETURNFLAG 
CHAR(1) NOT NULL, 
L_SHIPDATE  INTEGER NOT NULL); 
 
CREATE TABLE ORDERS  ( 
O_ORDERKEY  INTEGER NOT NULL, 
O_CUSTKEY  INTEGER NOT NULL, 
O_ORDERDATE INTEGER NOT NULL); 
 
CREATE TABLE CUSTOMER ( 
C_CUSTKEY  INTEGER NOT NULL, 
C_NATIONKEY INTEGER NOT NULL); 
 
We chose columns of type INTEGER and CHAR(1) to 
simplify  the  implementation.    The  standard  data  for  the 
above  table  schema  for TPC-H  scale_10  totals 60,000,000 
line  items  (1.8GB),  and  was  generated  by  the  data 
generator available from the TPC website.   
We  tested  three  systems  and  gave  each  of  them  a 
storage  budget  of  2.7   GB  (roughly  1.5  times  the  raw  data 
size)  for  all  data  plus  indices.    The  three  systems  were C-
Store  as  described  above  and  two  popular  commercial 
relational DBMS systems, one that implements a row store 
and  another  that  implements  a  column  store.    In  both  of 
these  systems,  we  turned  off  locking  and  logging.    We 
designed  the  schemas  for  the  three  systems  in  a  way  to 
achieve  the  best  possible  performance  given  the  above 
storage  budget.    The  row-store  was  unable  to  operate 
within  the  space  constraint  so  we  gave  it  4.5 GB which  is 
what  it  needed  to  store  its  tables  plus  indices.    The  actual 
disk usage numbers are shown below. 
Column Store 
Row Store 
C-Store 
1.987 GB 
2.650 GB 
4.480 GB 
Obviously, C-Store uses 40% of the space of the row 
store, even though it uses redundancy and the row store 
does not.  The main reasons are C-Store compression and 

absence of padding to word or block boundaries. The 
column store requires 30% more space than C-Store.  
Again, C-Store can store a redundant schema in less space 
because of superior compression and absence of padding. 
       We ran the following seven queries on each system: 
 
Q1.    Determine  the  total  number  of  lineitems  shipped  for 
each day after day D.   
SELECT l_shipdate, COUNT (*) 
FROM lineitem 
WHERE l_shipdate > D 
GROUP BY l_shipdate 
 Q2.   Determine  the  total  number  of  lineitems  shipped  for 
each supplier on day D.   
SELECT l_suppkey, COUNT (*) 
FROM lineitem 
WHERE l_shipdate = D 
GROUP BY l_suppkey 
Q3.    Determine  the  total  number  of  lineitems  shipped  for 
each supplier after day D.   
SELECT l_suppkey, COUNT (*) 
FROM lineitem 
WHERE l_shipdate > D 
GROUP BY l_suppkey 
Q4.    For  every  day  after  D,  determine  the  latest  shipdate 
of all items ordered on that day.  
SELECT o_orderdate, MAX (l_shipdate) 
FROM lineitem, orders 
WHERE l_orderkey = o_orderkey AND 
      o_orderdate > D 
GROUP BY o_orderdate 
Q5.  For each supplier, determine the latest shipdate of an 
item from an order that was made on some date, D. 
SELECT l_suppkey, MAX (l_shipdate) 
FROM lineitem, orders 
WHERE l_orderkey = o_orderkey AND  
      o_orderdate = D 
GROUP BY l_suppkey 
Q6.  For each supplier, determine the latest shipdate of an 
item from an order made after some date, D. 
SELECT l_suppkey, MAX (l_shipdate) 
FROM lineitem, orders 
WHERE l_orderkey = o_orderkey AND 
       o_orderdate > D 
GROUP BY l_suppkey 
Q7.   Return a  list of  identifiers  for all nations  represented 
by  customers  along with  their  total  lost  revenue  for 
the  parts  they  have  returned.    This  is  a  simplified 
version of query 10 (Q10) of TPC-H. 
SELECT c_nationkey, sum(l_extendedprice) 
FROM lineitem, orders, customers 
WHERE l_orderkey=o_orderkey AND 
 
o_custkey=c_custkey AND 
 
l_returnflag='R' 
GROUP BY c_nationkey 

 
We constructed schemas  for each of the three systems that 
best  matched  our  seven-query  workload.    These  schema 
were  tuned  individually  for  the  capabilities  of  each 
system. For C-Store, we used the following schema: 
 
 D1: (l_orderkey, l_partkey, l_suppkey, 
l_linenumber, l_quantity, 
l_extendedprice, l_returnflag, l_shipdate 
| l_shipdate, l_suppkey) 

Row Store 

D2: (o_orderdate, l_shipdate, l_suppkey | 
o_orderdate, l_suppkey) 
D3: (o_orderdate, o_custkey, o_orderkey |  
o_orderdate) 
D4: (l_returnflag, l_extendedprice, 
c_nationkey | l_returnflag) 
D5: (c_custkey, c_nationkey | c_custkey) 
D2  and  D4  are  materialized  (join)  views.    D3  and  D5 
are added for completeness since we don ’t use them  in any 
of  the  seven  queries.    They  are  included  so  that  we  can 
answer  arbitrary  queries  on  this  schema  as  is  true  for  the 
product schemas. 
On  the  commercial  row-store  DBMS,  we  used  the 
common  relational  schema  given  above  with  a  collection 
of  system-specific  tuning  parameters.  We  also  used 
system-specific  tuning  parameters  for  the  commercial 
column-store  DBMS.    Although  we  believe  we  chose 
good  values  for  the  commercial  systems,  obviously,  we 
cannot guarantee they are optimal. 
The  following  table  indicates  the  performance  that  we 
observed.   All measurements  are  in  seconds  and  are  taken 
on a dedicated machine. 
C-Store 
Query 

Column 
Store 
2.24 
6.80 
0.03 
Q1 
0.83 
1.09 
0.36 
Q2 
29.54 
93.26 
4.90 
Q3 
22.23 
722.90 
2.09 
Q4 
0.93 
116.56 
0.31 
Q5 
32.83 
652.90 
8.50 
Q6 
Q7 
33.24 
265.80 
2.54 
As  can  be  seen,  C-Store  is  much  faster  than  either 
commercial product.  The main reasons are: 
•  Column  representation  –  avoids  reads  of  unused 
attributes (same as competing column store). 
•  Storing  overlapping  projections,  rather  than  the whole 
table  –  allows  storage  of  multiple  orderings  of  a  column  
as appropriate. 
•  Better  compression  of  data  –  allows more  orderings  in 
the same space. 
•  Query 
compressed 
on 
operate 
operators 
representation  – mitigates  the  storage  barrier  problem  of 
current processors. 
In  order  to  give  the  other  systems  every  possible 
advantage,  we  tried  running  them  with  the  materialized 
views  that  correspond  to  the  projections  we  used  with  C-
Store.    This  time,  the  systems  used  space  as  follows  (C-
Store  numbers,  which  did  not  change,  are  included  as  a 
reference): 
 

C-Store 
1.987 GB 

Row Store 
11.900 GB 

Column Store 
4.090 GB 

 
The  relative  performance  numbers  in  seconds  are  as 
follows: 
 
 

Query 

C-Store 

Row Store 

Column 
Store 
2.34 
0.22 
0.03 
Q1 
0.83 
0.81 
0.36 
Q2 
29.10 
49.38 
4.90 
Q3 
22.23 
21.76 
2.09 
Q4 
0.63 
0.70 
0.31 
Q5 
25.46 
47.38 
8.50 
Q6 
Q7 
6.28 
18.47 
2.54 
As  can  be  seen,  the  performance  gap  closes,  but  at  the 
same  time,  the  amount  of  storage  needed  by  the  two 
commercial systems grows quite large.   
In  summary,  for  this  seven  query  benchmark,  C-Store 
is  on  average  164  times  faster  than  the  commercial  row-
store  and  21  times  faster  than  the  commercial  column-
store  in  the  space-constrained  case.    For  the  case  of 
unconstrained  space,  C-Store  is  6.4  times  faster  than  the 
commercial  row-store,  but  the  row-store  takes  6  times  the 
space.    C-Store  is  on  average  16.5  times  faster  than  the 
commercial  column-store,  but  the  column-store  requires 
1.83 times the space. 
 Of  course,  this  performance  data  is  very  preliminary.  
Once we get WS running and write a tuple mover, we will 
be in a better position to do an exhaustive study. 
10. Related Work 
One  of  the  thrusts  in  the  warehouse  market  is  in 
maintaining  so-called  “data cubes. ”   This work date
s  from 
Essbase by Arbor  software  in  the early 1990 ’s, whic h was 
effective  at 
“slicing  and  dicing” 
large  data  sets 
[GRAY97].    Efficiently  building  and maintaining  specific 
aggregates  on  stored  data  sets  has  been  widely  studied 
[KOTI99,  ZHAO97].  Precomputation  of  such  aggregates 
as  well  as  more  general  materialized  views  [STAU96]  is 
especially  effective  when  a  prespecified  set  of  queries  is 
run  at  regular  intervals.    On  the  other  hand,  when  the 
workload cannot be anticipated in advance, it is difficult to 
decide  what  to  precompute.    C-Store  is  aimed  entirely  at 
this latter problem. 
Including  two  differently  architected  DBMSs  in  a 
single  system  has  been  studied  before  in  data  mirrors 
[RAMA02].    However,  the  goal  of  data  mirrors  was  to 
achieve  better  query  performance  than  could  be  achieved 
by  either  of  the  two  underlying  systems  alone  in  a 
warehouse  environment.    In  contrast,  our  goal  is  to 
simultaneously  achieve  good  performance  on  update 
workloads  and  ad-hoc  queries.    Consequently,  C-Store 
differs dramatically from a data mirror in its design. 
Storing  data  via  columns  has  been  implemented  in 
several  systems,  including  Sybase  IQ,  Addamark,  Bubba 
[COPE88], Monet [BONC04], and KDB.  Of these, Monet 
is  probably  closest  to  C-Store  in  design  philosophy. 
However,  these  systems  typically  store  data  in  entry 
sequence  and  do  not  have  our  hybrid  architecture  nor  do 
they  have  our  model  of  overlapping  materialized 
projections. 

Similarly,  storing  tables  using an  inverted organization 
is  well  known.   Here,  every  attribute  is  stored  using  some 
sort  of  indexing,  and  record  identifiers  are  used  to  find 
corresponding  attributes  in  other  columns.    C-Store  uses 
this sort of organization in WS but extends the architecture 
with RS and a tuple mover. 
There  has  been  substantial  work  on  using  compressed 
data  in  databases; Roth  and Van Horn  [ROTH93]  provide 
an excellent  summary of many of the techniques that have 
been  developed.   Our  coding  schemes  are  similar  to  some 
of  these  techniques,  all  of  which  are  derived  from  a  long 
history  of  work  on  the  topic  in  the  broader  field  of 
computer  science  [WITT87].    Our  observation  that  it  is 
possible  to  operate  directly  on  compressed  data  has  been 
made before [GRAE91, WESM00]. 
Lastly,  materialized  views, 
snapshot 
isolation, 
transaction  management,  and  high  availability  have  also 
been  extensively  studied.    The  contribution  of  C-Store  is 
an  innovative  combination  of  these  techniques  that 
simultaneously  provides  improved  performance, K-safety, 
efficient retrieval, and high performance transactions. 
11. Conclusions 
This  paper  has  presented  the  design  of  C-Store,  a 
radical  departure  from  the  architecture  of  current DBMSs.  
Unlike  current  commercial  systems,  it  is  aimed  at  the 
“read-mostly”  DBMS  market. 
  The 
innovative 
contributions embodied in C-Store include: 
•  A  column  store  representation,  with  an  associated 
query execution engine. 
•  A  hybrid  architecture  that  allows  transactions  on  a 
column store. 
•  A  focus  on  economizing  the  storage  representation  on 
disk, by coding data values and dense-packing the data. 
•  A  data  model  consisting  of  overlapping  projections  of 
tables,  unlike  the  standard  fare  of  tables,  secondary 
indexes, and projections. 
•  A  design  optimized  for  a  shared  nothing  machine 
environment. 
•  Distributed  transactions  without  a  redo  log  or  two 
phase commit. 
•  Efficient snapshot isolation. 
Acknowledgements and References 
We  would  like  to  thank  David  DeWitt  for  his  helpful 
feedback and ideas. 

This  work  was  supported  by  the  National  Science 
Foundation  under  NSF  Grant  numbers  IIS-0086057  and 
IIS-0325525. 

[ADDA04]   http://www.addamark.com/products/sls.htm 
[BERE95]  Hal Berenson et al. A Critique of ANSI SQL Isolation 
Levels. In Proceedings of SIGMOD, 1995. 
[BONC04]  Peter Boncz  et. al.. MonetDB/X100: Hyper-pipelining 
Query Execution. In Proceedings CIDR 2004. 
 
S. Ceri and J. Widom. Deriving Production Rules for 
Incremental View Maintenance. In VLDB, 1991.  

[CERI91] 

[GRAY92] 

[MOHA92] 

[COPE88]  George Copeland et. al. Data Placement in Bubba. In 
Proceedings SIGMOD 1988. 
 
[DEWI90]  David Dewitt et. al. The GAMMA Database machine 
Project.  IEEE Transactions on Knowledge and Data 
Engineering, 2(1), March, 1990. 
[DEWI92]  David Dewitt and Jim Gray.  Parallel Database Systems: 
The Future of High Performance Database Processing. 
Communications of the ACM, 1992. 
[FREN95]  Clark D. French.  One Size Fits All Database Architectures 
Do Not Work for DSS. In Proceedings of SIGMOD, 1995. 
[GRAE91]  Goetz Graefe, Leonard D. Shapiro. Data Compression and 
Database Performance. In Proceedings of the Symposium 
on Applied Computing, 1991. 
[GRAE93]  G. Graefe. Query Evaluation Techniques for Large 
Databases. Computing Surveys, 25(2), 1993. 
Jim Gray and Andreas Reuter. Transaction Processing  
Concepts and Techniques, Morgan Kaufman, 1992. 
[GRAY97]  Gray et al. DataCube: A Relational Aggregation Operator 
Generalizing Group-By, Cross-Tab, and Sub-Totals. Data 
Mining and Knowledge Discovery, 1(1), 1997. 
[HONG92]   Wei Hong and Michael Stonebraker.  Exploiting Inter-
operator Parallelism in XPRS.  In SIGMOD, 1992. 
[KDB04] 
http://www.kx.com/products/database.php 
[KOTI99]  Yannis Kotidis, Nick Roussopoulos. DynaMat: A Dynamic 
View Management System for Data Warehouses. In 
Proceedings of  SIGMOD, 1999.  
 C. Mohan et. al:  ARIES: A Transaction Recovery Method 
Supporting Fine-granularity Locking and Partial Rollbacks 
Using Write-ahead Logging. TODS, March 1992. 
Patrick O'Neil, Edward Cheng, Dieter Gawlick, and 
Elizabeth O'Neil, The Log-Structured Merge-Tree. Acta 
Informatica 33, June 1996.  
P. O’Neil and D. Quass. Improved Query Per formance 
with Variant Indexes, In Proceedings of SIGMOD, 1997. 
[ORAC04]  Oracle Corporation.  Oracle 9i Database for Data 
Warehousing and Business Intelligence. White Paper. 
http://www.oracle.com/solutions/ 
business_intelligence/Oracle9idw_bwp. 
Stratos Papadomanolakis and Anastassia Ailamaki. 
AutoPart: Automating Schema Design for Large Scientific 
Databases Using Data Partitioning. In SSDBM 2004. 
[RAMA02]  Ravishankar Ramamurthy, David Dewitt. Qi Su: A Case 
for Fractured Mirrors.  In Proceedings of VLDB, 2002. 
[ROTH93]  Mark A. Roth, Scott J. Van Horn: Database Compression. 
SIGMOD Record 22(3). 1993. 
Patricia Selinger, Morton Astrahan, Donald Chamberlain, 
Raymond Lorie, Thomas Price.  Access Path Selection in a 
Relational Database.  In Proceedings of SIGMOD, 1979. 
[SLEE04] 
http://www.sleepycat.com/docs/ 
[STAU96]  Martin Staudt, Matthias Jarke. Incremental Maintenance of 
Externally Materialized Views.  In VLDB, 1996. 
[STON86]  Michael Stonebraker. The Case for Shared Nothing.  In 
Database Engineering, 9(1), 1986. 
[SYBA04] 
http://www.sybase.com/products/databaseservers/sybaseiq 
[TAND89]  Tandem Database Group: NonStop SQL, A Distributed 
High Performance, High Availability Implementation of 
SQL. In Proceedings of HPTPS, 1989. 
[VSAM04]    http://www.redbooks.ibm.com/redbooks.nsf/0/8280b48d5e 
3997bf85256cbd007e4a96?OpenDocument 
[WESM00]   Till Westmann, Donald Kossmann, Sven Helmer, Guido 
Moerkotte. The Implementation and Performance of 
Compressed Databases. SIGMOD Record 29(3), 2000. 
[WEST00]  Paul Westerman. Data Warehousing: Using the Wal-Mart 
Model. Morgan-Kaufmann Publishers , 2000. 
I. Witten, R. Neal, and J. Cleary. Arithmetic coding for 
data compression. Comm.  of the ACM, 30(6), June 1987. 
[ZHAO97]  Y. Zhao, P. Deshpande, and J. Naughton. An Array-Based 
Algorithm for Simultaneous Multidimensional Aggregates. 
In Proceedings of SIGMOD, 1997.  

[WITT87] 

[ONEI96] 

[ONEI97] 

[PAPA04] 

[SELI79] 

