Journal of Machine Learning Research 16 (2015) 155-186

Submitted 7/13; Revised 7/14; Published 2/15

Online Learning via Sequential Complexities

Alexander Rakhlin
Department of Statistics
University of Pennsylvania
Philadelphia, PA 19104

Karthik Sridharan
Department of Computer Science
Cornel l University
Ithaca, NY 14853

Ambuj Tewari
Department of Statistics
University of Michigan
Ann Arbor, MI 48109

Editor: Mehryar Mohri

rakhlin@wharton.upenn.edu

skarthik@wharton.upenn.edu

tewaria@umich.edu

Abstract
We consider the problem of sequential prediction and provide tools to study the minimax
value of the associated game. Classical statistical learning theory provides several useful
complexity measures to study learning with i.i.d. data. Our proposed sequential complex-
ities can be seen as extensions of these measures to the sequential setting. The developed
theory is shown to yield precise learning guarantees for the problem of sequential predic-
tion. In particular, we show necessary and suï¬ƒcient conditions for online learnability in
the setting of supervised learning. Several examples show the utility of our framework: we
can establish learnability without having to exhibit an explicit online learning algorithm.
Keywords: online learning, sequential complexities, regret minimization

1. Introduction

This paper is concerned with sequential prediction problems where no probabilistic assump-
tions are made regarding the data generating mechanism. Our viewpoint is expressed well
by the following quotation from Cover and Shenhar (1977):

â€œWe are interested in sequential prediction procedures that exploit any ap-
parent order in the sequence. We do not assume the existence of any underlying
distributions, but assume that the sequence is an outcome of a game against a
malevolent intelligent nature.â€

We will, in fact, take the game theoretic viewpoint seriously. All our investigations will
proceed by analyzing the minimax value of a repeated game between a player or learner
develop the theory in a somewhat abstract setting. Towards this end, ï¬x the sets F and
and a â€œmalevolent intelligent natureâ€, or the adversary.
Even though we have the setting of prediction problems in mind, it will be useful to
Â©2015 Alexander Rakhlin, Karthik Sridharan, Ambuj Tewari.

Rakhlin, Sridharan and Tewari
Z , as well as a loss function (cid:96) âˆ¶ F Ã— Z â†’ R, and consider the following T -round repeated
round t âˆˆ {1, . . . , T }, the learner chooses ft âˆˆ F , the adversary picks zt âˆˆ Z , and the learner
suï¬€ers loss (cid:96)(ft , zt ). At the end of T rounds we deï¬ne regret
two-player game, which we term the online learning or sequential prediction model. On
R(f1âˆ¶T , z1âˆ¶T ) Ã¡ TQ
(cid:96)(ft , zt ) âˆ’ inf
(cid:96)(f , zt )
f âˆˆF TQ
t=1
t=1
best ï¬xed decision. For the given pair (F , Z ), the problem is said to be online learnable
as the diï¬€erence between the cumulative loss of the player and the cumulative loss of the
if there exists an algorithm for the learner such that regret grows sublinearly in the time
horizon T , no matter what strategy the adversary employs.
The origin of the online learning (or sequential prediction) model can be traced back to
the work of Robbins (1950) on compound statistical decision problems. Some of the earliest
sequential prediction algorithms were proposed by Blackwell (1956a,b) and Hannan (1957).
Blackwellâ€™s method was based on his celebrated approachability theorem whereas Hannanâ€™s
was based on minimizing a randomly perturbed sum of previous losses. Hannanâ€™s ideas
were to later resurface in the inï¬‚uential Follow-the-Perturbed-Leader family (Kalai and
Vempala, 2005) of online learning algorithms. The seminal ideas in the work of Robbins,
Blackwell and Hannan led to further developments in many diï¬€erent ï¬elds. Cover (1967),
Davisson (1973), Ziv and Lempel (1977), Rissanen (1984), Feder et al. (1992), and others laid
the foundation of universal coding, compression and prediction in the Information Theory
literature. Within Computer Science, Littlestone and Warmuth (1994), Cesa-Bianchi et al.
(1997), Vovk (1998), and others studied the online learning model and the prediction with
expert advice framework. The connections between regret minimization and convergence
to equilibria was studied in Economics by Foster and Vohra (1997), Hart and Mas-Colell
(2000) and others.
We have no doubt left out many interesting works above. But even our partial list will
convince the reader that research in online learning and sequential prediction has beneï¬ted
from contributions by researchers from a variety of ï¬elds including Computer Science, Eco-
nomics, Information Theory, and Statistics. For an excellent synthesis and presentation of
results from these diï¬€erent ï¬elds we refer the reader to the book by Cesa-Bianchi and Lugosi
(2006). Many of the ideas in the ï¬eld are constructive, resulting in beautiful algorithms,
or algorithmic techniques, associated with names such as Follow-the-Regularized-Leader,
Follow-the-Perturbed-Leader, Weighted Ma jority, Hedge, and Online Gradient Descent.
However, analyzing speciï¬c algorithms has obvious disadvantages. The algorithm may not
be â€œoptimalâ€ for the task at hand. Even if it is optimal, one cannot prove that fact unless
one develops tools for analyzing the inherent complexity of the online learning problem.
Our goal is precisely to provide such tools. We will begin by deï¬ning the minimax value
of the game underlying the abstract online learning model. Then we will develop tools for
controlling the minimax value resulting in a theory that parallels statistical learning theory.
In particular, we develop analogues of combinatorial dimensions, covering numbers, and
Rademacher complexities. We will also provide results relating these complexities.
Note that our approach is non-constructive : controlling the sequential complexities
mentioned above will only guarantee the existence of a good online learning algorithm but

156

Online Learning via Sequential Complexities

will not explicitly create one. However, it turns out that that the minimax point of view
can indeed lead to constructive algorithms as shown by Rakhlin et al. (2012).

2. Minimax Value and Online Learnability
F is a subset of a separable metric space. Let Q be the set of probability measures on F
To proceed further in our analysis of the minimax value of the repeated game between the
and assume that Q is weakly compact. In order to allow randomized prediction, we allow
learner and the adversary, we need to make a few technical assumptions. We assume that
the learner to choose a distribution qt âˆˆ Q on every round. The minimax value of the game
 inf
VT (F , Z ) Ã¡ inf
 TQ
(cid:96)(ft , zt ) âˆ’ inf
(cid:96)(f , zt ) .
is then deï¬ned as
f âˆˆF TQ
q1 âˆˆQ sup
z1 âˆˆZ E
qT âˆˆQ sup
zT âˆˆZ E
f1 âˆ¼q1
fT âˆ¼qT
t=1
t=1
(1)
f âˆ¼q stands for the expectation operator integrating out the ran-
Henceforth, the notation E
choose each zt based on the history of moves f1âˆ¶tâˆ’1 and z1âˆ¶tâˆ’1 .
dom variable f with distribution q . We consider here the adaptive adversary who gets to
The ï¬rst key step in the study of the value of the game is to appeal to the minimax
theorem and exchange the pairs of inï¬ma and suprema in (1). This dual formulation is
assumption of weak compactness of Q and lower semi-continuity of the loss function.1 Under
easier to analyze because the choice of the player comes after the choice of the mixed
strategy of the adversary. We remark that the minimax theorem holds under a very general
these conditions, we can appeal to Theorem 1 stated below, which is adapted for our needs
Theorem 1 Let F and Z be the sets of moves for the two players, satisfying the necessary
from the work of Abernethy et al. (2009).
conditions for the minimax theorem to hold. Denote by Q and P the sets of probability
measures (mixed strategies) on F and Z , respectively. Then
 sup
VT (F , Z ) = sup
(cid:96)(f , zt ) ,
[(cid:96)(ft , zt )] âˆ’ inf
 TQ
f âˆˆF TQ
z1 âˆ¼p1
zT âˆ¼pT
zt âˆ¼pt
ft âˆˆF E
t=1
t=1
E
E
inf
where suprema over pt range over al l distributions in P .
p1
pT
VT (F , Z ), taking (2) as the starting point.
The question of learnability in the online learning model is now reduced to the study of
Deï¬nition 2 A class F is said to be online learnable with respect to the given Z and (cid:96) if
T â†’âˆ VT (F , Z )
â‰¤ 0 .
lim sup
T
Note that our notion of learnability is related to, but distinct from, Hannan consistency
(Hannan, 1957; Cesa-Bianchi and Lugosi, 2006). The latter notion requires the iterated
game to go on for an inï¬nite number of rounds and is formulated in terms of almost sure

(2)

1. We refer to Appendix A for a precise statement of the minimax theorem, as well as suï¬ƒcient conditions.

157

Rakhlin, Sridharan and Tewari

convergence. In contrast, we consider a distinct game for each T and look at expected regret.
Nevertheless, it is possible to obtain Hannan consistency using the techniques developed in
is allowed to make decisions in a larger set G , while the best-in-hindsight term in the regret
this paper by considering a slightly diï¬€erent game (Rakhlin et al., 2011).
deï¬nition is computed with respect to F âŠ† G . Such a settingâ€”interesting especially with
We also remark that the statements in this paper extend to the case when the learner
choose Y âŠ‚ R, Z = X Ã— Y , F âŠ† Y X = G and (cid:96)(f , (x, y)) =  f (x) âˆ’ y  . This setting will be
regard to computational concernsâ€”is termed improper learning. For example, prediction
studied later in the paper. Note that in the proper learning scenario, VT (F , Z ) â‰¥ 0 (e.g.,
with side information (or, the supervised learning problem) is one such case, where we
This paper is aimed at understanding the value of the game VT (F , Z ) for various func-
since all zt â€™s can be chosen to be the same), and thus the â€œlim supâ€ in Deï¬nition 2 can be
tion classes F . Since our focus is on the complexity of F , we shall often write VT (F ) keeping
simply replaced with the limit being equal to zero.
the dependence on Z (and (cid:96)) implicit. As we show, the sequential complexity notionsâ€”
Numbersâ€”also give us a handle on the value VT (F ). In the next section, we brieï¬‚y deï¬ne
that were shown by Rakhlin et al. (2014) to characterize uniform martingale Laws of Large
these sequential complexity notions and mention some of the key relations between them.
A more detailed account of the relationships between sequential complexity measures along
with complete proofs can be found in (Rakhlin et al., 2014).

3. Sequential Complexities

Unlike the well-studied statistical learning scenario with i.i.d. data, the online learning
problem possesses a certain sequential dependence. Such dependence cannot be captured
by classical notions of complexity that are based on a batch of data given as a tuple of T
examples. A basic unit that does capture temporal dependence is a binary tree. Surprisingly,
A Z -valued tree z of depth T is a complete rooted binary tree with nodes labeled by
for the sequential prediction problems considered in this paper, one need not look further
elements of Z . Such a tree z is identiï¬ed with the sequence (z1 , . . . , zT ) of labeling functions
than binary trees to capture the relevant complexity.
zi âˆ¶ {Â±1}iâˆ’1 â†’ Z which provide the labels for each node. Therefore, z1 âˆˆ Z is the label for
the root of the tree, while zi for i > 1 is the label of the node obtained by following the
path of length i âˆ’ 1 from the root, with +1 indicating â€˜rightâ€™ and âˆ’1 indicating â€˜leftâ€™. A path
of length T is given by the sequence  = (1 , . . . , T ) âˆˆ {Â±1}T . For brevity, we shall often
write zt (), where  = (1 , . . . , T ), but it is understood that zt depends only on the preï¬x
(1 , . . . , tâˆ’1 ).
Now, let 1 , . . . , T be independent Rademacher random variables. Given a Z -valued tree
z of depth T , we deï¬ne the sequential Rademacher complexity of a function class G âŠ† RZ
on a Z -valued tree z as
RT (G , z) Ã¡ E sup
tg(zt ()) ,
TQ
gâˆˆG 1
t=1
and we denote by RT (G ) = supz RT (G , z) its supremum over all Z -valued trees of depth T .
T
The importance of the introduced notion stems from the following result (Rakhlin et al.,

158

Online Learning via Sequential Complexities
2014, Theorem 2): for any distribution over a sequence (Z1 , . . . , ZT ), we have
E g(Zt ) Z tâˆ’1 (cid:6) âˆ’ g(Zt ) â‰¤ 2 RT (G ) ,
E sup
TQ
gâˆˆG 1
t=1
where Z tâˆ’1 = (Z1 , . . . , Ztâˆ’1 ). In other words, the martingale version of the uniform devi-
(3)
T
sequences in Z T . It then follows that a uniform martingale Law of Large Numbers holds
ations of means from expectations is controlled by the worst-case sequential Rademacher
for G if and only if RT (G ) â†’ 0. For i.i.d. random variables, a similar statement can be
complexity. A matching lower bound also holds for the supremum over distributions on
made in terms of the classical Rademacher complexity, and so one might hope that many
other complexity notions from empirical process theory have martingale (or we may say,
sequential) analogues. Luckily, this is indeed the case (Rakhlin et al., 2014). As we show
in this paper, these generalizations of the classical notions also give a handle on (as well
as necessary and suï¬ƒcient conditions for) online learnability, thus painting a picture that
completely parallels statistical learning theory. But before we present our main results, let
us recall some key deï¬nitions and results in (Rakhlin et al., 2014).
In providing further upper bounds on sequential Rademacher complexity, the following
respect to (cid:96)p norm) of G âŠ† RZ on a tree z of depth T if
deï¬nitions of an â€œeï¬€ective sizeâ€ of a function class generalize the classical notions of a
covering number. A set V of R-valued trees of depth T is a (sequential) Î±-cover (with
 vt () âˆ’ g(zt ()) p1~p â‰¤ Î±.
 1
âˆ€g âˆˆ G , âˆ€ âˆˆ {Â±1}T , âˆƒv âˆˆ V s.t.
TQ
t=1
The (sequential) covering number of a function class G on a given tree z is deï¬ned as
T
Np (Î±, G , z) Ã¡ min { V   âˆ¶ V is an Î±-cover w.r.t. (cid:96)p norm of G on z} .
It is straightforward to check that Np (Î±, G , z) â‰¤ Nq (Î±, G , z) whenever 1 â‰¤ p â‰¤ q â‰¤ âˆ.
Further deï¬ne Np (Î±, G , T ) = supz Np (Î±, G , z), the maximal (cid:96)p covering number of G over
depth T trees. For a class G of binary-valued functions, we also deï¬ne a so-called 0-cover
(or, cover at scale 0), denoted by N (0, G , z), as equal to any Np (0, G , z). The deï¬nition of
a 0-cover can be seen as the correct analogue of the size of a projection of G onto a tuple of
When G âŠ† [âˆ’1, 1]Z is a ï¬nite class of bounded functions, one can show (Rakhlin et al.,
points in the i.i.d. case. The size of this pro jection in the i.i.d. case was the starting point
of the work of Vapnik and Chervonenkis.
RT (G , z) â‰¤ 
2 log  G  
2014, Lemma 1) that
T
a bound that should (correctly) remind the reader of the Exponential Weights regret bound.
any G âŠ† [âˆ’1, 1]Z , for any Î± > 0,
With the deï¬nition of an Î±-cover with respect to (cid:96)1 norm, one can easily extend (4) beyond
RT (G , z) â‰¤ Î± + 
the ï¬nite case. Immediately from the deï¬nition of (cid:96)1 covering number, it follows that for
2 log N1 (Î±, G , z)
T
159

(5)

,

(4)

Rakhlin, Sridharan and Tewari

entropy integral bound. For p â‰¥ 1, the integrated complexity of a function class G âŠ† [âˆ’1, 1]Z
(Rakhlin et al., 2014, Eq. 9). A tighter control is obtained by integrating the covering
on a Z -valued tree of depth T is deï¬ned as
numbers at diï¬€erent scales. To this end, consider the following analogue of the Dudley

4Î± + 12âˆš
T (G , z) Ã¡ inf
log Np (Î´, G , z) dÎ´
T S 1
Î±â‰¥0
Dp
T (G , z), with D2
T (G , z) denoted simply by DT (G , z). We have previously
T (G ) = supz Dp
(6)
Î±
shown (Rakhlin et al., 2014, Theorem 3) that, for any function class G âŠ† [âˆ’1, 1]Z and any
Z -valued tree z of depth T ,
and Dp
RT (G , z) â‰¤ DT (G , z).
We next turn to the description of sequential combinatorial parameters. A Z -valued
(7)
tree z of depth d is shattered by a function class G âŠ† {Â±1}Z if for all  âˆˆ {Â±1}d , there exists
g âˆˆ G such that g(zt ()) = t for all t âˆˆ [d]. The Littlestone dimension Ldim(G , Z ) is the
largest positive integer d such that G shatters a Z -valued tree of depth d (Littlestone, 1988;
follows. A Z -valued tree z of depth d is Î±-shattered by a function class G âŠ† RZ if there
Ben-David et al., 2009). The scale-sensitive version of Littlestone dimension is deï¬ned as
âˆ€ âˆˆ {Â±1}d , âˆƒg âˆˆ G s.t. âˆ€t âˆˆ [d], t (g(zt ()) âˆ’ st ()) â‰¥ Î±~2.
exists an R-valued tree s of depth d such that
fatÎ± (G , Z ) at scale Î± is the largest d such that G Î±-shatters a Z -valued tree of depth d.
The tree s will be called a witness to shattering. The (sequential) fat-shattering dimension
The notions introduced above can be viewed as sequential generalizations of the VC
dimension and the fat-shattering dimension where tuples of points get replaced by complete
binary trees. In fact, one recovers the classical notions if the tree z in the above deï¬nitions is
restricted to have the same values within a level (hence, no temporal dependence). Crucially,
First, let G âŠ† {0, . . . , k}Z be a class of functions with fat2 (G ) = d. Then, it can be shown
the sequential combinatorial analogues provide control for the growth of sequential covering
(Rakhlin et al., 2014, Theorem 4) that for any T â‰¥ 1,
numbers, justifying the deï¬nitions.
T
Nâˆ (1~2, G , T ) â‰¤ dQ
i k i â‰¤ (ekT )d .
i=0
For the second result (Rakhlin et al., 2014, Corollary 1), suppose G is a class of [âˆ’1, 1]-valued
functions on Z . Then, for any Î± > 0, and any T â‰¥ 1,
Î± fatÎ± (G )
Nâˆ (Î±, G , T ) â‰¤  2eT
(8)
.
parameter (Rakhlin et al., 2014, Theorem 5). For a class G âŠ† {0, . . . , k}Z with fat1 (G ) = d,
Finally, we recall a bound on the size of the 0-cover in terms of the fat1 combinatorial
T
N (0, G , T ) â‰¤ dQ
i k i â‰¤ (ekT )d .
we have
i=0
160

(9)

Online Learning via Sequential Complexities
In particular, for k = 1 (that is, binary classiï¬cation) we have fat1 (G ) = Ldim(G ). The
inequality (9) is therefore a sequential analogue of the celebrated Vapnik-Chervonenkis-
Sauer-Shelah lemma.

4. Structural Properties
properties that RT (G ) satisï¬es. These properties allow one to establish online learnability
For the examples developed in this paper, it will be crucial to exploit a number of useful
for complex function classes even if no explicit learning algorithms are available.
Lemma 3 Let F , G âŠ† RZ and let conv(G ) denote the convex hul l of G . Let z be any Z -
We ï¬rst state some properties that are easily proved but are nevertheless very useful.
1. If F âŠ† G , then RT (F , z) â‰¤ RT (G , z).
valued tree of depth T . Then the fol lowing properties hold.
2. RT (conv(G ), z) = RT (G , z)
3. RT (cG , z) =  c RT (G , z) for al l c âˆˆ R.
4. For any h âˆ¶ Z â†’ R, RT (G + h, z) = RT (G , z) where G + h = {g + h âˆ¶ g âˆˆ G }.
These properties match those of the classical Rademacher complexity (Bartlett and Mendel-
son, 2003) and can be proved in essentially the same way (we therefore skip the straight-
forward proofs).
The next property is a key tool for many of the applications: it allows us to bound the
sequential Rademacher complexity for the Cartesian product of function classes composed
Lemma 4 Let G = G1 Ã— . . . Ã— Gk where each Gj âŠ† [âˆ’1, 1]Z . Further, let Ï† âˆ¶ Rk Ã— Z â†’ R be
with a Lipschitz mapping in terms of complexities of the individual classes.
such that Ï†(â‹…, z) is L-Lipschitz with respect to  â‹… âˆ for al l z âˆˆ Z , and let
Ï† â—‹ G = {z  Ï†((g1 (z), . . . , gk (z)), z) âˆ¶ gj âˆˆ Gj } .
âˆš
RT (Ï† â—‹ G ) â‰¤ 8 L 1 + 4
2 log3~2 (eT 2 ) âˆ‘k
j=1 RT (Gj )
Then we have
as long as RT (Gj ) â‰¥ 1~T for each j .
Let us explicitly state the more familiar contraction property, an immediate corollary
Corollary 5 Fix a class G âŠ† [âˆ’1, 1]Z with RT (G ) â‰¥ 1~T and a function Ï† âˆ¶ R Ã— Z â†’ R.
of the above result.
Assume Ï†(â‹…, z) is L-Lipschitz for al l z âˆˆ Z . Then
âˆš
2 log3~2 (eT 2 ) â‹… RT (G ),
RT (Ï† â—‹ G ) â‰¤ 8 L 1 + 4
where Ï† â—‹ G = {z  Ï†(g(z), z) âˆ¶ g âˆˆ G }.
We state another useful corollary of Lemma 4.

161

Rakhlin, Sridharan and Tewari
Corollary 6 For a ï¬xed binary function b âˆ¶ {Â±1}k â†’ {Â±1} and classes G1 , . . . , Gk of {Â±1}-
RT (b(G1 , . . . , Gk )) â‰¤ O log3~2 (T ) âˆ‘k
j=1 RT (Gj ).
valued functions,
Note that, in the classical case, the Lipschitz contraction property holds without any
extra poly-logarithmic factors in T (Ledoux and Talagrand, 1991). It is an open question
whether the poly-logarithmic factors can be removed in the results above.
It is worth
pointing out ahead of time that Theorem 8 belowâ€”in the setting of supervised learning with
convex Lipschitz lossâ€”does allow us to avoid the extraneous factor that would otherwise
appear from a combination of Theorem 7 and Corollary 5.

5. Main Results

We now relate the value of the game to the worst case expected value of the supremum
of an empirical process. However, unlike empirical processes that involve i.i.d. sums, our
process involves a sum of martingale diï¬€erences. In view of (3), the expected supremum
can be further upper-bounded by the sequential Rademacher complexity.
E[g(Zt ) Z1 , . . . , Ztâˆ’1 ] âˆ’ g(Zt ) â‰¤ 2 RT ((cid:96)(F )),
gâˆˆ(cid:96)(F )  1
T VT (F ) â‰¤ sup
TQ
Theorem 7 The minimax value is bounded as
t=1
1
E sup
where (cid:96)(F ) = {(cid:96)(f , â‹…) âˆ¶ f âˆˆ F } and the supremum is taken over al l distributions P over
P
T
(Z1 , . . . , ZT ).
We can now employ the tools developed earlier in the paper to upper bound the value of
the game. Interestingly, any non-trivial upper bound guarantees existence of a prediction
strategy that has sublinear regret irrespective of the sequence of the moves of the adversary.
This complexity-based approach of establishing learnability should be contrasted with the
purely algorithm-based approaches found in the literature.
5.1 Supervised Learning
In this improper learning scenario, the learner at time t picks a function ft âˆ¶ X â†’ R and the
adversary provides the input target pair zt = (xt , yt ) âˆˆ X Ã— Y where Y âŠ‚ R. In particular,
In this subsection we study the supervised learning problem mentioned earlier in the paper.
the binary classiï¬cation problem corresponds to the case Y = {Â±1}. Let F âŠ† Y X and let us
ï¬x the absolute value loss function (cid:96)( Ë†y , y) =   Ë†y âˆ’ y  . While we focus on the absolute loss, it
is easy to see that all the results hold (with modiï¬ed rates) for any loss (cid:96)( Ë†y , y) such that
for all Ë†y and y , Ï†((cid:96)( Ë†y , y)) â‰¤   Ë†y âˆ’ y   â‰¤ Î¦((cid:96)( Ë†y , y)) where Î¦ and Ï† are monotonically increasing
functions. For instance, the squared loss ( Ë†y âˆ’ y)2 is a classic example.
We now observe that the value of the improper supervised learning game can be equiv-
(cid:96)(f (xt ), yt ) ,
(cid:96)( Ë†yt , yt ) âˆ’ inf
 TQ
T (F ) = sup
V S
 sup
alently written as
f âˆˆF TQ
t=1
t=1
q1 âˆˆ ËœQ sup
inf
y1
x1
xT

qT âˆˆ ËœQ sup
inf
yT

Ë†y1 âˆ¼q1
E

Ë†yT âˆ¼qT
E

162

(10)

(11)

Online Learning via Sequential Complexities
where ËœQ denotes the set of probability distributions over Y and Ë†yt has distribution qt . This
equivalence is easy to verify: we may view the choice ft âˆ¶ X â†’ Y as pre-specifying predictions
ft (x) for all the possible x âˆˆ X , while alternatively we can simply make the choice Ë†yt âˆˆ Y
having observed the particular move xt âˆˆ X . The advantage of rewriting the game in the
shown for the set of distributions on the original space of functions of the type X â†’ Y .
form (10) is that the minimax theorem only needs to be applied to the pair Ë†yt and yt , given
the ï¬xed choice xt . The minimax theorem then holds even if weak compactness cannot be
An examination of the proof of Theorem 7 reveals that the value (10) is upper bounded
in exactly the same way, and the side information simply appears as an additional tree x
in sequential Rademacher complexity, giving us:
t (cid:96)(f (xt ()), yt ()) .
E sup
T (F ) â‰¤ 2 sup
T V S
TQ
f âˆˆF 1
t=1
1
T
x,y
However, for the supervised learning setting, we can strengthen Theorem 7. The following
theorem allows us to remove any convex Lipschitz loss (including the absolute loss) before
Theorem 8 Let Y = [âˆ’1, 1] and suppose, for any y âˆˆ Y , (cid:96)(â‹…, y) is convex and L-Lipschitz.
passing to the sequential Rademacher complexity.
T (F ) â‰¤ 2 L RT (F ).
T V S
Then the minimax value of a supervised learning problem is upper bounded as
1
We remark that the contraction property for sequential Rademacher complexity, stated in
Section 4, yields an extraneous logarithmic factor when applied to (11); here, we achieve
the desired bound by removing the Lipschitz function directly during the symmetrization
step.
Proposition 9 Consider the supervised learning problem with a function class F âŠ† [âˆ’1, 1]X
Armed with the theorem, we now prove the following result.
and absolute loss (cid:96)( Ë†y , y) =   Ë†y âˆ’ y  . Then, for any T â‰¥ 1, we have

 â‰¤ RT (F ) â‰¤ 1
Î±
min {fatÎ± , T }
âˆš
T (F ) â‰¤ 2RT (F ) â‰¤ 2DT (F )
T V S

1
4Î± + 12âˆš
 ,
sup
â‰¤ 2 inf
Î²  dÎ²
fatÎ² log  2eT
T
4
2
T S 1
Î±
where fatÎ± = fatÎ± (F ).
Î±
Î±
The proposition above implies that ï¬niteness of the fat-shattering dimension at all scales
is necessary and suï¬ƒcient for online learnability of the supervised learning problem. Fur-
ther, all the complexity notions introduced so far are within a poly-logarithmic factor from
each other whenever the problem is learnable. These results are summarized in the next
Theorem 10 For any function class F âŠ† [âˆ’1, 1]X , the fol lowing statements are equivalent
theorem:
163

(12)

Rakhlin, Sridharan and Tewari
1. Function class F is online learnable in the supervised setting with absolute loss.
2. Sequential Rademacher complexity satisï¬es limT â†’âˆ RT (F ) = 0.
3. For any Î± > 0, the scale-sensitive dimension fatÎ± (F ) is ï¬nite.
T (F ), the sequential Rademacher complexity RT (F ), and the integrated complexity DT (F )
V S
are within a multiplicative factor of O(log3~2 T ) of each other.
Moreover, if the function class is online learnable, then the value of the supervised game
Remark 11 Additional ly, the three statements of Theorem 10 are equivalent to F satisfy-
ing a martingale version of the uniform Law of Large Numbers. This property is termed
Sequential Uniform Convergence by Rakhlin et al. (2014), and we refer to their paper for
For binary classiï¬cation, we write V Binary
for V S
more details.
T . This case has been investigated
T
thoroughly by Ben-David et al. (2009) and indeed served as a key motivation for this paper.
setting is simply the 0-1 loss (cid:96)( Ë†y , y) = 1 { Ë†y â‰  y}, where 1 {U } is 1 if U is true and 0 otherwise.
As a consequence of Proposition 9 and (9), we have a tight control on the value of the game
for the binary classiï¬cation problem. Note that the absolute loss in the binary classiï¬cation
Corollary 12 For the binary classiï¬cation problem with function class F and the 0-1 loss,


T Ldim(F ) log T
(F ) â‰¤ K2
T min {Ldim(F ), T } â‰¤ V Binary
we have
for some universal constants K1 , K2 > 0.
K1
T
Both the upper and the lower bound in the above result were originally derived in Ben-
David et al. (2009). Notably, we achieved the same bounds non-constructively through
purely combinatorial and covering number arguments.
It is natural to ask whether being able to learn in the online model is diï¬€erent from
learning in the i.i.d. model (in the distribution-free supervised setting). The standard
example that exhibits a gap between the two frameworks (e.g., Littlestone, 1988; Ben-David
F = {fÎ¸ (x) = 1 {x â‰¤ Î¸} âˆ¶ Î¸ âˆˆ [0, 1]}
et al., 2009) is binary classiï¬cation using the class of step functions
on [0, 1]. This class has VC dimension 1, but is not learnable in the online setting. Indeed,
related class of â€œrampâ€ functions with slope L > 0
it is possible to verify that the Littlestone dimension is inï¬nite. Interestingly, the closely-
FL = fÎ¸ (x) = 1 {x â‰¤ Î¸} + (1 âˆ’ L(x âˆ’ Î¸))1 {Î¸ < x â‰¤ Î¸ + 1~L} âˆ¶ Î¸ âˆˆ [0, 1]
is learnable (say for supervised learning using absolute loss) in the online setting (and hence
also in the i.i.d. case). Furthermore, the larger class of all bounded L-Lipschitz functions
on a bounded interval is also online learnable (see Eq. 14 and proof of Proposition 18).
Once again, we are able to make these statements from purely complexity-based considera-
tions, without exhibiting an algorithm. Further examples where we can demonstrate online
learnability are explored in Section 6.

164

Online Learning via Sequential Complexities

5.2 Online Convex Optimization

Over the past decade, Online Convex Optimization (OCO) has emerged as a uniï¬ed on-
line learning framework (Zinkevich, 2003; Shalev-Shwartz, 2011). Various methods, such
as Exponential Weights, can be viewed as instances of online mirror descent, solving the
associated OCO problem. Much research eï¬€ort has been devoted to understanding this
abstract and simpliï¬ed setting. It is tempting to say that any problem of online learning,
as deï¬ned in the Introduction, can be viewed as OCO (in fact, online linear optimization)
unnecessary dependence on the number of functions in the class F . Nevertheless, OCO
over the set of probability distributions; however, one should also recognize that by lineariz-
ing the problem, any interesting structure is lost and one instead suï¬€ers from the possibly
is a central part of the recent literature, and we will study this scenario using techniques
the learner F is a bounded closed convex subset of a Banach space (B ,  â‹… ) with f  â‰¤ D
developed in this paper.
for all f âˆˆ F (the reader can think of Rd equipped with an (cid:96)p norm for simplicity). Let  â‹… 
The standard setting of online convex optimization is as follows. The set of moves of
be the dual norm. The adversaryâ€™s set Z consists of convex G-Lipschitz (with respect to
 â‹…  ) functions over F :
Z = Zcvx = {g âˆ¶ F â†’ R âˆ¶ g convex and G-Lipschitz w.r.t.  â‹… } .
Let the loss function be (cid:96)(f , g) = g(f ), the evaluation of the adversarially chosen function
Z = Zlin = {f  f , z  âˆ¶ z â‰¤ G}
at f . For the particular case of online linear optimization, we instead take
with Z now a subset of the dual space. It is well-known (e.g., Abernethy et al., 2008) that
Zcvx ) is as hard as the corresponding linear optimization problem with Zlin if one considers
the online convex optimization problem (without further assumptions on the functions in
Lemma 13 Suppose F , Zcvx , Zlin be deï¬ned as above. Then we have
deterministic algorithms. The same trivially extends to randomized methods:
VT (F , Zcvx ) = VT (F , Zlin ) .
OCO. The reader may wonder why we do not directly try to bound the value VT (F , Zcvx )
by RT (F , Zcvx ). In fact, this proof strategy cannot give a non-trivial bound if F is a subset
We will now show how to use the above result to derive minimax regret guarantees for
of a high-dimensional (or inï¬nite-dimensional) space (Shalev-Shwartz et al., 2009, Sec. 4.1).
A function Î¨ âˆ¶ F â†’ R is (Ïƒ, q)-uniformly convex (for q âˆˆ [2, âˆ)) on F with respect to a
Instead, we use the lemma above to bound the value of the game where adversary plays
norm  â‹…  if, for all Î¸ âˆˆ [0, 1] and f1 , f2 âˆˆ F ,
convex functions with that of the game where adversary plays linear functions.
Î¨(Î¸f1 + (1 âˆ’ Î¸)f2 ) â‰¤ Î¸Î¨(f1 ) + (1 âˆ’ Î¸)Î¨(f2 ) âˆ’ Ïƒ Î¸ (1 âˆ’ Î¸)
f1 âˆ’ f2 q .
A (Ïƒ, 2)-uniformly convex function will be called Ïƒ -strongly convex.
q
165

Rakhlin, Sridharan and Tewari

exploited in its proof is that Î¨ is (Ïƒ, q)-uniformly convex with respect to  â‹…  if and only if
We will give examples shortly but we ï¬rst state a proposition that is useful to bound
Î¨ is (1~Ïƒ, p)-uniformly smooth with respect to  â‹…  where 1~p + 1~q = 1.
the sequential Rademacher complexity of linear function classes. The crucial duality fact
Proposition 14 (Rakhlin et al., 2014) Let F be a subset of some Banach space B with
norm  â‹…  and let Z be a subset of the dual space B equipped with norm  â‹…  . Suppose that
Î¨ âˆ¶ F â†’ R is (Ïƒ, q)-uniformly convex with respect to  â‹…  and 0 â‰¤ Î¨(f ) â‰¤ Î¨max for al l f âˆˆ F .
Ïƒ T pâˆ’1 1~p
RT (F ) â‰¤ Cp Z   Î¨pâˆ’1
Then we have
max
,
where Z  = supzâˆˆZ z , p is such that 1~p + 1~q = 1, and Cp = (p~(p âˆ’ 1)) pâˆ’1
p .

Using the above Proposition in conjunction with Lemma 13 and Theorem 7, we can
immediately conclude thatVT (F , Zcvx ) â‰¤ 2 T RT (F ) â‰¤ 2G
2 Î¨max T
for any non-negative function Î¨ âˆ¶ F â†’ R that is Ïƒ -strongly convex w.r.t.  â‹… . Note that,
Ïƒ
typically, Î¨max will depend on D. For example, in the particular case when  â‹…  =  â‹…  =  â‹… 2 ,
âˆš
we can take Î¨(u) = 1
2 u2
for the online gradient descent algorithm. In general, for  â‹…  =  â‹… p and  â‹…  =  â‹… q , we

can use Î¨(u) = 1
T ~(p âˆ’ 1) since Î¨ is (p âˆ’ 1)-strongly convex
2 u2
2 and the above bound becomes 2GD
T and recovers the guarantee
w.r.t.  â‹… p . These O(âˆš
T ) regret rates are not new but we re-derive them to illustrate the
p to get a bound of 2GD
usefulness of the tools we developed.

6. Further Examples

Now we present some further applications of the tools we have developed in this paper for
some speciï¬c learning problems. To begin, we show how to bound the sequential Rade-
macher complexity of functions computed by neural networks. Then, we derive margin
based regret bounds in a fairly general setting. The classical analogues of these margin
bounds have played a big role in the modern theory of supervised learning where they help
explain the success of linear classiï¬ers in high dimensional spaces (e.g., Schapire et al., 1997;
Koltchinskii and Panchenko, 2002). We then study the complexity of classes formed by de-
cision trees, analyze the setting of transductive learning, and consider an online version of
the Isotron problem. Finally, we make a connection to the seminal work of Cesa-Bianchi
and Lugosi (1999) by re-deriving their bound on the minimax regret in a static experts
game in terms of the classical Rademacher averages.

6.1 Neural Networks

We provide below a bound on the sequential Rademacher complexity for classic multi-layer
neural networks thus showing they are learnable in the online setting. The model of neural

166

Online Learning via Sequential Complexities

Consider a k-layer 1-norm neural network, deï¬ned by a base function class F1 and,
networks we consider below and the bounds we provide are analogous to the ones considered
recursively, for each 2 â‰¤ i â‰¤ k ,
in the i.i.d. setting by Bartlett and Mendelson (2003).
 ,
Fi = x  Q
j Ïƒ (fj (x))  âˆ€j fj âˆˆ Fiâˆ’1 , w i 1 â‰¤ Bi
w i
j
Proposition 15 Suppose Ïƒ âˆ¶ R â†’ [âˆ’1, 1] is L-Lipschitz with Ïƒ(0) = 0. Then it holds that
where Ïƒ is a Lipschitz transfer function, such as the sigmoid function.
âˆš
RT (Fk ) â‰¤  kM
16Bi Lkâˆ’1 1 + 4
RT (F1 ).
2 log3~2 (eT 2 )k
i=2
 w1 â‰¤ B1
In particular, for the case ofF1 = x  âˆ‘j w1
and X âŠ‚ Rd we have the bound
j xj
âˆš
2 log3~2 (eT 2 )k
RT (Fk ) â‰¤  kM
16Bi Lkâˆ’1 1 + 4
i=1
where Xâˆ is such that âˆ€x âˆˆ X , xâˆ â‰¤ Xâˆ .
Our result is a non-constructive guarantee, and, to the best of our knowledge, no algorithms
for learning neural networks within the online learning model exist. It is not clear if the
above bounds could be obtained via computationally eï¬ƒcient methods.

2 log d
T



Xâˆ

6.2 Margin Based Regret

In the classical statistical setting, margin bounds provide guarantees on the expected zero-
one loss of a classiï¬er based on the empirical margin zero-one error. These results form the
basis of the theory of large margin classiï¬ers (see Schapire et al., 1997; Koltchinskii and
Panchenko, 2002). Recently, in the online setting, bounds of a similar ï¬‚avor have been shown
for general function classes F based on their sequential Rademacher complexity. We use
through the concept of margin via the Littlestone dimension (Ben-David et al., 2009). We
show that our machinery can easily lead to margin bounds for binary classiï¬cation problems
Proposition 16 For any function class F âŠ‚ [âˆ’1, 1]X , there exists a randomized prediction
ideas from (Koltchinskii and Panchenko, 2002) to do this.
strategy given by Ï„ such that for any sequence z1 , . . . , zT where each zt = (xt , yt ) âˆˆ X Ã— {Â±1},
E Ë†yt âˆ¼Ï„t (z1âˆ¶tâˆ’1 ) [1 { Ë†ytyt < 0}]
TQ
t=1
âˆš
âˆš
1 {f (xt )yt < 2Î³ } + 16
 inf
â‰¤ inf
T 1 + log log  1
2 log3~2 (eT 2 ) T RT (F ) + 2
Î³ 1 + 4
Î³  .
f âˆˆF TQ
Î³ >0
t=1

167

Rakhlin, Sridharan and Tewari

by some function f âˆˆ F . The upper bound guarantees that there exists a strategy (that does
To interpret the above bound, suppose that the sequence of yt â€™s is predicted with a margin 2Î³
complexity of F divided by the margin, up to poly-logarithmic factors. Crucially, the bound
does not directly depend on the dimensionality of the input space X .
not need to know the value of Î³ ) with cumulative loss given by the sequential Rademacher
6.3 Decision Trees
of decision trees of depth no more than d. The function class F for this problem is deï¬ned
as follows. Each f âˆˆ F is deï¬ned by choosing a rooted binary tree of depth no more than
We consider here the binary classiï¬cation problem where the learner competes with a set
d and associating to each node a binary valued decision function from a set H âŠ† {Â±1}X . A
binary value for a given x can be obtained by traversing the tree from the root according
to the value of the decision function at each node and then reading oï¬€ the label of the
leaf. Importantly, x â€œreachesâ€ only one leaf of the tree. Alternatively, for any leaf l, the
1 hl,i (x) = 1
membership of x is given by the conjunctionM
i
To complete the deï¬nition of f , we choose weights wl > 0, âˆ‘l wl = 1, along with the value
Ïƒl âˆˆ {Â±1} of the function on each leaf l. The resulting function f can be written as
where hl,i is either the decision function at node i along the path to the leaf l, or its negation.
1 hl,i (x) = 1
f (x) = Q
wlÏƒl M
i
l
where the sum runs over all the leaves of the tree.
The following proposition is the online analogue of a result about decision tree learning
Proposition 17 Denote by F the class of decision trees of depth at most d with decision
that Bartlett and Mendelson (2003) proved in the i.i.d. setting.
functions in H. There exists a randomized strategy Ï„ for the learner such that for any
sequence of instances z1 , . . . , zT , with zt = (xt , yt ) âˆˆ X Ã— {Â±1},
E Ë†yt âˆ¼Ï„t (z1âˆ¶tâˆ’1 ) [1 { Ë†yt â‰  yt}] â‰¤ inf
1 {f (xt ) â‰  yt}
TQ
f âˆˆF TQ
t=1
t=1
min C (l), d log3 (T ) T R(H) + âˆš
+ O Q
T log(N ) ,
where C (l) denotes the number of instances that reach the leaf l and are correctly classiï¬ed
l
t=1 1 {ytf (xt ) â‰¤ 0}, with N > 2 being the number of
in the decision tree f that minimizes âˆ‘T
leaves in this tree.

It is not clear whether computationally feasible online methods exist for learning decision
trees, and this represents an interesting avenue of further research.

168

Online Learning via Sequential Complexities

Let F be a class of functions from X to R. Let
6.4 Transductive Learning
Ì‚Nâˆ (Î±, F ) = min  G  âˆ¶ G âŠ† RX s.t. âˆ€f âˆˆ F âˆƒg âˆˆ G satisfying f âˆ’ gâˆ â‰¤ Î±
be the (cid:96)âˆ covering number at scale Î±, where the cover is pointwise on all of X . It is easy
(13)
âˆ€T , Nâˆ (Î±, F , T ) â‰¤ Ì‚Nâˆ (Î±, F ) .
to verify that
Indeed, let G be a minimal cover of F at scale Î±. We claim that for any X -valued tree of
(14)
depth T , the set V = {vg = g â—‹ x âˆ¶ g âˆˆ G} of R-valued trees is an (cid:96)âˆ cover of F on x. Fix any
 âˆˆ {Â±1}T and f âˆˆ F , and let g âˆˆ G be such that f âˆ’ gâˆ â‰¤ Î±. Clearly  vg
t () âˆ’ f (xt ())  â‰¤ Î±
for any 1 â‰¤ t â‰¤ T , concluding the proof.
of transductive learning, where the set X = {x1 , . . . , xn} is a ï¬nite set. To ensure online
learnability, it is suï¬ƒcient to consider an assumption on the dependence of Ì‚Nâˆ (Î±, F ) on Î±.
This simple observation can be applied in several situations. First, consider the problem
An obvious example of such a class is a VC-type class with Ì‚Nâˆ (Î±, F ) â‰¤ (c~Î±)d for some c
which can depend on n. Assume that F âŠ‚ [âˆ’1, 1]X . Substituting this bound on the covering
number into (6) and choosing Î± = 0, we observe that the value of the supervised game is
upper bounded by 2DT (F ) â‰¤ 48 âˆšdT log c by Proposition 9. It is easy to see that if n is
ï¬xed and the problem is learnable in the batch (i.e., i.i.d.) setting, then the problem is
n â‰¤ T and F consists of binary-valued functions. If F is a class with VC dimension d, the
learnable in the online transductive model.
Sauer-Shelah lemma ensures that the (cid:96)âˆ cover is smaller than (en~d)d â‰¤ (eT ~d)d . Using
In the transductive setting considered by Kakade and Kalai (2006), it is assumed that

the previous argument with c = eT , we obtain a bound of 4
dT log(eT ) for the value of
the game, matching the bound of Kakade and Kalai (2006) up to a constant factor.

6.5 Isotron

Kalai and Sastry (2009) introduced a method called Isotron for learning Single Index Models
(SIM). These models generalize linear and logistic regression, generalized linear models, and
revealed at once as a set {(xt , yt )}T
t=1 âˆˆ Rd Ã—R where yt = u(w, xt ) for some unknown w âˆˆ Rd
classiï¬cation by linear threshold functions. For brevity, we only describe the Idealized SIM
of bounded norm and an unknown non-decreasing u âˆ¶ R â†’ R with a bounded Lipschitz
problem considered by the authors. In its â€œbatchâ€ version, we assume that the data are
t=1 (fi (xt ) âˆ’ yt )2 ,
T âˆ‘T
where fi (x) = ui (wi , x) is the iterative approximation found by the algorithm on the ith
constant. Given this data, the goal is to iteratively ï¬nd the function u and the direction
w, making as few mistakes as possible. The error is measured as 1
round. The elegant computationally eï¬ƒcient method presented by Kalai and Sastry (2009)
is motivated by Perceptron, and a natural open question posed by the authors is whether
there is an online variant of Isotron. Before even attempting a quest for such an algorithm,
we can ask a more basic question:
is the (Idealized) SIM problem even learnable in the
online framework? After all, most online methods deal with convex functions, but u is only
assumed to be Lipschitz and non-decreasing. We answer the question easily with the tools
we have developed.

169

Rakhlin, Sridharan and Tewari

H = f (x, y) = (y âˆ’ u(w, x))2   u âˆ¶ [âˆ’1, 1] â†’ [âˆ’1, 1] 1-Lipschitz , w2 â‰¤ 1
We are interested in online learnability of
in the supervised setting, over X = B2 (the unit Euclidean ball in Rd ) and Y = [âˆ’1, 1]. In
(15)
It is evident that H is a composition with three levels: the squared loss, the Lipschitz non-
particular, we prove the result for Lipschitz, but not necessarily non-decreasing functions.
decreasing function, and the linear function. The proof of the following proposition shows
Proposition 18 The class H deï¬ned in (15) is online learnable in the (improper) super-
that the covering number of the class does not increase much under these compositions.
O(âˆš
T log3~2 (T )).
vised learning setting. Moreover, the minimax regret is
Once again, it is not clear whether a computationally eï¬ƒcient method attaining the
above guarantee exists.

6.6 Prediction of Individual Sequences with Static Experts

We also consider the problem of prediction of individual sequences, which has been studied
both in information theory and in learning theory.
In particular, in the case of binary
prediction, Cesa-Bianchi and Lugosi (1999) proved upper bounds on the minimax value in
terms of the (classical) Rademacher complexity and the (classical) Dudley integral. One of
we deï¬ne static experts as vectors Â¯f = (f1 , . . . , fT ) âˆˆ [0, 1]T , and let F denote a class of
the assumptions made by Cesa-Bianchi and Lugosi (1999) is that experts are static. That is,
such experts. Let Y = {0, 1}, putting us in the scenario of binary classiï¬cation with no side
their prediction only depends on the current round, not on the past information. Formally,
information. Then regret on a particular sequence y1 , . . . , yT can be written as
(cid:96)t ( Â¯f , yt ),
(cid:96)t ( Â¯ft , yt ) âˆ’ inf
Â¯f âˆˆF Q
TQ
t=1
t=1
where Â¯ft is the expert chosen by the learning algorithm at time t. Observe that the proof
of Theorem 7 does not require the loss to be time independent. In the case of absolute loss,
t  ft âˆ’ yt ()  .
sup
t (cid:96)t ( Â¯f , yt ()) = sup
sup
the Rademacher complexity appearing on the right hand side in Theorem 7 becomes
Â¯f âˆˆF TQ
Â¯f âˆˆF TQ
t=1
t=1
E
E
sup
where the supremum is over all Y -valued trees of depth T . Noting that for f âˆˆ [0, 1], y âˆˆ
y
y
{0, 1},  f âˆ’ y   can be written as (1 âˆ’ 2y)f + y , the above equals
 .
sup
tyt () = sup

Ã¯ + TQ
Ã¯Ã¯sup
t (1 âˆ’ 2yt ())ft
t (1 âˆ’ 2yt ())ft
Â¯f âˆˆF TQ
Â¯f âˆˆF TQ
t=1
t=1
t=1
E
E
sup
y
y
170

Online Learning via Sequential Complexities
It can be easily veriï¬ed that the joint distribution of {t (1 âˆ’ 2yt ())}T
t=1 is still i.i.d. Rade-
sup
 ,
macher and hence the value of the game is upper bounded by
Â¯f âˆˆF TQ
t=1
recovering the upper bound of Theorem 3 in (Cesa-Bianchi and Lugosi, 1999). We note that
for this particular scenario, the factor of 2 (that appears because of symmetrization) is not
needed. This factor is the price we pay for deducing the result from the general statement
of Theorem 7.

2E

tft

7. Discussion

The tools provided in this paper allow us to establish existence of regret minimization
algorithms by working directly with the minimax value. The non-constructive nature of
our results is due to the application of the minimax theorem: the dual strategy does not
give a handle on the primal strategy. Furthermore, by passing to upper bounds on the
dual formulation (2) of the value of the game, we remove the dependence on the dual
round t can be obtained by appealing to the minimax theorem for rounds t + 1 to T , yet
strategy altogether. After the original paper (Rakhlin et al., 2010) appeared, the algorithmic
approach has been developed by Rakhlin et al. (2012) who showed that the prediction for
keeping the minimax expression for round t as is. The notion of a relaxation (in the spirit of
approximate dynamic programming) then allowed the authors to develop a general recipe
for deriving computationally feasible prediction methods. The techniques of the present
paper form the basis for the algorithmic developments of Rakhlin et al. (2012). We refer
the reader to (Rakhlin and Sridharan, 2014; Rakhlin et al., 2012) for details.

Acknowledgments

We would like to thank J. Michael Steele and Dean Foster for helpful discussions. We
gratefully acknowledge the support of NSF under grants CAREER DMS-0954737 and CCF-
1116928.

Appendix A. A Minimax Theorem

The minimax theorem is one of this paperâ€™s main workhorses. For completeness, we state
a general version of this theorem â€” the von Neumann-Fan minimax theorem â€” due to
Theorem 19 (Borwein, 2014) Let A and B be Banach spaces. Let A âŠ‚ A be nonempty,
Borwein (2014) (see also Borwein and Zhuang, 1986).
weakly compact, and convex, and let B âŠ‚ B be nonempty and convex. Let g âˆ¶ A Ã— B â†’ R be
concave with respect to b âˆˆ B and convex and lower-semicontinuous with respect to a âˆˆ A,
g(a, b).
g(a, b) = inf
and weakly continuous in a when restricted to A. Then
aâˆˆA
aâˆˆA
bâˆˆB
bâˆˆB
sup
inf
sup

(16)

171

Rakhlin, Sridharan and Tewari

pt âˆˆP E [(cid:96)(ft , zt ) + Î¾ (zt )] = sup
qt âˆˆQ E [(cid:96)(ft , zt ) + Î¾ (zt )] ,
In the proof of Theorem 1, the minimax theorem is invoked to assure that
qt âˆˆQ sup
pt âˆˆP inf
(17)
inf
where Î¾ (zt ) is a rather complicated function that includes the repeated inï¬ma and suprema
from steps t + 1 to T of regret expression that includes the variable zt (but not ft ). The
expectation in (17) is with respect to ft âˆ¼ qt and zt âˆ¼ pt . To apply (16), we take g to be
the bilinear form in qt and pt , with A = Q and B = P . Equipped with the total variation
distance, Q and P can be seen as subsets of a Banach space of measures on F and Z ,
In terms of conditions, it is enough to check weak compactness of Q and
respectively.
assume continuity of the loss function (lower semi-continuity can be used as well).
Bogachev 2007, Theorem 8.6.2., and van der Vaart and Wellner 1996). If F itself is compact,
Weak compactness of the set of probability measures on a complete separable metric
then the set âˆ†(F ) of probability measures on F is tight, and hence (under the continuity
space is equivalent to uniform tightness by the fundamental result of Prohorov (see, e.g.,
of the loss) the minimax theorem holds. If F is not compact, tightness can be established
a family âˆ†(F ) of Borel probability measures on a separable reï¬‚exive Banach space E is
uniformly tight (under the weak topology) precisely when there exists a function V âˆ¶ E â†’
under the following general condition. According to Example 8.6.5 (ii) in Bogachev (2007),
[0, âˆ) continuous in the norm topology such that
qâˆˆâˆ†(F ) Ef âˆ¼q V (f ) < âˆ.
limf â†’âˆ V (f ) = âˆ and
sup
As an example, if F is a subset of a ball in E , it is enough to take V (f ) = f .
not need to invoke the minimax theorem on the space of functions F , but rather (see the
Finally, we remark that in the supervised learning case by considering the improper
learning scenario we allow xt to be observed before the choice Ë†yt is made. Therefore, we do
proof of Theorem 8) for two real-valued decisions in a bounded interval. This makes the
application of the minimax theorem straightforward.
Proof [of Theorem 1] For brevity, denote Ïˆ(z1âˆ¶T ) = inf f âˆˆF âˆ‘T
t=1 (cid:96)(f , zt ). The ï¬rst step in
Appendix B. Proofs
the proof is to appeal to the minimax theorem for every couple of inf and sup:
VT (F ) = inf
(cid:96)(ft , zt ) âˆ’ Ïˆ(z1âˆ¶T )
 TQ
Ef1 âˆ¼q1
EfT âˆ¼qT
t=1
z1 âˆ¼p1
zT âˆ¼pT
sup
= sup
 TQ
(cid:96)(ft , zt ) âˆ’ Ïˆ(z1âˆ¶T )
p1
q1
Ef1 âˆ¼q1
EfT âˆ¼qT
t=1
z1 âˆ¼p1
zT âˆ¼pT
. . . sup
inf
inf
(cid:96)(ft , zt ) âˆ’ Ïˆ(z1âˆ¶T ) ,
EzT âˆ¼pT  TQ
= sup
pT
p1
q1
qT
Ez1 âˆ¼p1 . . . sup
t=1
inf
inf
where qt and pt range over Q and P , the sets of distributions on F and Z , respectively.
p1
pT
fT
f1
From now on, it will be understood that zt has distribution pt . By moving the expectation

. . . inf
qT

sup
pT

172

Online Learning via Sequential Complexities

(18)

E
z1

pT âˆ’1
. . . sup

with respect to zT and then the inï¬mum with respect to fT inside the expression, we arrive
at
T âˆ’1Q
Ïˆ(z1âˆ¶T )
(cid:96)(fT , zT ) âˆ’ E
(cid:96)(ft , zt ) + inf
t=1
E
E
E
zT âˆ’1
pT âˆ’1
fT âˆ’1
sup
inf
. . . sup
sup
inf
T âˆ’1Q
(cid:96)(fT , zT ) âˆ’ Ïˆ(z1âˆ¶T ) .
(cid:96)(ft , zt ) + inf
= sup
zT
zT
pT
p1
z1
fT
f1
t=1
E
E
E
E
zT âˆ’1
pT âˆ’1
fT âˆ’1
sup
inf
. . . sup
inf
Let us now repeat the procedure for step T âˆ’ 1. The above expression is equal to
zT
zT
pT
z1
p1
fT
f1
T âˆ’1Q
(cid:96)(fT , zT ) âˆ’ Ïˆ(z1âˆ¶T )
inf
(cid:96)(ft , zt ) + sup
t=1
E
E
E
E
pT âˆ’1
zT âˆ’1
fT âˆ’1
inf
. . . sup
inf
sup
pT
p1
z1
zT
zT
f1
fT
which, in turn, is equal to
T âˆ’2Q
(cid:96)(fT âˆ’1 , zT âˆ’1 )
(cid:96)(ft , zt ) +  inf
t=1
E
zT âˆ’1
fT âˆ’1
sup
inf
(cid:96)(fT , zT ) âˆ’ Ïˆ(z1âˆ¶T )
inf
+ E
p1
f1
E
E
zT âˆ’1
sup
T âˆ’2Q
= sup
(cid:96)(ft , zt ) +  inf
(cid:96)(fT âˆ’1 , zT âˆ’1 )
pT
zT
zT
fT
t=1
E
E
E
E
pT âˆ’1
zT âˆ’1
zT âˆ’1
fT âˆ’1
inf
. . . sup
sup
+ inf
(cid:96)(fT , zT ) âˆ’ Ïˆ(z1âˆ¶T ) .
p1
z1
pT
zT
f1
E
Continuing in this fashion for T âˆ’ 2 and all the way down to t = 1 proves the theorem.
zT
fT
Proof [of Lemma 4] Without loss of generality assume that the Lipschitz constant L = 1,
as the general case follows by scaling Ï†. Fix a Z -valued tree z of depth T . We ï¬rst claim
log N2 (Î² , Ï† â—‹ G , z) â‰¤ kQ
log Nâˆ (Î² , Gj , z) .
that
j=1
Suppose V1 , . . . , Vk are minimal Î² -covers with respect to (cid:96)âˆ for G1 , . . . , Gk on the tree z.
V Ï† = {vÏ† âˆ¶ v âˆˆ V1 Ã— . . . Ã— Vk },
Consider the set
t () = Ï†(vt (), zt ()). Then, for any g = (g1 , . . . , gk ) âˆˆ G
and any  âˆˆ {Â±1}T , with representatives (v1 , . . . , vk ) âˆˆ V1 Ã— . . . Ã— Vk , we have,
where vÏ† is the tree such that vÏ†
Â¿``(cid:192) 1
t ()
t ()2 â‰¤ max
tâˆˆ[T ] Ï†(g(zt ()), zt ()) âˆ’ vÏ†
Ï†(g(zt ()), zt ()) âˆ’ vÏ†
TQ
t=1
tâˆˆ[T ]  gj (zt ())) âˆ’ vj
tâˆˆ[T ]  Ï†(g(zt ()), zt ()) âˆ’ Ï†(vt (), zt ())  â‰¤ max
= max
t ()  â‰¤ Î² .
T
j âˆˆ[k] max
173

Rakhlin, Sridharan and Tewari
Thus we see that V Ï† is an Î² -cover with respect to (cid:96)âˆ for Ï† â—‹ G on z. Hence
log N2 (Î² , Ï† â—‹ G , z) â‰¤ log( V Ï†  ) = kQ
log( Vj  ) = kQ
log Nâˆ (Î² , Gj , z).
j=1
j=1
(19)
For any g âˆˆ G and z âˆˆ Z , the value Ï†(g(z), z) is contained in the interval [âˆ’1 + Ï†(0, z), +1 +
Ï†(0, z)] by the Lipschitz property. Consider the R-valued tree Ï†(0, â‹…) â—‹ z. We now center
{Ï†(g(â‹…), â‹…) â—‹ z âˆ’ Ï†(0, â‹…) â—‹ z âˆ¶ g âˆˆ G }.
by this tree and consider the set of trees
invoke (7) since the function values are now in [âˆ’1, 1]:
Â¿```(cid:192) kQ
The centering does not change the size of the cover calculated in (19), but allows us to
4Î± + 12âˆš

log Nâˆ (Î² , Gj , z) dÎ²
RT (Ï† â—‹ G , z) â‰¤ inf
T S 1
j=1
4Î± + 12âˆš
 .

â‰¤ inf
log Nâˆ (Î² , Gj , z) dÎ²
Î±
kQ
Î±
S 1
j=1
(20)
We substitute the upper bound on covering numbers in (8) for each Gj and arrive at an
T
Î±
Î±
4Î± + 12âˆš
 .

upper bound of
fatÎ² (Gj ) log(2eT ~Î² )dÎ²
kQ
S 1
j=1
inf
Lemma 2 of Rakhlin et al. (2014) implies that for any Î² > 2RT (Gj ),
T
Î±
Î±
fatÎ² (Gj ) â‰¤ 32T RT (Gj )2
RT (Gj ). Substituting this together with the value of Î± = 2RT (Gj âˆ— ) into
Let j âˆ— = argmax
.
Î² 2
j

âˆš
(21) yields an upper bound
8 RT (Gj âˆ— ) + 48
log(2eT ~Î² )dÎ² .
RT (Gj ) S 1
kQ
2RT (Gjâˆ— ) 1
j=1
2
Using the fact that for any b > 1 and Î± âˆˆ (0, 1)
Î²


â‰¤ 2
log3~2 (x)b~Î±
log3~2 (b~Î±)
log xdx = 2
log(b~Î² )dÎ² = S b~Î±
S 1
1
1
Î²
x
3
3
b
Î±
b
âˆš
we obtain a further upper bound of
RT (Gj âˆ— )  .
8 RT (Gj âˆ— ) + 32
RT (Gj ) log3~2 
kQ
j=1
eT

(21)

(22)

2

174

Online Learning via Sequential Complexities
Replacing the ï¬rst term by 8 âˆ‘j RT (Gj ), we conclude that
âˆš
RT (Ï† â—‹ G , z) â‰¤ 8 1 + 4
2 log3~2 (eT 2 ) kQ
RT (Gj )
j=1
as long as RT (Gj ) â‰¥ 1~T for each j . The statement is concluded by observing that z was
chosen arbitrarily.
Proof [of Corollary 6] We ï¬rst extend the binary function b to a function Â¯b to any x âˆˆ Rk
if x âˆ’ aâˆ < 1 for some a âˆˆ {Â±1}k
Â¯b(x) =  (1 âˆ’ x âˆ’ aâˆ )b(a)
as follows :
0
otherwise
First note that Â¯b is well-deï¬ned since all points in the k-cube are separated by Lâˆ distance
2. Further note that Â¯b is 1-Lipschitz w.r.t. the Lâˆ norm and so applying Lemma 4 we
conclude the statement of the corollary.
Proof [of Theorem 7] Let Etâˆ’1 [â‹…] = E[â‹… Z1 , . . . , Ztâˆ’1 ] denote the conditional expectation.
Using Theorem 1 we have,
VT (F ) = sup
(cid:96)(f , Zt )
ft âˆˆF Etâˆ’1 (cid:96)(ft , â‹…) âˆ’ inf
 TQ
f âˆˆF TQ
Z1 âˆ¼p1
ZT âˆ¼pT
t=1
t=1
E
E
inf
= sup
sup
f âˆˆF  TQ
ft âˆˆF Etâˆ’1 (cid:96)(ft , â‹…) âˆ’ TQ
(cid:96)(f , Zt )
p1
Z1 âˆ¼p1
ZT âˆ¼pT
t=1
t=1
E
E
inf
â‰¤ sup
f âˆˆF  TQ
sup
(cid:96)(f , Zt ) .
Etâˆ’1 (cid:96)(f , â‹…) âˆ’ TQ
p1
Z1 âˆ¼p1
ZT âˆ¼pT
t=1
t=1
E
E
. . . sup
(23)
p1
pT
also holds if the choice ft of the learner comes from a larger set G , as long as F âŠ† G . The
The upper bound is obtained by replacing each inï¬mum by a particular choice f . This step
proof is concluded by appealing to (3).
Let ËœQ denote the set of distributions on Y = [âˆ’1, 1]. By convexity,
Proof [of Theorem 8]
(cid:96)â€² ( Ë†yt , yt ) ( Ë†yt âˆ’ f (xt )) ,
(cid:96)(f (xt ), yt ) â‰¤ sup
(cid:96)( Ë†yt , yt ) âˆ’ inf
f âˆˆF TQ
f âˆˆF TQ
TQ
t=1
t=1
t=1
where (cid:96)â€² ( Ë†yt , yt ) is a subgradient of the function y  (cid:96)(â‹…, yt ) at Ë†yt . Then the minimax value
(10) can be upper bounded as
(cid:96)â€² ( Ë†yt , yt ) ( Ë†yt âˆ’ f (xt )) .
E Ë†yT âˆ¼qT sup
T (F ) â‰¤ sup
V S
f âˆˆF TQ
Ë†y1 âˆ¼q1
t=1
q1 âˆˆ ËœQ
E
inf
x1

qT âˆˆ ËœQ
inf

. . . sup
xT

. . . sup
pT

. . . sup
pT

sup
y1

sup
yT

175

(24)

sup
yT

Rakhlin, Sridharan and Tewari
By the Lipschitz property of (cid:96), we can replace each subgradient (cid:96)â€² ( Ë†yt , yt ) with a number
st âˆˆ [âˆ’L, L] to obtain the upper bound
sT âˆˆ[âˆ’L,L] sup
st ( Ë†yt âˆ’ f (xt )) .
f âˆˆF TQ
Ë†yT âˆ¼qT
Ë†y1 âˆ¼q1
s1 âˆˆ[âˆ’L,L] . . . sup
t=1
qT âˆˆ ËœQ
q1 âˆˆ ËœQ
E
E
sup
inf
sup
sup
inf
sup
x1
y1
xT
st ( Ë†yt âˆ’ f (xt ))
sT âˆˆ[âˆ’L,L] sup
Since yt â€™s no longer appear in the optimization ob jective, we can simply write the above as
f âˆˆF TQ
Ë†yT âˆ¼qT
Ë†y1 âˆ¼q1
s1 âˆˆ[âˆ’L,L] . . . sup
t=1
qT âˆˆ ËœQ
q1 âˆˆ ËœQ
E
E
sup
inf
sup
inf
sup
st ( Ë†yt âˆ’ f (xt )) ,
sT âˆˆ[âˆ’L,L] sup
= sup
f âˆˆF TQ
x1
xT
Ë†yT âˆˆ[âˆ’1,1]
s1 âˆˆ[âˆ’L,L] . . . sup
Ë†y1 âˆˆ[âˆ’1,1]
t=1
sup
inf
sup
inf
x1
xT
where the equality follows because inï¬ma are obtained at point distributions. By the same
stf (xt ) .
st â‹… Ë†yt âˆ’ inf
EsT âˆ¼pT  TQ
reasoning, we now pass to distributions over st â€™s:
f âˆˆF TQ
s1 âˆ¼p1
Ë†y1 âˆˆ[âˆ’1,1] sup
Ë†yT âˆˆ[âˆ’1,1] sup
t=1
t=1
E
. . . sup
inf
sup
inf
xT
x1
p1
pT
supported on [âˆ’L, L], for any t, and st has distribution pt . Now note that
From now on, it will be understood that the supremum over pt ranges over all distributions
st â‹… f (xt )
st â‹… Ë†yt âˆ’ inf
EsT  TQ
f âˆˆF TQ
t=1
t=1
stf (xt ) = sup
st â‹… Ë†yt âˆ’ inf
EsT  TQ
Ë†yT âˆˆ[âˆ’1,1] EsT  TQ
stf (xt )
st â‹… Ë†yt âˆ’ inf
is concave (linear) in pT and is convex in Ë†yT and hence by the minimax theorem,
f âˆˆF TQ
f âˆˆF TQ
Ë†yT âˆˆ[âˆ’1,1] sup
t=1
t=1
t=1
t=1

stf (xt ) ,
inf
inf
= T âˆ’1Q
st â‹… Ë†yt + sup
Ë†yT âˆˆ[âˆ’1,1] EsT [sT ] â‹… Ë†yT âˆ’ inf
f âˆˆF TQ
pT
pT
t=1
t=1
EsT
inf
pT

T âˆ’1Q
stf (xt )

where the last step is similar to the one in the proof of Theorem 1, speciï¬cally (18). Similarly
Ë†yT âˆˆ[âˆ’1,1] EsT [sT ] â‹… Ë†yT âˆ’ inf
st â‹… Ë†yt + sup
f âˆˆF TQ
note that the term
EsT âˆ’1
t=1
t=1
EsT
inf
pT ,xT
is concave (linear) in pT âˆ’1 and is convex in Ë†yT âˆ’1 and hence again by the minimax theorem,

 T âˆ’1Q
stf (xt )

Ë†yT âˆˆ[âˆ’1,1] EsT [sT ] â‹… Ë†yT âˆ’ inf
st â‹… Ë†yt + sup
f âˆˆF TQ
Ë†yT âˆ’1 âˆˆ[âˆ’1,1] sup
t=1
t=1

 T âˆ’1Q
E
E
pT âˆ’1
sT âˆ’1
stf (xt )

inf
inf
Ë†yT âˆˆ[âˆ’1,1] EsT [sT ] â‹… Ë†yT âˆ’ inf
st â‹… Ë†yt + sup
= sup
f âˆˆF TQ
pT ,xT
sT
Ë†yT âˆ’1 âˆˆ[âˆ’1,1] E
t=1
t=1
EsT
stf (xt ) .
 TQ
pT âˆ’1
sT âˆ’1
inf
inf
= T âˆ’2Q
Ë†yt âˆˆ[âˆ’1,1] Est [st ] â‹… Ë†yt âˆ’ inf
st â‹… Ë†yt + sup
f âˆˆF TQ
pT ,xT
t=1
t=1
t=T âˆ’1
EsT
E
sT âˆ’1
pT âˆ’1
inf
sup
pT ,xT
176

Online Learning via Sequential Complexities

sup
pT

Proceeding in similar fashion and using this in (24) we conclude that,
EsT âˆ¼pT  TQ
st â‹… Ë†yt âˆ’ inf
stf (xt )
V S
T (F ) â‰¤ sup
f âˆˆF TQ
s1 âˆ¼p1
Ë†y1 âˆˆ[âˆ’1,1] sup
Ë†yT âˆˆ[âˆ’1,1] sup
t=1
t=1
 TQ
stf (xt )
E
inf
. . . sup
inf
Ë†yt âˆˆ[âˆ’1,1] Est âˆ¼pt [st ] â‹… Ë†yt âˆ’ inf
= sup
f âˆˆF TQ
pT
x1
xT
p1
sT âˆ¼pT
s1 âˆ¼p1
t=1
t=1
E
E
inf
sup
. . . sup
sup
EsT âˆ¼pT sup
(Est âˆ¼pt [st ] âˆ’ st ) f (xt ) ,
â‰¤ sup
f âˆˆF TQ
pT
x1
p1
xT
s1 âˆ¼p1
t=1
E
sup
. . . sup
sup
where we replaced each Ë†yt with a potentially suboptimal choice f (xt ). Passing the expec-
pT
x1
p1
xT
tation past the suprema we obtain an upper bound
sâ€²
t âˆ’ st f (xt )
T âˆ¼pT sup
f âˆˆF TQ
EsT ,sâ€²
1 âˆ¼p1
t=1
s1 ,sâ€²
E
sup
. . . sup
sup
t sâ€²
t âˆ’ st f (xt )
= sup
ET sup
f âˆˆF TQ
x1
p1
xT
1 âˆ¼p1
T âˆ¼pT
t=1
s1 ,sâ€²
sT ,sâ€²
E
E
E
. . . sup
sup
sup
â‰¤ sup
tstf (xt )
sT âˆˆ[âˆ’2L,2L] ET sup
f âˆˆF TQ
xT
p1
1
x1
pT
s1 âˆˆ[âˆ’2L,2L] E
t=1
sup
. . . sup
sup
= sup
tstf (xt )
sT âˆˆ{âˆ’2L,2L} ET sup
f âˆˆF TQ
1
x1
xT
s1 âˆˆ{âˆ’2L,2L} E
t=1
. . . sup
sup
sup
= 2L sup
sT âˆˆ{âˆ’1,1} ET sup
tstf (xt ) ,
f âˆˆF TQ
x1
1
xT
s1 âˆˆ{âˆ’1,1} E
t=1
sup
. . . sup
sup
(27)
where the last inequality is because, for every t âˆˆ [T ], we have convexity in st and so
xT
x1
1
supremum is achieved at either âˆ’2L or 2L. Notice that after using convexity to go to
Ïˆ âˆ¶ {Â±1}  R, we have that
gradients, the proof technique above basically mimics the proofs of Theorems 1 and 7 to get
to a symmetrized term as we did in those theorems. Now consider any arbitrary function
2 (Ïˆ(+s) + Ïˆ(âˆ’s)) = 1
2 (Ïˆ(+1) + Ïˆ(âˆ’1)) = E [Ïˆ()] .
sâˆˆ{Â±1} E [Ïˆ(s â‹… )] = sup
sâˆˆ{Â±1} 1
sup
Since in (27), for each t, st and t appear together as t â‹… st using the above equation
repeatedly, we conclude that
sT âˆˆ{âˆ’1,1} ET sup
tstf (xt )
T (F ) â‰¤ 2L sup
V S
f âˆˆF TQ
s1 âˆˆ{âˆ’1,1} E1 . . . sup
t=1
sup
sup
tf (xt ) .
ET sup
= 2L sup
f âˆˆF TQ
xT
x1
t=1
E1 . . . sup
(28)
We now claim that the above supremum can be written in terms of an X -valued tree. Brieï¬‚y,
x1
xT
the solution for x1 in (28) is attained (for simplicity, assume the supremum is attained) at

(25)

(26)

177

Rakhlin, Sridharan and Tewari
2 can be calculated for 1 = 1 and 1 = âˆ’1. Arguing
1 . The optimal value xâˆ—
an optimal value xâˆ—
in this manner leads to a tree x. We conclude
tf (xt ()) = 2 L T RT (F ).
E1âˆ¶T sup
T (F ) â‰¤ 2L sup
V S
f âˆˆF TQ
t=1
x

Proof [of Proposition 9] For the upper bound, we start by using Theorem 8 for absolute
loss, which has a Lipschitz constant of 1, to bound the value of the game by sequential
T V S
T (F ) â‰¤ 2 RT (F ) .
Rademacher complexity,
1
joint distribution on sequences (x1 , y1 ), . . . , (xt , yt ) in (2):
We combine the above inequality with (7) and (8) to obtain the upper bound.
Observe that a lower bound on the value can be obtained by choosing any particular
T (F ) â‰¥ E  TQ
V S
 yt âˆ’ f (xt )  .
ft âˆˆF E(xt ,yt )  yt âˆ’ ft (xt )   (x, y)1âˆ¶tâˆ’1  âˆ’ inf
f âˆˆF TQ
t=1
t=1
inf
To this end, choose any X -valued tree x of depth T . Let y1 , . . . , yT be i.i.d. Rademacher
random variables and deï¬ne xt = x(y1âˆ¶tâˆ’1 ) deterministically (that is, the conditional dis-
tribution of xt is a point distribution on x(y1âˆ¶tâˆ’1 )). It is easy to see that this distribution
makes the choice ft irrelevant, yielding
T (F ) â‰¥ E  TQ
V S
 yt âˆ’ f (xt )  = Ey1 ,...,yT sup
1 âˆ’ inf
ytf (xt ).
f âˆˆF TQ
f âˆˆF TQ
t=1
t=1
t=1
T (F ) â‰¥ RT (F ). The
Since this holds for any tree x, we obtain the desired lower bound V S
ï¬nal lower bound on RT (F ) (in terms of the fat-shattering dimensions) is proved by Rakhlin
et al. (2014, Lemma 2).
First, suppose that fatÎ± is inï¬nite for some Î± > 0. Then, the lower bound says that V S
T (F ) â‰¥
âˆš
âˆš
2) and hence lim supT â†’âˆ V S
T (F )~T â‰¥ Î±~(4
2). Thus, the class F is not online
Î±T ~(4
Proof [of Theorem 10] The equivalence of 1 and 2 follows directly from Proposition 9.
learnable in the supervised setting. Now, assume that fatÎ± is ï¬nite for all Î±. Fix an  > 0
and choose Î± = ~16. Using the upper bound, we have

âˆš
T (F ) â‰¤ 8T Î± + 24
Î²  dÎ²
fatÎ² log  2eT
V S
T S 1
T (1 âˆ’ Î±)
âˆš
â‰¤ 8T Î± + 24
fatÎ± log  2eT
Î± 
Î±
â‰¤ T ~2 + T ~2

178

Online Learning via Sequential Complexities
for T large enough. Thus, lim supT â†’âˆ V S
T (F )~T â‰¤ . Since  > 0 was arbitrary, this proves
that F is online learnable in the supervised setting.
The statement that V S
T (F ), RT (F ), and DT (F ) are within a multiplicative factor of
O(log3~2 T ) of each other whenever the problem is online learnable follows immediately
from Eq. (10) in (Rakhlin et al., 2014) and Proposition 9.
Proof [of Lemma 13] Consider the game (F , Zcvx ) and ï¬x a randomized strategy Ï€ of
the player. Then, the expected regret of a randomized strategy Ï€ against any adversary
playing g1 , . . . , gT can be lower-bounded via Jensenâ€™s inequality as
gt Eut âˆ¼Ï€t (g1âˆ¶tâˆ’1 ) [ut ] âˆ’ inf
Eut âˆ¼Ï€t (g1âˆ¶tâˆ’1 ) [gt (ut )] âˆ’ inf
gt (u) â‰¥ TQ
gt (u),
TQ
uâˆˆF TQ
uâˆˆF TQ
t=1
t=1
t=1
t=1
which is simply regret of a deterministic strategy obtained from Ï€ by playing Eut âˆ¼Ï€t (g1âˆ¶tâˆ’1 ) [ut ]
T (F , Zcvx ) where V det
tic ones. Hence, VT (F , Zcvx ) = V det
on round t. Thus, to any randomized strategy corresponds a deterministic one that is no
worse. On the other hand, the set of randomized strategies contains the set of determinis-
Abernethy et al. (2008) that says V det
T (F , Zcvx ) = V det
T (F , Zlin ). Note that Abernethy et al.
is deï¬ned as the minimax regret
T
obtainable only using deterministic player strategies. Now, we appeal to Theorem 14 of
(2008) deal with convex sets in ï¬nite dimensional spaces only. However, their proof relies
bounds the convex function). Since Zlin also consists of convex (in fact, linear) functions,
on fundamental properties of convex functions that are true in any general vector space
the above argument again gives V det
T (F , Zlin ) = VT (F , Zlin ). This ï¬nishes the proof of the
(such as the fact that the ï¬rst order Taylor expansion of a convex function globally lower
lemma.
Proof [of Proposition 15] We shall prove that for any i âˆˆ {2, . . . , k},
âˆš
RT (Fi ) â‰¤ 16LBi 1 + 4
2 log3~2 (eT 2 ) RT (Fiâˆ’1 ).
To see this note that for any x, RT (Fi , x) is equal to



j Ïƒ (fj (xt ()))Ã¯
Ã¯Ã¯Q
â‰¤ E
TQ
wi âˆ¶wi 1 â‰¤Bi
wi âˆ¶wi 1 â‰¤Bi
t=1
E
w i
sup
sup
t
âˆ€j fj âˆˆFiâˆ’1
âˆ€j fj âˆˆFiâˆ’1
j
by HÂ¨olderâ€™s inequality. Then RT (Fi ) is upper bounded as
tÏƒ (f (xt ()))
tÏƒ (f (xt ())) , âˆ’ TQ
max  TQ
E Bi sup
f âˆˆFiâˆ’1
t=1
t=1
sup
âˆ’tÏƒ (f (xt ())) .
tÏƒ (f (xt ())) , sup
â‰¤ sup
E Bi max  sup
TQ
TQ
x
f âˆˆFiâˆ’1
f âˆˆFiâˆ’1
t=1
t=1
x

tÏƒ (fj (xt ()))



w i 1 max
j

 TQ
t=1

179

(29)

Rakhlin, Sridharan and Tewari
Since 0 âˆˆ Fi together with the assumption of Ïƒ(0) = 0, both terms are non-negative, and
thus the maximum above can be upper bounded by the sum
E Bi sup
E Bi sup
tÏƒ (f (xt ())) + sup
âˆ’tÏƒ (f (xt ())) .
TQ
TQ
f âˆˆFiâˆ’1
f âˆˆFiâˆ’1
t=1
t=1
sup
Indeed, let xâˆ— be the tree achieving the
x
x
achieved). Then the mirror tree x deï¬ned via xt () = xâˆ—
t (âˆ’) yields the same value for the
We now claim that the two terms are equal.
supremum in the ï¬rst term (a modiï¬ed analysis can be carried out if the supremum is not
second term. Since the argument can be carried out in the reverse direction, the two terms
are equal, and the upper bound of
E  sup
tÏƒ (f (xt ()))
TQ
f âˆˆFiâˆ’1
t=1
2Bi sup
x
âˆš
2 log3~2 (eT 2 ) RT (Fiâˆ’1 ).
16BiL 1 + 4
follows. In view of contraction in Corollary 5, we obtain a further upper bound of
To ï¬nish the proof we note that for the base case of i = 1, RT (F1 ) is equal to

twxt ()
TQ
wâˆˆRd âˆ¶w1 â‰¤B1
t=1
E
sup
sup
x

 â‰¤ B1 sup
which is upper bounded by
txt ()âˆ
w1  TQ
iâˆˆ[d]  TQ
E max
txt ()[i] .
wâˆˆRd âˆ¶w1 â‰¤B1
t=1
t=1
E
sup
sup
Note that the instances x âˆˆ X are vectors in Rd and so for a given instance tree x, for any
x
x
i âˆˆ [d], x[i] given by only taking the ith co-ordinate is a valid real valued tree. By (4),

txt ()[i] â‰¤ B1
E max
T â‹… RT (F1 ) â‰¤ B1 sup
iâˆˆ[d]  TQ
2T X 2âˆ log d.
t=1
x
Using the above and (29) repeatedly we conclude the proof.
Proof [of Proposition 16] Fix a Î³ > 0 and use loss
(cid:96)( Ë†y , y) =  1
Ë†yy â‰¤ 0
1 âˆ’ Ë†yy~Î³ 0 < Ë†yy < Î³
Ë†yy â‰¥ Î³
Since this loss is 1~Î³ -Lipschitz, we can use (11) and the Rademacher contraction Corollary 5
0
to show that for each Î³ > 0 there exists a randomized strategy Ï„ Î³ such that for any data
(cid:96)(f (xt ), yt ) + Î³ âˆ’1ÏT T RT (F ),
t (z1âˆ¶tâˆ’1 ) [(cid:96)( Ë†yt , yt )] â‰¤ inf
f âˆˆF TQ
TQ
sequence
Ë†yt âˆ¼Ï„ Î³
t=1
t=1
E
180

Online Learning via Sequential Complexities
âˆš
2 log3~2 (eT 2 ) throughout the proof. Further, observe that the loss
where ÏT = 16 1 + 4
function is lower bounded by the zero-one loss 1 { Ë†yy < 0} and is upper bounded by the
margin zero-one loss 1 { Ë†yy < Î³ }. Hence,
t (z1âˆ¶tâˆ’1 ) [1 { Ë†ytyt < 0}] â‰¤ inf
1 {ytf (xt ) < Î³ } + Î³ âˆ’1ÏT T RT (F ).
TQ
f âˆˆF TQ
Ë†yt âˆ¼Ï„ Î³
t=1
t=1
E
(30)
we discretize the set of Î³ â€™s as Î³i = 1~2i and use the output of the randomized strategies
The above bound holds for randomized each strategy given by Ï„ Î³ , for any given Î³ . Now
experts algorithm (Algorithm 1) with initial weight for expert i as pi =
algorithm achieves O(âˆš
Ï„ Î³1 , Ï„ Î³2 , . . ., that attain the regret bounds given in (30), as experts. We then run a countable
T log(1~pi )) regret w.r.t. expert i. In view of Proposition 20, for
6
Ï€2 i2 . Such an
i ÏT T RT (F ) + âˆš
T 1 + 2 log  iÏ€âˆš
 .
1 {ytf (xt ) < Î³i} + Î³ âˆ’1
E Ë†yt âˆ¼Ï„t (z1âˆ¶tâˆ’1 ) [1 { Ë†ytyt < 0}] â‰¤ inf
this randomized strategy Ï„ , for any i,
f âˆˆF TQ
TQ
t=1
t=1
For any Î³ > 0, let iÎ³ âˆˆ 0, 1, . . . , be such that 2âˆ’(iÎ³ +1) < Î³ â‰¤ 2âˆ’iÎ³ . Then above right-hand side
6
1 {ytf (xt ) < 2Î³ } + Î³ âˆ’1ÏT T RT (F ) + âˆš
T 1 + 2 log  iÎ³ Ï€âˆš
 .
is upper bounded by
f âˆˆF TQ
t=1
The proof is concluded using the inequality iÎ³ â‰¤ log(1~Î³ ) and upper bounding constants.
inf
6
Proof [of Proposition 17] Fix some L > 0. The loss
Ï†L (Î±) = 
if Î± â‰¤ 0
1 âˆ’ LÎ± if 0 < Î± â‰¤ 1~L
1
is L-Lipschitz and so by Theorem 7 and Corollary 5 we have that for every L > 0, there exists
otherwise
0
a randomized strategy Ï„ L for the player, such that for any sequence z1 = (x1 , y1 ), . . . , zT =
(xT , yT ),
t (z1âˆ¶tâˆ’1 ) [Ï†L (yt Ë†yt )] â‰¤ inf
Ï†L (ytf (xt )) + LÏT T RT (F ),
f âˆˆF TQ
TQ
Ë†yt âˆ¼Ï„ L
t=1
t=1
âˆš
E
(31)
where ÏT = 16 1 + 4
2 log3~2 (eT 2 ) throughout this proof. Since Ï†L dominates the step
t (z1âˆ¶tâˆ’1 ) [1 { Ë†yt â‰  yt}] .
function, the left hand side of (31) also upper-bounds the expected indicator loss
TQ
Ë†yt âˆ¼Ï„ L
t=1
E
For any f âˆˆ F , we can relate the Ï†L -loss to the indicator loss by
C (l)Ï†L (wl ).
1 {ytf (xt ) â‰¤ 0} + Q
Ï†L (ytf (xt )) = TQ
TQ
t=1
t=1
l

181

Rakhlin, Sridharan and Tewari
Let us now use the above decomposition in (31). Crucially, the sign of f (x) does not depend
on wl , but only on the label Ïƒl of the unique leaf l reached by x. Thus, the inï¬mum in (31)
can be split into two inï¬ma:
C (l)Ï†L (wl ),
1 {ytf (xt ) â‰¤ 0} + inf
Ï†L (ytf (xt )) = inf
Q
f âˆˆF TQ
f âˆˆF TQ
t=1
t=1
inf
where it is understood that the C (l) term on the right hand side is computed using the
wl
l
C (l)Ï†L (wl ) â‰¤ Q
C (l) max(0, 1 âˆ’ Lwl ) = Q
max (0, (1 âˆ’ Lwl )C (l)) .
Q
function f minimizing the ï¬rst sum on the right hand side. We can further write
l
l
l
experts corresponding to the values L âˆˆ N. The prior on expert L is taken to be pL = 6
So far, we have derived a regret bound for a given L. Let us now remove the requirement
Ï€2 Lâˆ’2
so that âˆ‘ pL = 1. For the randomized strategy Ï„ obtained in this manner, from Proposition
to know L a priori by running the experts Algorithm 1 with Ï„ 1 , Ï„ 2 , . . . as a countable set of
20, for any sequence of instances and any L âˆˆ N,
max (0, (1 âˆ’ Lwl )C (l))
1 {ytf (xt ) â‰¤ 0} + inf
E Ë†yt âˆ¼Ï„t (z1âˆ¶tâˆ’1 ) [1 { Ë†y â‰  yt}] â‰¤ inf
f âˆˆF Q
f âˆˆF TQ
TQ
+ LÏT T RT (F ) + âˆš
âˆš
T log(LÏ€~âˆš
t=1
t=1
T + 2
6).
l
Now we pick L =  {l âˆ¶ C (l) > ÏT T RT (F )}  â‰¤ N and upper bound the second inï¬mum by
choosing wl = 0 if C (l) â‰¤ ÏT T RT (F ) and wl = 1~L otherwise:
C (l)1 {C (l) â‰¤ ÏT T RT (F )}
max (0, (1 âˆ’ Lwl )C (l)) + LÏT T RT (F ) â‰¤ Q
Q
+ ÏT T RT (F ) Q
1 {C (l) > ÏT T RT (F )}
inf
wl
l
l
l
min{C (l), ÏT T RT (F )}.
which can be written succinctly asQ
l
E Ë†yt âˆ¼Ï„t (z1âˆ¶tâˆ’1 ) [1 { Ë†yt â‰  yt}] â‰¤ inf
1 {ytf (xt ) â‰¤ 0}
We conclude that
f âˆˆF TQ
TQ
min(C (l), ÏT T RT (F )) + âˆš
T 1 + 2 log(N Ï€~âˆš
t=1
t=1
+ Q
6) .
Finally, we apply Corollary 6 and Lemma 3(2) to bound RT (F ) â‰¤ dO(log3~2 T ) RT (H) and
l
thus conclude the proof.
(1959), the class G of all bounded Lipschitz functions on a bounded interval has small metric
Proof [of Proposition 18] First, by the classical result of Kolmogorov and Tikhomirov
182

Online Learning via Sequential Complexities
log Ì‚Nâˆ (Î±, G ) = Î˜(1~Î±). For the particular class of non-decreasing 1-Lipschitz
functions, it is trivial to verify that the entropy is in fact bounded by 2~Î±. Considering all
1-Lipschitz functions increases this to c0 ~Î± for some universal constant c0 .
entropy:
Next, consider the class F = {w, x   w2 â‰¤ 1} over the Euclidean ball. By Proposi-
tion 14, RT (F ) â‰¤ 1~âˆš
T . Using the lower bound of Proposition 9, fatÎ± â‰¤ 32~Î±2 whenever
2~âˆš
2~âˆš
âˆš
âˆš
T . This implies that Nâˆ (Î±, F , T ) â‰¤ (2eT ~Î±)32~Î±2
whenever Î± > 4
Î± > 4
that this bound does not depend on the ambient dimension of X .
Next, we show that a composition of G with any â€œsmallâ€ class F âŠ‚ [âˆ’1, 1]X also has
T . Note
a small cover. To this end, suppose Nâˆ (Î±, F , T ) is the covering number for F . Fix a
particular tree x and let V = {v1 , . . . , vN } be an (cid:96)âˆ cover of F on x at scale Î±. Analogously,
let W = {g1 , . . . , gM } be an (cid:96)âˆ cover of G with M = Ì‚Nâˆ (Î±, G ). Consider the class G â—‹ F =
{g â—‹ f âˆ¶ g âˆˆ G , f âˆˆ F }. The claim is that {g(v) âˆ¶ v âˆˆ V , g âˆˆ W } provides an (cid:96)âˆ cover for G â—‹F on
x. Fix any f âˆˆ F , g âˆˆ G and  âˆˆ {Â±1}T . Let v âˆˆ V be such that maxtâˆˆ[T ]  f (xt ()) âˆ’ vt ()  â‰¤ Î±,
and let g â€² âˆˆ W be such that g âˆ’ g â€² âˆ â‰¤ Î±. Then, using the fact that functions in G are
1-Lipschitz, for any t âˆˆ [T ],
 g(f (xt ())) âˆ’ g â€² (vt ())  â‰¤  g(f (xt ())) âˆ’ g â€² (f (xt ())  +  g â€² (f (xt ()) âˆ’ g â€² (vt ())  â‰¤ 2Î± .
Hence, Nâˆ (2Î±, G â—‹ F , T ) â‰¤ Ì‚Nâˆ (Î±, G ) Ã— Nâˆ (Î±, F , T ).
by 8T times the sequential Rademacher complexity of the class G â—‹ F = {u(w, x)   u âˆ¶
[âˆ’1, 1] â†’ [âˆ’1, 1] is 1-Lipschitz , w2 â‰¤ 1} since the squared loss is 4-Lipschitz on the space
Finally, we put all the pieces together. By Theorem 8, the minimax value is bounded

âˆš
T DT (G â—‹ F ) â‰¤ 32
T log N (Î´, G â—‹ F , T ) dÎ´
T + 12 S 1
of possible values. The latter complexity is then bounded by
8~âˆš

âˆš
âˆš
â‰¤ 32
log(2eT )dÎ´ .
Î´ + 128
T + 12
T S 1
T
8~âˆš
4c0
bounded by O(âˆš
Î´2
T log3~2 (T )).
T
We therefore conclude that the value of the game for the supervised learning problem is

Appendix C. Exponentially Weighted Average (EWA) Algorithm on
Countable Experts

We consider here a version of the exponentially weighted experts algorithm for a countable
(possibly inï¬nite) number of experts and provide a bound on the expected regret of the
randomized algorithm. The proof of the result closely follows the ï¬nite case (e.g., Cesa-
Bianchi and Lugosi, 2006, Theorem 2.2). This result is well known and we include it here
for completeness, as it is needed in the proofs of Proposition 16 and Proposition 17.
produces an element of F at round t. Here we also assume that F âŠ† [0, 1]X . Denote by
Suppose we are provided with countable experts E1 , E2 , . . ., where each expert can
herself be thought of as a randomized/deterministic player strategy which, given history,
each expert p1 , p2 , . . . such that âˆ‘i pi = 1.
f i
t the function output by expert i at round t given the history. The EWA algorithm we
consider needs access to the countable set of experts and also needs an initial weighting on

183

Rakhlin, Sridharan and Tewari

i â† pi
for t = 1 to T do
Algorithm 1 EWA (E1 , E2 , . . ., p1 , p2 , . . .)
Initialize each w1
Play ft = f t
Pick randomly an expert i with probability wt
i
= wt
i
Update for each i, wt+1
i eâˆ’Î·f t
i (xt )
Receive xt
âˆ‘i wt
âˆ’Î·f t
i (xt )
i
i e
end for
Proposition 20 The exponential ly weighted average forecaster (Algorithm 1) with Î· =
T âˆ’1~2 enjoys the regret bound
i (xt ) + âˆš
8 + âˆš
T log (1~pi )
E [ft (xt )] â‰¤ TQ
TQ
t=1
t=1
T
f t

for any i âˆˆ N.
References

J. Abernethy, P. L. Bartlett, A. Rakhlin, and A. Tewari. Optimal strategies and minimax
lower bounds for online convex games. In Proceedings of the 21st Annual Conference on
Learning Theory, pages 414â€“424. Omnipress, 2008.

J. Abernethy, A. Agarwal, P. L. Bartlett, and A. Rakhlin. A stochastic view of optimal regret
through minimax duality.
In Proceedings of the 22nd Annual Conference on Learning
Theory, 2009.

P. L. Bartlett and S. Mendelson. Rademacher and Gaussian complexities: risk bounds and
structural results. Journal of Machine Learning Research, 3:463â€“482, 2003.

S. Ben-David, D. Pal, and S. Shalev-Shwartz. Agnostic online learning. In Proceedings of
the 22th Annual Conference on Learning Theory, 2009.

D. Blackwell. An analog of the minimax theorem for vector payoï¬€s. Paciï¬c Journal of
Mathematics, 6(1):1â€“8, 1956a.

D. Blackwell. Controlled random walks. In Proceedings of the International Congress of
Mathematicians, 1954, volume 3, pages 336â€“338. North Holland, 1956b.

V.I. Bogachev. Measure Theory, volume 2. Springer, 2007. ISBN 3540345132.

J.M. Borwein. A very complicated proof of the minimax theorem. Minimax Theory and Its
Applications, 1(1), 2014.

J.M. Borwein and D Zhuang. On Fanâ€™s minimax theorem. Mathematical programming, 34
(2):232â€“234, 1986.

184

Online Learning via Sequential Complexities

N. Cesa-Bianchi and G. Lugosi. On prediction of individual sequences. Annals of Statistics,
pages 1865â€“1895, 1999.

N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University
Press, 2006.

N. Cesa-Bianchi, Y. Freund, D. Haussler, D. P. Helmbold, R. E. Schapire, and M. K.
Warmuth. How to use expert advice. Journal of the ACM, 44(3):427â€“485, 1997.

T. Cover. Behavior of sequential predictors of binary sequences. In Transactions of the
Fourth Prague Conference on Information Theory, Statistical Decision Functions, Ran-
dom Processes, 1965, pages 263â€“272. Publishing House of the Czechoslovak Academy of
Sciences, 1967.

T. M. Cover and A. Shenhar. Compound Bayes predictors for sequences with apparent
Markov structure. IEEE Transactions on Systems, Man and Cybernetics, 7(6):421â€“424,
1977.

L. Davisson. Universal noiseless coding. Information Theory, IEEE Transactions on, 19
(6):783â€“795, 1973.

M. Feder, N. Merhav, and M. Gutman. Universal prediction of individual sequences. In-
formation Theory, IEEE Transactions on, 38(4):1258â€“1270, 1992.

D. P. Foster and R. V. Vohra. Calibrated learning and correlated equilibrium. Games and
Economic Behavior, 21(1):40â€“55, 1997.

J. Hannan. Approximation to Bayes risk in repeated play. Contributions to the Theory of
Games, 3:97â€“139, 1957.

S. Hart and A. Mas-Colell. A simple adaptive procedure leading to correlated equilibrium.
Econometrica, 68(5):1127â€“1150, 2000.

S. M. Kakade and A. T. Kalai. From batch to transductive online learning. In Y. Weiss,
B. SchÂ¨olkopf, and J.C. Platt, editors, Advances in Neural Information Processing Systems
18, pages 611â€“618. MIT Press, 2006.

A. Kalai and S. Vempala. Eï¬ƒcient algorithms for online decision problems. Journal of
Computer and System Sciences, 71(3):291â€“307, 2005.

A. T. Kalai and R. Sastry. The isotron algorithm: High-dimensional isotonic regression. In
Proceedings of the 22th Annual Conference on Learning Theory, 2009.

A.N. Kolmogorov and V.M. Tikhomirov. Îµ-entropy and Îµ-capacity of sets in function spaces.
Uspekhi Matematicheskikh Nauk, 14(2):3â€“86, 1959.

V. Koltchinskii and D. Panchenko. Empirical margin distributions and bounding the gen-
eralization error of combined classiï¬ers. Annals of Statistics, 30(1):1â€“50, 2002.

M. Ledoux and M. Talagrand. Probability in Banach Spaces. Springer-Verlag, New York,
1991.

185

Rakhlin, Sridharan and Tewari

N. Littlestone. Learning quickly when irrelevant attributes abound: A new linear-threshold
algorithm. Machine Learning, 2(4):285â€“318, 04 1988.

N. Littlestone and M. K. Warmuth. The weighted ma jority algorithm. Information and
Computation, 108(2):212â€“261, 1994.

A. Rakhlin and K. Sridharan. Statistical learning and sequential prediction, 2014. Available
at http://stat.wharton.upenn.edu/~rakhlin/courses/stat928/stat928_notes.pdf.

A. Rakhlin, K. Sridharan, and A. Tewari. Online learning: Random averages, combinatorial
parameters, and learnability. In Advances in Neural Information Processing Systems 23,
pages 1984â€“1992, 2010.

A. Rakhlin, K. Sridharan, and A. Tewari. Online learning: Beyond regret. In Proceedings
of the 24th Annual Conference on Learning Theory, volume 19 of JMLR Workshop and
Conference Proceedings, pages 559â€“594, 2011.

A. Rakhlin, O. Shamir, and K. Sridharan. Relax and randomize: From value to algorithms.
In Advances in Neural Information Processing Systems 25, pages 2150â€“2158, 2012.

A. Rakhlin, K. Sridharan, and A. Tewari. Sequential complexities and uniform laws of large
numbers. Probability Theory and Related Fields, 2014.

J. Rissanen. Universal coding, information, prediction, and estimation. Information Theory,
IEEE Transactions on, 30(4):629â€“636, 1984.

H. Robbins. Asymptotically subminimax solutions of compound statistical decision prob-
lems. In Proceedings of the Second Berkeley Symposium on Mathematical Statistics and
Probability, pages 131â€“149. University of California Press, 1950.

R. E. Schapire, Y. Freund, P. Bartlett, and W.S. Lee. Boosting the margin: A new expla-
nation for the eï¬€ectiveness of voting methods. The Annals of Statistics, pages 322â€“330,
1997.

S. Shalev-Shwartz. Online learning and online convex optimization. Foundations and Trends
in Machine Learning, 4(2):107â€“194, 2011.

S. Shalev-Shwartz, O. Shamir, N. Srebro, and K. Sridharan. Stochastic convex optimization.
In Conference on Learning Theory, 2009.

A. W. van der Vaart and J. A. Wellner. Weak Convergence and Empirical Processes with
Applications to Statistics. Springer-Verlag, New York, 1996.

V. Vovk. A game of prediction with expert advice. Journal of Computer and System
Sciences, 56(2):153â€“173, 1998.

M. Zinkevich. Online convex programming and generalized inï¬nitesimal gradient ascent.
In Proceedings of the Twentieth International Conference on Machine Learning, pages
928â€“936, 2003.

J. Ziv and A. Lempel. A universal algorithm for sequential data compression. Information
Theory, IEEE Transactions on, 23(3):337â€“343, 1977.

186

